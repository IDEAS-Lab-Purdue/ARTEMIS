{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processing\n",
    "import string\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/csuser/DATA/ARTEMIS/romania\n"
     ]
    }
   ],
   "source": [
    "# read RData\n",
    "#res = pyreadr.read_r('5v_cleandf.RData')\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = res[\"df\"]\n",
    "df = pd.read_csv('/media/csuser/DATA/ARTEMIS/yale/yale_triage.csv')\n",
    "# df.dropna()\n",
    "# df.to_csv('yale_triage.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(560486, 973)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = df.dropna()\n",
    "# with all the 972 columns, if you run dropna directly, there actually ends up being 0 \n",
    "# remaining rows\n",
    "\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "489\n",
      "489\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>triage_vital_temp</th>\n",
       "      <th>triage_vital_rr</th>\n",
       "      <th>triage_vital_hr</th>\n",
       "      <th>triage_vital_sbp</th>\n",
       "      <th>triage_vital_dbp</th>\n",
       "      <th>triage_vital_o2</th>\n",
       "      <th>age</th>\n",
       "      <th>2ndarymalig</th>\n",
       "      <th>abdomhernia</th>\n",
       "      <th>abdomnlpain</th>\n",
       "      <th>...</th>\n",
       "      <th>cc_vaginalpain</th>\n",
       "      <th>cc_weakness</th>\n",
       "      <th>cc_wheezing</th>\n",
       "      <th>cc_withdrawal-alcohol</th>\n",
       "      <th>cc_woundcheck</th>\n",
       "      <th>cc_woundinfection</th>\n",
       "      <th>cc_woundre-evaluation</th>\n",
       "      <th>cc_wristinjury</th>\n",
       "      <th>cc_wristpain</th>\n",
       "      <th>esi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97.8</td>\n",
       "      <td>16.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98.4</td>\n",
       "      <td>18.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98.5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97.8</td>\n",
       "      <td>17.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 489 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   triage_vital_temp  triage_vital_rr  triage_vital_hr  triage_vital_sbp  \\\n",
       "0               97.0             18.0             63.0             146.0   \n",
       "1               97.8             16.0             78.0             134.0   \n",
       "2               98.4             18.0            101.0             133.0   \n",
       "3               98.5             18.0             76.0             143.0   \n",
       "4               97.8             17.0             88.0             155.0   \n",
       "\n",
       "   triage_vital_dbp  triage_vital_o2   age  2ndarymalig  abdomhernia  \\\n",
       "0              85.0             97.0  40.0          0.0          0.0   \n",
       "1              78.0             97.0  66.0          0.0          0.0   \n",
       "2              72.0             97.0  84.0          0.0          0.0   \n",
       "3              87.0             98.0  86.0          0.0          0.0   \n",
       "4              75.0             98.0  87.0          0.0          0.0   \n",
       "\n",
       "   abdomnlpain  ...  cc_vaginalpain  cc_weakness  cc_wheezing  \\\n",
       "0          0.0  ...             0.0          0.0          0.0   \n",
       "1          0.0  ...             0.0          0.0          0.0   \n",
       "2          0.0  ...             0.0          0.0          0.0   \n",
       "3          0.0  ...             0.0          0.0          0.0   \n",
       "4          0.0  ...             0.0          0.0          0.0   \n",
       "\n",
       "   cc_withdrawal-alcohol  cc_woundcheck  cc_woundinfection  \\\n",
       "0                    0.0            0.0                0.0   \n",
       "1                    0.0            0.0                0.0   \n",
       "2                    0.0            0.0                0.0   \n",
       "3                    0.0            0.0                0.0   \n",
       "4                    0.0            0.0                0.0   \n",
       "\n",
       "   cc_woundre-evaluation  cc_wristinjury  cc_wristpain  esi  \n",
       "0                    0.0             0.0           0.0  4.0  \n",
       "1                    0.0             0.0           0.0  2.0  \n",
       "2                    0.0             0.0           0.0  3.0  \n",
       "3                    0.0             0.0           0.0  3.0  \n",
       "4                    0.0             0.0           0.0  4.0  \n",
       "\n",
       "[5 rows x 489 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = df.keys()\n",
    "#new_keys = ['triage_vital_temp', 'triage_vital_rr', 'triage_vital_hr', 'triage_vital_sbp', 'triage_vital_dbp', 'triage_vital_o2', 'esi', 'age']\n",
    "new_keys = ['triage_vital_temp', 'triage_vital_rr', 'triage_vital_hr', 'triage_vital_sbp', 'triage_vital_dbp', 'triage_vital_o2', 'age']\n",
    "reach = False\n",
    "\n",
    "for i in range(len(keys)):\n",
    "    if(keys[i]!='2ndarymalig' and reach==False):\n",
    "        # print(keys[i])\n",
    "        continue\n",
    "    reach = True\n",
    "    if(keys[i]!='whtblooddx'):\n",
    "        new_keys.append(keys[i])\n",
    "    else:\n",
    "        new_keys.append(keys[i])\n",
    "        break\n",
    "\n",
    "reach = False\n",
    "for i in range(len(keys)):\n",
    "    if(keys[i]!='cc_abdominalcramping' and reach==False):\n",
    "        continue\n",
    "    reach = True\n",
    "    if(keys[i]!='cc_wristpain'):\n",
    "        new_keys.append(keys[i])\n",
    "    else:\n",
    "        new_keys.append(keys[i])\n",
    "        break\n",
    "\n",
    "new_keys.append('esi')\n",
    "print(len(list(set(new_keys))))\n",
    "print(len(new_keys))\n",
    "#df = df[['triage_vital_temp', 'triage_vital_rr', 'triage_vital_hr', 'triage_vital_sbp', 'triage_vital_dbp', 'triage_vital_o2', 'esi', 'age', 'gender', 'arrivalmode', 'previousdispo']]\n",
    "df = df[new_keys]\n",
    "df = df.dropna()\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df[\"triage_vital_temp\"] >= 51.8) & (df[\"triage_vital_temp\"] <= 108.14) & (df[\"triage_vital_hr\"] > 0) & (df[\"triage_vital_hr\"] < 140) & (df[\"triage_vital_o2\"] > 0) & (df[\"triage_vital_o2\"] < 100)]\n",
    "df = df.drop(df.loc[df['triage_vital_sbp'] > 400].index) # impossible\n",
    "df = df.drop(df.loc[df['triage_vital_dbp'] > 400].index) # impossible\n",
    "df = df.drop(df.loc[df['triage_vital_rr'] > 200].index) # impossible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csuser/mambaforge/envs/tim/lib/python3.8/site-packages/pandas/plotting/_matplotlib/core.py:1070: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored\n",
      "  scatter = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109106    2.0\n",
      "141020    1.0\n",
      "Name: esi, dtype: float64\n",
      "(268469, 489)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.plot.scatter(x=\"triage_vital_temp\", y=\"esi\")\n",
    "print(df.esi[df.loc[df[\"triage_vital_temp\"] == max(df.triage_vital_temp)].index])\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>triage_vital_temp</th>\n",
       "      <th>triage_vital_rr</th>\n",
       "      <th>triage_vital_hr</th>\n",
       "      <th>triage_vital_sbp</th>\n",
       "      <th>triage_vital_dbp</th>\n",
       "      <th>triage_vital_o2</th>\n",
       "      <th>age</th>\n",
       "      <th>2ndarymalig</th>\n",
       "      <th>abdomhernia</th>\n",
       "      <th>abdomnlpain</th>\n",
       "      <th>...</th>\n",
       "      <th>cc_vaginalpain</th>\n",
       "      <th>cc_weakness</th>\n",
       "      <th>cc_wheezing</th>\n",
       "      <th>cc_withdrawal-alcohol</th>\n",
       "      <th>cc_woundcheck</th>\n",
       "      <th>cc_woundinfection</th>\n",
       "      <th>cc_woundre-evaluation</th>\n",
       "      <th>cc_wristinjury</th>\n",
       "      <th>cc_wristpain</th>\n",
       "      <th>esi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97.8</td>\n",
       "      <td>16.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98.4</td>\n",
       "      <td>18.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98.5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97.8</td>\n",
       "      <td>17.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269544</th>\n",
       "      <td>98.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269545</th>\n",
       "      <td>98.1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269546</th>\n",
       "      <td>97.5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269547</th>\n",
       "      <td>97.5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269548</th>\n",
       "      <td>98.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>268469 rows Ã— 489 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        triage_vital_temp  triage_vital_rr  triage_vital_hr  triage_vital_sbp  \\\n",
       "0                    97.0             18.0             63.0             146.0   \n",
       "1                    97.8             16.0             78.0             134.0   \n",
       "2                    98.4             18.0            101.0             133.0   \n",
       "3                    98.5             18.0             76.0             143.0   \n",
       "4                    97.8             17.0             88.0             155.0   \n",
       "...                   ...              ...              ...               ...   \n",
       "269544               98.0             16.0             71.0             117.0   \n",
       "269545               98.1             16.0             89.0             114.0   \n",
       "269546               97.5             18.0             89.0             125.0   \n",
       "269547               97.5             18.0             89.0             135.0   \n",
       "269548               98.0             16.0             77.0             118.0   \n",
       "\n",
       "        triage_vital_dbp  triage_vital_o2   age  2ndarymalig  abdomhernia  \\\n",
       "0                   85.0             97.0  40.0          0.0          0.0   \n",
       "1                   78.0             97.0  66.0          0.0          0.0   \n",
       "2                   72.0             97.0  84.0          0.0          0.0   \n",
       "3                   87.0             98.0  86.0          0.0          0.0   \n",
       "4                   75.0             98.0  87.0          0.0          0.0   \n",
       "...                  ...              ...   ...          ...          ...   \n",
       "269544              74.0             95.0  49.0          0.0          0.0   \n",
       "269545              75.0             94.0  49.0          0.0          0.0   \n",
       "269546              82.0             94.0  50.0          0.0          0.0   \n",
       "269547              92.0             98.0  50.0          0.0          0.0   \n",
       "269548              73.0             94.0  50.0          0.0          0.0   \n",
       "\n",
       "        abdomnlpain  ...  cc_vaginalpain  cc_weakness  cc_wheezing  \\\n",
       "0               0.0  ...             0.0          0.0          0.0   \n",
       "1               0.0  ...             0.0          0.0          0.0   \n",
       "2               0.0  ...             0.0          0.0          0.0   \n",
       "3               0.0  ...             0.0          0.0          0.0   \n",
       "4               0.0  ...             0.0          0.0          0.0   \n",
       "...             ...  ...             ...          ...          ...   \n",
       "269544          0.0  ...             0.0          0.0          0.0   \n",
       "269545          0.0  ...             0.0          0.0          0.0   \n",
       "269546          0.0  ...             0.0          0.0          0.0   \n",
       "269547          0.0  ...             0.0          0.0          0.0   \n",
       "269548          0.0  ...             0.0          0.0          0.0   \n",
       "\n",
       "        cc_withdrawal-alcohol  cc_woundcheck  cc_woundinfection  \\\n",
       "0                         0.0            0.0                0.0   \n",
       "1                         0.0            0.0                0.0   \n",
       "2                         0.0            0.0                0.0   \n",
       "3                         0.0            0.0                0.0   \n",
       "4                         0.0            0.0                0.0   \n",
       "...                       ...            ...                ...   \n",
       "269544                    0.0            0.0                0.0   \n",
       "269545                    0.0            0.0                0.0   \n",
       "269546                    0.0            0.0                0.0   \n",
       "269547                    0.0            0.0                0.0   \n",
       "269548                    0.0            0.0                0.0   \n",
       "\n",
       "        cc_woundre-evaluation  cc_wristinjury  cc_wristpain  esi  \n",
       "0                         0.0             0.0           0.0  4.0  \n",
       "1                         0.0             0.0           0.0  2.0  \n",
       "2                         0.0             0.0           0.0  3.0  \n",
       "3                         0.0             0.0           0.0  3.0  \n",
       "4                         0.0             0.0           0.0  4.0  \n",
       "...                       ...             ...           ...  ...  \n",
       "269544                    0.0             0.0           0.0  3.0  \n",
       "269545                    0.0             0.0           0.0  3.0  \n",
       "269546                    0.0             0.0           0.0  3.0  \n",
       "269547                    0.0             0.0           0.0  3.0  \n",
       "269548                    0.0             0.0           0.0  3.0  \n",
       "\n",
       "[268469 rows x 489 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0    117852\n",
       "4.0     71472\n",
       "2.0     67048\n",
       "5.0     11835\n",
       "1.0       262\n",
       "Name: esi, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"esi\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-29 21:28:40.649188: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-29 21:28:40.676019: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-29 21:28:41.163955: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the data\n",
    "numerical_cols = ['triage_vital_temp', 'triage_vital_hr', 'triage_vital_o2', 'triage_vital_sbp', 'triage_vital_dbp', 'triage_vital_rr', 'age']\n",
    "for col in numerical_cols:\n",
    "   df[col] = (df[col] - df[col].min()) / (df[col].max() - df[col].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversample and plot imbalanced dataset with SMOTE\n",
    "# Oversample with SMOTE and random undersample for imbalanced dataset\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from matplotlib import pyplot\n",
    "from numpy import where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>triage_vital_temp</th>\n",
       "      <th>triage_vital_rr</th>\n",
       "      <th>triage_vital_hr</th>\n",
       "      <th>triage_vital_sbp</th>\n",
       "      <th>triage_vital_dbp</th>\n",
       "      <th>triage_vital_o2</th>\n",
       "      <th>age</th>\n",
       "      <th>2ndarymalig</th>\n",
       "      <th>abdomhernia</th>\n",
       "      <th>abdomnlpain</th>\n",
       "      <th>...</th>\n",
       "      <th>cc_vaginalpain</th>\n",
       "      <th>cc_weakness</th>\n",
       "      <th>cc_wheezing</th>\n",
       "      <th>cc_withdrawal-alcohol</th>\n",
       "      <th>cc_woundcheck</th>\n",
       "      <th>cc_woundinfection</th>\n",
       "      <th>cc_woundre-evaluation</th>\n",
       "      <th>cc_wristinjury</th>\n",
       "      <th>cc_wristpain</th>\n",
       "      <th>esi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.43750</td>\n",
       "      <td>0.163934</td>\n",
       "      <td>0.302752</td>\n",
       "      <td>0.363985</td>\n",
       "      <td>0.365854</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.247191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.48750</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>0.440367</td>\n",
       "      <td>0.318008</td>\n",
       "      <td>0.323171</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.539326</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.52500</td>\n",
       "      <td>0.163934</td>\n",
       "      <td>0.651376</td>\n",
       "      <td>0.314176</td>\n",
       "      <td>0.286585</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.741573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.53125</td>\n",
       "      <td>0.163934</td>\n",
       "      <td>0.422018</td>\n",
       "      <td>0.352490</td>\n",
       "      <td>0.378049</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.48750</td>\n",
       "      <td>0.147541</td>\n",
       "      <td>0.532110</td>\n",
       "      <td>0.398467</td>\n",
       "      <td>0.304878</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269544</th>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>0.376147</td>\n",
       "      <td>0.252874</td>\n",
       "      <td>0.298780</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.348315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269545</th>\n",
       "      <td>0.50625</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>0.541284</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.304878</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.348315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269546</th>\n",
       "      <td>0.46875</td>\n",
       "      <td>0.163934</td>\n",
       "      <td>0.541284</td>\n",
       "      <td>0.283525</td>\n",
       "      <td>0.347561</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.359551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269547</th>\n",
       "      <td>0.46875</td>\n",
       "      <td>0.163934</td>\n",
       "      <td>0.541284</td>\n",
       "      <td>0.321839</td>\n",
       "      <td>0.408537</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.359551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269548</th>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>0.431193</td>\n",
       "      <td>0.256705</td>\n",
       "      <td>0.292683</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.359551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>268469 rows Ã— 489 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        triage_vital_temp  triage_vital_rr  triage_vital_hr  triage_vital_sbp  \\\n",
       "0                 0.43750         0.163934         0.302752          0.363985   \n",
       "1                 0.48750         0.131148         0.440367          0.318008   \n",
       "2                 0.52500         0.163934         0.651376          0.314176   \n",
       "3                 0.53125         0.163934         0.422018          0.352490   \n",
       "4                 0.48750         0.147541         0.532110          0.398467   \n",
       "...                   ...              ...              ...               ...   \n",
       "269544            0.50000         0.131148         0.376147          0.252874   \n",
       "269545            0.50625         0.131148         0.541284          0.241379   \n",
       "269546            0.46875         0.163934         0.541284          0.283525   \n",
       "269547            0.46875         0.163934         0.541284          0.321839   \n",
       "269548            0.50000         0.131148         0.431193          0.256705   \n",
       "\n",
       "        triage_vital_dbp  triage_vital_o2       age  2ndarymalig  abdomhernia  \\\n",
       "0               0.365854         0.948718  0.247191          0.0          0.0   \n",
       "1               0.323171         0.948718  0.539326          0.0          0.0   \n",
       "2               0.286585         0.948718  0.741573          0.0          0.0   \n",
       "3               0.378049         0.974359  0.764045          0.0          0.0   \n",
       "4               0.304878         0.974359  0.775281          0.0          0.0   \n",
       "...                  ...              ...       ...          ...          ...   \n",
       "269544          0.298780         0.897436  0.348315          0.0          0.0   \n",
       "269545          0.304878         0.871795  0.348315          0.0          0.0   \n",
       "269546          0.347561         0.871795  0.359551          0.0          0.0   \n",
       "269547          0.408537         0.974359  0.359551          0.0          0.0   \n",
       "269548          0.292683         0.871795  0.359551          0.0          0.0   \n",
       "\n",
       "        abdomnlpain  ...  cc_vaginalpain  cc_weakness  cc_wheezing  \\\n",
       "0               0.0  ...             0.0          0.0          0.0   \n",
       "1               0.0  ...             0.0          0.0          0.0   \n",
       "2               0.0  ...             0.0          0.0          0.0   \n",
       "3               0.0  ...             0.0          0.0          0.0   \n",
       "4               0.0  ...             0.0          0.0          0.0   \n",
       "...             ...  ...             ...          ...          ...   \n",
       "269544          0.0  ...             0.0          0.0          0.0   \n",
       "269545          0.0  ...             0.0          0.0          0.0   \n",
       "269546          0.0  ...             0.0          0.0          0.0   \n",
       "269547          0.0  ...             0.0          0.0          0.0   \n",
       "269548          0.0  ...             0.0          0.0          0.0   \n",
       "\n",
       "        cc_withdrawal-alcohol  cc_woundcheck  cc_woundinfection  \\\n",
       "0                         0.0            0.0                0.0   \n",
       "1                         0.0            0.0                0.0   \n",
       "2                         0.0            0.0                0.0   \n",
       "3                         0.0            0.0                0.0   \n",
       "4                         0.0            0.0                0.0   \n",
       "...                       ...            ...                ...   \n",
       "269544                    0.0            0.0                0.0   \n",
       "269545                    0.0            0.0                0.0   \n",
       "269546                    0.0            0.0                0.0   \n",
       "269547                    0.0            0.0                0.0   \n",
       "269548                    0.0            0.0                0.0   \n",
       "\n",
       "        cc_woundre-evaluation  cc_wristinjury  cc_wristpain  esi  \n",
       "0                         0.0             0.0           0.0  4.0  \n",
       "1                         0.0             0.0           0.0  2.0  \n",
       "2                         0.0             0.0           0.0  3.0  \n",
       "3                         0.0             0.0           0.0  3.0  \n",
       "4                         0.0             0.0           0.0  4.0  \n",
       "...                       ...             ...           ...  ...  \n",
       "269544                    0.0             0.0           0.0  3.0  \n",
       "269545                    0.0             0.0           0.0  3.0  \n",
       "269546                    0.0             0.0           0.0  3.0  \n",
       "269547                    0.0             0.0           0.0  3.0  \n",
       "269548                    0.0             0.0           0.0  3.0  \n",
       "\n",
       "[268469 rows x 489 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({3.0: 117852, 4.0: 71472, 2.0: 67048, 5.0: 11835, 1.0: 262})\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['esi'], axis=1).to_numpy()\n",
    "y = df['esi'].to_numpy()\n",
    "counter = Counter(y)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>triage_vital_temp</th>\n",
       "      <th>triage_vital_rr</th>\n",
       "      <th>triage_vital_hr</th>\n",
       "      <th>triage_vital_sbp</th>\n",
       "      <th>triage_vital_dbp</th>\n",
       "      <th>triage_vital_o2</th>\n",
       "      <th>age</th>\n",
       "      <th>2ndarymalig</th>\n",
       "      <th>abdomhernia</th>\n",
       "      <th>abdomnlpain</th>\n",
       "      <th>...</th>\n",
       "      <th>cc_vaginalpain</th>\n",
       "      <th>cc_weakness</th>\n",
       "      <th>cc_wheezing</th>\n",
       "      <th>cc_withdrawal-alcohol</th>\n",
       "      <th>cc_woundcheck</th>\n",
       "      <th>cc_woundinfection</th>\n",
       "      <th>cc_woundre-evaluation</th>\n",
       "      <th>cc_wristinjury</th>\n",
       "      <th>cc_wristpain</th>\n",
       "      <th>esi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.43750</td>\n",
       "      <td>0.163934</td>\n",
       "      <td>0.302752</td>\n",
       "      <td>0.363985</td>\n",
       "      <td>0.365854</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.247191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.48750</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>0.440367</td>\n",
       "      <td>0.318008</td>\n",
       "      <td>0.323171</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.539326</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.52500</td>\n",
       "      <td>0.163934</td>\n",
       "      <td>0.651376</td>\n",
       "      <td>0.314176</td>\n",
       "      <td>0.286585</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.741573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.53125</td>\n",
       "      <td>0.163934</td>\n",
       "      <td>0.422018</td>\n",
       "      <td>0.352490</td>\n",
       "      <td>0.378049</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.48750</td>\n",
       "      <td>0.147541</td>\n",
       "      <td>0.532110</td>\n",
       "      <td>0.398467</td>\n",
       "      <td>0.304878</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269544</th>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>0.376147</td>\n",
       "      <td>0.252874</td>\n",
       "      <td>0.298780</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.348315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269545</th>\n",
       "      <td>0.50625</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>0.541284</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.304878</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.348315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269546</th>\n",
       "      <td>0.46875</td>\n",
       "      <td>0.163934</td>\n",
       "      <td>0.541284</td>\n",
       "      <td>0.283525</td>\n",
       "      <td>0.347561</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.359551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269547</th>\n",
       "      <td>0.46875</td>\n",
       "      <td>0.163934</td>\n",
       "      <td>0.541284</td>\n",
       "      <td>0.321839</td>\n",
       "      <td>0.408537</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.359551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269548</th>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>0.431193</td>\n",
       "      <td>0.256705</td>\n",
       "      <td>0.292683</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.359551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>268469 rows Ã— 489 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        triage_vital_temp  triage_vital_rr  triage_vital_hr  triage_vital_sbp  \\\n",
       "0                 0.43750         0.163934         0.302752          0.363985   \n",
       "1                 0.48750         0.131148         0.440367          0.318008   \n",
       "2                 0.52500         0.163934         0.651376          0.314176   \n",
       "3                 0.53125         0.163934         0.422018          0.352490   \n",
       "4                 0.48750         0.147541         0.532110          0.398467   \n",
       "...                   ...              ...              ...               ...   \n",
       "269544            0.50000         0.131148         0.376147          0.252874   \n",
       "269545            0.50625         0.131148         0.541284          0.241379   \n",
       "269546            0.46875         0.163934         0.541284          0.283525   \n",
       "269547            0.46875         0.163934         0.541284          0.321839   \n",
       "269548            0.50000         0.131148         0.431193          0.256705   \n",
       "\n",
       "        triage_vital_dbp  triage_vital_o2       age  2ndarymalig  abdomhernia  \\\n",
       "0               0.365854         0.948718  0.247191          0.0          0.0   \n",
       "1               0.323171         0.948718  0.539326          0.0          0.0   \n",
       "2               0.286585         0.948718  0.741573          0.0          0.0   \n",
       "3               0.378049         0.974359  0.764045          0.0          0.0   \n",
       "4               0.304878         0.974359  0.775281          0.0          0.0   \n",
       "...                  ...              ...       ...          ...          ...   \n",
       "269544          0.298780         0.897436  0.348315          0.0          0.0   \n",
       "269545          0.304878         0.871795  0.348315          0.0          0.0   \n",
       "269546          0.347561         0.871795  0.359551          0.0          0.0   \n",
       "269547          0.408537         0.974359  0.359551          0.0          0.0   \n",
       "269548          0.292683         0.871795  0.359551          0.0          0.0   \n",
       "\n",
       "        abdomnlpain  ...  cc_vaginalpain  cc_weakness  cc_wheezing  \\\n",
       "0               0.0  ...             0.0          0.0          0.0   \n",
       "1               0.0  ...             0.0          0.0          0.0   \n",
       "2               0.0  ...             0.0          0.0          0.0   \n",
       "3               0.0  ...             0.0          0.0          0.0   \n",
       "4               0.0  ...             0.0          0.0          0.0   \n",
       "...             ...  ...             ...          ...          ...   \n",
       "269544          0.0  ...             0.0          0.0          0.0   \n",
       "269545          0.0  ...             0.0          0.0          0.0   \n",
       "269546          0.0  ...             0.0          0.0          0.0   \n",
       "269547          0.0  ...             0.0          0.0          0.0   \n",
       "269548          0.0  ...             0.0          0.0          0.0   \n",
       "\n",
       "        cc_withdrawal-alcohol  cc_woundcheck  cc_woundinfection  \\\n",
       "0                         0.0            0.0                0.0   \n",
       "1                         0.0            0.0                0.0   \n",
       "2                         0.0            0.0                0.0   \n",
       "3                         0.0            0.0                0.0   \n",
       "4                         0.0            0.0                0.0   \n",
       "...                       ...            ...                ...   \n",
       "269544                    0.0            0.0                0.0   \n",
       "269545                    0.0            0.0                0.0   \n",
       "269546                    0.0            0.0                0.0   \n",
       "269547                    0.0            0.0                0.0   \n",
       "269548                    0.0            0.0                0.0   \n",
       "\n",
       "        cc_woundre-evaluation  cc_wristinjury  cc_wristpain  esi  \n",
       "0                         0.0             0.0           0.0  4.0  \n",
       "1                         0.0             0.0           0.0  2.0  \n",
       "2                         0.0             0.0           0.0  3.0  \n",
       "3                         0.0             0.0           0.0  3.0  \n",
       "4                         0.0             0.0           0.0  4.0  \n",
       "...                       ...             ...           ...  ...  \n",
       "269544                    0.0             0.0           0.0  3.0  \n",
       "269545                    0.0             0.0           0.0  3.0  \n",
       "269546                    0.0             0.0           0.0  3.0  \n",
       "269547                    0.0             0.0           0.0  3.0  \n",
       "269548                    0.0             0.0           0.0  3.0  \n",
       "\n",
       "[268469 rows x 489 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for label, _ in counter.items():\n",
    "    row_ix = where(y == label)[0]\n",
    "    plt.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "over = SMOTE(sampling_strategy={1: 117852, 2: 117852, 3: 117852, 4: 117852, 5: 117852})\n",
    "# under = RandomUnderSampler(sampling_strategy={1: 117852, 2: 117852, 3: 117852, 4: 117852, 5: 117852})\n",
    "steps = [('o', over),]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "X, y = pipeline.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({4.0: 117852, 2.0: 117852, 3.0: 117852, 5.0: 117852, 1.0: 117852})\n"
     ]
    }
   ],
   "source": [
    "counter = Counter(y)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for label, _ in counter.items():\n",
    "    row_ix = where(y == label)[0]\n",
    "    plt.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>triage_vital_temp</th>\n",
       "      <th>triage_vital_rr</th>\n",
       "      <th>triage_vital_hr</th>\n",
       "      <th>triage_vital_sbp</th>\n",
       "      <th>triage_vital_dbp</th>\n",
       "      <th>triage_vital_o2</th>\n",
       "      <th>age</th>\n",
       "      <th>2ndarymalig</th>\n",
       "      <th>abdomhernia</th>\n",
       "      <th>abdomnlpain</th>\n",
       "      <th>...</th>\n",
       "      <th>cc_vaginalpain</th>\n",
       "      <th>cc_weakness</th>\n",
       "      <th>cc_wheezing</th>\n",
       "      <th>cc_withdrawal-alcohol</th>\n",
       "      <th>cc_woundcheck</th>\n",
       "      <th>cc_woundinfection</th>\n",
       "      <th>cc_woundre-evaluation</th>\n",
       "      <th>cc_wristinjury</th>\n",
       "      <th>cc_wristpain</th>\n",
       "      <th>esi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.43750</td>\n",
       "      <td>0.163934</td>\n",
       "      <td>0.302752</td>\n",
       "      <td>0.363985</td>\n",
       "      <td>0.365854</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.247191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.48750</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>0.440367</td>\n",
       "      <td>0.318008</td>\n",
       "      <td>0.323171</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.539326</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.52500</td>\n",
       "      <td>0.163934</td>\n",
       "      <td>0.651376</td>\n",
       "      <td>0.314176</td>\n",
       "      <td>0.286585</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.741573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.53125</td>\n",
       "      <td>0.163934</td>\n",
       "      <td>0.422018</td>\n",
       "      <td>0.352490</td>\n",
       "      <td>0.378049</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.48750</td>\n",
       "      <td>0.147541</td>\n",
       "      <td>0.532110</td>\n",
       "      <td>0.398467</td>\n",
       "      <td>0.304878</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269544</th>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>0.376147</td>\n",
       "      <td>0.252874</td>\n",
       "      <td>0.298780</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.348315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269545</th>\n",
       "      <td>0.50625</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>0.541284</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.304878</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.348315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269546</th>\n",
       "      <td>0.46875</td>\n",
       "      <td>0.163934</td>\n",
       "      <td>0.541284</td>\n",
       "      <td>0.283525</td>\n",
       "      <td>0.347561</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.359551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269547</th>\n",
       "      <td>0.46875</td>\n",
       "      <td>0.163934</td>\n",
       "      <td>0.541284</td>\n",
       "      <td>0.321839</td>\n",
       "      <td>0.408537</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.359551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269548</th>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>0.431193</td>\n",
       "      <td>0.256705</td>\n",
       "      <td>0.292683</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.359551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>268469 rows Ã— 489 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        triage_vital_temp  triage_vital_rr  triage_vital_hr  triage_vital_sbp  \\\n",
       "0                 0.43750         0.163934         0.302752          0.363985   \n",
       "1                 0.48750         0.131148         0.440367          0.318008   \n",
       "2                 0.52500         0.163934         0.651376          0.314176   \n",
       "3                 0.53125         0.163934         0.422018          0.352490   \n",
       "4                 0.48750         0.147541         0.532110          0.398467   \n",
       "...                   ...              ...              ...               ...   \n",
       "269544            0.50000         0.131148         0.376147          0.252874   \n",
       "269545            0.50625         0.131148         0.541284          0.241379   \n",
       "269546            0.46875         0.163934         0.541284          0.283525   \n",
       "269547            0.46875         0.163934         0.541284          0.321839   \n",
       "269548            0.50000         0.131148         0.431193          0.256705   \n",
       "\n",
       "        triage_vital_dbp  triage_vital_o2       age  2ndarymalig  abdomhernia  \\\n",
       "0               0.365854         0.948718  0.247191          0.0          0.0   \n",
       "1               0.323171         0.948718  0.539326          0.0          0.0   \n",
       "2               0.286585         0.948718  0.741573          0.0          0.0   \n",
       "3               0.378049         0.974359  0.764045          0.0          0.0   \n",
       "4               0.304878         0.974359  0.775281          0.0          0.0   \n",
       "...                  ...              ...       ...          ...          ...   \n",
       "269544          0.298780         0.897436  0.348315          0.0          0.0   \n",
       "269545          0.304878         0.871795  0.348315          0.0          0.0   \n",
       "269546          0.347561         0.871795  0.359551          0.0          0.0   \n",
       "269547          0.408537         0.974359  0.359551          0.0          0.0   \n",
       "269548          0.292683         0.871795  0.359551          0.0          0.0   \n",
       "\n",
       "        abdomnlpain  ...  cc_vaginalpain  cc_weakness  cc_wheezing  \\\n",
       "0               0.0  ...             0.0          0.0          0.0   \n",
       "1               0.0  ...             0.0          0.0          0.0   \n",
       "2               0.0  ...             0.0          0.0          0.0   \n",
       "3               0.0  ...             0.0          0.0          0.0   \n",
       "4               0.0  ...             0.0          0.0          0.0   \n",
       "...             ...  ...             ...          ...          ...   \n",
       "269544          0.0  ...             0.0          0.0          0.0   \n",
       "269545          0.0  ...             0.0          0.0          0.0   \n",
       "269546          0.0  ...             0.0          0.0          0.0   \n",
       "269547          0.0  ...             0.0          0.0          0.0   \n",
       "269548          0.0  ...             0.0          0.0          0.0   \n",
       "\n",
       "        cc_withdrawal-alcohol  cc_woundcheck  cc_woundinfection  \\\n",
       "0                         0.0            0.0                0.0   \n",
       "1                         0.0            0.0                0.0   \n",
       "2                         0.0            0.0                0.0   \n",
       "3                         0.0            0.0                0.0   \n",
       "4                         0.0            0.0                0.0   \n",
       "...                       ...            ...                ...   \n",
       "269544                    0.0            0.0                0.0   \n",
       "269545                    0.0            0.0                0.0   \n",
       "269546                    0.0            0.0                0.0   \n",
       "269547                    0.0            0.0                0.0   \n",
       "269548                    0.0            0.0                0.0   \n",
       "\n",
       "        cc_woundre-evaluation  cc_wristinjury  cc_wristpain  esi  \n",
       "0                         0.0             0.0           0.0  4.0  \n",
       "1                         0.0             0.0           0.0  2.0  \n",
       "2                         0.0             0.0           0.0  3.0  \n",
       "3                         0.0             0.0           0.0  3.0  \n",
       "4                         0.0             0.0           0.0  4.0  \n",
       "...                       ...             ...           ...  ...  \n",
       "269544                    0.0             0.0           0.0  3.0  \n",
       "269545                    0.0             0.0           0.0  3.0  \n",
       "269546                    0.0             0.0           0.0  3.0  \n",
       "269547                    0.0             0.0           0.0  3.0  \n",
       "269548                    0.0             0.0           0.0  3.0  \n",
       "\n",
       "[268469 rows x 489 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Concatenate X and y numpy arrays\n",
    "Xy = np.concatenate((X, y.reshape(-1, 1)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/csuser/DATA/ARTEMIS/romania\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a pandas DataFrame from the concatenated array\n",
    "#new_keys.remove('esi')\n",
    "#new_keys.append('esi')\n",
    "df = pd.DataFrame(data=Xy, columns=new_keys)\n",
    "df.head()\n",
    "df.to_csv('/media/csuser/DATA/ARTEMIS/yale/yale_triage_smote.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up the first column since its unnamed and has indices\n",
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('/media/csuser/DATA/ARTEMIS/yale/yale_triage_smote.csv')\n",
    "\n",
    "# Remove the first column and all data under it\n",
    "df = df.iloc[:, 1:]\n",
    "\n",
    "# Write the modified DataFrame back to the CSV file\n",
    "df.to_csv('/media/csuser/DATA/ARTEMIS/yale/yale_triage_smote.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(589260, 489)\n",
      "[[0.4375     0.16393442 0.3027523  ... 0.         0.         0.        ]\n",
      " [0.4875     0.13114753 0.44036698 ... 0.         0.         0.        ]\n",
      " [0.525      0.16393442 0.6513761  ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.47515714 0.13135365 0.3853211  ... 0.         0.         0.        ]\n",
      " [0.48324358 0.18509515 0.59691554 ... 0.         0.         0.        ]\n",
      " [0.4848628  0.16591077 0.4381549  ... 0.         0.         0.        ]]\n",
      "(589260, 488)\n",
      "[array([1, 2, 3, 4, 5])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(589260, 5)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/media/csuser/DATA/ARTEMIS/yale/yale_triage_smote.csv')\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "print(df.shape)\n",
    "x = df.drop(['esi'], axis=1)\n",
    "y = df['esi']\n",
    "\n",
    "x = x.to_numpy().astype(np.float32)\n",
    "y = y.to_numpy().reshape(-1,1).astype(np.int_)\n",
    "\n",
    "print(np.asarray(x))\n",
    "\n",
    "# x = tf.constant(np.asarray(x), dtype=tf.float64)\n",
    "# y = tf.constant(np.asarray(y).reshape(-1, 1), dtype=tf.float64)\n",
    "\n",
    "print(x.shape)\n",
    "\n",
    "# convert to one hot vector\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(handle_unknown='ignore', sparse=False).fit(y)\n",
    "print(ohe.categories_)\n",
    "\n",
    "y = ohe.transform(y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>triage_vital_temp</th>\n",
       "      <th>triage_vital_rr</th>\n",
       "      <th>triage_vital_hr</th>\n",
       "      <th>triage_vital_sbp</th>\n",
       "      <th>triage_vital_dbp</th>\n",
       "      <th>triage_vital_o2</th>\n",
       "      <th>age</th>\n",
       "      <th>2ndarymalig</th>\n",
       "      <th>abdomhernia</th>\n",
       "      <th>abdomnlpain</th>\n",
       "      <th>...</th>\n",
       "      <th>cc_vaginalpain</th>\n",
       "      <th>cc_weakness</th>\n",
       "      <th>cc_wheezing</th>\n",
       "      <th>cc_withdrawal-alcohol</th>\n",
       "      <th>cc_woundcheck</th>\n",
       "      <th>cc_woundinfection</th>\n",
       "      <th>cc_woundre-evaluation</th>\n",
       "      <th>cc_wristinjury</th>\n",
       "      <th>cc_wristpain</th>\n",
       "      <th>esi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.43750</td>\n",
       "      <td>0.163934</td>\n",
       "      <td>0.302752</td>\n",
       "      <td>0.363985</td>\n",
       "      <td>0.365854</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.247191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.48750</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>0.440367</td>\n",
       "      <td>0.318008</td>\n",
       "      <td>0.323171</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.539326</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.52500</td>\n",
       "      <td>0.163934</td>\n",
       "      <td>0.651376</td>\n",
       "      <td>0.314176</td>\n",
       "      <td>0.286585</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.741573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.53125</td>\n",
       "      <td>0.163934</td>\n",
       "      <td>0.422018</td>\n",
       "      <td>0.352490</td>\n",
       "      <td>0.378049</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.48750</td>\n",
       "      <td>0.147541</td>\n",
       "      <td>0.532110</td>\n",
       "      <td>0.398467</td>\n",
       "      <td>0.304878</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 489 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   triage_vital_temp  triage_vital_rr  triage_vital_hr  triage_vital_sbp  \\\n",
       "0            0.43750         0.163934         0.302752          0.363985   \n",
       "1            0.48750         0.131148         0.440367          0.318008   \n",
       "2            0.52500         0.163934         0.651376          0.314176   \n",
       "3            0.53125         0.163934         0.422018          0.352490   \n",
       "4            0.48750         0.147541         0.532110          0.398467   \n",
       "\n",
       "   triage_vital_dbp  triage_vital_o2       age  2ndarymalig  abdomhernia  \\\n",
       "0          0.365854         0.948718  0.247191          0.0          0.0   \n",
       "1          0.323171         0.948718  0.539326          0.0          0.0   \n",
       "2          0.286585         0.948718  0.741573          0.0          0.0   \n",
       "3          0.378049         0.974359  0.764045          0.0          0.0   \n",
       "4          0.304878         0.974359  0.775281          0.0          0.0   \n",
       "\n",
       "   abdomnlpain  ...  cc_vaginalpain  cc_weakness  cc_wheezing  \\\n",
       "0          0.0  ...             0.0          0.0          0.0   \n",
       "1          0.0  ...             0.0          0.0          0.0   \n",
       "2          0.0  ...             0.0          0.0          0.0   \n",
       "3          0.0  ...             0.0          0.0          0.0   \n",
       "4          0.0  ...             0.0          0.0          0.0   \n",
       "\n",
       "   cc_withdrawal-alcohol  cc_woundcheck  cc_woundinfection  \\\n",
       "0                    0.0            0.0                0.0   \n",
       "1                    0.0            0.0                0.0   \n",
       "2                    0.0            0.0                0.0   \n",
       "3                    0.0            0.0                0.0   \n",
       "4                    0.0            0.0                0.0   \n",
       "\n",
       "   cc_woundre-evaluation  cc_wristinjury  cc_wristpain  esi  \n",
       "0                    0.0             0.0           0.0  4.0  \n",
       "1                    0.0             0.0           0.0  2.0  \n",
       "2                    0.0             0.0           0.0  3.0  \n",
       "3                    0.0             0.0           0.0  3.0  \n",
       "4                    0.0             0.0           0.0  4.0  \n",
       "\n",
       "[5 rows x 489 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # yale model\n",
    "def make_model(input_shape, num_classes):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    dense1 = layers.Dense(units=50, activation='ReLU', use_bias=True,)(inputs)\n",
    "    dense2 = layers.Dense(units=50, activation='ReLU', use_bias=True,)(dense1)\n",
    "    dense3 = layers.Dense(units=50, activation='ReLU', use_bias=True,)(dense2)\n",
    "    dense4 = layers.Dense(units=50, activation='ReLU', use_bias=True,)(dense3)\n",
    "    output = layers.Dense(units=num_classes, activation='softmax')(dense4)\n",
    "    return keras.Model(inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=1)\n",
    "X_train, X_val, y_train, y_val =  train_test_split(X_train, y_train, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 488)]             0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 50)                24450     \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 5)                 255       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,355\n",
      "Trainable params: 32,355\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = make_model(input_shape=(488), num_classes=y[0].shape[0])\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adamax(learning_rate=0.01, weight_decay=1e-6),\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "# make the save callback\n",
    "best_model_path = '/media/csuser/DATA/ARTEMIS/models/yale_smote'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=best_model_path,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "# load the saved model by:\n",
    "# model.load_weights(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "11786/11786 [==============================] - 9s 733us/step - loss: 0.0793 - accuracy: 0.7048 - val_loss: 0.0744 - val_accuracy: 0.7256\n",
      "Epoch 2/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0722 - accuracy: 0.7353 - val_loss: 0.0723 - val_accuracy: 0.7348\n",
      "Epoch 3/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0694 - accuracy: 0.7476 - val_loss: 0.0712 - val_accuracy: 0.7392\n",
      "Epoch 4/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0676 - accuracy: 0.7556 - val_loss: 0.0700 - val_accuracy: 0.7426\n",
      "Epoch 5/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0662 - accuracy: 0.7612 - val_loss: 0.0694 - val_accuracy: 0.7481\n",
      "Epoch 6/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0650 - accuracy: 0.7670 - val_loss: 0.0683 - val_accuracy: 0.7518\n",
      "Epoch 7/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0641 - accuracy: 0.7709 - val_loss: 0.0679 - val_accuracy: 0.7541\n",
      "Epoch 8/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0635 - accuracy: 0.7732 - val_loss: 0.0685 - val_accuracy: 0.7536\n",
      "Epoch 9/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0628 - accuracy: 0.7761 - val_loss: 0.0678 - val_accuracy: 0.7565\n",
      "Epoch 10/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0622 - accuracy: 0.7787 - val_loss: 0.0676 - val_accuracy: 0.7563\n",
      "Epoch 11/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0616 - accuracy: 0.7817 - val_loss: 0.0671 - val_accuracy: 0.7584\n",
      "Epoch 12/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0611 - accuracy: 0.7835 - val_loss: 0.0669 - val_accuracy: 0.7593\n",
      "Epoch 13/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0607 - accuracy: 0.7857 - val_loss: 0.0671 - val_accuracy: 0.7593\n",
      "Epoch 14/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0603 - accuracy: 0.7876 - val_loss: 0.0674 - val_accuracy: 0.7607\n",
      "Epoch 15/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0599 - accuracy: 0.7889 - val_loss: 0.0680 - val_accuracy: 0.7586\n",
      "Epoch 16/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0596 - accuracy: 0.7902 - val_loss: 0.0668 - val_accuracy: 0.7614\n",
      "Epoch 17/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0593 - accuracy: 0.7914 - val_loss: 0.0673 - val_accuracy: 0.7621\n",
      "Epoch 18/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0589 - accuracy: 0.7928 - val_loss: 0.0671 - val_accuracy: 0.7619\n",
      "Epoch 19/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0586 - accuracy: 0.7946 - val_loss: 0.0669 - val_accuracy: 0.7631\n",
      "Epoch 20/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0584 - accuracy: 0.7957 - val_loss: 0.0678 - val_accuracy: 0.7610\n",
      "Epoch 21/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0581 - accuracy: 0.7965 - val_loss: 0.0664 - val_accuracy: 0.7647\n",
      "Epoch 22/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0579 - accuracy: 0.7977 - val_loss: 0.0667 - val_accuracy: 0.7619\n",
      "Epoch 23/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0578 - accuracy: 0.7980 - val_loss: 0.0666 - val_accuracy: 0.7643\n",
      "Epoch 24/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0575 - accuracy: 0.7993 - val_loss: 0.0670 - val_accuracy: 0.7632\n",
      "Epoch 25/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0574 - accuracy: 0.8002 - val_loss: 0.0668 - val_accuracy: 0.7626\n",
      "Epoch 26/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0572 - accuracy: 0.8012 - val_loss: 0.0678 - val_accuracy: 0.7619\n",
      "Epoch 27/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0569 - accuracy: 0.8024 - val_loss: 0.0669 - val_accuracy: 0.7660\n",
      "Epoch 28/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0568 - accuracy: 0.8029 - val_loss: 0.0665 - val_accuracy: 0.7645\n",
      "Epoch 29/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0566 - accuracy: 0.8036 - val_loss: 0.0676 - val_accuracy: 0.7629\n",
      "Epoch 30/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0564 - accuracy: 0.8047 - val_loss: 0.0676 - val_accuracy: 0.7659\n",
      "Epoch 31/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0562 - accuracy: 0.8056 - val_loss: 0.0664 - val_accuracy: 0.7654\n",
      "Epoch 32/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0561 - accuracy: 0.8059 - val_loss: 0.0675 - val_accuracy: 0.7636\n",
      "Epoch 33/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0560 - accuracy: 0.8068 - val_loss: 0.0664 - val_accuracy: 0.7658\n",
      "Epoch 34/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0559 - accuracy: 0.8065 - val_loss: 0.0672 - val_accuracy: 0.7620\n",
      "Epoch 35/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0558 - accuracy: 0.8072 - val_loss: 0.0672 - val_accuracy: 0.7645\n",
      "Epoch 36/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0556 - accuracy: 0.8083 - val_loss: 0.0665 - val_accuracy: 0.7658\n",
      "Epoch 37/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0554 - accuracy: 0.8092 - val_loss: 0.0676 - val_accuracy: 0.7649\n",
      "Epoch 38/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0553 - accuracy: 0.8092 - val_loss: 0.0672 - val_accuracy: 0.7649\n",
      "Epoch 39/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0553 - accuracy: 0.8093 - val_loss: 0.0674 - val_accuracy: 0.7653\n",
      "Epoch 40/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0551 - accuracy: 0.8101 - val_loss: 0.0679 - val_accuracy: 0.7636\n",
      "Epoch 41/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0550 - accuracy: 0.8105 - val_loss: 0.0669 - val_accuracy: 0.7648\n",
      "Epoch 42/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0549 - accuracy: 0.8109 - val_loss: 0.0665 - val_accuracy: 0.7637\n",
      "Epoch 43/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0548 - accuracy: 0.8112 - val_loss: 0.0676 - val_accuracy: 0.7645\n",
      "Epoch 44/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0546 - accuracy: 0.8126 - val_loss: 0.0665 - val_accuracy: 0.7662\n",
      "Epoch 45/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0545 - accuracy: 0.8127 - val_loss: 0.0676 - val_accuracy: 0.7617\n",
      "Epoch 46/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0545 - accuracy: 0.8127 - val_loss: 0.0668 - val_accuracy: 0.7665\n",
      "Epoch 47/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0543 - accuracy: 0.8136 - val_loss: 0.0666 - val_accuracy: 0.7663\n",
      "Epoch 48/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0542 - accuracy: 0.8137 - val_loss: 0.0668 - val_accuracy: 0.7658\n",
      "Epoch 49/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0541 - accuracy: 0.8145 - val_loss: 0.0670 - val_accuracy: 0.7665\n",
      "Epoch 50/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0540 - accuracy: 0.8151 - val_loss: 0.0680 - val_accuracy: 0.7629\n",
      "Epoch 51/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0539 - accuracy: 0.8152 - val_loss: 0.0663 - val_accuracy: 0.7677\n",
      "Epoch 52/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0539 - accuracy: 0.8155 - val_loss: 0.0678 - val_accuracy: 0.7654\n",
      "Epoch 53/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0538 - accuracy: 0.8157 - val_loss: 0.0679 - val_accuracy: 0.7639\n",
      "Epoch 54/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0538 - accuracy: 0.8163 - val_loss: 0.0677 - val_accuracy: 0.7659\n",
      "Epoch 55/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0536 - accuracy: 0.8170 - val_loss: 0.0672 - val_accuracy: 0.7647\n",
      "Epoch 56/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0535 - accuracy: 0.8174 - val_loss: 0.0674 - val_accuracy: 0.7651\n",
      "Epoch 57/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0535 - accuracy: 0.8172 - val_loss: 0.0675 - val_accuracy: 0.7656\n",
      "Epoch 58/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0534 - accuracy: 0.8175 - val_loss: 0.0672 - val_accuracy: 0.7646\n",
      "Epoch 59/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0533 - accuracy: 0.8182 - val_loss: 0.0680 - val_accuracy: 0.7660\n",
      "Epoch 60/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0531 - accuracy: 0.8189 - val_loss: 0.0675 - val_accuracy: 0.7662\n",
      "Epoch 61/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0531 - accuracy: 0.8193 - val_loss: 0.0675 - val_accuracy: 0.7644\n",
      "Epoch 62/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0530 - accuracy: 0.8197 - val_loss: 0.0675 - val_accuracy: 0.7657\n",
      "Epoch 63/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0530 - accuracy: 0.8197 - val_loss: 0.0680 - val_accuracy: 0.7663\n",
      "Epoch 64/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0529 - accuracy: 0.8197 - val_loss: 0.0675 - val_accuracy: 0.7668\n",
      "Epoch 65/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0529 - accuracy: 0.8200 - val_loss: 0.0673 - val_accuracy: 0.7663\n",
      "Epoch 66/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0528 - accuracy: 0.8203 - val_loss: 0.0676 - val_accuracy: 0.7654\n",
      "Epoch 67/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0527 - accuracy: 0.8206 - val_loss: 0.0684 - val_accuracy: 0.7663\n",
      "Epoch 68/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0526 - accuracy: 0.8209 - val_loss: 0.0680 - val_accuracy: 0.7659\n",
      "Epoch 69/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0525 - accuracy: 0.8218 - val_loss: 0.0678 - val_accuracy: 0.7661\n",
      "Epoch 70/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0526 - accuracy: 0.8211 - val_loss: 0.0686 - val_accuracy: 0.7669\n",
      "Epoch 71/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0525 - accuracy: 0.8216 - val_loss: 0.0673 - val_accuracy: 0.7655\n",
      "Epoch 72/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0524 - accuracy: 0.8223 - val_loss: 0.0685 - val_accuracy: 0.7646\n",
      "Epoch 73/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0523 - accuracy: 0.8220 - val_loss: 0.0678 - val_accuracy: 0.7665\n",
      "Epoch 74/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0523 - accuracy: 0.8221 - val_loss: 0.0680 - val_accuracy: 0.7650\n",
      "Epoch 75/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0523 - accuracy: 0.8225 - val_loss: 0.0682 - val_accuracy: 0.7659\n",
      "Epoch 76/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0522 - accuracy: 0.8232 - val_loss: 0.0670 - val_accuracy: 0.7677\n",
      "Epoch 77/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0522 - accuracy: 0.8231 - val_loss: 0.0685 - val_accuracy: 0.7665\n",
      "Epoch 78/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0521 - accuracy: 0.8235 - val_loss: 0.0676 - val_accuracy: 0.7632\n",
      "Epoch 79/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0521 - accuracy: 0.8233 - val_loss: 0.0679 - val_accuracy: 0.7661\n",
      "Epoch 80/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0519 - accuracy: 0.8241 - val_loss: 0.0685 - val_accuracy: 0.7653\n",
      "Epoch 81/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0519 - accuracy: 0.8241 - val_loss: 0.0682 - val_accuracy: 0.7665\n",
      "Epoch 82/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0518 - accuracy: 0.8248 - val_loss: 0.0679 - val_accuracy: 0.7657\n",
      "Epoch 83/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0518 - accuracy: 0.8243 - val_loss: 0.0671 - val_accuracy: 0.7665\n",
      "Epoch 84/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0518 - accuracy: 0.8249 - val_loss: 0.0680 - val_accuracy: 0.7677\n",
      "Epoch 85/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0518 - accuracy: 0.8246 - val_loss: 0.0676 - val_accuracy: 0.7657\n",
      "Epoch 86/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0517 - accuracy: 0.8254 - val_loss: 0.0680 - val_accuracy: 0.7681\n",
      "Epoch 87/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0516 - accuracy: 0.8253 - val_loss: 0.0676 - val_accuracy: 0.7679\n",
      "Epoch 88/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0516 - accuracy: 0.8257 - val_loss: 0.0678 - val_accuracy: 0.7661\n",
      "Epoch 89/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0515 - accuracy: 0.8261 - val_loss: 0.0679 - val_accuracy: 0.7651\n",
      "Epoch 90/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0515 - accuracy: 0.8259 - val_loss: 0.0685 - val_accuracy: 0.7664\n",
      "Epoch 91/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0515 - accuracy: 0.8263 - val_loss: 0.0680 - val_accuracy: 0.7657\n",
      "Epoch 92/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0514 - accuracy: 0.8263 - val_loss: 0.0681 - val_accuracy: 0.7676\n",
      "Epoch 93/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0514 - accuracy: 0.8265 - val_loss: 0.0691 - val_accuracy: 0.7667\n",
      "Epoch 94/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0514 - accuracy: 0.8266 - val_loss: 0.0691 - val_accuracy: 0.7652\n",
      "Epoch 95/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0514 - accuracy: 0.8269 - val_loss: 0.0684 - val_accuracy: 0.7670\n",
      "Epoch 96/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0513 - accuracy: 0.8268 - val_loss: 0.0680 - val_accuracy: 0.7677\n",
      "Epoch 97/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0512 - accuracy: 0.8272 - val_loss: 0.0683 - val_accuracy: 0.7674\n",
      "Epoch 98/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0512 - accuracy: 0.8273 - val_loss: 0.0677 - val_accuracy: 0.7671\n",
      "Epoch 99/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0512 - accuracy: 0.8276 - val_loss: 0.0678 - val_accuracy: 0.7677\n",
      "Epoch 100/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0511 - accuracy: 0.8275 - val_loss: 0.0686 - val_accuracy: 0.7678\n",
      "Epoch 101/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0511 - accuracy: 0.8281 - val_loss: 0.0685 - val_accuracy: 0.7673\n",
      "Epoch 102/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0510 - accuracy: 0.8281 - val_loss: 0.0684 - val_accuracy: 0.7660\n",
      "Epoch 103/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0510 - accuracy: 0.8282 - val_loss: 0.0685 - val_accuracy: 0.7669\n",
      "Epoch 104/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0510 - accuracy: 0.8281 - val_loss: 0.0677 - val_accuracy: 0.7660\n",
      "Epoch 105/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0510 - accuracy: 0.8287 - val_loss: 0.0675 - val_accuracy: 0.7689\n",
      "Epoch 106/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0510 - accuracy: 0.8287 - val_loss: 0.0689 - val_accuracy: 0.7656\n",
      "Epoch 107/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0509 - accuracy: 0.8289 - val_loss: 0.0685 - val_accuracy: 0.7676\n",
      "Epoch 108/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0508 - accuracy: 0.8293 - val_loss: 0.0688 - val_accuracy: 0.7665\n",
      "Epoch 109/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0509 - accuracy: 0.8290 - val_loss: 0.0690 - val_accuracy: 0.7666\n",
      "Epoch 110/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0508 - accuracy: 0.8290 - val_loss: 0.0677 - val_accuracy: 0.7667\n",
      "Epoch 111/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0508 - accuracy: 0.8295 - val_loss: 0.0688 - val_accuracy: 0.7673\n",
      "Epoch 112/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0507 - accuracy: 0.8299 - val_loss: 0.0679 - val_accuracy: 0.7671\n",
      "Epoch 113/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0507 - accuracy: 0.8294 - val_loss: 0.0684 - val_accuracy: 0.7681\n",
      "Epoch 114/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0507 - accuracy: 0.8298 - val_loss: 0.0681 - val_accuracy: 0.7668\n",
      "Epoch 115/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0506 - accuracy: 0.8304 - val_loss: 0.0686 - val_accuracy: 0.7676\n",
      "Epoch 116/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0506 - accuracy: 0.8299 - val_loss: 0.0688 - val_accuracy: 0.7658\n",
      "Epoch 117/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0506 - accuracy: 0.8303 - val_loss: 0.0689 - val_accuracy: 0.7682\n",
      "Epoch 118/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0505 - accuracy: 0.8306 - val_loss: 0.0686 - val_accuracy: 0.7669\n",
      "Epoch 119/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0506 - accuracy: 0.8305 - val_loss: 0.0688 - val_accuracy: 0.7670\n",
      "Epoch 120/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0506 - accuracy: 0.8305 - val_loss: 0.0686 - val_accuracy: 0.7675\n",
      "Epoch 121/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0504 - accuracy: 0.8310 - val_loss: 0.0682 - val_accuracy: 0.7671\n",
      "Epoch 122/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0504 - accuracy: 0.8313 - val_loss: 0.0692 - val_accuracy: 0.7673\n",
      "Epoch 123/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0505 - accuracy: 0.8309 - val_loss: 0.0692 - val_accuracy: 0.7663\n",
      "Epoch 124/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0504 - accuracy: 0.8311 - val_loss: 0.0694 - val_accuracy: 0.7671\n",
      "Epoch 125/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0503 - accuracy: 0.8313 - val_loss: 0.0689 - val_accuracy: 0.7677\n",
      "Epoch 126/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0502 - accuracy: 0.8316 - val_loss: 0.0686 - val_accuracy: 0.7678\n",
      "Epoch 127/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0503 - accuracy: 0.8319 - val_loss: 0.0684 - val_accuracy: 0.7677\n",
      "Epoch 128/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0503 - accuracy: 0.8316 - val_loss: 0.0680 - val_accuracy: 0.7672\n",
      "Epoch 129/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0502 - accuracy: 0.8320 - val_loss: 0.0681 - val_accuracy: 0.7685\n",
      "Epoch 130/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0502 - accuracy: 0.8320 - val_loss: 0.0684 - val_accuracy: 0.7664\n",
      "Epoch 131/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0502 - accuracy: 0.8317 - val_loss: 0.0680 - val_accuracy: 0.7679\n",
      "Epoch 132/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0500 - accuracy: 0.8323 - val_loss: 0.0687 - val_accuracy: 0.7686\n",
      "Epoch 133/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0501 - accuracy: 0.8328 - val_loss: 0.0689 - val_accuracy: 0.7663\n",
      "Epoch 134/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0500 - accuracy: 0.8328 - val_loss: 0.0681 - val_accuracy: 0.7699\n",
      "Epoch 135/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0501 - accuracy: 0.8323 - val_loss: 0.0688 - val_accuracy: 0.7663\n",
      "Epoch 136/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0501 - accuracy: 0.8325 - val_loss: 0.0684 - val_accuracy: 0.7678\n",
      "Epoch 137/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0500 - accuracy: 0.8330 - val_loss: 0.0685 - val_accuracy: 0.7676\n",
      "Epoch 138/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0500 - accuracy: 0.8327 - val_loss: 0.0690 - val_accuracy: 0.7686\n",
      "Epoch 139/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0500 - accuracy: 0.8326 - val_loss: 0.0684 - val_accuracy: 0.7667\n",
      "Epoch 140/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0499 - accuracy: 0.8330 - val_loss: 0.0689 - val_accuracy: 0.7678\n",
      "Epoch 141/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0500 - accuracy: 0.8331 - val_loss: 0.0695 - val_accuracy: 0.7654\n",
      "Epoch 142/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0498 - accuracy: 0.8331 - val_loss: 0.0698 - val_accuracy: 0.7659\n",
      "Epoch 143/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0500 - accuracy: 0.8331 - val_loss: 0.0689 - val_accuracy: 0.7664\n",
      "Epoch 144/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0499 - accuracy: 0.8333 - val_loss: 0.0694 - val_accuracy: 0.7660\n",
      "Epoch 145/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0498 - accuracy: 0.8339 - val_loss: 0.0691 - val_accuracy: 0.7677\n",
      "Epoch 146/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0498 - accuracy: 0.8339 - val_loss: 0.0698 - val_accuracy: 0.7666\n",
      "Epoch 147/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0498 - accuracy: 0.8335 - val_loss: 0.0686 - val_accuracy: 0.7680\n",
      "Epoch 148/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0499 - accuracy: 0.8334 - val_loss: 0.0689 - val_accuracy: 0.7674\n",
      "Epoch 149/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0498 - accuracy: 0.8339 - val_loss: 0.0690 - val_accuracy: 0.7674\n",
      "Epoch 150/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0498 - accuracy: 0.8336 - val_loss: 0.0685 - val_accuracy: 0.7688\n",
      "Epoch 151/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0497 - accuracy: 0.8338 - val_loss: 0.0687 - val_accuracy: 0.7671\n",
      "Epoch 152/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0498 - accuracy: 0.8345 - val_loss: 0.0699 - val_accuracy: 0.7671\n",
      "Epoch 153/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0497 - accuracy: 0.8340 - val_loss: 0.0705 - val_accuracy: 0.7664\n",
      "Epoch 154/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0497 - accuracy: 0.8343 - val_loss: 0.0689 - val_accuracy: 0.7676\n",
      "Epoch 155/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0497 - accuracy: 0.8346 - val_loss: 0.0696 - val_accuracy: 0.7678\n",
      "Epoch 156/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0496 - accuracy: 0.8349 - val_loss: 0.0688 - val_accuracy: 0.7668\n",
      "Epoch 157/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0496 - accuracy: 0.8349 - val_loss: 0.0700 - val_accuracy: 0.7669\n",
      "Epoch 158/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0496 - accuracy: 0.8350 - val_loss: 0.0697 - val_accuracy: 0.7662\n",
      "Epoch 159/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0496 - accuracy: 0.8347 - val_loss: 0.0695 - val_accuracy: 0.7661\n",
      "Epoch 160/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0496 - accuracy: 0.8348 - val_loss: 0.0685 - val_accuracy: 0.7685\n",
      "Epoch 161/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0495 - accuracy: 0.8347 - val_loss: 0.0696 - val_accuracy: 0.7683\n",
      "Epoch 162/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0495 - accuracy: 0.8348 - val_loss: 0.0702 - val_accuracy: 0.7684\n",
      "Epoch 163/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0495 - accuracy: 0.8350 - val_loss: 0.0683 - val_accuracy: 0.7686\n",
      "Epoch 164/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0494 - accuracy: 0.8350 - val_loss: 0.0690 - val_accuracy: 0.7675\n",
      "Epoch 165/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0495 - accuracy: 0.8346 - val_loss: 0.0687 - val_accuracy: 0.7669\n",
      "Epoch 166/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0494 - accuracy: 0.8355 - val_loss: 0.0694 - val_accuracy: 0.7669\n",
      "Epoch 167/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0494 - accuracy: 0.8351 - val_loss: 0.0691 - val_accuracy: 0.7682\n",
      "Epoch 168/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0494 - accuracy: 0.8358 - val_loss: 0.0695 - val_accuracy: 0.7663\n",
      "Epoch 169/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0495 - accuracy: 0.8352 - val_loss: 0.0694 - val_accuracy: 0.7680\n",
      "Epoch 170/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0494 - accuracy: 0.8351 - val_loss: 0.0690 - val_accuracy: 0.7675\n",
      "Epoch 171/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0494 - accuracy: 0.8358 - val_loss: 0.0700 - val_accuracy: 0.7666\n",
      "Epoch 172/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0493 - accuracy: 0.8359 - val_loss: 0.0706 - val_accuracy: 0.7638\n",
      "Epoch 173/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0493 - accuracy: 0.8360 - val_loss: 0.0690 - val_accuracy: 0.7668\n",
      "Epoch 174/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0493 - accuracy: 0.8361 - val_loss: 0.0694 - val_accuracy: 0.7679\n",
      "Epoch 175/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0493 - accuracy: 0.8358 - val_loss: 0.0693 - val_accuracy: 0.7683\n",
      "Epoch 176/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0493 - accuracy: 0.8364 - val_loss: 0.0696 - val_accuracy: 0.7683\n",
      "Epoch 177/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0493 - accuracy: 0.8362 - val_loss: 0.0688 - val_accuracy: 0.7686\n",
      "Epoch 178/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0492 - accuracy: 0.8362 - val_loss: 0.0696 - val_accuracy: 0.7677\n",
      "Epoch 179/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0492 - accuracy: 0.8368 - val_loss: 0.0693 - val_accuracy: 0.7648\n",
      "Epoch 180/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0492 - accuracy: 0.8361 - val_loss: 0.0694 - val_accuracy: 0.7682\n",
      "Epoch 181/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0491 - accuracy: 0.8369 - val_loss: 0.0688 - val_accuracy: 0.7673\n",
      "Epoch 182/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0491 - accuracy: 0.8366 - val_loss: 0.0695 - val_accuracy: 0.7662\n",
      "Epoch 183/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0492 - accuracy: 0.8368 - val_loss: 0.0704 - val_accuracy: 0.7647\n",
      "Epoch 184/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0491 - accuracy: 0.8367 - val_loss: 0.0693 - val_accuracy: 0.7667\n",
      "Epoch 185/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0491 - accuracy: 0.8371 - val_loss: 0.0700 - val_accuracy: 0.7690\n",
      "Epoch 186/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0490 - accuracy: 0.8375 - val_loss: 0.0696 - val_accuracy: 0.7662\n",
      "Epoch 187/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0491 - accuracy: 0.8371 - val_loss: 0.0692 - val_accuracy: 0.7672\n",
      "Epoch 188/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0492 - accuracy: 0.8370 - val_loss: 0.0695 - val_accuracy: 0.7666\n",
      "Epoch 189/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0491 - accuracy: 0.8373 - val_loss: 0.0686 - val_accuracy: 0.7677\n",
      "Epoch 190/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0491 - accuracy: 0.8368 - val_loss: 0.0695 - val_accuracy: 0.7677\n",
      "Epoch 191/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0490 - accuracy: 0.8378 - val_loss: 0.0698 - val_accuracy: 0.7676\n",
      "Epoch 192/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0490 - accuracy: 0.8376 - val_loss: 0.0692 - val_accuracy: 0.7677\n",
      "Epoch 193/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0490 - accuracy: 0.8374 - val_loss: 0.0696 - val_accuracy: 0.7683\n",
      "Epoch 194/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0489 - accuracy: 0.8379 - val_loss: 0.0705 - val_accuracy: 0.7666\n",
      "Epoch 195/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0490 - accuracy: 0.8378 - val_loss: 0.0688 - val_accuracy: 0.7668\n",
      "Epoch 196/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0489 - accuracy: 0.8378 - val_loss: 0.0696 - val_accuracy: 0.7664\n",
      "Epoch 197/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0490 - accuracy: 0.8376 - val_loss: 0.0699 - val_accuracy: 0.7677\n",
      "Epoch 198/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0489 - accuracy: 0.8377 - val_loss: 0.0697 - val_accuracy: 0.7679\n",
      "Epoch 199/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0489 - accuracy: 0.8381 - val_loss: 0.0696 - val_accuracy: 0.7664\n",
      "Epoch 200/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0489 - accuracy: 0.8381 - val_loss: 0.0688 - val_accuracy: 0.7672\n",
      "Epoch 201/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0489 - accuracy: 0.8378 - val_loss: 0.0700 - val_accuracy: 0.7662\n",
      "Epoch 202/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0489 - accuracy: 0.8377 - val_loss: 0.0700 - val_accuracy: 0.7658\n",
      "Epoch 203/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0488 - accuracy: 0.8386 - val_loss: 0.0697 - val_accuracy: 0.7672\n",
      "Epoch 204/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0488 - accuracy: 0.8385 - val_loss: 0.0702 - val_accuracy: 0.7663\n",
      "Epoch 205/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0488 - accuracy: 0.8382 - val_loss: 0.0698 - val_accuracy: 0.7662\n",
      "Epoch 206/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0489 - accuracy: 0.8382 - val_loss: 0.0705 - val_accuracy: 0.7666\n",
      "Epoch 207/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0488 - accuracy: 0.8384 - val_loss: 0.0699 - val_accuracy: 0.7673\n",
      "Epoch 208/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0489 - accuracy: 0.8379 - val_loss: 0.0702 - val_accuracy: 0.7658\n",
      "Epoch 209/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0488 - accuracy: 0.8383 - val_loss: 0.0704 - val_accuracy: 0.7651\n",
      "Epoch 210/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0488 - accuracy: 0.8382 - val_loss: 0.0696 - val_accuracy: 0.7673\n",
      "Epoch 211/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0487 - accuracy: 0.8387 - val_loss: 0.0704 - val_accuracy: 0.7652\n",
      "Epoch 212/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0487 - accuracy: 0.8384 - val_loss: 0.0692 - val_accuracy: 0.7672\n",
      "Epoch 213/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0487 - accuracy: 0.8386 - val_loss: 0.0693 - val_accuracy: 0.7668\n",
      "Epoch 214/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0487 - accuracy: 0.8388 - val_loss: 0.0700 - val_accuracy: 0.7669\n",
      "Epoch 215/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0487 - accuracy: 0.8391 - val_loss: 0.0701 - val_accuracy: 0.7669\n",
      "Epoch 216/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0486 - accuracy: 0.8391 - val_loss: 0.0693 - val_accuracy: 0.7668\n",
      "Epoch 217/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0487 - accuracy: 0.8389 - val_loss: 0.0699 - val_accuracy: 0.7688\n",
      "Epoch 218/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0486 - accuracy: 0.8391 - val_loss: 0.0694 - val_accuracy: 0.7669\n",
      "Epoch 219/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0486 - accuracy: 0.8392 - val_loss: 0.0704 - val_accuracy: 0.7664\n",
      "Epoch 220/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0486 - accuracy: 0.8388 - val_loss: 0.0699 - val_accuracy: 0.7661\n",
      "Epoch 221/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0485 - accuracy: 0.8395 - val_loss: 0.0700 - val_accuracy: 0.7669\n",
      "Epoch 222/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0486 - accuracy: 0.8392 - val_loss: 0.0697 - val_accuracy: 0.7679\n",
      "Epoch 223/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0486 - accuracy: 0.8394 - val_loss: 0.0703 - val_accuracy: 0.7681\n",
      "Epoch 224/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0486 - accuracy: 0.8391 - val_loss: 0.0698 - val_accuracy: 0.7671\n",
      "Epoch 225/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0486 - accuracy: 0.8393 - val_loss: 0.0701 - val_accuracy: 0.7662\n",
      "Epoch 226/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0486 - accuracy: 0.8393 - val_loss: 0.0695 - val_accuracy: 0.7663\n",
      "Epoch 227/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0486 - accuracy: 0.8394 - val_loss: 0.0699 - val_accuracy: 0.7663\n",
      "Epoch 228/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0486 - accuracy: 0.8392 - val_loss: 0.0703 - val_accuracy: 0.7675\n",
      "Epoch 229/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0485 - accuracy: 0.8398 - val_loss: 0.0708 - val_accuracy: 0.7655\n",
      "Epoch 230/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0486 - accuracy: 0.8394 - val_loss: 0.0694 - val_accuracy: 0.7643\n",
      "Epoch 231/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0485 - accuracy: 0.8394 - val_loss: 0.0708 - val_accuracy: 0.7657\n",
      "Epoch 232/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0485 - accuracy: 0.8399 - val_loss: 0.0712 - val_accuracy: 0.7649\n",
      "Epoch 233/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0485 - accuracy: 0.8393 - val_loss: 0.0695 - val_accuracy: 0.7678\n",
      "Epoch 234/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0486 - accuracy: 0.8395 - val_loss: 0.0704 - val_accuracy: 0.7670\n",
      "Epoch 235/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0485 - accuracy: 0.8400 - val_loss: 0.0697 - val_accuracy: 0.7677\n",
      "Epoch 236/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0484 - accuracy: 0.8400 - val_loss: 0.0701 - val_accuracy: 0.7664\n",
      "Epoch 237/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0485 - accuracy: 0.8398 - val_loss: 0.0703 - val_accuracy: 0.7648\n",
      "Epoch 238/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0485 - accuracy: 0.8401 - val_loss: 0.0700 - val_accuracy: 0.7671\n",
      "Epoch 239/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0485 - accuracy: 0.8399 - val_loss: 0.0703 - val_accuracy: 0.7674\n",
      "Epoch 240/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0484 - accuracy: 0.8401 - val_loss: 0.0700 - val_accuracy: 0.7669\n",
      "Epoch 241/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0484 - accuracy: 0.8403 - val_loss: 0.0700 - val_accuracy: 0.7670\n",
      "Epoch 242/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0485 - accuracy: 0.8401 - val_loss: 0.0691 - val_accuracy: 0.7673\n",
      "Epoch 243/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0484 - accuracy: 0.8404 - val_loss: 0.0699 - val_accuracy: 0.7663\n",
      "Epoch 244/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0484 - accuracy: 0.8404 - val_loss: 0.0695 - val_accuracy: 0.7676\n",
      "Epoch 245/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0484 - accuracy: 0.8405 - val_loss: 0.0700 - val_accuracy: 0.7676\n",
      "Epoch 246/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0483 - accuracy: 0.8404 - val_loss: 0.0705 - val_accuracy: 0.7679\n",
      "Epoch 247/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0484 - accuracy: 0.8402 - val_loss: 0.0705 - val_accuracy: 0.7659\n",
      "Epoch 248/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0484 - accuracy: 0.8403 - val_loss: 0.0703 - val_accuracy: 0.7674\n",
      "Epoch 249/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0485 - accuracy: 0.8396 - val_loss: 0.0697 - val_accuracy: 0.7674\n",
      "Epoch 250/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0483 - accuracy: 0.8407 - val_loss: 0.0709 - val_accuracy: 0.7656\n",
      "Epoch 251/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0484 - accuracy: 0.8407 - val_loss: 0.0703 - val_accuracy: 0.7664\n",
      "Epoch 252/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0483 - accuracy: 0.8409 - val_loss: 0.0701 - val_accuracy: 0.7664\n",
      "Epoch 253/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0483 - accuracy: 0.8404 - val_loss: 0.0709 - val_accuracy: 0.7650\n",
      "Epoch 254/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0483 - accuracy: 0.8409 - val_loss: 0.0719 - val_accuracy: 0.7643\n",
      "Epoch 255/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0483 - accuracy: 0.8406 - val_loss: 0.0699 - val_accuracy: 0.7664\n",
      "Epoch 256/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0482 - accuracy: 0.8410 - val_loss: 0.0695 - val_accuracy: 0.7685\n",
      "Epoch 257/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0482 - accuracy: 0.8408 - val_loss: 0.0703 - val_accuracy: 0.7655\n",
      "Epoch 258/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0482 - accuracy: 0.8414 - val_loss: 0.0705 - val_accuracy: 0.7666\n",
      "Epoch 259/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0482 - accuracy: 0.8412 - val_loss: 0.0701 - val_accuracy: 0.7668\n",
      "Epoch 260/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0483 - accuracy: 0.8404 - val_loss: 0.0697 - val_accuracy: 0.7678\n",
      "Epoch 261/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0482 - accuracy: 0.8411 - val_loss: 0.0703 - val_accuracy: 0.7667\n",
      "Epoch 262/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0482 - accuracy: 0.8408 - val_loss: 0.0702 - val_accuracy: 0.7663\n",
      "Epoch 263/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0482 - accuracy: 0.8413 - val_loss: 0.0711 - val_accuracy: 0.7666\n",
      "Epoch 264/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0482 - accuracy: 0.8411 - val_loss: 0.0701 - val_accuracy: 0.7663\n",
      "Epoch 265/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0482 - accuracy: 0.8409 - val_loss: 0.0703 - val_accuracy: 0.7663\n",
      "Epoch 266/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0482 - accuracy: 0.8408 - val_loss: 0.0715 - val_accuracy: 0.7643\n",
      "Epoch 267/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0482 - accuracy: 0.8407 - val_loss: 0.0716 - val_accuracy: 0.7647\n",
      "Epoch 268/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0482 - accuracy: 0.8411 - val_loss: 0.0703 - val_accuracy: 0.7659\n",
      "Epoch 269/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0481 - accuracy: 0.8414 - val_loss: 0.0707 - val_accuracy: 0.7663\n",
      "Epoch 270/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0481 - accuracy: 0.8413 - val_loss: 0.0705 - val_accuracy: 0.7682\n",
      "Epoch 271/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0481 - accuracy: 0.8420 - val_loss: 0.0701 - val_accuracy: 0.7684\n",
      "Epoch 272/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0482 - accuracy: 0.8412 - val_loss: 0.0710 - val_accuracy: 0.7679\n",
      "Epoch 273/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0481 - accuracy: 0.8416 - val_loss: 0.0707 - val_accuracy: 0.7673\n",
      "Epoch 274/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0480 - accuracy: 0.8420 - val_loss: 0.0702 - val_accuracy: 0.7662\n",
      "Epoch 275/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0481 - accuracy: 0.8417 - val_loss: 0.0707 - val_accuracy: 0.7657\n",
      "Epoch 276/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0481 - accuracy: 0.8416 - val_loss: 0.0707 - val_accuracy: 0.7668\n",
      "Epoch 277/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0481 - accuracy: 0.8417 - val_loss: 0.0707 - val_accuracy: 0.7674\n",
      "Epoch 278/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0480 - accuracy: 0.8419 - val_loss: 0.0706 - val_accuracy: 0.7676\n",
      "Epoch 279/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0481 - accuracy: 0.8420 - val_loss: 0.0712 - val_accuracy: 0.7653\n",
      "Epoch 280/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0481 - accuracy: 0.8414 - val_loss: 0.0713 - val_accuracy: 0.7669\n",
      "Epoch 281/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0480 - accuracy: 0.8418 - val_loss: 0.0705 - val_accuracy: 0.7671\n",
      "Epoch 282/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0480 - accuracy: 0.8420 - val_loss: 0.0705 - val_accuracy: 0.7672\n",
      "Epoch 283/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0481 - accuracy: 0.8418 - val_loss: 0.0706 - val_accuracy: 0.7673\n",
      "Epoch 284/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0481 - accuracy: 0.8420 - val_loss: 0.0703 - val_accuracy: 0.7658\n",
      "Epoch 285/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0481 - accuracy: 0.8415 - val_loss: 0.0703 - val_accuracy: 0.7663\n",
      "Epoch 286/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0480 - accuracy: 0.8419 - val_loss: 0.0701 - val_accuracy: 0.7665\n",
      "Epoch 287/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0481 - accuracy: 0.8414 - val_loss: 0.0695 - val_accuracy: 0.7670\n",
      "Epoch 288/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0480 - accuracy: 0.8420 - val_loss: 0.0709 - val_accuracy: 0.7660\n",
      "Epoch 289/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0480 - accuracy: 0.8421 - val_loss: 0.0701 - val_accuracy: 0.7681\n",
      "Epoch 290/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0480 - accuracy: 0.8420 - val_loss: 0.0703 - val_accuracy: 0.7674\n",
      "Epoch 291/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0479 - accuracy: 0.8424 - val_loss: 0.0704 - val_accuracy: 0.7668\n",
      "Epoch 292/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0480 - accuracy: 0.8423 - val_loss: 0.0710 - val_accuracy: 0.7670\n",
      "Epoch 293/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0481 - accuracy: 0.8421 - val_loss: 0.0714 - val_accuracy: 0.7648\n",
      "Epoch 294/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0480 - accuracy: 0.8420 - val_loss: 0.0709 - val_accuracy: 0.7649\n",
      "Epoch 295/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0480 - accuracy: 0.8421 - val_loss: 0.0706 - val_accuracy: 0.7654\n",
      "Epoch 296/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0480 - accuracy: 0.8422 - val_loss: 0.0707 - val_accuracy: 0.7670\n",
      "Epoch 297/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0480 - accuracy: 0.8420 - val_loss: 0.0702 - val_accuracy: 0.7655\n",
      "Epoch 298/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0480 - accuracy: 0.8421 - val_loss: 0.0704 - val_accuracy: 0.7654\n",
      "Epoch 299/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0479 - accuracy: 0.8422 - val_loss: 0.0718 - val_accuracy: 0.7658\n",
      "Epoch 300/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0479 - accuracy: 0.8421 - val_loss: 0.0709 - val_accuracy: 0.7676\n",
      "Epoch 301/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0479 - accuracy: 0.8426 - val_loss: 0.0705 - val_accuracy: 0.7686\n",
      "Epoch 302/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0479 - accuracy: 0.8429 - val_loss: 0.0709 - val_accuracy: 0.7637\n",
      "Epoch 303/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0478 - accuracy: 0.8430 - val_loss: 0.0710 - val_accuracy: 0.7651\n",
      "Epoch 304/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0479 - accuracy: 0.8426 - val_loss: 0.0711 - val_accuracy: 0.7662\n",
      "Epoch 305/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0479 - accuracy: 0.8426 - val_loss: 0.0709 - val_accuracy: 0.7676\n",
      "Epoch 306/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0480 - accuracy: 0.8422 - val_loss: 0.0711 - val_accuracy: 0.7656\n",
      "Epoch 307/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0480 - accuracy: 0.8424 - val_loss: 0.0709 - val_accuracy: 0.7661\n",
      "Epoch 308/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0480 - accuracy: 0.8422 - val_loss: 0.0703 - val_accuracy: 0.7680\n",
      "Epoch 309/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0479 - accuracy: 0.8424 - val_loss: 0.0701 - val_accuracy: 0.7679\n",
      "Epoch 310/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0479 - accuracy: 0.8428 - val_loss: 0.0704 - val_accuracy: 0.7656\n",
      "Epoch 311/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0478 - accuracy: 0.8428 - val_loss: 0.0705 - val_accuracy: 0.7664\n",
      "Epoch 312/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0478 - accuracy: 0.8431 - val_loss: 0.0706 - val_accuracy: 0.7670\n",
      "Epoch 313/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0479 - accuracy: 0.8428 - val_loss: 0.0706 - val_accuracy: 0.7654\n",
      "Epoch 314/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0479 - accuracy: 0.8423 - val_loss: 0.0708 - val_accuracy: 0.7663\n",
      "Epoch 315/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0478 - accuracy: 0.8430 - val_loss: 0.0714 - val_accuracy: 0.7661\n",
      "Epoch 316/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0478 - accuracy: 0.8424 - val_loss: 0.0700 - val_accuracy: 0.7666\n",
      "Epoch 317/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0479 - accuracy: 0.8429 - val_loss: 0.0706 - val_accuracy: 0.7678\n",
      "Epoch 318/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0478 - accuracy: 0.8424 - val_loss: 0.0701 - val_accuracy: 0.7678\n",
      "Epoch 319/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0478 - accuracy: 0.8430 - val_loss: 0.0715 - val_accuracy: 0.7664\n",
      "Epoch 320/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0479 - accuracy: 0.8426 - val_loss: 0.0711 - val_accuracy: 0.7666\n",
      "Epoch 321/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0478 - accuracy: 0.8430 - val_loss: 0.0714 - val_accuracy: 0.7679\n",
      "Epoch 322/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0478 - accuracy: 0.8432 - val_loss: 0.0707 - val_accuracy: 0.7665\n",
      "Epoch 323/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0478 - accuracy: 0.8429 - val_loss: 0.0708 - val_accuracy: 0.7679\n",
      "Epoch 324/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0477 - accuracy: 0.8433 - val_loss: 0.0701 - val_accuracy: 0.7674\n",
      "Epoch 325/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0478 - accuracy: 0.8432 - val_loss: 0.0712 - val_accuracy: 0.7656\n",
      "Epoch 326/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0478 - accuracy: 0.8430 - val_loss: 0.0706 - val_accuracy: 0.7667\n",
      "Epoch 327/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0477 - accuracy: 0.8433 - val_loss: 0.0712 - val_accuracy: 0.7670\n",
      "Epoch 328/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0477 - accuracy: 0.8433 - val_loss: 0.0710 - val_accuracy: 0.7661\n",
      "Epoch 329/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0478 - accuracy: 0.8430 - val_loss: 0.0707 - val_accuracy: 0.7670\n",
      "Epoch 330/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0477 - accuracy: 0.8435 - val_loss: 0.0711 - val_accuracy: 0.7664\n",
      "Epoch 331/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0477 - accuracy: 0.8431 - val_loss: 0.0720 - val_accuracy: 0.7643\n",
      "Epoch 332/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0478 - accuracy: 0.8431 - val_loss: 0.0709 - val_accuracy: 0.7667\n",
      "Epoch 333/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0476 - accuracy: 0.8435 - val_loss: 0.0709 - val_accuracy: 0.7649\n",
      "Epoch 334/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0477 - accuracy: 0.8436 - val_loss: 0.0705 - val_accuracy: 0.7668\n",
      "Epoch 335/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0476 - accuracy: 0.8435 - val_loss: 0.0714 - val_accuracy: 0.7640\n",
      "Epoch 336/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0476 - accuracy: 0.8438 - val_loss: 0.0702 - val_accuracy: 0.7673\n",
      "Epoch 337/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0477 - accuracy: 0.8437 - val_loss: 0.0708 - val_accuracy: 0.7669\n",
      "Epoch 338/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0477 - accuracy: 0.8437 - val_loss: 0.0710 - val_accuracy: 0.7668\n",
      "Epoch 339/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0477 - accuracy: 0.8436 - val_loss: 0.0712 - val_accuracy: 0.7671\n",
      "Epoch 340/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0477 - accuracy: 0.8436 - val_loss: 0.0702 - val_accuracy: 0.7661\n",
      "Epoch 341/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0477 - accuracy: 0.8436 - val_loss: 0.0712 - val_accuracy: 0.7662\n",
      "Epoch 342/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0477 - accuracy: 0.8435 - val_loss: 0.0712 - val_accuracy: 0.7659\n",
      "Epoch 343/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0477 - accuracy: 0.8434 - val_loss: 0.0706 - val_accuracy: 0.7658\n",
      "Epoch 344/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0476 - accuracy: 0.8440 - val_loss: 0.0709 - val_accuracy: 0.7669\n",
      "Epoch 345/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0476 - accuracy: 0.8439 - val_loss: 0.0707 - val_accuracy: 0.7664\n",
      "Epoch 346/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0476 - accuracy: 0.8437 - val_loss: 0.0712 - val_accuracy: 0.7652\n",
      "Epoch 347/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0476 - accuracy: 0.8437 - val_loss: 0.0708 - val_accuracy: 0.7669\n",
      "Epoch 348/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0476 - accuracy: 0.8440 - val_loss: 0.0704 - val_accuracy: 0.7648\n",
      "Epoch 349/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0476 - accuracy: 0.8439 - val_loss: 0.0709 - val_accuracy: 0.7675\n",
      "Epoch 350/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0475 - accuracy: 0.8444 - val_loss: 0.0715 - val_accuracy: 0.7659\n",
      "Epoch 351/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0476 - accuracy: 0.8443 - val_loss: 0.0713 - val_accuracy: 0.7656\n",
      "Epoch 352/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0476 - accuracy: 0.8441 - val_loss: 0.0715 - val_accuracy: 0.7671\n",
      "Epoch 353/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0476 - accuracy: 0.8440 - val_loss: 0.0715 - val_accuracy: 0.7642\n",
      "Epoch 354/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0475 - accuracy: 0.8440 - val_loss: 0.0716 - val_accuracy: 0.7662\n",
      "Epoch 355/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0477 - accuracy: 0.8438 - val_loss: 0.0713 - val_accuracy: 0.7669\n",
      "Epoch 356/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0476 - accuracy: 0.8440 - val_loss: 0.0707 - val_accuracy: 0.7664\n",
      "Epoch 357/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0475 - accuracy: 0.8444 - val_loss: 0.0715 - val_accuracy: 0.7667\n",
      "Epoch 358/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0476 - accuracy: 0.8439 - val_loss: 0.0704 - val_accuracy: 0.7660\n",
      "Epoch 359/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0477 - accuracy: 0.8434 - val_loss: 0.0706 - val_accuracy: 0.7659\n",
      "Epoch 360/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0476 - accuracy: 0.8437 - val_loss: 0.0706 - val_accuracy: 0.7670\n",
      "Epoch 361/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0475 - accuracy: 0.8446 - val_loss: 0.0715 - val_accuracy: 0.7673\n",
      "Epoch 362/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0476 - accuracy: 0.8447 - val_loss: 0.0709 - val_accuracy: 0.7666\n",
      "Epoch 363/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0476 - accuracy: 0.8441 - val_loss: 0.0706 - val_accuracy: 0.7654\n",
      "Epoch 364/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0474 - accuracy: 0.8450 - val_loss: 0.0708 - val_accuracy: 0.7668\n",
      "Epoch 365/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0474 - accuracy: 0.8450 - val_loss: 0.0711 - val_accuracy: 0.7656\n",
      "Epoch 366/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0475 - accuracy: 0.8445 - val_loss: 0.0711 - val_accuracy: 0.7656\n",
      "Epoch 367/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0475 - accuracy: 0.8446 - val_loss: 0.0715 - val_accuracy: 0.7650\n",
      "Epoch 368/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0475 - accuracy: 0.8448 - val_loss: 0.0717 - val_accuracy: 0.7661\n",
      "Epoch 369/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0475 - accuracy: 0.8448 - val_loss: 0.0710 - val_accuracy: 0.7669\n",
      "Epoch 370/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0476 - accuracy: 0.8442 - val_loss: 0.0707 - val_accuracy: 0.7670\n",
      "Epoch 371/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0475 - accuracy: 0.8444 - val_loss: 0.0712 - val_accuracy: 0.7674\n",
      "Epoch 372/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0475 - accuracy: 0.8447 - val_loss: 0.0714 - val_accuracy: 0.7673\n",
      "Epoch 373/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0474 - accuracy: 0.8449 - val_loss: 0.0712 - val_accuracy: 0.7663\n",
      "Epoch 374/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0475 - accuracy: 0.8449 - val_loss: 0.0716 - val_accuracy: 0.7671\n",
      "Epoch 375/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0475 - accuracy: 0.8450 - val_loss: 0.0713 - val_accuracy: 0.7639\n",
      "Epoch 376/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0475 - accuracy: 0.8442 - val_loss: 0.0711 - val_accuracy: 0.7675\n",
      "Epoch 377/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0475 - accuracy: 0.8444 - val_loss: 0.0715 - val_accuracy: 0.7665\n",
      "Epoch 378/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0476 - accuracy: 0.8444 - val_loss: 0.0709 - val_accuracy: 0.7668\n",
      "Epoch 379/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0474 - accuracy: 0.8447 - val_loss: 0.0711 - val_accuracy: 0.7664\n",
      "Epoch 380/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0475 - accuracy: 0.8441 - val_loss: 0.0716 - val_accuracy: 0.7656\n",
      "Epoch 381/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0474 - accuracy: 0.8448 - val_loss: 0.0718 - val_accuracy: 0.7643\n",
      "Epoch 382/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0474 - accuracy: 0.8447 - val_loss: 0.0716 - val_accuracy: 0.7660\n",
      "Epoch 383/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0474 - accuracy: 0.8445 - val_loss: 0.0716 - val_accuracy: 0.7667\n",
      "Epoch 384/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0474 - accuracy: 0.8448 - val_loss: 0.0710 - val_accuracy: 0.7650\n",
      "Epoch 385/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0475 - accuracy: 0.8448 - val_loss: 0.0716 - val_accuracy: 0.7651\n",
      "Epoch 386/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0474 - accuracy: 0.8450 - val_loss: 0.0712 - val_accuracy: 0.7660\n",
      "Epoch 387/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0474 - accuracy: 0.8449 - val_loss: 0.0711 - val_accuracy: 0.7656\n",
      "Epoch 388/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0475 - accuracy: 0.8446 - val_loss: 0.0709 - val_accuracy: 0.7659\n",
      "Epoch 389/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0475 - accuracy: 0.8448 - val_loss: 0.0714 - val_accuracy: 0.7657\n",
      "Epoch 390/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0474 - accuracy: 0.8453 - val_loss: 0.0707 - val_accuracy: 0.7657\n",
      "Epoch 391/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0475 - accuracy: 0.8453 - val_loss: 0.0709 - val_accuracy: 0.7659\n",
      "Epoch 392/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0474 - accuracy: 0.8447 - val_loss: 0.0715 - val_accuracy: 0.7658\n",
      "Epoch 393/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0475 - accuracy: 0.8450 - val_loss: 0.0711 - val_accuracy: 0.7670\n",
      "Epoch 394/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0474 - accuracy: 0.8453 - val_loss: 0.0710 - val_accuracy: 0.7659\n",
      "Epoch 395/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0474 - accuracy: 0.8455 - val_loss: 0.0722 - val_accuracy: 0.7664\n",
      "Epoch 396/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0474 - accuracy: 0.8449 - val_loss: 0.0723 - val_accuracy: 0.7658\n",
      "Epoch 397/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0473 - accuracy: 0.8457 - val_loss: 0.0719 - val_accuracy: 0.7647\n",
      "Epoch 398/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0474 - accuracy: 0.8451 - val_loss: 0.0713 - val_accuracy: 0.7653\n",
      "Epoch 399/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0474 - accuracy: 0.8450 - val_loss: 0.0726 - val_accuracy: 0.7668\n",
      "Epoch 400/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0474 - accuracy: 0.8449 - val_loss: 0.0714 - val_accuracy: 0.7654\n",
      "Epoch 401/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0474 - accuracy: 0.8452 - val_loss: 0.0715 - val_accuracy: 0.7663\n",
      "Epoch 402/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0473 - accuracy: 0.8451 - val_loss: 0.0709 - val_accuracy: 0.7667\n",
      "Epoch 403/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0473 - accuracy: 0.8455 - val_loss: 0.0713 - val_accuracy: 0.7668\n",
      "Epoch 404/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0473 - accuracy: 0.8454 - val_loss: 0.0710 - val_accuracy: 0.7659\n",
      "Epoch 405/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0473 - accuracy: 0.8452 - val_loss: 0.0714 - val_accuracy: 0.7671\n",
      "Epoch 406/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0473 - accuracy: 0.8453 - val_loss: 0.0712 - val_accuracy: 0.7642\n",
      "Epoch 407/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0473 - accuracy: 0.8454 - val_loss: 0.0713 - val_accuracy: 0.7654\n",
      "Epoch 408/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0473 - accuracy: 0.8455 - val_loss: 0.0701 - val_accuracy: 0.7675\n",
      "Epoch 409/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0473 - accuracy: 0.8458 - val_loss: 0.0712 - val_accuracy: 0.7663\n",
      "Epoch 410/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0473 - accuracy: 0.8459 - val_loss: 0.0720 - val_accuracy: 0.7641\n",
      "Epoch 411/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0473 - accuracy: 0.8452 - val_loss: 0.0722 - val_accuracy: 0.7668\n",
      "Epoch 412/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0473 - accuracy: 0.8451 - val_loss: 0.0723 - val_accuracy: 0.7649\n",
      "Epoch 413/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0473 - accuracy: 0.8453 - val_loss: 0.0712 - val_accuracy: 0.7660\n",
      "Epoch 414/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0474 - accuracy: 0.8450 - val_loss: 0.0715 - val_accuracy: 0.7643\n",
      "Epoch 415/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0473 - accuracy: 0.8456 - val_loss: 0.0709 - val_accuracy: 0.7653\n",
      "Epoch 416/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0473 - accuracy: 0.8455 - val_loss: 0.0731 - val_accuracy: 0.7655\n",
      "Epoch 417/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0473 - accuracy: 0.8453 - val_loss: 0.0713 - val_accuracy: 0.7654\n",
      "Epoch 418/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0473 - accuracy: 0.8456 - val_loss: 0.0708 - val_accuracy: 0.7648\n",
      "Epoch 419/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0473 - accuracy: 0.8455 - val_loss: 0.0710 - val_accuracy: 0.7657\n",
      "Epoch 420/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0473 - accuracy: 0.8458 - val_loss: 0.0708 - val_accuracy: 0.7652\n",
      "Epoch 421/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0472 - accuracy: 0.8459 - val_loss: 0.0715 - val_accuracy: 0.7659\n",
      "Epoch 422/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0474 - accuracy: 0.8455 - val_loss: 0.0719 - val_accuracy: 0.7637\n",
      "Epoch 423/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0473 - accuracy: 0.8457 - val_loss: 0.0713 - val_accuracy: 0.7658\n",
      "Epoch 424/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0474 - accuracy: 0.8453 - val_loss: 0.0715 - val_accuracy: 0.7657\n",
      "Epoch 425/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0472 - accuracy: 0.8460 - val_loss: 0.0716 - val_accuracy: 0.7649\n",
      "Epoch 426/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0472 - accuracy: 0.8457 - val_loss: 0.0712 - val_accuracy: 0.7652\n",
      "Epoch 427/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0473 - accuracy: 0.8459 - val_loss: 0.0707 - val_accuracy: 0.7677\n",
      "Epoch 428/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0473 - accuracy: 0.8456 - val_loss: 0.0723 - val_accuracy: 0.7644\n",
      "Epoch 429/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0473 - accuracy: 0.8459 - val_loss: 0.0719 - val_accuracy: 0.7629\n",
      "Epoch 430/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0473 - accuracy: 0.8454 - val_loss: 0.0715 - val_accuracy: 0.7664\n",
      "Epoch 431/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0473 - accuracy: 0.8455 - val_loss: 0.0720 - val_accuracy: 0.7658\n",
      "Epoch 432/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0474 - accuracy: 0.8453 - val_loss: 0.0716 - val_accuracy: 0.7667\n",
      "Epoch 433/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0473 - accuracy: 0.8458 - val_loss: 0.0721 - val_accuracy: 0.7657\n",
      "Epoch 434/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0472 - accuracy: 0.8458 - val_loss: 0.0716 - val_accuracy: 0.7658\n",
      "Epoch 435/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0473 - accuracy: 0.8457 - val_loss: 0.0718 - val_accuracy: 0.7663\n",
      "Epoch 436/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0472 - accuracy: 0.8459 - val_loss: 0.0725 - val_accuracy: 0.7642\n",
      "Epoch 437/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0472 - accuracy: 0.8463 - val_loss: 0.0712 - val_accuracy: 0.7669\n",
      "Epoch 438/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0472 - accuracy: 0.8459 - val_loss: 0.0716 - val_accuracy: 0.7662\n",
      "Epoch 439/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0473 - accuracy: 0.8459 - val_loss: 0.0717 - val_accuracy: 0.7643\n",
      "Epoch 440/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0473 - accuracy: 0.8457 - val_loss: 0.0719 - val_accuracy: 0.7661\n",
      "Epoch 441/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0473 - accuracy: 0.8460 - val_loss: 0.0720 - val_accuracy: 0.7650\n",
      "Epoch 442/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0472 - accuracy: 0.8460 - val_loss: 0.0718 - val_accuracy: 0.7669\n",
      "Epoch 443/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0474 - accuracy: 0.8457 - val_loss: 0.0714 - val_accuracy: 0.7665\n",
      "Epoch 444/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0472 - accuracy: 0.8460 - val_loss: 0.0718 - val_accuracy: 0.7660\n",
      "Epoch 445/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0473 - accuracy: 0.8457 - val_loss: 0.0720 - val_accuracy: 0.7668\n",
      "Epoch 446/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0473 - accuracy: 0.8459 - val_loss: 0.0734 - val_accuracy: 0.7660\n",
      "Epoch 447/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0474 - accuracy: 0.8456 - val_loss: 0.0717 - val_accuracy: 0.7651\n",
      "Epoch 448/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0472 - accuracy: 0.8463 - val_loss: 0.0717 - val_accuracy: 0.7653\n",
      "Epoch 449/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0472 - accuracy: 0.8461 - val_loss: 0.0711 - val_accuracy: 0.7658\n",
      "Epoch 450/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0473 - accuracy: 0.8458 - val_loss: 0.0727 - val_accuracy: 0.7640\n",
      "Epoch 451/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0472 - accuracy: 0.8462 - val_loss: 0.0717 - val_accuracy: 0.7668\n",
      "Epoch 452/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0472 - accuracy: 0.8461 - val_loss: 0.0730 - val_accuracy: 0.7647\n",
      "Epoch 453/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0473 - accuracy: 0.8460 - val_loss: 0.0717 - val_accuracy: 0.7642\n",
      "Epoch 454/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0472 - accuracy: 0.8462 - val_loss: 0.0722 - val_accuracy: 0.7656\n",
      "Epoch 455/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0471 - accuracy: 0.8468 - val_loss: 0.0711 - val_accuracy: 0.7659\n",
      "Epoch 456/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0472 - accuracy: 0.8463 - val_loss: 0.0714 - val_accuracy: 0.7665\n",
      "Epoch 457/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0472 - accuracy: 0.8461 - val_loss: 0.0722 - val_accuracy: 0.7652\n",
      "Epoch 458/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0472 - accuracy: 0.8465 - val_loss: 0.0717 - val_accuracy: 0.7649\n",
      "Epoch 459/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0472 - accuracy: 0.8466 - val_loss: 0.0717 - val_accuracy: 0.7659\n",
      "Epoch 460/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0472 - accuracy: 0.8465 - val_loss: 0.0720 - val_accuracy: 0.7652\n",
      "Epoch 461/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0472 - accuracy: 0.8463 - val_loss: 0.0716 - val_accuracy: 0.7656\n",
      "Epoch 462/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0472 - accuracy: 0.8466 - val_loss: 0.0720 - val_accuracy: 0.7664\n",
      "Epoch 463/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0472 - accuracy: 0.8465 - val_loss: 0.0715 - val_accuracy: 0.7653\n",
      "Epoch 464/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0472 - accuracy: 0.8465 - val_loss: 0.0724 - val_accuracy: 0.7628\n",
      "Epoch 465/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0471 - accuracy: 0.8463 - val_loss: 0.0710 - val_accuracy: 0.7664\n",
      "Epoch 466/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0471 - accuracy: 0.8464 - val_loss: 0.0732 - val_accuracy: 0.7638\n",
      "Epoch 467/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0471 - accuracy: 0.8467 - val_loss: 0.0724 - val_accuracy: 0.7668\n",
      "Epoch 468/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0471 - accuracy: 0.8465 - val_loss: 0.0716 - val_accuracy: 0.7664\n",
      "Epoch 469/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0471 - accuracy: 0.8467 - val_loss: 0.0719 - val_accuracy: 0.7662\n",
      "Epoch 470/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0471 - accuracy: 0.8472 - val_loss: 0.0716 - val_accuracy: 0.7666\n",
      "Epoch 471/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0472 - accuracy: 0.8464 - val_loss: 0.0726 - val_accuracy: 0.7642\n",
      "Epoch 472/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0471 - accuracy: 0.8469 - val_loss: 0.0716 - val_accuracy: 0.7652\n",
      "Epoch 473/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0471 - accuracy: 0.8467 - val_loss: 0.0721 - val_accuracy: 0.7648\n",
      "Epoch 474/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0472 - accuracy: 0.8464 - val_loss: 0.0724 - val_accuracy: 0.7646\n",
      "Epoch 475/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0472 - accuracy: 0.8466 - val_loss: 0.0714 - val_accuracy: 0.7671\n",
      "Epoch 476/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0472 - accuracy: 0.8464 - val_loss: 0.0721 - val_accuracy: 0.7641\n",
      "Epoch 477/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0472 - accuracy: 0.8463 - val_loss: 0.0717 - val_accuracy: 0.7660\n",
      "Epoch 478/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0471 - accuracy: 0.8465 - val_loss: 0.0711 - val_accuracy: 0.7672\n",
      "Epoch 479/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0472 - accuracy: 0.8465 - val_loss: 0.0718 - val_accuracy: 0.7659\n",
      "Epoch 480/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0471 - accuracy: 0.8471 - val_loss: 0.0723 - val_accuracy: 0.7671\n",
      "Epoch 481/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0471 - accuracy: 0.8465 - val_loss: 0.0709 - val_accuracy: 0.7645\n",
      "Epoch 482/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0472 - accuracy: 0.8463 - val_loss: 0.0721 - val_accuracy: 0.7662\n",
      "Epoch 483/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0471 - accuracy: 0.8465 - val_loss: 0.0709 - val_accuracy: 0.7667\n",
      "Epoch 484/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0471 - accuracy: 0.8464 - val_loss: 0.0719 - val_accuracy: 0.7628\n",
      "Epoch 485/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0472 - accuracy: 0.8465 - val_loss: 0.0713 - val_accuracy: 0.7668\n",
      "Epoch 486/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0472 - accuracy: 0.8465 - val_loss: 0.0711 - val_accuracy: 0.7653\n",
      "Epoch 487/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0471 - accuracy: 0.8464 - val_loss: 0.0715 - val_accuracy: 0.7644\n",
      "Epoch 488/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0471 - accuracy: 0.8466 - val_loss: 0.0725 - val_accuracy: 0.7650\n",
      "Epoch 489/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0472 - accuracy: 0.8463 - val_loss: 0.0709 - val_accuracy: 0.7666\n",
      "Epoch 490/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0472 - accuracy: 0.8466 - val_loss: 0.0722 - val_accuracy: 0.7656\n",
      "Epoch 491/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0473 - accuracy: 0.8459 - val_loss: 0.0719 - val_accuracy: 0.7649\n",
      "Epoch 492/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0472 - accuracy: 0.8463 - val_loss: 0.0712 - val_accuracy: 0.7658\n",
      "Epoch 493/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0472 - accuracy: 0.8468 - val_loss: 0.0724 - val_accuracy: 0.7669\n",
      "Epoch 494/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0472 - accuracy: 0.8464 - val_loss: 0.0710 - val_accuracy: 0.7668\n",
      "Epoch 495/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0471 - accuracy: 0.8468 - val_loss: 0.0728 - val_accuracy: 0.7647\n",
      "Epoch 496/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0471 - accuracy: 0.8469 - val_loss: 0.0719 - val_accuracy: 0.7654\n",
      "Epoch 497/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0471 - accuracy: 0.8468 - val_loss: 0.0727 - val_accuracy: 0.7656\n",
      "Epoch 498/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0471 - accuracy: 0.8464 - val_loss: 0.0720 - val_accuracy: 0.7671\n",
      "Epoch 499/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0470 - accuracy: 0.8470 - val_loss: 0.0710 - val_accuracy: 0.7674\n",
      "Epoch 500/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0470 - accuracy: 0.8469 - val_loss: 0.0718 - val_accuracy: 0.7667\n",
      "Epoch 501/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0470 - accuracy: 0.8471 - val_loss: 0.0727 - val_accuracy: 0.7654\n",
      "Epoch 502/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0472 - accuracy: 0.8462 - val_loss: 0.0716 - val_accuracy: 0.7659\n",
      "Epoch 503/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0471 - accuracy: 0.8469 - val_loss: 0.0723 - val_accuracy: 0.7657\n",
      "Epoch 504/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0470 - accuracy: 0.8465 - val_loss: 0.0719 - val_accuracy: 0.7659\n",
      "Epoch 505/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0471 - accuracy: 0.8467 - val_loss: 0.0717 - val_accuracy: 0.7638\n",
      "Epoch 506/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0472 - accuracy: 0.8465 - val_loss: 0.0721 - val_accuracy: 0.7670\n",
      "Epoch 507/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0471 - accuracy: 0.8466 - val_loss: 0.0730 - val_accuracy: 0.7661\n",
      "Epoch 508/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0472 - accuracy: 0.8467 - val_loss: 0.0717 - val_accuracy: 0.7660\n",
      "Epoch 509/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0471 - accuracy: 0.8469 - val_loss: 0.0723 - val_accuracy: 0.7658\n",
      "Epoch 510/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0472 - accuracy: 0.8467 - val_loss: 0.0723 - val_accuracy: 0.7659\n",
      "Epoch 511/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0471 - accuracy: 0.8471 - val_loss: 0.0715 - val_accuracy: 0.7658\n",
      "Epoch 512/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0472 - accuracy: 0.8468 - val_loss: 0.0726 - val_accuracy: 0.7661\n",
      "Epoch 513/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0471 - accuracy: 0.8470 - val_loss: 0.0724 - val_accuracy: 0.7637\n",
      "Epoch 514/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0472 - accuracy: 0.8466 - val_loss: 0.0723 - val_accuracy: 0.7647\n",
      "Epoch 515/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0472 - accuracy: 0.8467 - val_loss: 0.0715 - val_accuracy: 0.7654\n",
      "Epoch 516/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0472 - accuracy: 0.8461 - val_loss: 0.0726 - val_accuracy: 0.7647\n",
      "Epoch 517/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0472 - accuracy: 0.8465 - val_loss: 0.0726 - val_accuracy: 0.7657\n",
      "Epoch 518/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0471 - accuracy: 0.8468 - val_loss: 0.0718 - val_accuracy: 0.7664\n",
      "Epoch 519/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0472 - accuracy: 0.8465 - val_loss: 0.0714 - val_accuracy: 0.7656\n",
      "Epoch 520/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0472 - accuracy: 0.8467 - val_loss: 0.0721 - val_accuracy: 0.7653\n",
      "Epoch 521/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0473 - accuracy: 0.8463 - val_loss: 0.0713 - val_accuracy: 0.7640\n",
      "Epoch 522/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0471 - accuracy: 0.8471 - val_loss: 0.0727 - val_accuracy: 0.7661\n",
      "Epoch 523/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0472 - accuracy: 0.8466 - val_loss: 0.0719 - val_accuracy: 0.7652\n",
      "Epoch 524/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0471 - accuracy: 0.8469 - val_loss: 0.0714 - val_accuracy: 0.7668\n",
      "Epoch 525/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0471 - accuracy: 0.8465 - val_loss: 0.0724 - val_accuracy: 0.7660\n",
      "Epoch 526/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0472 - accuracy: 0.8470 - val_loss: 0.0726 - val_accuracy: 0.7658\n",
      "Epoch 527/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0472 - accuracy: 0.8466 - val_loss: 0.0717 - val_accuracy: 0.7655\n",
      "Epoch 528/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0472 - accuracy: 0.8463 - val_loss: 0.0729 - val_accuracy: 0.7605\n",
      "Epoch 529/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0472 - accuracy: 0.8464 - val_loss: 0.0717 - val_accuracy: 0.7643\n",
      "Epoch 530/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0471 - accuracy: 0.8469 - val_loss: 0.0720 - val_accuracy: 0.7653\n",
      "Epoch 531/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0472 - accuracy: 0.8470 - val_loss: 0.0717 - val_accuracy: 0.7655\n",
      "Epoch 532/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0471 - accuracy: 0.8467 - val_loss: 0.0728 - val_accuracy: 0.7630\n",
      "Epoch 533/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0471 - accuracy: 0.8468 - val_loss: 0.0719 - val_accuracy: 0.7651\n",
      "Epoch 534/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0471 - accuracy: 0.8471 - val_loss: 0.0722 - val_accuracy: 0.7641\n",
      "Epoch 535/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0472 - accuracy: 0.8467 - val_loss: 0.0728 - val_accuracy: 0.7660\n",
      "Epoch 536/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0472 - accuracy: 0.8465 - val_loss: 0.0723 - val_accuracy: 0.7655\n",
      "Epoch 537/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0472 - accuracy: 0.8471 - val_loss: 0.0723 - val_accuracy: 0.7656\n",
      "Epoch 538/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0472 - accuracy: 0.8467 - val_loss: 0.0717 - val_accuracy: 0.7649\n",
      "Epoch 539/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0470 - accuracy: 0.8473 - val_loss: 0.0722 - val_accuracy: 0.7659\n",
      "Epoch 540/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0471 - accuracy: 0.8469 - val_loss: 0.0730 - val_accuracy: 0.7637\n",
      "Epoch 541/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0471 - accuracy: 0.8472 - val_loss: 0.0716 - val_accuracy: 0.7657\n",
      "Epoch 542/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0471 - accuracy: 0.8470 - val_loss: 0.0717 - val_accuracy: 0.7649\n",
      "Epoch 543/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0470 - accuracy: 0.8471 - val_loss: 0.0724 - val_accuracy: 0.7647\n",
      "Epoch 544/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0471 - accuracy: 0.8470 - val_loss: 0.0719 - val_accuracy: 0.7644\n",
      "Epoch 545/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0472 - accuracy: 0.8469 - val_loss: 0.0717 - val_accuracy: 0.7653\n",
      "Epoch 546/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0471 - accuracy: 0.8469 - val_loss: 0.0723 - val_accuracy: 0.7647\n",
      "Epoch 547/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0472 - accuracy: 0.8467 - val_loss: 0.0731 - val_accuracy: 0.7643\n",
      "Epoch 548/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0472 - accuracy: 0.8471 - val_loss: 0.0720 - val_accuracy: 0.7644\n",
      "Epoch 549/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0471 - accuracy: 0.8471 - val_loss: 0.0725 - val_accuracy: 0.7647\n",
      "Epoch 550/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0471 - accuracy: 0.8469 - val_loss: 0.0728 - val_accuracy: 0.7670\n",
      "Epoch 551/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0470 - accuracy: 0.8471 - val_loss: 0.0718 - val_accuracy: 0.7637\n",
      "Epoch 552/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0472 - accuracy: 0.8467 - val_loss: 0.0728 - val_accuracy: 0.7655\n",
      "Epoch 553/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0471 - accuracy: 0.8473 - val_loss: 0.0731 - val_accuracy: 0.7646\n",
      "Epoch 554/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0472 - accuracy: 0.8468 - val_loss: 0.0717 - val_accuracy: 0.7648\n",
      "Epoch 555/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0472 - accuracy: 0.8467 - val_loss: 0.0722 - val_accuracy: 0.7647\n",
      "Epoch 556/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0471 - accuracy: 0.8471 - val_loss: 0.0725 - val_accuracy: 0.7655\n",
      "Epoch 557/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0470 - accuracy: 0.8473 - val_loss: 0.0723 - val_accuracy: 0.7639\n",
      "Epoch 558/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0471 - accuracy: 0.8473 - val_loss: 0.0714 - val_accuracy: 0.7666\n",
      "Epoch 559/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0471 - accuracy: 0.8475 - val_loss: 0.0725 - val_accuracy: 0.7659\n",
      "Epoch 560/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0472 - accuracy: 0.8467 - val_loss: 0.0715 - val_accuracy: 0.7664\n",
      "Epoch 561/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0471 - accuracy: 0.8468 - val_loss: 0.0721 - val_accuracy: 0.7647\n",
      "Epoch 562/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0471 - accuracy: 0.8471 - val_loss: 0.0722 - val_accuracy: 0.7646\n",
      "Epoch 563/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0471 - accuracy: 0.8470 - val_loss: 0.0726 - val_accuracy: 0.7649\n",
      "Epoch 564/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0471 - accuracy: 0.8474 - val_loss: 0.0717 - val_accuracy: 0.7648\n",
      "Epoch 565/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0472 - accuracy: 0.8468 - val_loss: 0.0725 - val_accuracy: 0.7661\n",
      "Epoch 566/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0471 - accuracy: 0.8472 - val_loss: 0.0718 - val_accuracy: 0.7666\n",
      "Epoch 567/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0470 - accuracy: 0.8474 - val_loss: 0.0728 - val_accuracy: 0.7651\n",
      "Epoch 568/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0472 - accuracy: 0.8468 - val_loss: 0.0719 - val_accuracy: 0.7658\n",
      "Epoch 569/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0471 - accuracy: 0.8475 - val_loss: 0.0721 - val_accuracy: 0.7659\n",
      "Epoch 570/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0472 - accuracy: 0.8469 - val_loss: 0.0727 - val_accuracy: 0.7666\n",
      "Epoch 571/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0472 - accuracy: 0.8470 - val_loss: 0.0728 - val_accuracy: 0.7661\n",
      "Epoch 572/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0471 - accuracy: 0.8471 - val_loss: 0.0724 - val_accuracy: 0.7668\n",
      "Epoch 573/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0472 - accuracy: 0.8472 - val_loss: 0.0714 - val_accuracy: 0.7657\n",
      "Epoch 574/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0471 - accuracy: 0.8471 - val_loss: 0.0727 - val_accuracy: 0.7655\n",
      "Epoch 575/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0471 - accuracy: 0.8472 - val_loss: 0.0725 - val_accuracy: 0.7649\n",
      "Epoch 576/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0471 - accuracy: 0.8472 - val_loss: 0.0722 - val_accuracy: 0.7620\n",
      "Epoch 577/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0471 - accuracy: 0.8471 - val_loss: 0.0726 - val_accuracy: 0.7634\n",
      "Epoch 578/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0471 - accuracy: 0.8473 - val_loss: 0.0720 - val_accuracy: 0.7656\n",
      "Epoch 579/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0471 - accuracy: 0.8473 - val_loss: 0.0727 - val_accuracy: 0.7656\n",
      "Epoch 580/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0472 - accuracy: 0.8473 - val_loss: 0.0726 - val_accuracy: 0.7659\n",
      "Epoch 581/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0471 - accuracy: 0.8474 - val_loss: 0.0724 - val_accuracy: 0.7655\n",
      "Epoch 582/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0472 - accuracy: 0.8470 - val_loss: 0.0723 - val_accuracy: 0.7655\n",
      "Epoch 583/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0472 - accuracy: 0.8470 - val_loss: 0.0726 - val_accuracy: 0.7659\n",
      "Epoch 584/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0470 - accuracy: 0.8476 - val_loss: 0.0714 - val_accuracy: 0.7658\n",
      "Epoch 585/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0471 - accuracy: 0.8473 - val_loss: 0.0723 - val_accuracy: 0.7661\n",
      "Epoch 586/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0471 - accuracy: 0.8472 - val_loss: 0.0729 - val_accuracy: 0.7637\n",
      "Epoch 587/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0471 - accuracy: 0.8476 - val_loss: 0.0728 - val_accuracy: 0.7635\n",
      "Epoch 588/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0471 - accuracy: 0.8474 - val_loss: 0.0720 - val_accuracy: 0.7659\n",
      "Epoch 589/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0470 - accuracy: 0.8477 - val_loss: 0.0723 - val_accuracy: 0.7655\n",
      "Epoch 590/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0470 - accuracy: 0.8475 - val_loss: 0.0721 - val_accuracy: 0.7645\n",
      "Epoch 591/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0471 - accuracy: 0.8476 - val_loss: 0.0717 - val_accuracy: 0.7644\n",
      "Epoch 592/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0472 - accuracy: 0.8470 - val_loss: 0.0731 - val_accuracy: 0.7618\n",
      "Epoch 593/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0471 - accuracy: 0.8476 - val_loss: 0.0722 - val_accuracy: 0.7663\n",
      "Epoch 594/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0471 - accuracy: 0.8473 - val_loss: 0.0723 - val_accuracy: 0.7660\n",
      "Epoch 595/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0471 - accuracy: 0.8474 - val_loss: 0.0732 - val_accuracy: 0.7646\n",
      "Epoch 596/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0472 - accuracy: 0.8470 - val_loss: 0.0713 - val_accuracy: 0.7662\n",
      "Epoch 597/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0471 - accuracy: 0.8476 - val_loss: 0.0717 - val_accuracy: 0.7661\n",
      "Epoch 598/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0471 - accuracy: 0.8474 - val_loss: 0.0737 - val_accuracy: 0.7642\n",
      "Epoch 599/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0471 - accuracy: 0.8473 - val_loss: 0.0720 - val_accuracy: 0.7638\n",
      "Epoch 600/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0472 - accuracy: 0.8475 - val_loss: 0.0720 - val_accuracy: 0.7659\n",
      "Epoch 601/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0472 - accuracy: 0.8476 - val_loss: 0.0723 - val_accuracy: 0.7652\n",
      "Epoch 602/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0472 - accuracy: 0.8468 - val_loss: 0.0725 - val_accuracy: 0.7656\n",
      "Epoch 603/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0472 - accuracy: 0.8472 - val_loss: 0.0731 - val_accuracy: 0.7645\n",
      "Epoch 604/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0471 - accuracy: 0.8472 - val_loss: 0.0727 - val_accuracy: 0.7623\n",
      "Epoch 605/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0472 - accuracy: 0.8472 - val_loss: 0.0727 - val_accuracy: 0.7632\n",
      "Epoch 606/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0471 - accuracy: 0.8477 - val_loss: 0.0732 - val_accuracy: 0.7647\n",
      "Epoch 607/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0471 - accuracy: 0.8478 - val_loss: 0.0731 - val_accuracy: 0.7644\n",
      "Epoch 608/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0472 - accuracy: 0.8469 - val_loss: 0.0723 - val_accuracy: 0.7652\n",
      "Epoch 609/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0471 - accuracy: 0.8475 - val_loss: 0.0729 - val_accuracy: 0.7644\n",
      "Epoch 610/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0472 - accuracy: 0.8471 - val_loss: 0.0729 - val_accuracy: 0.7654\n",
      "Epoch 611/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0471 - accuracy: 0.8475 - val_loss: 0.0721 - val_accuracy: 0.7661\n",
      "Epoch 612/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0472 - accuracy: 0.8472 - val_loss: 0.0731 - val_accuracy: 0.7628\n",
      "Epoch 613/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0470 - accuracy: 0.8476 - val_loss: 0.0722 - val_accuracy: 0.7661\n",
      "Epoch 614/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0471 - accuracy: 0.8474 - val_loss: 0.0713 - val_accuracy: 0.7660\n",
      "Epoch 615/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0471 - accuracy: 0.8479 - val_loss: 0.0724 - val_accuracy: 0.7671\n",
      "Epoch 616/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0470 - accuracy: 0.8475 - val_loss: 0.0729 - val_accuracy: 0.7651\n",
      "Epoch 617/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0470 - accuracy: 0.8479 - val_loss: 0.0729 - val_accuracy: 0.7625\n",
      "Epoch 618/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0470 - accuracy: 0.8480 - val_loss: 0.0721 - val_accuracy: 0.7662\n",
      "Epoch 619/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0471 - accuracy: 0.8477 - val_loss: 0.0733 - val_accuracy: 0.7651\n",
      "Epoch 620/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0471 - accuracy: 0.8475 - val_loss: 0.0727 - val_accuracy: 0.7670\n",
      "Epoch 621/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0470 - accuracy: 0.8476 - val_loss: 0.0731 - val_accuracy: 0.7651\n",
      "Epoch 622/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0471 - accuracy: 0.8476 - val_loss: 0.0725 - val_accuracy: 0.7645\n",
      "Epoch 623/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0472 - accuracy: 0.8472 - val_loss: 0.0736 - val_accuracy: 0.7647\n",
      "Epoch 624/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0472 - accuracy: 0.8472 - val_loss: 0.0721 - val_accuracy: 0.7641\n",
      "Epoch 625/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0471 - accuracy: 0.8478 - val_loss: 0.0726 - val_accuracy: 0.7672\n",
      "Epoch 626/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0471 - accuracy: 0.8480 - val_loss: 0.0719 - val_accuracy: 0.7663\n",
      "Epoch 627/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0470 - accuracy: 0.8477 - val_loss: 0.0719 - val_accuracy: 0.7660\n",
      "Epoch 628/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0471 - accuracy: 0.8476 - val_loss: 0.0730 - val_accuracy: 0.7646\n",
      "Epoch 629/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0469 - accuracy: 0.8482 - val_loss: 0.0726 - val_accuracy: 0.7653\n",
      "Epoch 630/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0472 - accuracy: 0.8471 - val_loss: 0.0736 - val_accuracy: 0.7644\n",
      "Epoch 631/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0471 - accuracy: 0.8479 - val_loss: 0.0734 - val_accuracy: 0.7655\n",
      "Epoch 632/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0470 - accuracy: 0.8479 - val_loss: 0.0723 - val_accuracy: 0.7650\n",
      "Epoch 633/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0471 - accuracy: 0.8479 - val_loss: 0.0723 - val_accuracy: 0.7656\n",
      "Epoch 634/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0470 - accuracy: 0.8480 - val_loss: 0.0722 - val_accuracy: 0.7650\n",
      "Epoch 635/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0472 - accuracy: 0.8474 - val_loss: 0.0734 - val_accuracy: 0.7658\n",
      "Epoch 636/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0471 - accuracy: 0.8473 - val_loss: 0.0720 - val_accuracy: 0.7654\n",
      "Epoch 637/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0471 - accuracy: 0.8477 - val_loss: 0.0729 - val_accuracy: 0.7653\n",
      "Epoch 638/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0471 - accuracy: 0.8476 - val_loss: 0.0721 - val_accuracy: 0.7642\n",
      "Epoch 639/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0471 - accuracy: 0.8475 - val_loss: 0.0728 - val_accuracy: 0.7649\n",
      "Epoch 640/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0471 - accuracy: 0.8477 - val_loss: 0.0717 - val_accuracy: 0.7643\n",
      "Epoch 641/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0470 - accuracy: 0.8479 - val_loss: 0.0731 - val_accuracy: 0.7629\n",
      "Epoch 642/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0471 - accuracy: 0.8479 - val_loss: 0.0726 - val_accuracy: 0.7647\n",
      "Epoch 643/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0470 - accuracy: 0.8477 - val_loss: 0.0727 - val_accuracy: 0.7655\n",
      "Epoch 644/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0471 - accuracy: 0.8477 - val_loss: 0.0722 - val_accuracy: 0.7653\n",
      "Epoch 645/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0471 - accuracy: 0.8469 - val_loss: 0.0725 - val_accuracy: 0.7644\n",
      "Epoch 646/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0471 - accuracy: 0.8475 - val_loss: 0.0724 - val_accuracy: 0.7659\n",
      "Epoch 647/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0471 - accuracy: 0.8478 - val_loss: 0.0726 - val_accuracy: 0.7650\n",
      "Epoch 648/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0471 - accuracy: 0.8478 - val_loss: 0.0729 - val_accuracy: 0.7656\n",
      "Epoch 649/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0471 - accuracy: 0.8477 - val_loss: 0.0727 - val_accuracy: 0.7660\n",
      "Epoch 650/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0471 - accuracy: 0.8475 - val_loss: 0.0735 - val_accuracy: 0.7654\n",
      "Epoch 651/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0470 - accuracy: 0.8484 - val_loss: 0.0728 - val_accuracy: 0.7658\n",
      "Epoch 652/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0470 - accuracy: 0.8481 - val_loss: 0.0714 - val_accuracy: 0.7654\n",
      "Epoch 653/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0471 - accuracy: 0.8477 - val_loss: 0.0724 - val_accuracy: 0.7640\n",
      "Epoch 654/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0472 - accuracy: 0.8475 - val_loss: 0.0724 - val_accuracy: 0.7647\n",
      "Epoch 655/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0472 - accuracy: 0.8477 - val_loss: 0.0729 - val_accuracy: 0.7652\n",
      "Epoch 656/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0472 - accuracy: 0.8476 - val_loss: 0.0725 - val_accuracy: 0.7639\n",
      "Epoch 657/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0471 - accuracy: 0.8477 - val_loss: 0.0726 - val_accuracy: 0.7653\n",
      "Epoch 658/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0472 - accuracy: 0.8475 - val_loss: 0.0722 - val_accuracy: 0.7650\n",
      "Epoch 659/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0471 - accuracy: 0.8479 - val_loss: 0.0732 - val_accuracy: 0.7649\n",
      "Epoch 660/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0471 - accuracy: 0.8482 - val_loss: 0.0735 - val_accuracy: 0.7639\n",
      "Epoch 661/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0472 - accuracy: 0.8480 - val_loss: 0.0729 - val_accuracy: 0.7660\n",
      "Epoch 662/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0471 - accuracy: 0.8483 - val_loss: 0.0723 - val_accuracy: 0.7638\n",
      "Epoch 663/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0471 - accuracy: 0.8481 - val_loss: 0.0723 - val_accuracy: 0.7656\n",
      "Epoch 664/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0471 - accuracy: 0.8479 - val_loss: 0.0728 - val_accuracy: 0.7651\n",
      "Epoch 665/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0471 - accuracy: 0.8481 - val_loss: 0.0720 - val_accuracy: 0.7650\n",
      "Epoch 666/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0471 - accuracy: 0.8479 - val_loss: 0.0735 - val_accuracy: 0.7658\n",
      "Epoch 667/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0471 - accuracy: 0.8482 - val_loss: 0.0738 - val_accuracy: 0.7638\n",
      "Epoch 668/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0470 - accuracy: 0.8483 - val_loss: 0.0729 - val_accuracy: 0.7663\n",
      "Epoch 669/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0471 - accuracy: 0.8480 - val_loss: 0.0732 - val_accuracy: 0.7662\n",
      "Epoch 670/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0471 - accuracy: 0.8484 - val_loss: 0.0722 - val_accuracy: 0.7657\n",
      "Epoch 671/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0471 - accuracy: 0.8482 - val_loss: 0.0732 - val_accuracy: 0.7659\n",
      "Epoch 672/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0470 - accuracy: 0.8481 - val_loss: 0.0720 - val_accuracy: 0.7661\n",
      "Epoch 673/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0471 - accuracy: 0.8478 - val_loss: 0.0724 - val_accuracy: 0.7657\n",
      "Epoch 674/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0470 - accuracy: 0.8478 - val_loss: 0.0730 - val_accuracy: 0.7647\n",
      "Epoch 675/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0470 - accuracy: 0.8483 - val_loss: 0.0731 - val_accuracy: 0.7649\n",
      "Epoch 676/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0470 - accuracy: 0.8484 - val_loss: 0.0725 - val_accuracy: 0.7651\n",
      "Epoch 677/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0470 - accuracy: 0.8483 - val_loss: 0.0738 - val_accuracy: 0.7641\n",
      "Epoch 678/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0471 - accuracy: 0.8481 - val_loss: 0.0718 - val_accuracy: 0.7649\n",
      "Epoch 679/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0470 - accuracy: 0.8480 - val_loss: 0.0728 - val_accuracy: 0.7663\n",
      "Epoch 680/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0471 - accuracy: 0.8479 - val_loss: 0.0729 - val_accuracy: 0.7649\n",
      "Epoch 681/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0471 - accuracy: 0.8478 - val_loss: 0.0726 - val_accuracy: 0.7658\n",
      "Epoch 682/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0470 - accuracy: 0.8480 - val_loss: 0.0725 - val_accuracy: 0.7648\n",
      "Epoch 683/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0470 - accuracy: 0.8484 - val_loss: 0.0732 - val_accuracy: 0.7651\n",
      "Epoch 684/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0470 - accuracy: 0.8481 - val_loss: 0.0723 - val_accuracy: 0.7641\n",
      "Epoch 685/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0470 - accuracy: 0.8482 - val_loss: 0.0734 - val_accuracy: 0.7630\n",
      "Epoch 686/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0471 - accuracy: 0.8477 - val_loss: 0.0726 - val_accuracy: 0.7660\n",
      "Epoch 687/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0470 - accuracy: 0.8482 - val_loss: 0.0729 - val_accuracy: 0.7657\n",
      "Epoch 688/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0470 - accuracy: 0.8484 - val_loss: 0.0720 - val_accuracy: 0.7643\n",
      "Epoch 689/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0470 - accuracy: 0.8484 - val_loss: 0.0732 - val_accuracy: 0.7629\n",
      "Epoch 690/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0472 - accuracy: 0.8478 - val_loss: 0.0721 - val_accuracy: 0.7657\n",
      "Epoch 691/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0471 - accuracy: 0.8480 - val_loss: 0.0735 - val_accuracy: 0.7635\n",
      "Epoch 692/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0470 - accuracy: 0.8486 - val_loss: 0.0733 - val_accuracy: 0.7649\n",
      "Epoch 693/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0470 - accuracy: 0.8484 - val_loss: 0.0737 - val_accuracy: 0.7652\n",
      "Epoch 694/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0471 - accuracy: 0.8482 - val_loss: 0.0725 - val_accuracy: 0.7650\n",
      "Epoch 695/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0470 - accuracy: 0.8485 - val_loss: 0.0729 - val_accuracy: 0.7645\n",
      "Epoch 696/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0470 - accuracy: 0.8481 - val_loss: 0.0735 - val_accuracy: 0.7646\n",
      "Epoch 697/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0469 - accuracy: 0.8484 - val_loss: 0.0724 - val_accuracy: 0.7658\n",
      "Epoch 698/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0470 - accuracy: 0.8485 - val_loss: 0.0727 - val_accuracy: 0.7648\n",
      "Epoch 699/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0470 - accuracy: 0.8485 - val_loss: 0.0736 - val_accuracy: 0.7647\n",
      "Epoch 700/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0471 - accuracy: 0.8484 - val_loss: 0.0722 - val_accuracy: 0.7654\n",
      "Epoch 701/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0470 - accuracy: 0.8480 - val_loss: 0.0723 - val_accuracy: 0.7654\n",
      "Epoch 702/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0471 - accuracy: 0.8478 - val_loss: 0.0731 - val_accuracy: 0.7663\n",
      "Epoch 703/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0470 - accuracy: 0.8488 - val_loss: 0.0727 - val_accuracy: 0.7652\n",
      "Epoch 704/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0470 - accuracy: 0.8482 - val_loss: 0.0728 - val_accuracy: 0.7657\n",
      "Epoch 705/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0470 - accuracy: 0.8481 - val_loss: 0.0745 - val_accuracy: 0.7649\n",
      "Epoch 706/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0470 - accuracy: 0.8484 - val_loss: 0.0730 - val_accuracy: 0.7651\n",
      "Epoch 707/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0471 - accuracy: 0.8484 - val_loss: 0.0732 - val_accuracy: 0.7655\n",
      "Epoch 708/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0470 - accuracy: 0.8488 - val_loss: 0.0726 - val_accuracy: 0.7654\n",
      "Epoch 709/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0469 - accuracy: 0.8488 - val_loss: 0.0732 - val_accuracy: 0.7654\n",
      "Epoch 710/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0470 - accuracy: 0.8485 - val_loss: 0.0724 - val_accuracy: 0.7662\n",
      "Epoch 711/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0469 - accuracy: 0.8485 - val_loss: 0.0729 - val_accuracy: 0.7656\n",
      "Epoch 712/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0470 - accuracy: 0.8479 - val_loss: 0.0731 - val_accuracy: 0.7648\n",
      "Epoch 713/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0471 - accuracy: 0.8479 - val_loss: 0.0748 - val_accuracy: 0.7629\n",
      "Epoch 714/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0470 - accuracy: 0.8485 - val_loss: 0.0732 - val_accuracy: 0.7642\n",
      "Epoch 715/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0471 - accuracy: 0.8478 - val_loss: 0.0733 - val_accuracy: 0.7647\n",
      "Epoch 716/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0470 - accuracy: 0.8483 - val_loss: 0.0739 - val_accuracy: 0.7656\n",
      "Epoch 717/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0470 - accuracy: 0.8485 - val_loss: 0.0735 - val_accuracy: 0.7658\n",
      "Epoch 718/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0470 - accuracy: 0.8485 - val_loss: 0.0726 - val_accuracy: 0.7646\n",
      "Epoch 719/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0470 - accuracy: 0.8484 - val_loss: 0.0719 - val_accuracy: 0.7657\n",
      "Epoch 720/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0469 - accuracy: 0.8484 - val_loss: 0.0723 - val_accuracy: 0.7660\n",
      "Epoch 721/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0470 - accuracy: 0.8483 - val_loss: 0.0730 - val_accuracy: 0.7652\n",
      "Epoch 722/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0470 - accuracy: 0.8484 - val_loss: 0.0732 - val_accuracy: 0.7640\n",
      "Epoch 723/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0470 - accuracy: 0.8480 - val_loss: 0.0728 - val_accuracy: 0.7635\n",
      "Epoch 724/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0471 - accuracy: 0.8479 - val_loss: 0.0732 - val_accuracy: 0.7648\n",
      "Epoch 725/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0471 - accuracy: 0.8484 - val_loss: 0.0728 - val_accuracy: 0.7665\n",
      "Epoch 726/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0471 - accuracy: 0.8482 - val_loss: 0.0730 - val_accuracy: 0.7645\n",
      "Epoch 727/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0469 - accuracy: 0.8483 - val_loss: 0.0735 - val_accuracy: 0.7643\n",
      "Epoch 728/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0470 - accuracy: 0.8478 - val_loss: 0.0731 - val_accuracy: 0.7652\n",
      "Epoch 729/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0471 - accuracy: 0.8480 - val_loss: 0.0725 - val_accuracy: 0.7642\n",
      "Epoch 730/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0471 - accuracy: 0.8479 - val_loss: 0.0730 - val_accuracy: 0.7641\n",
      "Epoch 731/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0470 - accuracy: 0.8480 - val_loss: 0.0730 - val_accuracy: 0.7646\n",
      "Epoch 732/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0470 - accuracy: 0.8483 - val_loss: 0.0730 - val_accuracy: 0.7655\n",
      "Epoch 733/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0471 - accuracy: 0.8480 - val_loss: 0.0741 - val_accuracy: 0.7631\n",
      "Epoch 734/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0470 - accuracy: 0.8479 - val_loss: 0.0737 - val_accuracy: 0.7657\n",
      "Epoch 735/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0470 - accuracy: 0.8488 - val_loss: 0.0725 - val_accuracy: 0.7658\n",
      "Epoch 736/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0469 - accuracy: 0.8484 - val_loss: 0.0729 - val_accuracy: 0.7637\n",
      "Epoch 737/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0471 - accuracy: 0.8480 - val_loss: 0.0729 - val_accuracy: 0.7652\n",
      "Epoch 738/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0471 - accuracy: 0.8479 - val_loss: 0.0729 - val_accuracy: 0.7653\n",
      "Epoch 739/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0469 - accuracy: 0.8485 - val_loss: 0.0725 - val_accuracy: 0.7653\n",
      "Epoch 740/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0471 - accuracy: 0.8480 - val_loss: 0.0737 - val_accuracy: 0.7635\n",
      "Epoch 741/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0470 - accuracy: 0.8484 - val_loss: 0.0728 - val_accuracy: 0.7654\n",
      "Epoch 742/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0470 - accuracy: 0.8481 - val_loss: 0.0732 - val_accuracy: 0.7632\n",
      "Epoch 743/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0472 - accuracy: 0.8478 - val_loss: 0.0729 - val_accuracy: 0.7637\n",
      "Epoch 744/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0471 - accuracy: 0.8479 - val_loss: 0.0732 - val_accuracy: 0.7650\n",
      "Epoch 745/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0470 - accuracy: 0.8485 - val_loss: 0.0728 - val_accuracy: 0.7650\n",
      "Epoch 746/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0470 - accuracy: 0.8485 - val_loss: 0.0731 - val_accuracy: 0.7640\n",
      "Epoch 747/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0471 - accuracy: 0.8481 - val_loss: 0.0719 - val_accuracy: 0.7651\n",
      "Epoch 748/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0470 - accuracy: 0.8485 - val_loss: 0.0729 - val_accuracy: 0.7655\n",
      "Epoch 749/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0471 - accuracy: 0.8478 - val_loss: 0.0729 - val_accuracy: 0.7652\n",
      "Epoch 750/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0470 - accuracy: 0.8483 - val_loss: 0.0740 - val_accuracy: 0.7636\n",
      "Epoch 751/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0471 - accuracy: 0.8483 - val_loss: 0.0728 - val_accuracy: 0.7643\n",
      "Epoch 752/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0470 - accuracy: 0.8480 - val_loss: 0.0727 - val_accuracy: 0.7651\n",
      "Epoch 753/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0469 - accuracy: 0.8488 - val_loss: 0.0736 - val_accuracy: 0.7652\n",
      "Epoch 754/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0471 - accuracy: 0.8483 - val_loss: 0.0731 - val_accuracy: 0.7661\n",
      "Epoch 755/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0471 - accuracy: 0.8484 - val_loss: 0.0727 - val_accuracy: 0.7653\n",
      "Epoch 756/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0471 - accuracy: 0.8477 - val_loss: 0.0738 - val_accuracy: 0.7635\n",
      "Epoch 757/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0470 - accuracy: 0.8484 - val_loss: 0.0734 - val_accuracy: 0.7659\n",
      "Epoch 758/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0471 - accuracy: 0.8484 - val_loss: 0.0741 - val_accuracy: 0.7650\n",
      "Epoch 759/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0470 - accuracy: 0.8484 - val_loss: 0.0720 - val_accuracy: 0.7649\n",
      "Epoch 760/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0471 - accuracy: 0.8482 - val_loss: 0.0734 - val_accuracy: 0.7658\n",
      "Epoch 761/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0471 - accuracy: 0.8480 - val_loss: 0.0725 - val_accuracy: 0.7655\n",
      "Epoch 762/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0471 - accuracy: 0.8482 - val_loss: 0.0735 - val_accuracy: 0.7649\n",
      "Epoch 763/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0470 - accuracy: 0.8485 - val_loss: 0.0726 - val_accuracy: 0.7637\n",
      "Epoch 764/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0471 - accuracy: 0.8481 - val_loss: 0.0730 - val_accuracy: 0.7649\n",
      "Epoch 765/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0471 - accuracy: 0.8487 - val_loss: 0.0733 - val_accuracy: 0.7637\n",
      "Epoch 766/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0472 - accuracy: 0.8478 - val_loss: 0.0738 - val_accuracy: 0.7649\n",
      "Epoch 767/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0472 - accuracy: 0.8479 - val_loss: 0.0738 - val_accuracy: 0.7648\n",
      "Epoch 768/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0469 - accuracy: 0.8488 - val_loss: 0.0738 - val_accuracy: 0.7649\n",
      "Epoch 769/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0472 - accuracy: 0.8480 - val_loss: 0.0729 - val_accuracy: 0.7652\n",
      "Epoch 770/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0471 - accuracy: 0.8485 - val_loss: 0.0736 - val_accuracy: 0.7663\n",
      "Epoch 771/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0470 - accuracy: 0.8486 - val_loss: 0.0733 - val_accuracy: 0.7644\n",
      "Epoch 772/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0471 - accuracy: 0.8484 - val_loss: 0.0729 - val_accuracy: 0.7643\n",
      "Epoch 773/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0471 - accuracy: 0.8482 - val_loss: 0.0735 - val_accuracy: 0.7661\n",
      "Epoch 774/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0471 - accuracy: 0.8479 - val_loss: 0.0729 - val_accuracy: 0.7650\n",
      "Epoch 775/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0472 - accuracy: 0.8481 - val_loss: 0.0734 - val_accuracy: 0.7653\n",
      "Epoch 776/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0471 - accuracy: 0.8482 - val_loss: 0.0735 - val_accuracy: 0.7658\n",
      "Epoch 777/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0471 - accuracy: 0.8485 - val_loss: 0.0728 - val_accuracy: 0.7640\n",
      "Epoch 778/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0471 - accuracy: 0.8486 - val_loss: 0.0740 - val_accuracy: 0.7635\n",
      "Epoch 779/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0471 - accuracy: 0.8484 - val_loss: 0.0743 - val_accuracy: 0.7645\n",
      "Epoch 780/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0472 - accuracy: 0.8481 - val_loss: 0.0743 - val_accuracy: 0.7610\n",
      "Epoch 781/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0471 - accuracy: 0.8485 - val_loss: 0.0728 - val_accuracy: 0.7650\n",
      "Epoch 782/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0471 - accuracy: 0.8483 - val_loss: 0.0733 - val_accuracy: 0.7647\n",
      "Epoch 783/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0471 - accuracy: 0.8482 - val_loss: 0.0738 - val_accuracy: 0.7643\n",
      "Epoch 784/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0471 - accuracy: 0.8482 - val_loss: 0.0733 - val_accuracy: 0.7649\n",
      "Epoch 785/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0471 - accuracy: 0.8481 - val_loss: 0.0730 - val_accuracy: 0.7646\n",
      "Epoch 786/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0472 - accuracy: 0.8480 - val_loss: 0.0735 - val_accuracy: 0.7629\n",
      "Epoch 787/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0471 - accuracy: 0.8483 - val_loss: 0.0729 - val_accuracy: 0.7646\n",
      "Epoch 788/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0470 - accuracy: 0.8483 - val_loss: 0.0727 - val_accuracy: 0.7658\n",
      "Epoch 789/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0471 - accuracy: 0.8482 - val_loss: 0.0731 - val_accuracy: 0.7639\n",
      "Epoch 790/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0471 - accuracy: 0.8482 - val_loss: 0.0732 - val_accuracy: 0.7635\n",
      "Epoch 791/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0471 - accuracy: 0.8484 - val_loss: 0.0734 - val_accuracy: 0.7650\n",
      "Epoch 792/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0472 - accuracy: 0.8482 - val_loss: 0.0736 - val_accuracy: 0.7642\n",
      "Epoch 793/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0471 - accuracy: 0.8481 - val_loss: 0.0736 - val_accuracy: 0.7647\n",
      "Epoch 794/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0471 - accuracy: 0.8483 - val_loss: 0.0735 - val_accuracy: 0.7652\n",
      "Epoch 795/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0472 - accuracy: 0.8481 - val_loss: 0.0732 - val_accuracy: 0.7657\n",
      "Epoch 796/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0471 - accuracy: 0.8480 - val_loss: 0.0732 - val_accuracy: 0.7658\n",
      "Epoch 797/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0471 - accuracy: 0.8480 - val_loss: 0.0736 - val_accuracy: 0.7628\n",
      "Epoch 798/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0472 - accuracy: 0.8478 - val_loss: 0.0735 - val_accuracy: 0.7636\n",
      "Epoch 799/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0472 - accuracy: 0.8482 - val_loss: 0.0740 - val_accuracy: 0.7619\n",
      "Epoch 800/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0471 - accuracy: 0.8481 - val_loss: 0.0739 - val_accuracy: 0.7641\n",
      "Epoch 801/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0471 - accuracy: 0.8482 - val_loss: 0.0737 - val_accuracy: 0.7647\n",
      "Epoch 802/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0472 - accuracy: 0.8477 - val_loss: 0.0740 - val_accuracy: 0.7645\n",
      "Epoch 803/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0472 - accuracy: 0.8480 - val_loss: 0.0736 - val_accuracy: 0.7637\n",
      "Epoch 804/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0472 - accuracy: 0.8474 - val_loss: 0.0732 - val_accuracy: 0.7646\n",
      "Epoch 805/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0472 - accuracy: 0.8477 - val_loss: 0.0734 - val_accuracy: 0.7633\n",
      "Epoch 806/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0472 - accuracy: 0.8478 - val_loss: 0.0734 - val_accuracy: 0.7646\n",
      "Epoch 807/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0472 - accuracy: 0.8480 - val_loss: 0.0733 - val_accuracy: 0.7640\n",
      "Epoch 808/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0471 - accuracy: 0.8480 - val_loss: 0.0731 - val_accuracy: 0.7650\n",
      "Epoch 809/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0471 - accuracy: 0.8479 - val_loss: 0.0731 - val_accuracy: 0.7637\n",
      "Epoch 810/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0471 - accuracy: 0.8483 - val_loss: 0.0741 - val_accuracy: 0.7640\n",
      "Epoch 811/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0471 - accuracy: 0.8481 - val_loss: 0.0730 - val_accuracy: 0.7641\n",
      "Epoch 812/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0472 - accuracy: 0.8482 - val_loss: 0.0738 - val_accuracy: 0.7645\n",
      "Epoch 813/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0472 - accuracy: 0.8480 - val_loss: 0.0723 - val_accuracy: 0.7653\n",
      "Epoch 814/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0472 - accuracy: 0.8482 - val_loss: 0.0728 - val_accuracy: 0.7651\n",
      "Epoch 815/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0471 - accuracy: 0.8482 - val_loss: 0.0736 - val_accuracy: 0.7637\n",
      "Epoch 816/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0471 - accuracy: 0.8481 - val_loss: 0.0735 - val_accuracy: 0.7640\n",
      "Epoch 817/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0472 - accuracy: 0.8482 - val_loss: 0.0735 - val_accuracy: 0.7634\n",
      "Epoch 818/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0474 - accuracy: 0.8475 - val_loss: 0.0738 - val_accuracy: 0.7635\n",
      "Epoch 819/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0473 - accuracy: 0.8480 - val_loss: 0.0735 - val_accuracy: 0.7621\n",
      "Epoch 820/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0473 - accuracy: 0.8478 - val_loss: 0.0745 - val_accuracy: 0.7635\n",
      "Epoch 821/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0472 - accuracy: 0.8478 - val_loss: 0.0732 - val_accuracy: 0.7638\n",
      "Epoch 822/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0471 - accuracy: 0.8479 - val_loss: 0.0729 - val_accuracy: 0.7643\n",
      "Epoch 823/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0472 - accuracy: 0.8478 - val_loss: 0.0734 - val_accuracy: 0.7648\n",
      "Epoch 824/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0471 - accuracy: 0.8480 - val_loss: 0.0730 - val_accuracy: 0.7645\n",
      "Epoch 825/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0472 - accuracy: 0.8480 - val_loss: 0.0725 - val_accuracy: 0.7649\n",
      "Epoch 826/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0471 - accuracy: 0.8483 - val_loss: 0.0727 - val_accuracy: 0.7628\n",
      "Epoch 827/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0471 - accuracy: 0.8489 - val_loss: 0.0738 - val_accuracy: 0.7637\n",
      "Epoch 828/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0471 - accuracy: 0.8485 - val_loss: 0.0730 - val_accuracy: 0.7644\n",
      "Epoch 829/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0471 - accuracy: 0.8482 - val_loss: 0.0726 - val_accuracy: 0.7655\n",
      "Epoch 830/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0471 - accuracy: 0.8481 - val_loss: 0.0725 - val_accuracy: 0.7641\n",
      "Epoch 831/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0472 - accuracy: 0.8478 - val_loss: 0.0729 - val_accuracy: 0.7655\n",
      "Epoch 832/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0471 - accuracy: 0.8482 - val_loss: 0.0731 - val_accuracy: 0.7650\n",
      "Epoch 833/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0471 - accuracy: 0.8486 - val_loss: 0.0730 - val_accuracy: 0.7645\n",
      "Epoch 834/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0474 - accuracy: 0.8473 - val_loss: 0.0746 - val_accuracy: 0.7596\n",
      "Epoch 835/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0472 - accuracy: 0.8484 - val_loss: 0.0731 - val_accuracy: 0.7641\n",
      "Epoch 836/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0473 - accuracy: 0.8477 - val_loss: 0.0734 - val_accuracy: 0.7626\n",
      "Epoch 837/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0471 - accuracy: 0.8483 - val_loss: 0.0736 - val_accuracy: 0.7650\n",
      "Epoch 838/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0472 - accuracy: 0.8481 - val_loss: 0.0731 - val_accuracy: 0.7649\n",
      "Epoch 839/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0472 - accuracy: 0.8484 - val_loss: 0.0734 - val_accuracy: 0.7648\n",
      "Epoch 840/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0472 - accuracy: 0.8481 - val_loss: 0.0733 - val_accuracy: 0.7623\n",
      "Epoch 841/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0473 - accuracy: 0.8476 - val_loss: 0.0729 - val_accuracy: 0.7642\n",
      "Epoch 842/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0471 - accuracy: 0.8484 - val_loss: 0.0729 - val_accuracy: 0.7650\n",
      "Epoch 843/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0471 - accuracy: 0.8484 - val_loss: 0.0736 - val_accuracy: 0.7649\n",
      "Epoch 844/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0472 - accuracy: 0.8477 - val_loss: 0.0735 - val_accuracy: 0.7654\n",
      "Epoch 845/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0473 - accuracy: 0.8480 - val_loss: 0.0744 - val_accuracy: 0.7646\n",
      "Epoch 846/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0472 - accuracy: 0.8481 - val_loss: 0.0734 - val_accuracy: 0.7656\n",
      "Epoch 847/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0473 - accuracy: 0.8474 - val_loss: 0.0728 - val_accuracy: 0.7650\n",
      "Epoch 848/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0472 - accuracy: 0.8479 - val_loss: 0.0739 - val_accuracy: 0.7634\n",
      "Epoch 849/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0472 - accuracy: 0.8481 - val_loss: 0.0740 - val_accuracy: 0.7640\n",
      "Epoch 850/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0472 - accuracy: 0.8481 - val_loss: 0.0741 - val_accuracy: 0.7618\n",
      "Epoch 851/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0472 - accuracy: 0.8482 - val_loss: 0.0730 - val_accuracy: 0.7641\n",
      "Epoch 852/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0471 - accuracy: 0.8484 - val_loss: 0.0735 - val_accuracy: 0.7640\n",
      "Epoch 853/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0472 - accuracy: 0.8482 - val_loss: 0.0738 - val_accuracy: 0.7652\n",
      "Epoch 854/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0472 - accuracy: 0.8480 - val_loss: 0.0740 - val_accuracy: 0.7634\n",
      "Epoch 855/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0471 - accuracy: 0.8484 - val_loss: 0.0745 - val_accuracy: 0.7632\n",
      "Epoch 856/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0472 - accuracy: 0.8480 - val_loss: 0.0740 - val_accuracy: 0.7639\n",
      "Epoch 857/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0471 - accuracy: 0.8480 - val_loss: 0.0731 - val_accuracy: 0.7643\n",
      "Epoch 858/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0472 - accuracy: 0.8478 - val_loss: 0.0746 - val_accuracy: 0.7634\n",
      "Epoch 859/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0472 - accuracy: 0.8477 - val_loss: 0.0734 - val_accuracy: 0.7629\n",
      "Epoch 860/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0473 - accuracy: 0.8475 - val_loss: 0.0736 - val_accuracy: 0.7637\n",
      "Epoch 861/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0473 - accuracy: 0.8477 - val_loss: 0.0731 - val_accuracy: 0.7641\n",
      "Epoch 862/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0473 - accuracy: 0.8480 - val_loss: 0.0731 - val_accuracy: 0.7625\n",
      "Epoch 863/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0473 - accuracy: 0.8482 - val_loss: 0.0738 - val_accuracy: 0.7635\n",
      "Epoch 864/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0472 - accuracy: 0.8481 - val_loss: 0.0736 - val_accuracy: 0.7650\n",
      "Epoch 865/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0473 - accuracy: 0.8479 - val_loss: 0.0730 - val_accuracy: 0.7624\n",
      "Epoch 866/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0472 - accuracy: 0.8485 - val_loss: 0.0734 - val_accuracy: 0.7636\n",
      "Epoch 867/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0473 - accuracy: 0.8485 - val_loss: 0.0737 - val_accuracy: 0.7654\n",
      "Epoch 868/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0473 - accuracy: 0.8477 - val_loss: 0.0730 - val_accuracy: 0.7642\n",
      "Epoch 869/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0472 - accuracy: 0.8481 - val_loss: 0.0728 - val_accuracy: 0.7651\n",
      "Epoch 870/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0473 - accuracy: 0.8479 - val_loss: 0.0742 - val_accuracy: 0.7645\n",
      "Epoch 871/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0473 - accuracy: 0.8479 - val_loss: 0.0743 - val_accuracy: 0.7635\n",
      "Epoch 872/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0473 - accuracy: 0.8480 - val_loss: 0.0734 - val_accuracy: 0.7625\n",
      "Epoch 873/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0472 - accuracy: 0.8478 - val_loss: 0.0728 - val_accuracy: 0.7645\n",
      "Epoch 874/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0471 - accuracy: 0.8486 - val_loss: 0.0732 - val_accuracy: 0.7631\n",
      "Epoch 875/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0473 - accuracy: 0.8476 - val_loss: 0.0747 - val_accuracy: 0.7616\n",
      "Epoch 876/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0473 - accuracy: 0.8480 - val_loss: 0.0738 - val_accuracy: 0.7610\n",
      "Epoch 877/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0472 - accuracy: 0.8482 - val_loss: 0.0736 - val_accuracy: 0.7624\n",
      "Epoch 878/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0471 - accuracy: 0.8482 - val_loss: 0.0743 - val_accuracy: 0.7619\n",
      "Epoch 879/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0472 - accuracy: 0.8483 - val_loss: 0.0730 - val_accuracy: 0.7637\n",
      "Epoch 880/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0475 - accuracy: 0.8470 - val_loss: 0.0750 - val_accuracy: 0.7613\n",
      "Epoch 881/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0473 - accuracy: 0.8479 - val_loss: 0.0731 - val_accuracy: 0.7635\n",
      "Epoch 882/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0472 - accuracy: 0.8482 - val_loss: 0.0733 - val_accuracy: 0.7645\n",
      "Epoch 883/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0471 - accuracy: 0.8487 - val_loss: 0.0740 - val_accuracy: 0.7649\n",
      "Epoch 884/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0473 - accuracy: 0.8482 - val_loss: 0.0736 - val_accuracy: 0.7642\n",
      "Epoch 885/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0472 - accuracy: 0.8483 - val_loss: 0.0744 - val_accuracy: 0.7639\n",
      "Epoch 886/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0472 - accuracy: 0.8487 - val_loss: 0.0742 - val_accuracy: 0.7639\n",
      "Epoch 887/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0471 - accuracy: 0.8485 - val_loss: 0.0749 - val_accuracy: 0.7626\n",
      "Epoch 888/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0470 - accuracy: 0.8488 - val_loss: 0.0740 - val_accuracy: 0.7648\n",
      "Epoch 889/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0473 - accuracy: 0.8477 - val_loss: 0.0743 - val_accuracy: 0.7635\n",
      "Epoch 890/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0473 - accuracy: 0.8477 - val_loss: 0.0735 - val_accuracy: 0.7653\n",
      "Epoch 891/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0474 - accuracy: 0.8474 - val_loss: 0.0733 - val_accuracy: 0.7634\n",
      "Epoch 892/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0472 - accuracy: 0.8482 - val_loss: 0.0728 - val_accuracy: 0.7655\n",
      "Epoch 893/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0472 - accuracy: 0.8480 - val_loss: 0.0728 - val_accuracy: 0.7646\n",
      "Epoch 894/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0472 - accuracy: 0.8481 - val_loss: 0.0738 - val_accuracy: 0.7630\n",
      "Epoch 895/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0471 - accuracy: 0.8486 - val_loss: 0.0735 - val_accuracy: 0.7645\n",
      "Epoch 896/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0473 - accuracy: 0.8483 - val_loss: 0.0739 - val_accuracy: 0.7634\n",
      "Epoch 897/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0472 - accuracy: 0.8486 - val_loss: 0.0742 - val_accuracy: 0.7628\n",
      "Epoch 898/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0471 - accuracy: 0.8484 - val_loss: 0.0737 - val_accuracy: 0.7619\n",
      "Epoch 899/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0473 - accuracy: 0.8480 - val_loss: 0.0744 - val_accuracy: 0.7628\n",
      "Epoch 900/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0472 - accuracy: 0.8485 - val_loss: 0.0745 - val_accuracy: 0.7654\n",
      "Epoch 901/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0471 - accuracy: 0.8485 - val_loss: 0.0736 - val_accuracy: 0.7644\n",
      "Epoch 902/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0472 - accuracy: 0.8482 - val_loss: 0.0728 - val_accuracy: 0.7651\n",
      "Epoch 903/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0474 - accuracy: 0.8479 - val_loss: 0.0744 - val_accuracy: 0.7635\n",
      "Epoch 904/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0472 - accuracy: 0.8479 - val_loss: 0.0745 - val_accuracy: 0.7629\n",
      "Epoch 905/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0472 - accuracy: 0.8480 - val_loss: 0.0741 - val_accuracy: 0.7634\n",
      "Epoch 906/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0471 - accuracy: 0.8483 - val_loss: 0.0737 - val_accuracy: 0.7605\n",
      "Epoch 907/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0472 - accuracy: 0.8484 - val_loss: 0.0737 - val_accuracy: 0.7623\n",
      "Epoch 908/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0472 - accuracy: 0.8483 - val_loss: 0.0741 - val_accuracy: 0.7628\n",
      "Epoch 909/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0472 - accuracy: 0.8479 - val_loss: 0.0738 - val_accuracy: 0.7633\n",
      "Epoch 910/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0473 - accuracy: 0.8479 - val_loss: 0.0734 - val_accuracy: 0.7642\n",
      "Epoch 911/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0472 - accuracy: 0.8485 - val_loss: 0.0749 - val_accuracy: 0.7647\n",
      "Epoch 912/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0473 - accuracy: 0.8483 - val_loss: 0.0741 - val_accuracy: 0.7626\n",
      "Epoch 913/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0474 - accuracy: 0.8479 - val_loss: 0.0738 - val_accuracy: 0.7631\n",
      "Epoch 914/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0473 - accuracy: 0.8481 - val_loss: 0.0745 - val_accuracy: 0.7635\n",
      "Epoch 915/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0474 - accuracy: 0.8477 - val_loss: 0.0739 - val_accuracy: 0.7644\n",
      "Epoch 916/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0473 - accuracy: 0.8479 - val_loss: 0.0736 - val_accuracy: 0.7638\n",
      "Epoch 917/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0473 - accuracy: 0.8481 - val_loss: 0.0727 - val_accuracy: 0.7646\n",
      "Epoch 918/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0472 - accuracy: 0.8483 - val_loss: 0.0740 - val_accuracy: 0.7612\n",
      "Epoch 919/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0473 - accuracy: 0.8481 - val_loss: 0.0735 - val_accuracy: 0.7631\n",
      "Epoch 920/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0473 - accuracy: 0.8486 - val_loss: 0.0747 - val_accuracy: 0.7629\n",
      "Epoch 921/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0473 - accuracy: 0.8482 - val_loss: 0.0729 - val_accuracy: 0.7652\n",
      "Epoch 922/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0474 - accuracy: 0.8480 - val_loss: 0.0742 - val_accuracy: 0.7623\n",
      "Epoch 923/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0474 - accuracy: 0.8479 - val_loss: 0.0741 - val_accuracy: 0.7651\n",
      "Epoch 924/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0474 - accuracy: 0.8476 - val_loss: 0.0739 - val_accuracy: 0.7638\n",
      "Epoch 925/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0474 - accuracy: 0.8477 - val_loss: 0.0748 - val_accuracy: 0.7649\n",
      "Epoch 926/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0473 - accuracy: 0.8479 - val_loss: 0.0738 - val_accuracy: 0.7647\n",
      "Epoch 927/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0472 - accuracy: 0.8484 - val_loss: 0.0744 - val_accuracy: 0.7622\n",
      "Epoch 928/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0473 - accuracy: 0.8479 - val_loss: 0.0735 - val_accuracy: 0.7635\n",
      "Epoch 929/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0472 - accuracy: 0.8483 - val_loss: 0.0742 - val_accuracy: 0.7653\n",
      "Epoch 930/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0473 - accuracy: 0.8481 - val_loss: 0.0737 - val_accuracy: 0.7640\n",
      "Epoch 931/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0473 - accuracy: 0.8480 - val_loss: 0.0739 - val_accuracy: 0.7633\n",
      "Epoch 932/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0473 - accuracy: 0.8482 - val_loss: 0.0734 - val_accuracy: 0.7642\n",
      "Epoch 933/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0473 - accuracy: 0.8480 - val_loss: 0.0738 - val_accuracy: 0.7649\n",
      "Epoch 934/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0473 - accuracy: 0.8478 - val_loss: 0.0734 - val_accuracy: 0.7638\n",
      "Epoch 935/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0473 - accuracy: 0.8479 - val_loss: 0.0746 - val_accuracy: 0.7620\n",
      "Epoch 936/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0473 - accuracy: 0.8480 - val_loss: 0.0734 - val_accuracy: 0.7629\n",
      "Epoch 937/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0473 - accuracy: 0.8482 - val_loss: 0.0727 - val_accuracy: 0.7645\n",
      "Epoch 938/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0473 - accuracy: 0.8481 - val_loss: 0.0747 - val_accuracy: 0.7641\n",
      "Epoch 939/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0474 - accuracy: 0.8475 - val_loss: 0.0737 - val_accuracy: 0.7644\n",
      "Epoch 940/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0473 - accuracy: 0.8480 - val_loss: 0.0733 - val_accuracy: 0.7644\n",
      "Epoch 941/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0473 - accuracy: 0.8480 - val_loss: 0.0739 - val_accuracy: 0.7637\n",
      "Epoch 942/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0473 - accuracy: 0.8482 - val_loss: 0.0738 - val_accuracy: 0.7645\n",
      "Epoch 943/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0474 - accuracy: 0.8477 - val_loss: 0.0739 - val_accuracy: 0.7646\n",
      "Epoch 944/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0474 - accuracy: 0.8479 - val_loss: 0.0747 - val_accuracy: 0.7652\n",
      "Epoch 945/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0474 - accuracy: 0.8480 - val_loss: 0.0739 - val_accuracy: 0.7626\n",
      "Epoch 946/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0474 - accuracy: 0.8477 - val_loss: 0.0729 - val_accuracy: 0.7648\n",
      "Epoch 947/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0474 - accuracy: 0.8479 - val_loss: 0.0733 - val_accuracy: 0.7641\n",
      "Epoch 948/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0474 - accuracy: 0.8479 - val_loss: 0.0748 - val_accuracy: 0.7641\n",
      "Epoch 949/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0474 - accuracy: 0.8477 - val_loss: 0.0737 - val_accuracy: 0.7640\n",
      "Epoch 950/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0474 - accuracy: 0.8478 - val_loss: 0.0742 - val_accuracy: 0.7639\n",
      "Epoch 951/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0475 - accuracy: 0.8473 - val_loss: 0.0741 - val_accuracy: 0.7623\n",
      "Epoch 952/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0476 - accuracy: 0.8470 - val_loss: 0.0742 - val_accuracy: 0.7640\n",
      "Epoch 953/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0474 - accuracy: 0.8479 - val_loss: 0.0741 - val_accuracy: 0.7636\n",
      "Epoch 954/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0475 - accuracy: 0.8477 - val_loss: 0.0738 - val_accuracy: 0.7635\n",
      "Epoch 955/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0474 - accuracy: 0.8481 - val_loss: 0.0743 - val_accuracy: 0.7647\n",
      "Epoch 956/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0475 - accuracy: 0.8477 - val_loss: 0.0744 - val_accuracy: 0.7649\n",
      "Epoch 957/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0475 - accuracy: 0.8477 - val_loss: 0.0745 - val_accuracy: 0.7626\n",
      "Epoch 958/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0475 - accuracy: 0.8475 - val_loss: 0.0744 - val_accuracy: 0.7643\n",
      "Epoch 959/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0475 - accuracy: 0.8477 - val_loss: 0.0735 - val_accuracy: 0.7632\n",
      "Epoch 960/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0477 - accuracy: 0.8469 - val_loss: 0.0735 - val_accuracy: 0.7632\n",
      "Epoch 961/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0475 - accuracy: 0.8476 - val_loss: 0.0749 - val_accuracy: 0.7633\n",
      "Epoch 962/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0474 - accuracy: 0.8478 - val_loss: 0.0735 - val_accuracy: 0.7639\n",
      "Epoch 963/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0474 - accuracy: 0.8479 - val_loss: 0.0743 - val_accuracy: 0.7633\n",
      "Epoch 964/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0475 - accuracy: 0.8477 - val_loss: 0.0748 - val_accuracy: 0.7646\n",
      "Epoch 965/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0474 - accuracy: 0.8478 - val_loss: 0.0737 - val_accuracy: 0.7638\n",
      "Epoch 966/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0475 - accuracy: 0.8474 - val_loss: 0.0740 - val_accuracy: 0.7645\n",
      "Epoch 967/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0475 - accuracy: 0.8474 - val_loss: 0.0746 - val_accuracy: 0.7612\n",
      "Epoch 968/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0474 - accuracy: 0.8481 - val_loss: 0.0745 - val_accuracy: 0.7656\n",
      "Epoch 969/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0474 - accuracy: 0.8480 - val_loss: 0.0754 - val_accuracy: 0.7624\n",
      "Epoch 970/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0474 - accuracy: 0.8477 - val_loss: 0.0741 - val_accuracy: 0.7607\n",
      "Epoch 971/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0474 - accuracy: 0.8480 - val_loss: 0.0748 - val_accuracy: 0.7658\n",
      "Epoch 972/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0474 - accuracy: 0.8480 - val_loss: 0.0730 - val_accuracy: 0.7630\n",
      "Epoch 973/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0475 - accuracy: 0.8477 - val_loss: 0.0744 - val_accuracy: 0.7637\n",
      "Epoch 974/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0475 - accuracy: 0.8475 - val_loss: 0.0747 - val_accuracy: 0.7632\n",
      "Epoch 975/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0473 - accuracy: 0.8484 - val_loss: 0.0750 - val_accuracy: 0.7628\n",
      "Epoch 976/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0477 - accuracy: 0.8473 - val_loss: 0.0744 - val_accuracy: 0.7628\n",
      "Epoch 977/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0475 - accuracy: 0.8477 - val_loss: 0.0742 - val_accuracy: 0.7635\n",
      "Epoch 978/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0474 - accuracy: 0.8479 - val_loss: 0.0736 - val_accuracy: 0.7653\n",
      "Epoch 979/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0475 - accuracy: 0.8472 - val_loss: 0.0731 - val_accuracy: 0.7643\n",
      "Epoch 980/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0474 - accuracy: 0.8479 - val_loss: 0.0747 - val_accuracy: 0.7629\n",
      "Epoch 981/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0474 - accuracy: 0.8477 - val_loss: 0.0743 - val_accuracy: 0.7618\n",
      "Epoch 982/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0472 - accuracy: 0.8486 - val_loss: 0.0739 - val_accuracy: 0.7644\n",
      "Epoch 983/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0474 - accuracy: 0.8482 - val_loss: 0.0742 - val_accuracy: 0.7624\n",
      "Epoch 984/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0475 - accuracy: 0.8478 - val_loss: 0.0744 - val_accuracy: 0.7645\n",
      "Epoch 985/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0475 - accuracy: 0.8475 - val_loss: 0.0739 - val_accuracy: 0.7648\n",
      "Epoch 986/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0473 - accuracy: 0.8480 - val_loss: 0.0738 - val_accuracy: 0.7632\n",
      "Epoch 987/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0475 - accuracy: 0.8476 - val_loss: 0.0741 - val_accuracy: 0.7642\n",
      "Epoch 988/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0475 - accuracy: 0.8476 - val_loss: 0.0747 - val_accuracy: 0.7623\n",
      "Epoch 989/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0476 - accuracy: 0.8477 - val_loss: 0.0734 - val_accuracy: 0.7627\n",
      "Epoch 990/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0475 - accuracy: 0.8477 - val_loss: 0.0743 - val_accuracy: 0.7635\n",
      "Epoch 991/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0475 - accuracy: 0.8475 - val_loss: 0.0751 - val_accuracy: 0.7633\n",
      "Epoch 992/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0474 - accuracy: 0.8481 - val_loss: 0.0743 - val_accuracy: 0.7638\n",
      "Epoch 993/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0475 - accuracy: 0.8477 - val_loss: 0.0752 - val_accuracy: 0.7626\n",
      "Epoch 994/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0474 - accuracy: 0.8477 - val_loss: 0.0744 - val_accuracy: 0.7645\n",
      "Epoch 995/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0473 - accuracy: 0.8478 - val_loss: 0.0734 - val_accuracy: 0.7638\n",
      "Epoch 996/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0474 - accuracy: 0.8481 - val_loss: 0.0743 - val_accuracy: 0.7638\n",
      "Epoch 997/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0474 - accuracy: 0.8479 - val_loss: 0.0744 - val_accuracy: 0.7640\n",
      "Epoch 998/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0474 - accuracy: 0.8477 - val_loss: 0.0744 - val_accuracy: 0.7630\n",
      "Epoch 999/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0477 - accuracy: 0.8472 - val_loss: 0.0748 - val_accuracy: 0.7633\n",
      "Epoch 1000/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0474 - accuracy: 0.8479 - val_loss: 0.0750 - val_accuracy: 0.7643\n",
      "Epoch 1001/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0475 - accuracy: 0.8477 - val_loss: 0.0737 - val_accuracy: 0.7640\n",
      "Epoch 1002/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0476 - accuracy: 0.8477 - val_loss: 0.0753 - val_accuracy: 0.7630\n",
      "Epoch 1003/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0474 - accuracy: 0.8476 - val_loss: 0.0751 - val_accuracy: 0.7621\n",
      "Epoch 1004/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0475 - accuracy: 0.8476 - val_loss: 0.0746 - val_accuracy: 0.7630\n",
      "Epoch 1005/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0475 - accuracy: 0.8472 - val_loss: 0.0747 - val_accuracy: 0.7634\n",
      "Epoch 1006/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0474 - accuracy: 0.8479 - val_loss: 0.0746 - val_accuracy: 0.7640\n",
      "Epoch 1007/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0474 - accuracy: 0.8482 - val_loss: 0.0744 - val_accuracy: 0.7620\n",
      "Epoch 1008/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0474 - accuracy: 0.8483 - val_loss: 0.0748 - val_accuracy: 0.7627\n",
      "Epoch 1009/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0475 - accuracy: 0.8478 - val_loss: 0.0748 - val_accuracy: 0.7638\n",
      "Epoch 1010/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0475 - accuracy: 0.8474 - val_loss: 0.0743 - val_accuracy: 0.7624\n",
      "Epoch 1011/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0477 - accuracy: 0.8472 - val_loss: 0.0743 - val_accuracy: 0.7631\n",
      "Epoch 1012/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0475 - accuracy: 0.8481 - val_loss: 0.0743 - val_accuracy: 0.7623\n",
      "Epoch 1013/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0474 - accuracy: 0.8480 - val_loss: 0.0746 - val_accuracy: 0.7631\n",
      "Epoch 1014/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0475 - accuracy: 0.8475 - val_loss: 0.0745 - val_accuracy: 0.7633\n",
      "Epoch 1015/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0476 - accuracy: 0.8472 - val_loss: 0.0739 - val_accuracy: 0.7640\n",
      "Epoch 1016/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0474 - accuracy: 0.8481 - val_loss: 0.0742 - val_accuracy: 0.7607\n",
      "Epoch 1017/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0475 - accuracy: 0.8474 - val_loss: 0.0738 - val_accuracy: 0.7626\n",
      "Epoch 1018/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0474 - accuracy: 0.8479 - val_loss: 0.0730 - val_accuracy: 0.7643\n",
      "Epoch 1019/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0475 - accuracy: 0.8476 - val_loss: 0.0744 - val_accuracy: 0.7629\n",
      "Epoch 1020/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0475 - accuracy: 0.8477 - val_loss: 0.0745 - val_accuracy: 0.7641\n",
      "Epoch 1021/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0474 - accuracy: 0.8479 - val_loss: 0.0736 - val_accuracy: 0.7637\n",
      "Epoch 1022/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0474 - accuracy: 0.8480 - val_loss: 0.0738 - val_accuracy: 0.7632\n",
      "Epoch 1023/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0475 - accuracy: 0.8480 - val_loss: 0.0745 - val_accuracy: 0.7623\n",
      "Epoch 1024/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0475 - accuracy: 0.8475 - val_loss: 0.0757 - val_accuracy: 0.7625\n",
      "Epoch 1025/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0476 - accuracy: 0.8474 - val_loss: 0.0751 - val_accuracy: 0.7627\n",
      "Epoch 1026/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0474 - accuracy: 0.8478 - val_loss: 0.0736 - val_accuracy: 0.7615\n",
      "Epoch 1027/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0474 - accuracy: 0.8480 - val_loss: 0.0746 - val_accuracy: 0.7615\n",
      "Epoch 1028/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0475 - accuracy: 0.8478 - val_loss: 0.0746 - val_accuracy: 0.7624\n",
      "Epoch 1029/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0473 - accuracy: 0.8479 - val_loss: 0.0740 - val_accuracy: 0.7636\n",
      "Epoch 1030/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0473 - accuracy: 0.8478 - val_loss: 0.0737 - val_accuracy: 0.7628\n",
      "Epoch 1031/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0473 - accuracy: 0.8482 - val_loss: 0.0733 - val_accuracy: 0.7646\n",
      "Epoch 1032/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0474 - accuracy: 0.8478 - val_loss: 0.0750 - val_accuracy: 0.7627\n",
      "Epoch 1033/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0475 - accuracy: 0.8478 - val_loss: 0.0740 - val_accuracy: 0.7638\n",
      "Epoch 1034/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0474 - accuracy: 0.8477 - val_loss: 0.0737 - val_accuracy: 0.7636\n",
      "Epoch 1035/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0475 - accuracy: 0.8474 - val_loss: 0.0746 - val_accuracy: 0.7642\n",
      "Epoch 1036/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0474 - accuracy: 0.8482 - val_loss: 0.0744 - val_accuracy: 0.7624\n",
      "Epoch 1037/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0475 - accuracy: 0.8478 - val_loss: 0.0743 - val_accuracy: 0.7635\n",
      "Epoch 1038/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0475 - accuracy: 0.8483 - val_loss: 0.0741 - val_accuracy: 0.7635\n",
      "Epoch 1039/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0475 - accuracy: 0.8479 - val_loss: 0.0737 - val_accuracy: 0.7632\n",
      "Epoch 1040/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0474 - accuracy: 0.8476 - val_loss: 0.0742 - val_accuracy: 0.7636\n",
      "Epoch 1041/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0476 - accuracy: 0.8475 - val_loss: 0.0740 - val_accuracy: 0.7633\n",
      "Epoch 1042/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0476 - accuracy: 0.8473 - val_loss: 0.0736 - val_accuracy: 0.7642\n",
      "Epoch 1043/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0475 - accuracy: 0.8474 - val_loss: 0.0739 - val_accuracy: 0.7640\n",
      "Epoch 1044/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0475 - accuracy: 0.8476 - val_loss: 0.0741 - val_accuracy: 0.7631\n",
      "Epoch 1045/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0475 - accuracy: 0.8478 - val_loss: 0.0746 - val_accuracy: 0.7616\n",
      "Epoch 1046/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0475 - accuracy: 0.8476 - val_loss: 0.0736 - val_accuracy: 0.7628\n",
      "Epoch 1047/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0475 - accuracy: 0.8476 - val_loss: 0.0744 - val_accuracy: 0.7632\n",
      "Epoch 1048/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0476 - accuracy: 0.8476 - val_loss: 0.0744 - val_accuracy: 0.7616\n",
      "Epoch 1049/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0475 - accuracy: 0.8478 - val_loss: 0.0749 - val_accuracy: 0.7621\n",
      "Epoch 1050/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0475 - accuracy: 0.8478 - val_loss: 0.0747 - val_accuracy: 0.7628\n",
      "Epoch 1051/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0475 - accuracy: 0.8476 - val_loss: 0.0743 - val_accuracy: 0.7635\n",
      "Epoch 1052/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0475 - accuracy: 0.8478 - val_loss: 0.0743 - val_accuracy: 0.7623\n",
      "Epoch 1053/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0475 - accuracy: 0.8479 - val_loss: 0.0743 - val_accuracy: 0.7632\n",
      "Epoch 1054/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0476 - accuracy: 0.8474 - val_loss: 0.0751 - val_accuracy: 0.7611\n",
      "Epoch 1055/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0476 - accuracy: 0.8472 - val_loss: 0.0740 - val_accuracy: 0.7631\n",
      "Epoch 1056/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0477 - accuracy: 0.8476 - val_loss: 0.0741 - val_accuracy: 0.7631\n",
      "Epoch 1057/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0476 - accuracy: 0.8477 - val_loss: 0.0740 - val_accuracy: 0.7617\n",
      "Epoch 1058/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0476 - accuracy: 0.8479 - val_loss: 0.0745 - val_accuracy: 0.7624\n",
      "Epoch 1059/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0475 - accuracy: 0.8479 - val_loss: 0.0736 - val_accuracy: 0.7618\n",
      "Epoch 1060/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0475 - accuracy: 0.8476 - val_loss: 0.0754 - val_accuracy: 0.7622\n",
      "Epoch 1061/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0477 - accuracy: 0.8473 - val_loss: 0.0753 - val_accuracy: 0.7629\n",
      "Epoch 1062/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0476 - accuracy: 0.8473 - val_loss: 0.0736 - val_accuracy: 0.7626\n",
      "Epoch 1063/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0477 - accuracy: 0.8474 - val_loss: 0.0748 - val_accuracy: 0.7622\n",
      "Epoch 1064/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0476 - accuracy: 0.8477 - val_loss: 0.0756 - val_accuracy: 0.7614\n",
      "Epoch 1065/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0477 - accuracy: 0.8470 - val_loss: 0.0738 - val_accuracy: 0.7635\n",
      "Epoch 1066/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0475 - accuracy: 0.8479 - val_loss: 0.0743 - val_accuracy: 0.7637\n",
      "Epoch 1067/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0475 - accuracy: 0.8479 - val_loss: 0.0753 - val_accuracy: 0.7611\n",
      "Epoch 1068/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0477 - accuracy: 0.8473 - val_loss: 0.0741 - val_accuracy: 0.7636\n",
      "Epoch 1069/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0476 - accuracy: 0.8473 - val_loss: 0.0751 - val_accuracy: 0.7618\n",
      "Epoch 1070/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0476 - accuracy: 0.8478 - val_loss: 0.0746 - val_accuracy: 0.7625\n",
      "Epoch 1071/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0476 - accuracy: 0.8480 - val_loss: 0.0755 - val_accuracy: 0.7578\n",
      "Epoch 1072/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0476 - accuracy: 0.8480 - val_loss: 0.0750 - val_accuracy: 0.7630\n",
      "Epoch 1073/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0475 - accuracy: 0.8478 - val_loss: 0.0740 - val_accuracy: 0.7624\n",
      "Epoch 1074/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0476 - accuracy: 0.8475 - val_loss: 0.0743 - val_accuracy: 0.7644\n",
      "Epoch 1075/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0475 - accuracy: 0.8480 - val_loss: 0.0736 - val_accuracy: 0.7638\n",
      "Epoch 1076/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0477 - accuracy: 0.8478 - val_loss: 0.0743 - val_accuracy: 0.7636\n",
      "Epoch 1077/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0475 - accuracy: 0.8479 - val_loss: 0.0736 - val_accuracy: 0.7627\n",
      "Epoch 1078/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0476 - accuracy: 0.8478 - val_loss: 0.0746 - val_accuracy: 0.7624\n",
      "Epoch 1079/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0477 - accuracy: 0.8473 - val_loss: 0.0745 - val_accuracy: 0.7624\n",
      "Epoch 1080/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0476 - accuracy: 0.8479 - val_loss: 0.0737 - val_accuracy: 0.7628\n",
      "Epoch 1081/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0476 - accuracy: 0.8475 - val_loss: 0.0742 - val_accuracy: 0.7635\n",
      "Epoch 1082/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0475 - accuracy: 0.8481 - val_loss: 0.0751 - val_accuracy: 0.7621\n",
      "Epoch 1083/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0477 - accuracy: 0.8470 - val_loss: 0.0740 - val_accuracy: 0.7630\n",
      "Epoch 1084/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0477 - accuracy: 0.8473 - val_loss: 0.0750 - val_accuracy: 0.7617\n",
      "Epoch 1085/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0476 - accuracy: 0.8474 - val_loss: 0.0753 - val_accuracy: 0.7624\n",
      "Epoch 1086/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0477 - accuracy: 0.8474 - val_loss: 0.0741 - val_accuracy: 0.7628\n",
      "Epoch 1087/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0477 - accuracy: 0.8469 - val_loss: 0.0751 - val_accuracy: 0.7610\n",
      "Epoch 1088/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0477 - accuracy: 0.8471 - val_loss: 0.0740 - val_accuracy: 0.7635\n",
      "Epoch 1089/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0477 - accuracy: 0.8471 - val_loss: 0.0746 - val_accuracy: 0.7622\n",
      "Epoch 1090/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0477 - accuracy: 0.8476 - val_loss: 0.0742 - val_accuracy: 0.7615\n",
      "Epoch 1091/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0478 - accuracy: 0.8470 - val_loss: 0.0750 - val_accuracy: 0.7616\n",
      "Epoch 1092/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0476 - accuracy: 0.8482 - val_loss: 0.0744 - val_accuracy: 0.7616\n",
      "Epoch 1093/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0477 - accuracy: 0.8475 - val_loss: 0.0745 - val_accuracy: 0.7612\n",
      "Epoch 1094/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0478 - accuracy: 0.8470 - val_loss: 0.0741 - val_accuracy: 0.7625\n",
      "Epoch 1095/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0479 - accuracy: 0.8470 - val_loss: 0.0742 - val_accuracy: 0.7632\n",
      "Epoch 1096/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0477 - accuracy: 0.8479 - val_loss: 0.0745 - val_accuracy: 0.7642\n",
      "Epoch 1097/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0476 - accuracy: 0.8477 - val_loss: 0.0746 - val_accuracy: 0.7616\n",
      "Epoch 1098/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0476 - accuracy: 0.8475 - val_loss: 0.0747 - val_accuracy: 0.7626\n",
      "Epoch 1099/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0477 - accuracy: 0.8475 - val_loss: 0.0742 - val_accuracy: 0.7625\n",
      "Epoch 1100/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0478 - accuracy: 0.8470 - val_loss: 0.0754 - val_accuracy: 0.7628\n",
      "Epoch 1101/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0478 - accuracy: 0.8471 - val_loss: 0.0736 - val_accuracy: 0.7630\n",
      "Epoch 1102/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0476 - accuracy: 0.8477 - val_loss: 0.0743 - val_accuracy: 0.7635\n",
      "Epoch 1103/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0479 - accuracy: 0.8471 - val_loss: 0.0748 - val_accuracy: 0.7619\n",
      "Epoch 1104/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0479 - accuracy: 0.8469 - val_loss: 0.0755 - val_accuracy: 0.7644\n",
      "Epoch 1105/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0478 - accuracy: 0.8471 - val_loss: 0.0743 - val_accuracy: 0.7638\n",
      "Epoch 1106/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0478 - accuracy: 0.8472 - val_loss: 0.0753 - val_accuracy: 0.7644\n",
      "Epoch 1107/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0479 - accuracy: 0.8471 - val_loss: 0.0748 - val_accuracy: 0.7616\n",
      "Epoch 1108/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0478 - accuracy: 0.8470 - val_loss: 0.0746 - val_accuracy: 0.7636\n",
      "Epoch 1109/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0478 - accuracy: 0.8470 - val_loss: 0.0742 - val_accuracy: 0.7620\n",
      "Epoch 1110/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0478 - accuracy: 0.8472 - val_loss: 0.0748 - val_accuracy: 0.7624\n",
      "Epoch 1111/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0478 - accuracy: 0.8472 - val_loss: 0.0740 - val_accuracy: 0.7639\n",
      "Epoch 1112/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0479 - accuracy: 0.8470 - val_loss: 0.0738 - val_accuracy: 0.7624\n",
      "Epoch 1113/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0480 - accuracy: 0.8466 - val_loss: 0.0741 - val_accuracy: 0.7619\n",
      "Epoch 1114/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0478 - accuracy: 0.8469 - val_loss: 0.0740 - val_accuracy: 0.7630\n",
      "Epoch 1115/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0478 - accuracy: 0.8475 - val_loss: 0.0751 - val_accuracy: 0.7613\n",
      "Epoch 1116/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0478 - accuracy: 0.8474 - val_loss: 0.0749 - val_accuracy: 0.7636\n",
      "Epoch 1117/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0478 - accuracy: 0.8470 - val_loss: 0.0746 - val_accuracy: 0.7629\n",
      "Epoch 1118/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0477 - accuracy: 0.8475 - val_loss: 0.0748 - val_accuracy: 0.7619\n",
      "Epoch 1119/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0478 - accuracy: 0.8472 - val_loss: 0.0748 - val_accuracy: 0.7636\n",
      "Epoch 1120/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0477 - accuracy: 0.8472 - val_loss: 0.0739 - val_accuracy: 0.7633\n",
      "Epoch 1121/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0478 - accuracy: 0.8470 - val_loss: 0.0752 - val_accuracy: 0.7617\n",
      "Epoch 1122/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0478 - accuracy: 0.8469 - val_loss: 0.0742 - val_accuracy: 0.7622\n",
      "Epoch 1123/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0478 - accuracy: 0.8474 - val_loss: 0.0753 - val_accuracy: 0.7629\n",
      "Epoch 1124/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0477 - accuracy: 0.8474 - val_loss: 0.0741 - val_accuracy: 0.7626\n",
      "Epoch 1125/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0476 - accuracy: 0.8476 - val_loss: 0.0743 - val_accuracy: 0.7610\n",
      "Epoch 1126/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0476 - accuracy: 0.8478 - val_loss: 0.0747 - val_accuracy: 0.7606\n",
      "Epoch 1127/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0477 - accuracy: 0.8473 - val_loss: 0.0745 - val_accuracy: 0.7632\n",
      "Epoch 1128/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0477 - accuracy: 0.8478 - val_loss: 0.0751 - val_accuracy: 0.7625\n",
      "Epoch 1129/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0477 - accuracy: 0.8472 - val_loss: 0.0746 - val_accuracy: 0.7633\n",
      "Epoch 1130/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0478 - accuracy: 0.8471 - val_loss: 0.0746 - val_accuracy: 0.7621\n",
      "Epoch 1131/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0478 - accuracy: 0.8474 - val_loss: 0.0748 - val_accuracy: 0.7624\n",
      "Epoch 1132/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0476 - accuracy: 0.8480 - val_loss: 0.0741 - val_accuracy: 0.7637\n",
      "Epoch 1133/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0479 - accuracy: 0.8468 - val_loss: 0.0754 - val_accuracy: 0.7609\n",
      "Epoch 1134/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0479 - accuracy: 0.8466 - val_loss: 0.0746 - val_accuracy: 0.7614\n",
      "Epoch 1135/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0479 - accuracy: 0.8472 - val_loss: 0.0751 - val_accuracy: 0.7631\n",
      "Epoch 1136/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0478 - accuracy: 0.8474 - val_loss: 0.0755 - val_accuracy: 0.7628\n",
      "Epoch 1137/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0479 - accuracy: 0.8469 - val_loss: 0.0741 - val_accuracy: 0.7628\n",
      "Epoch 1138/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0479 - accuracy: 0.8467 - val_loss: 0.0739 - val_accuracy: 0.7639\n",
      "Epoch 1139/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0478 - accuracy: 0.8471 - val_loss: 0.0746 - val_accuracy: 0.7632\n",
      "Epoch 1140/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0478 - accuracy: 0.8472 - val_loss: 0.0745 - val_accuracy: 0.7624\n",
      "Epoch 1141/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0478 - accuracy: 0.8471 - val_loss: 0.0738 - val_accuracy: 0.7641\n",
      "Epoch 1142/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0479 - accuracy: 0.8468 - val_loss: 0.0743 - val_accuracy: 0.7614\n",
      "Epoch 1143/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0478 - accuracy: 0.8471 - val_loss: 0.0743 - val_accuracy: 0.7627\n",
      "Epoch 1144/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0479 - accuracy: 0.8466 - val_loss: 0.0747 - val_accuracy: 0.7616\n",
      "Epoch 1145/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0479 - accuracy: 0.8469 - val_loss: 0.0739 - val_accuracy: 0.7624\n",
      "Epoch 1146/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0478 - accuracy: 0.8469 - val_loss: 0.0738 - val_accuracy: 0.7633\n",
      "Epoch 1147/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0478 - accuracy: 0.8472 - val_loss: 0.0743 - val_accuracy: 0.7618\n",
      "Epoch 1148/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0477 - accuracy: 0.8474 - val_loss: 0.0751 - val_accuracy: 0.7633\n",
      "Epoch 1149/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0478 - accuracy: 0.8472 - val_loss: 0.0746 - val_accuracy: 0.7617\n",
      "Epoch 1150/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0478 - accuracy: 0.8472 - val_loss: 0.0751 - val_accuracy: 0.7634\n",
      "Epoch 1151/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0478 - accuracy: 0.8471 - val_loss: 0.0755 - val_accuracy: 0.7623\n",
      "Epoch 1152/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0479 - accuracy: 0.8467 - val_loss: 0.0756 - val_accuracy: 0.7611\n",
      "Epoch 1153/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0477 - accuracy: 0.8474 - val_loss: 0.0755 - val_accuracy: 0.7629\n",
      "Epoch 1154/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0476 - accuracy: 0.8478 - val_loss: 0.0744 - val_accuracy: 0.7640\n",
      "Epoch 1155/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0478 - accuracy: 0.8473 - val_loss: 0.0751 - val_accuracy: 0.7640\n",
      "Epoch 1156/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0477 - accuracy: 0.8473 - val_loss: 0.0749 - val_accuracy: 0.7610\n",
      "Epoch 1157/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0478 - accuracy: 0.8471 - val_loss: 0.0745 - val_accuracy: 0.7621\n",
      "Epoch 1158/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0477 - accuracy: 0.8474 - val_loss: 0.0751 - val_accuracy: 0.7620\n",
      "Epoch 1159/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0480 - accuracy: 0.8466 - val_loss: 0.0749 - val_accuracy: 0.7610\n",
      "Epoch 1160/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0480 - accuracy: 0.8464 - val_loss: 0.0751 - val_accuracy: 0.7623\n",
      "Epoch 1161/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0479 - accuracy: 0.8470 - val_loss: 0.0756 - val_accuracy: 0.7621\n",
      "Epoch 1162/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0479 - accuracy: 0.8468 - val_loss: 0.0753 - val_accuracy: 0.7615\n",
      "Epoch 1163/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0478 - accuracy: 0.8475 - val_loss: 0.0758 - val_accuracy: 0.7628\n",
      "Epoch 1164/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0477 - accuracy: 0.8473 - val_loss: 0.0746 - val_accuracy: 0.7630\n",
      "Epoch 1165/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0478 - accuracy: 0.8468 - val_loss: 0.0745 - val_accuracy: 0.7625\n",
      "Epoch 1166/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0478 - accuracy: 0.8470 - val_loss: 0.0752 - val_accuracy: 0.7618\n",
      "Epoch 1167/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0478 - accuracy: 0.8471 - val_loss: 0.0753 - val_accuracy: 0.7630\n",
      "Epoch 1168/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0477 - accuracy: 0.8477 - val_loss: 0.0746 - val_accuracy: 0.7631\n",
      "Epoch 1169/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0478 - accuracy: 0.8473 - val_loss: 0.0744 - val_accuracy: 0.7631\n",
      "Epoch 1170/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0477 - accuracy: 0.8470 - val_loss: 0.0741 - val_accuracy: 0.7635\n",
      "Epoch 1171/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0477 - accuracy: 0.8476 - val_loss: 0.0743 - val_accuracy: 0.7629\n",
      "Epoch 1172/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0479 - accuracy: 0.8468 - val_loss: 0.0755 - val_accuracy: 0.7591\n",
      "Epoch 1173/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0480 - accuracy: 0.8463 - val_loss: 0.0743 - val_accuracy: 0.7629\n",
      "Epoch 1174/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0477 - accuracy: 0.8474 - val_loss: 0.0747 - val_accuracy: 0.7637\n",
      "Epoch 1175/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0477 - accuracy: 0.8478 - val_loss: 0.0750 - val_accuracy: 0.7622\n",
      "Epoch 1176/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0477 - accuracy: 0.8474 - val_loss: 0.0739 - val_accuracy: 0.7638\n",
      "Epoch 1177/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0476 - accuracy: 0.8478 - val_loss: 0.0755 - val_accuracy: 0.7638\n",
      "Epoch 1178/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0477 - accuracy: 0.8475 - val_loss: 0.0741 - val_accuracy: 0.7640\n",
      "Epoch 1179/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0478 - accuracy: 0.8467 - val_loss: 0.0744 - val_accuracy: 0.7624\n",
      "Epoch 1180/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0476 - accuracy: 0.8476 - val_loss: 0.0753 - val_accuracy: 0.7631\n",
      "Epoch 1181/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0477 - accuracy: 0.8474 - val_loss: 0.0750 - val_accuracy: 0.7615\n",
      "Epoch 1182/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0478 - accuracy: 0.8474 - val_loss: 0.0746 - val_accuracy: 0.7633\n",
      "Epoch 1183/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0479 - accuracy: 0.8468 - val_loss: 0.0751 - val_accuracy: 0.7622\n",
      "Epoch 1184/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0479 - accuracy: 0.8471 - val_loss: 0.0752 - val_accuracy: 0.7625\n",
      "Epoch 1185/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0480 - accuracy: 0.8467 - val_loss: 0.0745 - val_accuracy: 0.7638\n",
      "Epoch 1186/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0479 - accuracy: 0.8469 - val_loss: 0.0747 - val_accuracy: 0.7640\n",
      "Epoch 1187/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0478 - accuracy: 0.8470 - val_loss: 0.0745 - val_accuracy: 0.7628\n",
      "Epoch 1188/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0479 - accuracy: 0.8471 - val_loss: 0.0738 - val_accuracy: 0.7622\n",
      "Epoch 1189/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0478 - accuracy: 0.8471 - val_loss: 0.0747 - val_accuracy: 0.7636\n",
      "Epoch 1190/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0478 - accuracy: 0.8471 - val_loss: 0.0752 - val_accuracy: 0.7624\n",
      "Epoch 1191/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0478 - accuracy: 0.8471 - val_loss: 0.0751 - val_accuracy: 0.7628\n",
      "Epoch 1192/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0479 - accuracy: 0.8469 - val_loss: 0.0743 - val_accuracy: 0.7619\n",
      "Epoch 1193/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0478 - accuracy: 0.8473 - val_loss: 0.0755 - val_accuracy: 0.7610\n",
      "Epoch 1194/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0478 - accuracy: 0.8466 - val_loss: 0.0745 - val_accuracy: 0.7627\n",
      "Epoch 1195/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0479 - accuracy: 0.8469 - val_loss: 0.0742 - val_accuracy: 0.7620\n",
      "Epoch 1196/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0478 - accuracy: 0.8470 - val_loss: 0.0755 - val_accuracy: 0.7627\n",
      "Epoch 1197/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0479 - accuracy: 0.8468 - val_loss: 0.0744 - val_accuracy: 0.7625\n",
      "Epoch 1198/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0478 - accuracy: 0.8473 - val_loss: 0.0740 - val_accuracy: 0.7610\n",
      "Epoch 1199/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0480 - accuracy: 0.8469 - val_loss: 0.0757 - val_accuracy: 0.7621\n",
      "Epoch 1200/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0481 - accuracy: 0.8464 - val_loss: 0.0753 - val_accuracy: 0.7604\n",
      "Epoch 1201/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0479 - accuracy: 0.8470 - val_loss: 0.0750 - val_accuracy: 0.7609\n",
      "Epoch 1202/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0480 - accuracy: 0.8467 - val_loss: 0.0745 - val_accuracy: 0.7614\n",
      "Epoch 1203/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0479 - accuracy: 0.8467 - val_loss: 0.0753 - val_accuracy: 0.7631\n",
      "Epoch 1204/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0480 - accuracy: 0.8463 - val_loss: 0.0748 - val_accuracy: 0.7622\n",
      "Epoch 1205/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0480 - accuracy: 0.8470 - val_loss: 0.0751 - val_accuracy: 0.7632\n",
      "Epoch 1206/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0479 - accuracy: 0.8469 - val_loss: 0.0747 - val_accuracy: 0.7624\n",
      "Epoch 1207/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0480 - accuracy: 0.8468 - val_loss: 0.0748 - val_accuracy: 0.7634\n",
      "Epoch 1208/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0479 - accuracy: 0.8473 - val_loss: 0.0746 - val_accuracy: 0.7619\n",
      "Epoch 1209/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0480 - accuracy: 0.8466 - val_loss: 0.0756 - val_accuracy: 0.7631\n",
      "Epoch 1210/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0479 - accuracy: 0.8471 - val_loss: 0.0742 - val_accuracy: 0.7643\n",
      "Epoch 1211/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0480 - accuracy: 0.8468 - val_loss: 0.0765 - val_accuracy: 0.7607\n",
      "Epoch 1212/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0481 - accuracy: 0.8463 - val_loss: 0.0754 - val_accuracy: 0.7619\n",
      "Epoch 1213/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0481 - accuracy: 0.8465 - val_loss: 0.0751 - val_accuracy: 0.7614\n",
      "Epoch 1214/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0477 - accuracy: 0.8476 - val_loss: 0.0751 - val_accuracy: 0.7637\n",
      "Epoch 1215/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0480 - accuracy: 0.8468 - val_loss: 0.0757 - val_accuracy: 0.7599\n",
      "Epoch 1216/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0479 - accuracy: 0.8472 - val_loss: 0.0750 - val_accuracy: 0.7612\n",
      "Epoch 1217/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0481 - accuracy: 0.8466 - val_loss: 0.0748 - val_accuracy: 0.7624\n",
      "Epoch 1218/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0479 - accuracy: 0.8468 - val_loss: 0.0761 - val_accuracy: 0.7617\n",
      "Epoch 1219/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0481 - accuracy: 0.8464 - val_loss: 0.0755 - val_accuracy: 0.7628\n",
      "Epoch 1220/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0479 - accuracy: 0.8469 - val_loss: 0.0748 - val_accuracy: 0.7630\n",
      "Epoch 1221/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0481 - accuracy: 0.8467 - val_loss: 0.0757 - val_accuracy: 0.7628\n",
      "Epoch 1222/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0480 - accuracy: 0.8472 - val_loss: 0.0749 - val_accuracy: 0.7638\n",
      "Epoch 1223/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0481 - accuracy: 0.8463 - val_loss: 0.0758 - val_accuracy: 0.7627\n",
      "Epoch 1224/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0480 - accuracy: 0.8467 - val_loss: 0.0764 - val_accuracy: 0.7624\n",
      "Epoch 1225/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0479 - accuracy: 0.8468 - val_loss: 0.0742 - val_accuracy: 0.7632\n",
      "Epoch 1226/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0478 - accuracy: 0.8471 - val_loss: 0.0752 - val_accuracy: 0.7604\n",
      "Epoch 1227/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0481 - accuracy: 0.8460 - val_loss: 0.0751 - val_accuracy: 0.7627\n",
      "Epoch 1228/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0481 - accuracy: 0.8461 - val_loss: 0.0759 - val_accuracy: 0.7625\n",
      "Epoch 1229/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0480 - accuracy: 0.8467 - val_loss: 0.0741 - val_accuracy: 0.7634\n",
      "Epoch 1230/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0479 - accuracy: 0.8471 - val_loss: 0.0752 - val_accuracy: 0.7622\n",
      "Epoch 1231/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0480 - accuracy: 0.8465 - val_loss: 0.0743 - val_accuracy: 0.7637\n",
      "Epoch 1232/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0479 - accuracy: 0.8467 - val_loss: 0.0746 - val_accuracy: 0.7626\n",
      "Epoch 1233/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0480 - accuracy: 0.8467 - val_loss: 0.0752 - val_accuracy: 0.7622\n",
      "Epoch 1234/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0479 - accuracy: 0.8469 - val_loss: 0.0758 - val_accuracy: 0.7620\n",
      "Epoch 1235/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0480 - accuracy: 0.8465 - val_loss: 0.0760 - val_accuracy: 0.7620\n",
      "Epoch 1236/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0479 - accuracy: 0.8466 - val_loss: 0.0747 - val_accuracy: 0.7628\n",
      "Epoch 1237/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0479 - accuracy: 0.8471 - val_loss: 0.0750 - val_accuracy: 0.7611\n",
      "Epoch 1238/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0478 - accuracy: 0.8472 - val_loss: 0.0749 - val_accuracy: 0.7620\n",
      "Epoch 1239/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0481 - accuracy: 0.8464 - val_loss: 0.0745 - val_accuracy: 0.7633\n",
      "Epoch 1240/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0479 - accuracy: 0.8468 - val_loss: 0.0755 - val_accuracy: 0.7625\n",
      "Epoch 1241/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0479 - accuracy: 0.8468 - val_loss: 0.0744 - val_accuracy: 0.7631\n",
      "Epoch 1242/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0482 - accuracy: 0.8460 - val_loss: 0.0744 - val_accuracy: 0.7626\n",
      "Epoch 1243/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0479 - accuracy: 0.8471 - val_loss: 0.0753 - val_accuracy: 0.7574\n",
      "Epoch 1244/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0478 - accuracy: 0.8475 - val_loss: 0.0758 - val_accuracy: 0.7630\n",
      "Epoch 1245/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0479 - accuracy: 0.8470 - val_loss: 0.0759 - val_accuracy: 0.7622\n",
      "Epoch 1246/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0479 - accuracy: 0.8466 - val_loss: 0.0745 - val_accuracy: 0.7623\n",
      "Epoch 1247/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0479 - accuracy: 0.8466 - val_loss: 0.0747 - val_accuracy: 0.7616\n",
      "Epoch 1248/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0480 - accuracy: 0.8466 - val_loss: 0.0747 - val_accuracy: 0.7630\n",
      "Epoch 1249/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0480 - accuracy: 0.8466 - val_loss: 0.0741 - val_accuracy: 0.7627\n",
      "Epoch 1250/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0480 - accuracy: 0.8468 - val_loss: 0.0756 - val_accuracy: 0.7624\n",
      "Epoch 1251/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0480 - accuracy: 0.8465 - val_loss: 0.0754 - val_accuracy: 0.7626\n",
      "Epoch 1252/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0480 - accuracy: 0.8469 - val_loss: 0.0744 - val_accuracy: 0.7621\n",
      "Epoch 1253/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0478 - accuracy: 0.8473 - val_loss: 0.0764 - val_accuracy: 0.7610\n",
      "Epoch 1254/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0480 - accuracy: 0.8465 - val_loss: 0.0743 - val_accuracy: 0.7618\n",
      "Epoch 1255/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0480 - accuracy: 0.8471 - val_loss: 0.0745 - val_accuracy: 0.7611\n",
      "Epoch 1256/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0481 - accuracy: 0.8467 - val_loss: 0.0745 - val_accuracy: 0.7621\n",
      "Epoch 1257/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0478 - accuracy: 0.8471 - val_loss: 0.0752 - val_accuracy: 0.7631\n",
      "Epoch 1258/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0479 - accuracy: 0.8469 - val_loss: 0.0767 - val_accuracy: 0.7623\n",
      "Epoch 1259/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0479 - accuracy: 0.8468 - val_loss: 0.0750 - val_accuracy: 0.7606\n",
      "Epoch 1260/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0480 - accuracy: 0.8464 - val_loss: 0.0759 - val_accuracy: 0.7611\n",
      "Epoch 1261/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0481 - accuracy: 0.8464 - val_loss: 0.0745 - val_accuracy: 0.7625\n",
      "Epoch 1262/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0480 - accuracy: 0.8471 - val_loss: 0.0747 - val_accuracy: 0.7621\n",
      "Epoch 1263/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0481 - accuracy: 0.8463 - val_loss: 0.0748 - val_accuracy: 0.7622\n",
      "Epoch 1264/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0480 - accuracy: 0.8462 - val_loss: 0.0747 - val_accuracy: 0.7629\n",
      "Epoch 1265/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0480 - accuracy: 0.8467 - val_loss: 0.0744 - val_accuracy: 0.7623\n",
      "Epoch 1266/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0480 - accuracy: 0.8467 - val_loss: 0.0753 - val_accuracy: 0.7621\n",
      "Epoch 1267/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0480 - accuracy: 0.8468 - val_loss: 0.0750 - val_accuracy: 0.7613\n",
      "Epoch 1268/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0479 - accuracy: 0.8469 - val_loss: 0.0754 - val_accuracy: 0.7615\n",
      "Epoch 1269/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0479 - accuracy: 0.8467 - val_loss: 0.0755 - val_accuracy: 0.7611\n",
      "Epoch 1270/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0482 - accuracy: 0.8458 - val_loss: 0.0755 - val_accuracy: 0.7610\n",
      "Epoch 1271/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0478 - accuracy: 0.8472 - val_loss: 0.0745 - val_accuracy: 0.7624\n",
      "Epoch 1272/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0479 - accuracy: 0.8468 - val_loss: 0.0755 - val_accuracy: 0.7608\n",
      "Epoch 1273/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0480 - accuracy: 0.8463 - val_loss: 0.0754 - val_accuracy: 0.7623\n",
      "Epoch 1274/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0483 - accuracy: 0.8451 - val_loss: 0.0750 - val_accuracy: 0.7623\n",
      "Epoch 1275/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0480 - accuracy: 0.8467 - val_loss: 0.0748 - val_accuracy: 0.7613\n",
      "Epoch 1276/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0481 - accuracy: 0.8465 - val_loss: 0.0746 - val_accuracy: 0.7613\n",
      "Epoch 1277/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0481 - accuracy: 0.8463 - val_loss: 0.0755 - val_accuracy: 0.7609\n",
      "Epoch 1278/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0482 - accuracy: 0.8463 - val_loss: 0.0747 - val_accuracy: 0.7607\n",
      "Epoch 1279/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0481 - accuracy: 0.8460 - val_loss: 0.0739 - val_accuracy: 0.7616\n",
      "Epoch 1280/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0482 - accuracy: 0.8459 - val_loss: 0.0767 - val_accuracy: 0.7612\n",
      "Epoch 1281/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0481 - accuracy: 0.8463 - val_loss: 0.0748 - val_accuracy: 0.7622\n",
      "Epoch 1282/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0480 - accuracy: 0.8466 - val_loss: 0.0742 - val_accuracy: 0.7623\n",
      "Epoch 1283/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0481 - accuracy: 0.8464 - val_loss: 0.0748 - val_accuracy: 0.7622\n",
      "Epoch 1284/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0480 - accuracy: 0.8466 - val_loss: 0.0749 - val_accuracy: 0.7618\n",
      "Epoch 1285/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0480 - accuracy: 0.8469 - val_loss: 0.0752 - val_accuracy: 0.7609\n",
      "Epoch 1286/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0483 - accuracy: 0.8456 - val_loss: 0.0757 - val_accuracy: 0.7605\n",
      "Epoch 1287/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0482 - accuracy: 0.8462 - val_loss: 0.0748 - val_accuracy: 0.7627\n",
      "Epoch 1288/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0481 - accuracy: 0.8467 - val_loss: 0.0746 - val_accuracy: 0.7607\n",
      "Epoch 1289/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0482 - accuracy: 0.8460 - val_loss: 0.0746 - val_accuracy: 0.7600\n",
      "Epoch 1290/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0482 - accuracy: 0.8463 - val_loss: 0.0759 - val_accuracy: 0.7605\n",
      "Epoch 1291/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0483 - accuracy: 0.8456 - val_loss: 0.0760 - val_accuracy: 0.7626\n",
      "Epoch 1292/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0482 - accuracy: 0.8463 - val_loss: 0.0748 - val_accuracy: 0.7625\n",
      "Epoch 1293/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0483 - accuracy: 0.8460 - val_loss: 0.0746 - val_accuracy: 0.7631\n",
      "Epoch 1294/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0482 - accuracy: 0.8460 - val_loss: 0.0740 - val_accuracy: 0.7625\n",
      "Epoch 1295/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0482 - accuracy: 0.8466 - val_loss: 0.0755 - val_accuracy: 0.7607\n",
      "Epoch 1296/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0480 - accuracy: 0.8468 - val_loss: 0.0760 - val_accuracy: 0.7583\n",
      "Epoch 1297/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0481 - accuracy: 0.8467 - val_loss: 0.0739 - val_accuracy: 0.7616\n",
      "Epoch 1298/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0479 - accuracy: 0.8472 - val_loss: 0.0754 - val_accuracy: 0.7610\n",
      "Epoch 1299/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0481 - accuracy: 0.8466 - val_loss: 0.0762 - val_accuracy: 0.7611\n",
      "Epoch 1300/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0482 - accuracy: 0.8467 - val_loss: 0.0759 - val_accuracy: 0.7620\n",
      "Epoch 1301/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0483 - accuracy: 0.8457 - val_loss: 0.0751 - val_accuracy: 0.7611\n",
      "Epoch 1302/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0483 - accuracy: 0.8458 - val_loss: 0.0757 - val_accuracy: 0.7609\n",
      "Epoch 1303/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0481 - accuracy: 0.8464 - val_loss: 0.0749 - val_accuracy: 0.7618\n",
      "Epoch 1304/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0480 - accuracy: 0.8468 - val_loss: 0.0750 - val_accuracy: 0.7629\n",
      "Epoch 1305/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0481 - accuracy: 0.8466 - val_loss: 0.0758 - val_accuracy: 0.7610\n",
      "Epoch 1306/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0481 - accuracy: 0.8465 - val_loss: 0.0755 - val_accuracy: 0.7622\n",
      "Epoch 1307/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0481 - accuracy: 0.8463 - val_loss: 0.0749 - val_accuracy: 0.7627\n",
      "Epoch 1308/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0482 - accuracy: 0.8464 - val_loss: 0.0754 - val_accuracy: 0.7631\n",
      "Epoch 1309/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0481 - accuracy: 0.8465 - val_loss: 0.0758 - val_accuracy: 0.7614\n",
      "Epoch 1310/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0480 - accuracy: 0.8465 - val_loss: 0.0757 - val_accuracy: 0.7605\n",
      "Epoch 1311/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0481 - accuracy: 0.8464 - val_loss: 0.0748 - val_accuracy: 0.7611\n",
      "Epoch 1312/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0481 - accuracy: 0.8467 - val_loss: 0.0753 - val_accuracy: 0.7607\n",
      "Epoch 1313/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0482 - accuracy: 0.8462 - val_loss: 0.0746 - val_accuracy: 0.7624\n",
      "Epoch 1314/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0482 - accuracy: 0.8463 - val_loss: 0.0749 - val_accuracy: 0.7615\n",
      "Epoch 1315/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0482 - accuracy: 0.8463 - val_loss: 0.0756 - val_accuracy: 0.7616\n",
      "Epoch 1316/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0483 - accuracy: 0.8463 - val_loss: 0.0757 - val_accuracy: 0.7614\n",
      "Epoch 1317/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0483 - accuracy: 0.8461 - val_loss: 0.0756 - val_accuracy: 0.7557\n",
      "Epoch 1318/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0482 - accuracy: 0.8463 - val_loss: 0.0754 - val_accuracy: 0.7621\n",
      "Epoch 1319/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0482 - accuracy: 0.8461 - val_loss: 0.0746 - val_accuracy: 0.7610\n",
      "Epoch 1320/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0483 - accuracy: 0.8458 - val_loss: 0.0760 - val_accuracy: 0.7615\n",
      "Epoch 1321/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0483 - accuracy: 0.8459 - val_loss: 0.0762 - val_accuracy: 0.7595\n",
      "Epoch 1322/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0485 - accuracy: 0.8457 - val_loss: 0.0756 - val_accuracy: 0.7617\n",
      "Epoch 1323/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0483 - accuracy: 0.8463 - val_loss: 0.0746 - val_accuracy: 0.7617\n",
      "Epoch 1324/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0482 - accuracy: 0.8462 - val_loss: 0.0747 - val_accuracy: 0.7634\n",
      "Epoch 1325/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0484 - accuracy: 0.8460 - val_loss: 0.0760 - val_accuracy: 0.7619\n",
      "Epoch 1326/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0482 - accuracy: 0.8464 - val_loss: 0.0759 - val_accuracy: 0.7614\n",
      "Epoch 1327/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0483 - accuracy: 0.8459 - val_loss: 0.0763 - val_accuracy: 0.7594\n",
      "Epoch 1328/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0482 - accuracy: 0.8462 - val_loss: 0.0746 - val_accuracy: 0.7621\n",
      "Epoch 1329/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0482 - accuracy: 0.8465 - val_loss: 0.0753 - val_accuracy: 0.7629\n",
      "Epoch 1330/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0483 - accuracy: 0.8459 - val_loss: 0.0750 - val_accuracy: 0.7621\n",
      "Epoch 1331/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0483 - accuracy: 0.8457 - val_loss: 0.0757 - val_accuracy: 0.7613\n",
      "Epoch 1332/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0483 - accuracy: 0.8459 - val_loss: 0.0761 - val_accuracy: 0.7602\n",
      "Epoch 1333/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0483 - accuracy: 0.8458 - val_loss: 0.0751 - val_accuracy: 0.7614\n",
      "Epoch 1334/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0484 - accuracy: 0.8457 - val_loss: 0.0775 - val_accuracy: 0.7587\n",
      "Epoch 1335/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0483 - accuracy: 0.8456 - val_loss: 0.0752 - val_accuracy: 0.7611\n",
      "Epoch 1336/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0483 - accuracy: 0.8459 - val_loss: 0.0749 - val_accuracy: 0.7615\n",
      "Epoch 1337/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0483 - accuracy: 0.8459 - val_loss: 0.0762 - val_accuracy: 0.7581\n",
      "Epoch 1338/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0484 - accuracy: 0.8457 - val_loss: 0.0753 - val_accuracy: 0.7602\n",
      "Epoch 1339/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0483 - accuracy: 0.8459 - val_loss: 0.0757 - val_accuracy: 0.7587\n",
      "Epoch 1340/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0483 - accuracy: 0.8457 - val_loss: 0.0757 - val_accuracy: 0.7615\n",
      "Epoch 1341/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0482 - accuracy: 0.8458 - val_loss: 0.0748 - val_accuracy: 0.7593\n",
      "Epoch 1342/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0484 - accuracy: 0.8456 - val_loss: 0.0762 - val_accuracy: 0.7625\n",
      "Epoch 1343/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0482 - accuracy: 0.8464 - val_loss: 0.0752 - val_accuracy: 0.7606\n",
      "Epoch 1344/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0482 - accuracy: 0.8463 - val_loss: 0.0761 - val_accuracy: 0.7611\n",
      "Epoch 1345/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0484 - accuracy: 0.8460 - val_loss: 0.0750 - val_accuracy: 0.7616\n",
      "Epoch 1346/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0483 - accuracy: 0.8459 - val_loss: 0.0745 - val_accuracy: 0.7624\n",
      "Epoch 1347/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0485 - accuracy: 0.8452 - val_loss: 0.0760 - val_accuracy: 0.7597\n",
      "Epoch 1348/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0482 - accuracy: 0.8460 - val_loss: 0.0760 - val_accuracy: 0.7620\n",
      "Epoch 1349/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0483 - accuracy: 0.8463 - val_loss: 0.0749 - val_accuracy: 0.7615\n",
      "Epoch 1350/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0484 - accuracy: 0.8456 - val_loss: 0.0761 - val_accuracy: 0.7608\n",
      "Epoch 1351/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0483 - accuracy: 0.8459 - val_loss: 0.0748 - val_accuracy: 0.7626\n",
      "Epoch 1352/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0482 - accuracy: 0.8464 - val_loss: 0.0754 - val_accuracy: 0.7625\n",
      "Epoch 1353/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0483 - accuracy: 0.8461 - val_loss: 0.0746 - val_accuracy: 0.7624\n",
      "Epoch 1354/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0483 - accuracy: 0.8460 - val_loss: 0.0750 - val_accuracy: 0.7604\n",
      "Epoch 1355/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0484 - accuracy: 0.8453 - val_loss: 0.0741 - val_accuracy: 0.7622\n",
      "Epoch 1356/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0484 - accuracy: 0.8456 - val_loss: 0.0761 - val_accuracy: 0.7591\n",
      "Epoch 1357/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0485 - accuracy: 0.8454 - val_loss: 0.0761 - val_accuracy: 0.7585\n",
      "Epoch 1358/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0484 - accuracy: 0.8455 - val_loss: 0.0763 - val_accuracy: 0.7602\n",
      "Epoch 1359/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0484 - accuracy: 0.8454 - val_loss: 0.0771 - val_accuracy: 0.7603\n",
      "Epoch 1360/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0482 - accuracy: 0.8458 - val_loss: 0.0757 - val_accuracy: 0.7617\n",
      "Epoch 1361/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0484 - accuracy: 0.8455 - val_loss: 0.0757 - val_accuracy: 0.7614\n",
      "Epoch 1362/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0484 - accuracy: 0.8457 - val_loss: 0.0755 - val_accuracy: 0.7610\n",
      "Epoch 1363/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0482 - accuracy: 0.8459 - val_loss: 0.0758 - val_accuracy: 0.7619\n",
      "Epoch 1364/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0483 - accuracy: 0.8460 - val_loss: 0.0748 - val_accuracy: 0.7627\n",
      "Epoch 1365/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0483 - accuracy: 0.8462 - val_loss: 0.0753 - val_accuracy: 0.7613\n",
      "Epoch 1366/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0483 - accuracy: 0.8458 - val_loss: 0.0753 - val_accuracy: 0.7614\n",
      "Epoch 1367/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0483 - accuracy: 0.8458 - val_loss: 0.0747 - val_accuracy: 0.7622\n",
      "Epoch 1368/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0484 - accuracy: 0.8453 - val_loss: 0.0755 - val_accuracy: 0.7614\n",
      "Epoch 1369/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0485 - accuracy: 0.8453 - val_loss: 0.0762 - val_accuracy: 0.7593\n",
      "Epoch 1370/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0485 - accuracy: 0.8453 - val_loss: 0.0763 - val_accuracy: 0.7611\n",
      "Epoch 1371/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0486 - accuracy: 0.8453 - val_loss: 0.0740 - val_accuracy: 0.7612\n",
      "Epoch 1372/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0487 - accuracy: 0.8447 - val_loss: 0.0758 - val_accuracy: 0.7593\n",
      "Epoch 1373/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0486 - accuracy: 0.8449 - val_loss: 0.0758 - val_accuracy: 0.7614\n",
      "Epoch 1374/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0486 - accuracy: 0.8447 - val_loss: 0.0758 - val_accuracy: 0.7593\n",
      "Epoch 1375/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0483 - accuracy: 0.8457 - val_loss: 0.0752 - val_accuracy: 0.7619\n",
      "Epoch 1376/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0484 - accuracy: 0.8458 - val_loss: 0.0753 - val_accuracy: 0.7601\n",
      "Epoch 1377/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0484 - accuracy: 0.8454 - val_loss: 0.0750 - val_accuracy: 0.7608\n",
      "Epoch 1378/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0483 - accuracy: 0.8460 - val_loss: 0.0765 - val_accuracy: 0.7615\n",
      "Epoch 1379/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0486 - accuracy: 0.8447 - val_loss: 0.0765 - val_accuracy: 0.7606\n",
      "Epoch 1380/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0484 - accuracy: 0.8457 - val_loss: 0.0748 - val_accuracy: 0.7602\n",
      "Epoch 1381/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0483 - accuracy: 0.8458 - val_loss: 0.0758 - val_accuracy: 0.7616\n",
      "Epoch 1382/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0487 - accuracy: 0.8446 - val_loss: 0.0758 - val_accuracy: 0.7607\n",
      "Epoch 1383/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0487 - accuracy: 0.8445 - val_loss: 0.0753 - val_accuracy: 0.7605\n",
      "Epoch 1384/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0483 - accuracy: 0.8461 - val_loss: 0.0755 - val_accuracy: 0.7617\n",
      "Epoch 1385/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0483 - accuracy: 0.8463 - val_loss: 0.0753 - val_accuracy: 0.7610\n",
      "Epoch 1386/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0484 - accuracy: 0.8456 - val_loss: 0.0749 - val_accuracy: 0.7605\n",
      "Epoch 1387/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0484 - accuracy: 0.8452 - val_loss: 0.0749 - val_accuracy: 0.7613\n",
      "Epoch 1388/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0484 - accuracy: 0.8453 - val_loss: 0.0753 - val_accuracy: 0.7619\n",
      "Epoch 1389/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0483 - accuracy: 0.8457 - val_loss: 0.0756 - val_accuracy: 0.7596\n",
      "Epoch 1390/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0485 - accuracy: 0.8453 - val_loss: 0.0754 - val_accuracy: 0.7594\n",
      "Epoch 1391/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0485 - accuracy: 0.8451 - val_loss: 0.0763 - val_accuracy: 0.7619\n",
      "Epoch 1392/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0485 - accuracy: 0.8455 - val_loss: 0.0747 - val_accuracy: 0.7615\n",
      "Epoch 1393/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0486 - accuracy: 0.8449 - val_loss: 0.0763 - val_accuracy: 0.7600\n",
      "Epoch 1394/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0486 - accuracy: 0.8453 - val_loss: 0.0761 - val_accuracy: 0.7602\n",
      "Epoch 1395/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0486 - accuracy: 0.8449 - val_loss: 0.0752 - val_accuracy: 0.7610\n",
      "Epoch 1396/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0486 - accuracy: 0.8456 - val_loss: 0.0759 - val_accuracy: 0.7608\n",
      "Epoch 1397/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0485 - accuracy: 0.8455 - val_loss: 0.0759 - val_accuracy: 0.7606\n",
      "Epoch 1398/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0486 - accuracy: 0.8453 - val_loss: 0.0760 - val_accuracy: 0.7614\n",
      "Epoch 1399/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0486 - accuracy: 0.8452 - val_loss: 0.0754 - val_accuracy: 0.7607\n",
      "Epoch 1400/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0484 - accuracy: 0.8459 - val_loss: 0.0764 - val_accuracy: 0.7615\n",
      "Epoch 1401/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0484 - accuracy: 0.8458 - val_loss: 0.0748 - val_accuracy: 0.7621\n",
      "Epoch 1402/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0486 - accuracy: 0.8455 - val_loss: 0.0760 - val_accuracy: 0.7608\n",
      "Epoch 1403/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0487 - accuracy: 0.8450 - val_loss: 0.0754 - val_accuracy: 0.7602\n",
      "Epoch 1404/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0487 - accuracy: 0.8451 - val_loss: 0.0757 - val_accuracy: 0.7602\n",
      "Epoch 1405/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0487 - accuracy: 0.8448 - val_loss: 0.0752 - val_accuracy: 0.7596\n",
      "Epoch 1406/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0485 - accuracy: 0.8456 - val_loss: 0.0758 - val_accuracy: 0.7585\n",
      "Epoch 1407/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0488 - accuracy: 0.8444 - val_loss: 0.0763 - val_accuracy: 0.7598\n",
      "Epoch 1408/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0486 - accuracy: 0.8451 - val_loss: 0.0754 - val_accuracy: 0.7617\n",
      "Epoch 1409/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0486 - accuracy: 0.8451 - val_loss: 0.0756 - val_accuracy: 0.7617\n",
      "Epoch 1410/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0485 - accuracy: 0.8457 - val_loss: 0.0760 - val_accuracy: 0.7602\n",
      "Epoch 1411/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0485 - accuracy: 0.8457 - val_loss: 0.0747 - val_accuracy: 0.7618\n",
      "Epoch 1412/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0484 - accuracy: 0.8459 - val_loss: 0.0755 - val_accuracy: 0.7607\n",
      "Epoch 1413/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0488 - accuracy: 0.8443 - val_loss: 0.0776 - val_accuracy: 0.7599\n",
      "Epoch 1414/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0487 - accuracy: 0.8449 - val_loss: 0.0750 - val_accuracy: 0.7609\n",
      "Epoch 1415/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0484 - accuracy: 0.8455 - val_loss: 0.0752 - val_accuracy: 0.7599\n",
      "Epoch 1416/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0485 - accuracy: 0.8452 - val_loss: 0.0754 - val_accuracy: 0.7595\n",
      "Epoch 1417/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0485 - accuracy: 0.8455 - val_loss: 0.0761 - val_accuracy: 0.7563\n",
      "Epoch 1418/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0485 - accuracy: 0.8452 - val_loss: 0.0749 - val_accuracy: 0.7626\n",
      "Epoch 1419/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0484 - accuracy: 0.8459 - val_loss: 0.0745 - val_accuracy: 0.7617\n",
      "Epoch 1420/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0485 - accuracy: 0.8457 - val_loss: 0.0756 - val_accuracy: 0.7614\n",
      "Epoch 1421/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0485 - accuracy: 0.8458 - val_loss: 0.0761 - val_accuracy: 0.7598\n",
      "Epoch 1422/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0485 - accuracy: 0.8456 - val_loss: 0.0758 - val_accuracy: 0.7615\n",
      "Epoch 1423/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0485 - accuracy: 0.8457 - val_loss: 0.0763 - val_accuracy: 0.7612\n",
      "Epoch 1424/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0485 - accuracy: 0.8455 - val_loss: 0.0755 - val_accuracy: 0.7610\n",
      "Epoch 1425/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0486 - accuracy: 0.8451 - val_loss: 0.0760 - val_accuracy: 0.7632\n",
      "Epoch 1426/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0484 - accuracy: 0.8460 - val_loss: 0.0755 - val_accuracy: 0.7610\n",
      "Epoch 1427/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0485 - accuracy: 0.8457 - val_loss: 0.0762 - val_accuracy: 0.7619\n",
      "Epoch 1428/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0484 - accuracy: 0.8460 - val_loss: 0.0753 - val_accuracy: 0.7593\n",
      "Epoch 1429/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0485 - accuracy: 0.8455 - val_loss: 0.0758 - val_accuracy: 0.7594\n",
      "Epoch 1430/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0485 - accuracy: 0.8456 - val_loss: 0.0765 - val_accuracy: 0.7609\n",
      "Epoch 1431/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0486 - accuracy: 0.8452 - val_loss: 0.0758 - val_accuracy: 0.7577\n",
      "Epoch 1432/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0486 - accuracy: 0.8458 - val_loss: 0.0754 - val_accuracy: 0.7613\n",
      "Epoch 1433/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0486 - accuracy: 0.8448 - val_loss: 0.0756 - val_accuracy: 0.7607\n",
      "Epoch 1434/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0486 - accuracy: 0.8452 - val_loss: 0.0757 - val_accuracy: 0.7603\n",
      "Epoch 1435/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0485 - accuracy: 0.8454 - val_loss: 0.0751 - val_accuracy: 0.7608\n",
      "Epoch 1436/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0485 - accuracy: 0.8458 - val_loss: 0.0763 - val_accuracy: 0.7602\n",
      "Epoch 1437/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0487 - accuracy: 0.8454 - val_loss: 0.0760 - val_accuracy: 0.7606\n",
      "Epoch 1438/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0485 - accuracy: 0.8456 - val_loss: 0.0752 - val_accuracy: 0.7603\n",
      "Epoch 1439/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0485 - accuracy: 0.8455 - val_loss: 0.0751 - val_accuracy: 0.7607\n",
      "Epoch 1440/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0485 - accuracy: 0.8454 - val_loss: 0.0762 - val_accuracy: 0.7598\n",
      "Epoch 1441/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0486 - accuracy: 0.8454 - val_loss: 0.0762 - val_accuracy: 0.7600\n",
      "Epoch 1442/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0485 - accuracy: 0.8458 - val_loss: 0.0760 - val_accuracy: 0.7585\n",
      "Epoch 1443/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0487 - accuracy: 0.8453 - val_loss: 0.0754 - val_accuracy: 0.7601\n",
      "Epoch 1444/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0485 - accuracy: 0.8454 - val_loss: 0.0769 - val_accuracy: 0.7591\n",
      "Epoch 1445/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0488 - accuracy: 0.8449 - val_loss: 0.0758 - val_accuracy: 0.7604\n",
      "Epoch 1446/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0488 - accuracy: 0.8447 - val_loss: 0.0757 - val_accuracy: 0.7605\n",
      "Epoch 1447/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0487 - accuracy: 0.8449 - val_loss: 0.0754 - val_accuracy: 0.7611\n",
      "Epoch 1448/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0487 - accuracy: 0.8447 - val_loss: 0.0762 - val_accuracy: 0.7596\n",
      "Epoch 1449/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0486 - accuracy: 0.8456 - val_loss: 0.0763 - val_accuracy: 0.7595\n",
      "Epoch 1450/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0487 - accuracy: 0.8449 - val_loss: 0.0771 - val_accuracy: 0.7596\n",
      "Epoch 1451/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0487 - accuracy: 0.8450 - val_loss: 0.0759 - val_accuracy: 0.7612\n",
      "Epoch 1452/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0489 - accuracy: 0.8443 - val_loss: 0.0766 - val_accuracy: 0.7596\n",
      "Epoch 1453/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0487 - accuracy: 0.8450 - val_loss: 0.0762 - val_accuracy: 0.7604\n",
      "Epoch 1454/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0488 - accuracy: 0.8446 - val_loss: 0.0759 - val_accuracy: 0.7600\n",
      "Epoch 1455/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0488 - accuracy: 0.8451 - val_loss: 0.0752 - val_accuracy: 0.7609\n",
      "Epoch 1456/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0487 - accuracy: 0.8453 - val_loss: 0.0762 - val_accuracy: 0.7595\n",
      "Epoch 1457/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0488 - accuracy: 0.8447 - val_loss: 0.0761 - val_accuracy: 0.7606\n",
      "Epoch 1458/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0490 - accuracy: 0.8443 - val_loss: 0.0758 - val_accuracy: 0.7586\n",
      "Epoch 1459/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0490 - accuracy: 0.8444 - val_loss: 0.0764 - val_accuracy: 0.7596\n",
      "Epoch 1460/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0488 - accuracy: 0.8448 - val_loss: 0.0759 - val_accuracy: 0.7606\n",
      "Epoch 1461/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0488 - accuracy: 0.8450 - val_loss: 0.0767 - val_accuracy: 0.7602\n",
      "Epoch 1462/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0488 - accuracy: 0.8447 - val_loss: 0.0770 - val_accuracy: 0.7604\n",
      "Epoch 1463/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0489 - accuracy: 0.8445 - val_loss: 0.0761 - val_accuracy: 0.7604\n",
      "Epoch 1464/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0486 - accuracy: 0.8455 - val_loss: 0.0762 - val_accuracy: 0.7601\n",
      "Epoch 1465/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0487 - accuracy: 0.8454 - val_loss: 0.0760 - val_accuracy: 0.7597\n",
      "Epoch 1466/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0486 - accuracy: 0.8454 - val_loss: 0.0765 - val_accuracy: 0.7599\n",
      "Epoch 1467/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0487 - accuracy: 0.8456 - val_loss: 0.0754 - val_accuracy: 0.7603\n",
      "Epoch 1468/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0486 - accuracy: 0.8453 - val_loss: 0.0763 - val_accuracy: 0.7594\n",
      "Epoch 1469/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0488 - accuracy: 0.8448 - val_loss: 0.0746 - val_accuracy: 0.7623\n",
      "Epoch 1470/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0488 - accuracy: 0.8444 - val_loss: 0.0752 - val_accuracy: 0.7600\n",
      "Epoch 1471/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0487 - accuracy: 0.8450 - val_loss: 0.0765 - val_accuracy: 0.7602\n",
      "Epoch 1472/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0489 - accuracy: 0.8444 - val_loss: 0.0750 - val_accuracy: 0.7614\n",
      "Epoch 1473/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0487 - accuracy: 0.8450 - val_loss: 0.0753 - val_accuracy: 0.7602\n",
      "Epoch 1474/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0485 - accuracy: 0.8455 - val_loss: 0.0753 - val_accuracy: 0.7602\n",
      "Epoch 1475/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0488 - accuracy: 0.8449 - val_loss: 0.0767 - val_accuracy: 0.7570\n",
      "Epoch 1476/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0488 - accuracy: 0.8447 - val_loss: 0.0770 - val_accuracy: 0.7597\n",
      "Epoch 1477/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0488 - accuracy: 0.8447 - val_loss: 0.0767 - val_accuracy: 0.7588\n",
      "Epoch 1478/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0488 - accuracy: 0.8448 - val_loss: 0.0757 - val_accuracy: 0.7605\n",
      "Epoch 1479/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0488 - accuracy: 0.8448 - val_loss: 0.0760 - val_accuracy: 0.7600\n",
      "Epoch 1480/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0488 - accuracy: 0.8447 - val_loss: 0.0762 - val_accuracy: 0.7591\n",
      "Epoch 1481/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0487 - accuracy: 0.8453 - val_loss: 0.0760 - val_accuracy: 0.7611\n",
      "Epoch 1482/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0488 - accuracy: 0.8449 - val_loss: 0.0754 - val_accuracy: 0.7612\n",
      "Epoch 1483/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0488 - accuracy: 0.8444 - val_loss: 0.0751 - val_accuracy: 0.7604\n",
      "Epoch 1484/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0489 - accuracy: 0.8447 - val_loss: 0.0762 - val_accuracy: 0.7589\n",
      "Epoch 1485/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0489 - accuracy: 0.8446 - val_loss: 0.0761 - val_accuracy: 0.7599\n",
      "Epoch 1486/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0488 - accuracy: 0.8450 - val_loss: 0.0758 - val_accuracy: 0.7594\n",
      "Epoch 1487/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0487 - accuracy: 0.8451 - val_loss: 0.0763 - val_accuracy: 0.7586\n",
      "Epoch 1488/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0489 - accuracy: 0.8444 - val_loss: 0.0774 - val_accuracy: 0.7589\n",
      "Epoch 1489/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0486 - accuracy: 0.8453 - val_loss: 0.0763 - val_accuracy: 0.7604\n",
      "Epoch 1490/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0485 - accuracy: 0.8457 - val_loss: 0.0766 - val_accuracy: 0.7605\n",
      "Epoch 1491/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0488 - accuracy: 0.8450 - val_loss: 0.0761 - val_accuracy: 0.7584\n",
      "Epoch 1492/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0487 - accuracy: 0.8448 - val_loss: 0.0762 - val_accuracy: 0.7582\n",
      "Epoch 1493/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0489 - accuracy: 0.8447 - val_loss: 0.0772 - val_accuracy: 0.7576\n",
      "Epoch 1494/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0488 - accuracy: 0.8450 - val_loss: 0.0764 - val_accuracy: 0.7593\n",
      "Epoch 1495/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0489 - accuracy: 0.8449 - val_loss: 0.0771 - val_accuracy: 0.7577\n",
      "Epoch 1496/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0490 - accuracy: 0.8442 - val_loss: 0.0757 - val_accuracy: 0.7594\n",
      "Epoch 1497/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0491 - accuracy: 0.8441 - val_loss: 0.0761 - val_accuracy: 0.7604\n",
      "Epoch 1498/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0490 - accuracy: 0.8443 - val_loss: 0.0764 - val_accuracy: 0.7595\n",
      "Epoch 1499/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0490 - accuracy: 0.8443 - val_loss: 0.0761 - val_accuracy: 0.7587\n",
      "Epoch 1500/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0489 - accuracy: 0.8444 - val_loss: 0.0749 - val_accuracy: 0.7608\n",
      "Epoch 1501/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0489 - accuracy: 0.8447 - val_loss: 0.0765 - val_accuracy: 0.7593\n",
      "Epoch 1502/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0489 - accuracy: 0.8448 - val_loss: 0.0766 - val_accuracy: 0.7593\n",
      "Epoch 1503/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0488 - accuracy: 0.8449 - val_loss: 0.0760 - val_accuracy: 0.7576\n",
      "Epoch 1504/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0488 - accuracy: 0.8446 - val_loss: 0.0753 - val_accuracy: 0.7600\n",
      "Epoch 1505/5000\n",
      "11786/11786 [==============================] - 8s 718us/step - loss: 0.0487 - accuracy: 0.8453 - val_loss: 0.0762 - val_accuracy: 0.7589\n",
      "Epoch 1506/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0488 - accuracy: 0.8451 - val_loss: 0.0756 - val_accuracy: 0.7603\n",
      "Epoch 1507/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0487 - accuracy: 0.8453 - val_loss: 0.0759 - val_accuracy: 0.7602\n",
      "Epoch 1508/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0488 - accuracy: 0.8446 - val_loss: 0.0760 - val_accuracy: 0.7600\n",
      "Epoch 1509/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0489 - accuracy: 0.8444 - val_loss: 0.0759 - val_accuracy: 0.7573\n",
      "Epoch 1510/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0487 - accuracy: 0.8451 - val_loss: 0.0764 - val_accuracy: 0.7596\n",
      "Epoch 1511/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0493 - accuracy: 0.8434 - val_loss: 0.0777 - val_accuracy: 0.7567\n",
      "Epoch 1512/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0489 - accuracy: 0.8444 - val_loss: 0.0758 - val_accuracy: 0.7610\n",
      "Epoch 1513/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0489 - accuracy: 0.8446 - val_loss: 0.0759 - val_accuracy: 0.7590\n",
      "Epoch 1514/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0488 - accuracy: 0.8449 - val_loss: 0.0768 - val_accuracy: 0.7603\n",
      "Epoch 1515/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0489 - accuracy: 0.8442 - val_loss: 0.0770 - val_accuracy: 0.7593\n",
      "Epoch 1516/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0488 - accuracy: 0.8448 - val_loss: 0.0756 - val_accuracy: 0.7597\n",
      "Epoch 1517/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0490 - accuracy: 0.8443 - val_loss: 0.0762 - val_accuracy: 0.7603\n",
      "Epoch 1518/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0489 - accuracy: 0.8447 - val_loss: 0.0761 - val_accuracy: 0.7593\n",
      "Epoch 1519/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0490 - accuracy: 0.8443 - val_loss: 0.0770 - val_accuracy: 0.7583\n",
      "Epoch 1520/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0489 - accuracy: 0.8448 - val_loss: 0.0761 - val_accuracy: 0.7601\n",
      "Epoch 1521/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0489 - accuracy: 0.8447 - val_loss: 0.0764 - val_accuracy: 0.7591\n",
      "Epoch 1522/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0489 - accuracy: 0.8445 - val_loss: 0.0780 - val_accuracy: 0.7585\n",
      "Epoch 1523/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0488 - accuracy: 0.8447 - val_loss: 0.0768 - val_accuracy: 0.7576\n",
      "Epoch 1524/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0488 - accuracy: 0.8448 - val_loss: 0.0766 - val_accuracy: 0.7599\n",
      "Epoch 1525/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0489 - accuracy: 0.8443 - val_loss: 0.0758 - val_accuracy: 0.7599\n",
      "Epoch 1526/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0489 - accuracy: 0.8446 - val_loss: 0.0757 - val_accuracy: 0.7596\n",
      "Epoch 1527/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0490 - accuracy: 0.8442 - val_loss: 0.0757 - val_accuracy: 0.7608\n",
      "Epoch 1528/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0490 - accuracy: 0.8440 - val_loss: 0.0774 - val_accuracy: 0.7563\n",
      "Epoch 1529/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0490 - accuracy: 0.8439 - val_loss: 0.0758 - val_accuracy: 0.7606\n",
      "Epoch 1530/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0488 - accuracy: 0.8449 - val_loss: 0.0766 - val_accuracy: 0.7595\n",
      "Epoch 1531/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0490 - accuracy: 0.8443 - val_loss: 0.0755 - val_accuracy: 0.7595\n",
      "Epoch 1532/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0490 - accuracy: 0.8440 - val_loss: 0.0760 - val_accuracy: 0.7600\n",
      "Epoch 1533/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0492 - accuracy: 0.8433 - val_loss: 0.0766 - val_accuracy: 0.7581\n",
      "Epoch 1534/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0492 - accuracy: 0.8436 - val_loss: 0.0780 - val_accuracy: 0.7575\n",
      "Epoch 1535/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0495 - accuracy: 0.8430 - val_loss: 0.0775 - val_accuracy: 0.7590\n",
      "Epoch 1536/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0492 - accuracy: 0.8437 - val_loss: 0.0765 - val_accuracy: 0.7591\n",
      "Epoch 1537/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0491 - accuracy: 0.8438 - val_loss: 0.0758 - val_accuracy: 0.7594\n",
      "Epoch 1538/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0489 - accuracy: 0.8446 - val_loss: 0.0762 - val_accuracy: 0.7603\n",
      "Epoch 1539/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0490 - accuracy: 0.8443 - val_loss: 0.0760 - val_accuracy: 0.7571\n",
      "Epoch 1540/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0490 - accuracy: 0.8441 - val_loss: 0.0750 - val_accuracy: 0.7600\n",
      "Epoch 1541/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0491 - accuracy: 0.8438 - val_loss: 0.0770 - val_accuracy: 0.7580\n",
      "Epoch 1542/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0491 - accuracy: 0.8442 - val_loss: 0.0756 - val_accuracy: 0.7592\n",
      "Epoch 1543/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0490 - accuracy: 0.8443 - val_loss: 0.0761 - val_accuracy: 0.7603\n",
      "Epoch 1544/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0490 - accuracy: 0.8440 - val_loss: 0.0764 - val_accuracy: 0.7596\n",
      "Epoch 1545/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0489 - accuracy: 0.8447 - val_loss: 0.0762 - val_accuracy: 0.7601\n",
      "Epoch 1546/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0490 - accuracy: 0.8442 - val_loss: 0.0770 - val_accuracy: 0.7591\n",
      "Epoch 1547/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0491 - accuracy: 0.8443 - val_loss: 0.0767 - val_accuracy: 0.7575\n",
      "Epoch 1548/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0491 - accuracy: 0.8445 - val_loss: 0.0759 - val_accuracy: 0.7570\n",
      "Epoch 1549/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0491 - accuracy: 0.8443 - val_loss: 0.0780 - val_accuracy: 0.7574\n",
      "Epoch 1550/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0490 - accuracy: 0.8446 - val_loss: 0.0767 - val_accuracy: 0.7565\n",
      "Epoch 1551/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0491 - accuracy: 0.8440 - val_loss: 0.0765 - val_accuracy: 0.7594\n",
      "Epoch 1552/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0492 - accuracy: 0.8434 - val_loss: 0.0770 - val_accuracy: 0.7593\n",
      "Epoch 1553/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0492 - accuracy: 0.8437 - val_loss: 0.0768 - val_accuracy: 0.7597\n",
      "Epoch 1554/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0491 - accuracy: 0.8438 - val_loss: 0.0764 - val_accuracy: 0.7584\n",
      "Epoch 1555/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0491 - accuracy: 0.8441 - val_loss: 0.0768 - val_accuracy: 0.7571\n",
      "Epoch 1556/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0490 - accuracy: 0.8440 - val_loss: 0.0759 - val_accuracy: 0.7595\n",
      "Epoch 1557/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0491 - accuracy: 0.8441 - val_loss: 0.0771 - val_accuracy: 0.7593\n",
      "Epoch 1558/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0491 - accuracy: 0.8437 - val_loss: 0.0763 - val_accuracy: 0.7584\n",
      "Epoch 1559/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0490 - accuracy: 0.8444 - val_loss: 0.0757 - val_accuracy: 0.7585\n",
      "Epoch 1560/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0491 - accuracy: 0.8440 - val_loss: 0.0765 - val_accuracy: 0.7578\n",
      "Epoch 1561/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0492 - accuracy: 0.8437 - val_loss: 0.0771 - val_accuracy: 0.7586\n",
      "Epoch 1562/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0492 - accuracy: 0.8438 - val_loss: 0.0756 - val_accuracy: 0.7589\n",
      "Epoch 1563/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0491 - accuracy: 0.8439 - val_loss: 0.0758 - val_accuracy: 0.7588\n",
      "Epoch 1564/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0490 - accuracy: 0.8443 - val_loss: 0.0759 - val_accuracy: 0.7600\n",
      "Epoch 1565/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0490 - accuracy: 0.8444 - val_loss: 0.0777 - val_accuracy: 0.7568\n",
      "Epoch 1566/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0492 - accuracy: 0.8435 - val_loss: 0.0769 - val_accuracy: 0.7596\n",
      "Epoch 1567/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0491 - accuracy: 0.8440 - val_loss: 0.0764 - val_accuracy: 0.7599\n",
      "Epoch 1568/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0491 - accuracy: 0.8441 - val_loss: 0.0769 - val_accuracy: 0.7580\n",
      "Epoch 1569/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0491 - accuracy: 0.8439 - val_loss: 0.0763 - val_accuracy: 0.7591\n",
      "Epoch 1570/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0490 - accuracy: 0.8443 - val_loss: 0.0765 - val_accuracy: 0.7583\n",
      "Epoch 1571/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0490 - accuracy: 0.8444 - val_loss: 0.0759 - val_accuracy: 0.7581\n",
      "Epoch 1572/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0491 - accuracy: 0.8441 - val_loss: 0.0765 - val_accuracy: 0.7589\n",
      "Epoch 1573/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0490 - accuracy: 0.8445 - val_loss: 0.0761 - val_accuracy: 0.7587\n",
      "Epoch 1574/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0490 - accuracy: 0.8446 - val_loss: 0.0764 - val_accuracy: 0.7603\n",
      "Epoch 1575/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0491 - accuracy: 0.8438 - val_loss: 0.0770 - val_accuracy: 0.7609\n",
      "Epoch 1576/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0491 - accuracy: 0.8439 - val_loss: 0.0758 - val_accuracy: 0.7585\n",
      "Epoch 1577/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0491 - accuracy: 0.8444 - val_loss: 0.0757 - val_accuracy: 0.7596\n",
      "Epoch 1578/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0490 - accuracy: 0.8441 - val_loss: 0.0771 - val_accuracy: 0.7600\n",
      "Epoch 1579/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0491 - accuracy: 0.8443 - val_loss: 0.0761 - val_accuracy: 0.7593\n",
      "Epoch 1580/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0492 - accuracy: 0.8437 - val_loss: 0.0769 - val_accuracy: 0.7576\n",
      "Epoch 1581/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0491 - accuracy: 0.8440 - val_loss: 0.0764 - val_accuracy: 0.7600\n",
      "Epoch 1582/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0492 - accuracy: 0.8440 - val_loss: 0.0770 - val_accuracy: 0.7593\n",
      "Epoch 1583/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0491 - accuracy: 0.8439 - val_loss: 0.0774 - val_accuracy: 0.7585\n",
      "Epoch 1584/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0491 - accuracy: 0.8439 - val_loss: 0.0766 - val_accuracy: 0.7605\n",
      "Epoch 1585/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0490 - accuracy: 0.8447 - val_loss: 0.0762 - val_accuracy: 0.7598\n",
      "Epoch 1586/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0492 - accuracy: 0.8436 - val_loss: 0.0760 - val_accuracy: 0.7595\n",
      "Epoch 1587/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0492 - accuracy: 0.8438 - val_loss: 0.0763 - val_accuracy: 0.7593\n",
      "Epoch 1588/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0492 - accuracy: 0.8433 - val_loss: 0.0781 - val_accuracy: 0.7572\n",
      "Epoch 1589/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0491 - accuracy: 0.8442 - val_loss: 0.0767 - val_accuracy: 0.7583\n",
      "Epoch 1590/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0492 - accuracy: 0.8437 - val_loss: 0.0765 - val_accuracy: 0.7587\n",
      "Epoch 1591/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0492 - accuracy: 0.8440 - val_loss: 0.0766 - val_accuracy: 0.7605\n",
      "Epoch 1592/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0492 - accuracy: 0.8437 - val_loss: 0.0766 - val_accuracy: 0.7590\n",
      "Epoch 1593/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0492 - accuracy: 0.8434 - val_loss: 0.0768 - val_accuracy: 0.7567\n",
      "Epoch 1594/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0492 - accuracy: 0.8437 - val_loss: 0.0760 - val_accuracy: 0.7570\n",
      "Epoch 1595/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0492 - accuracy: 0.8437 - val_loss: 0.0766 - val_accuracy: 0.7590\n",
      "Epoch 1596/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0491 - accuracy: 0.8439 - val_loss: 0.0765 - val_accuracy: 0.7580\n",
      "Epoch 1597/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0491 - accuracy: 0.8435 - val_loss: 0.0763 - val_accuracy: 0.7595\n",
      "Epoch 1598/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0492 - accuracy: 0.8440 - val_loss: 0.0762 - val_accuracy: 0.7582\n",
      "Epoch 1599/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0492 - accuracy: 0.8435 - val_loss: 0.0774 - val_accuracy: 0.7591\n",
      "Epoch 1600/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0492 - accuracy: 0.8438 - val_loss: 0.0762 - val_accuracy: 0.7589\n",
      "Epoch 1601/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0493 - accuracy: 0.8434 - val_loss: 0.0770 - val_accuracy: 0.7590\n",
      "Epoch 1602/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0494 - accuracy: 0.8433 - val_loss: 0.0766 - val_accuracy: 0.7586\n",
      "Epoch 1603/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0492 - accuracy: 0.8436 - val_loss: 0.0769 - val_accuracy: 0.7580\n",
      "Epoch 1604/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0492 - accuracy: 0.8439 - val_loss: 0.0768 - val_accuracy: 0.7596\n",
      "Epoch 1605/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0493 - accuracy: 0.8438 - val_loss: 0.0770 - val_accuracy: 0.7594\n",
      "Epoch 1606/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0493 - accuracy: 0.8432 - val_loss: 0.0764 - val_accuracy: 0.7596\n",
      "Epoch 1607/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0494 - accuracy: 0.8431 - val_loss: 0.0761 - val_accuracy: 0.7590\n",
      "Epoch 1608/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0492 - accuracy: 0.8438 - val_loss: 0.0775 - val_accuracy: 0.7593\n",
      "Epoch 1609/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0494 - accuracy: 0.8430 - val_loss: 0.0766 - val_accuracy: 0.7574\n",
      "Epoch 1610/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0495 - accuracy: 0.8433 - val_loss: 0.0770 - val_accuracy: 0.7595\n",
      "Epoch 1611/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0494 - accuracy: 0.8435 - val_loss: 0.0759 - val_accuracy: 0.7587\n",
      "Epoch 1612/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0494 - accuracy: 0.8431 - val_loss: 0.0765 - val_accuracy: 0.7595\n",
      "Epoch 1613/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0493 - accuracy: 0.8434 - val_loss: 0.0781 - val_accuracy: 0.7570\n",
      "Epoch 1614/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0493 - accuracy: 0.8434 - val_loss: 0.0763 - val_accuracy: 0.7585\n",
      "Epoch 1615/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0494 - accuracy: 0.8431 - val_loss: 0.0766 - val_accuracy: 0.7552\n",
      "Epoch 1616/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0494 - accuracy: 0.8429 - val_loss: 0.0758 - val_accuracy: 0.7581\n",
      "Epoch 1617/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0493 - accuracy: 0.8436 - val_loss: 0.0760 - val_accuracy: 0.7592\n",
      "Epoch 1618/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0495 - accuracy: 0.8432 - val_loss: 0.0765 - val_accuracy: 0.7568\n",
      "Epoch 1619/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0494 - accuracy: 0.8432 - val_loss: 0.0779 - val_accuracy: 0.7580\n",
      "Epoch 1620/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0492 - accuracy: 0.8436 - val_loss: 0.0768 - val_accuracy: 0.7583\n",
      "Epoch 1621/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0493 - accuracy: 0.8435 - val_loss: 0.0760 - val_accuracy: 0.7593\n",
      "Epoch 1622/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0493 - accuracy: 0.8429 - val_loss: 0.0767 - val_accuracy: 0.7572\n",
      "Epoch 1623/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0492 - accuracy: 0.8435 - val_loss: 0.0769 - val_accuracy: 0.7575\n",
      "Epoch 1624/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0492 - accuracy: 0.8436 - val_loss: 0.0776 - val_accuracy: 0.7583\n",
      "Epoch 1625/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0494 - accuracy: 0.8430 - val_loss: 0.0765 - val_accuracy: 0.7591\n",
      "Epoch 1626/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0494 - accuracy: 0.8431 - val_loss: 0.0766 - val_accuracy: 0.7576\n",
      "Epoch 1627/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0493 - accuracy: 0.8434 - val_loss: 0.0766 - val_accuracy: 0.7584\n",
      "Epoch 1628/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0493 - accuracy: 0.8435 - val_loss: 0.0767 - val_accuracy: 0.7597\n",
      "Epoch 1629/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0492 - accuracy: 0.8436 - val_loss: 0.0763 - val_accuracy: 0.7598\n",
      "Epoch 1630/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0495 - accuracy: 0.8428 - val_loss: 0.0758 - val_accuracy: 0.7578\n",
      "Epoch 1631/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0494 - accuracy: 0.8428 - val_loss: 0.0766 - val_accuracy: 0.7578\n",
      "Epoch 1632/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0495 - accuracy: 0.8431 - val_loss: 0.0766 - val_accuracy: 0.7588\n",
      "Epoch 1633/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0493 - accuracy: 0.8436 - val_loss: 0.0764 - val_accuracy: 0.7586\n",
      "Epoch 1634/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0494 - accuracy: 0.8432 - val_loss: 0.0758 - val_accuracy: 0.7590\n",
      "Epoch 1635/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0492 - accuracy: 0.8440 - val_loss: 0.0764 - val_accuracy: 0.7596\n",
      "Epoch 1636/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0492 - accuracy: 0.8437 - val_loss: 0.0765 - val_accuracy: 0.7592\n",
      "Epoch 1637/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0492 - accuracy: 0.8438 - val_loss: 0.0761 - val_accuracy: 0.7600\n",
      "Epoch 1638/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0493 - accuracy: 0.8437 - val_loss: 0.0770 - val_accuracy: 0.7589\n",
      "Epoch 1639/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0492 - accuracy: 0.8441 - val_loss: 0.0756 - val_accuracy: 0.7590\n",
      "Epoch 1640/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0492 - accuracy: 0.8441 - val_loss: 0.0765 - val_accuracy: 0.7605\n",
      "Epoch 1641/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0494 - accuracy: 0.8434 - val_loss: 0.0767 - val_accuracy: 0.7584\n",
      "Epoch 1642/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0492 - accuracy: 0.8439 - val_loss: 0.0768 - val_accuracy: 0.7588\n",
      "Epoch 1643/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0493 - accuracy: 0.8435 - val_loss: 0.0769 - val_accuracy: 0.7590\n",
      "Epoch 1644/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0493 - accuracy: 0.8438 - val_loss: 0.0782 - val_accuracy: 0.7556\n",
      "Epoch 1645/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0494 - accuracy: 0.8432 - val_loss: 0.0772 - val_accuracy: 0.7582\n",
      "Epoch 1646/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0493 - accuracy: 0.8435 - val_loss: 0.0774 - val_accuracy: 0.7573\n",
      "Epoch 1647/5000\n",
      "11786/11786 [==============================] - 8s 685us/step - loss: 0.0494 - accuracy: 0.8433 - val_loss: 0.0758 - val_accuracy: 0.7583\n",
      "Epoch 1648/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0493 - accuracy: 0.8434 - val_loss: 0.0769 - val_accuracy: 0.7586\n",
      "Epoch 1649/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0493 - accuracy: 0.8438 - val_loss: 0.0772 - val_accuracy: 0.7570\n",
      "Epoch 1650/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0494 - accuracy: 0.8430 - val_loss: 0.0776 - val_accuracy: 0.7572\n",
      "Epoch 1651/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0494 - accuracy: 0.8432 - val_loss: 0.0773 - val_accuracy: 0.7584\n",
      "Epoch 1652/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0492 - accuracy: 0.8438 - val_loss: 0.0762 - val_accuracy: 0.7593\n",
      "Epoch 1653/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0496 - accuracy: 0.8431 - val_loss: 0.0767 - val_accuracy: 0.7582\n",
      "Epoch 1654/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0493 - accuracy: 0.8438 - val_loss: 0.0758 - val_accuracy: 0.7590\n",
      "Epoch 1655/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0492 - accuracy: 0.8439 - val_loss: 0.0769 - val_accuracy: 0.7562\n",
      "Epoch 1656/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0493 - accuracy: 0.8439 - val_loss: 0.0768 - val_accuracy: 0.7592\n",
      "Epoch 1657/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0494 - accuracy: 0.8433 - val_loss: 0.0764 - val_accuracy: 0.7579\n",
      "Epoch 1658/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0494 - accuracy: 0.8434 - val_loss: 0.0763 - val_accuracy: 0.7577\n",
      "Epoch 1659/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0494 - accuracy: 0.8434 - val_loss: 0.0774 - val_accuracy: 0.7569\n",
      "Epoch 1660/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0495 - accuracy: 0.8431 - val_loss: 0.0764 - val_accuracy: 0.7592\n",
      "Epoch 1661/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0495 - accuracy: 0.8432 - val_loss: 0.0763 - val_accuracy: 0.7566\n",
      "Epoch 1662/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0496 - accuracy: 0.8427 - val_loss: 0.0777 - val_accuracy: 0.7575\n",
      "Epoch 1663/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0494 - accuracy: 0.8434 - val_loss: 0.0767 - val_accuracy: 0.7584\n",
      "Epoch 1664/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0493 - accuracy: 0.8437 - val_loss: 0.0774 - val_accuracy: 0.7577\n",
      "Epoch 1665/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0492 - accuracy: 0.8438 - val_loss: 0.0764 - val_accuracy: 0.7581\n",
      "Epoch 1666/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0493 - accuracy: 0.8433 - val_loss: 0.0762 - val_accuracy: 0.7584\n",
      "Epoch 1667/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0494 - accuracy: 0.8436 - val_loss: 0.0764 - val_accuracy: 0.7587\n",
      "Epoch 1668/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0495 - accuracy: 0.8433 - val_loss: 0.0774 - val_accuracy: 0.7577\n",
      "Epoch 1669/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0494 - accuracy: 0.8431 - val_loss: 0.0767 - val_accuracy: 0.7586\n",
      "Epoch 1670/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0493 - accuracy: 0.8435 - val_loss: 0.0766 - val_accuracy: 0.7590\n",
      "Epoch 1671/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0492 - accuracy: 0.8437 - val_loss: 0.0756 - val_accuracy: 0.7583\n",
      "Epoch 1672/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0493 - accuracy: 0.8435 - val_loss: 0.0764 - val_accuracy: 0.7580\n",
      "Epoch 1673/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0492 - accuracy: 0.8438 - val_loss: 0.0767 - val_accuracy: 0.7591\n",
      "Epoch 1674/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0493 - accuracy: 0.8437 - val_loss: 0.0766 - val_accuracy: 0.7602\n",
      "Epoch 1675/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0493 - accuracy: 0.8434 - val_loss: 0.0763 - val_accuracy: 0.7592\n",
      "Epoch 1676/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0494 - accuracy: 0.8435 - val_loss: 0.0764 - val_accuracy: 0.7573\n",
      "Epoch 1677/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0493 - accuracy: 0.8435 - val_loss: 0.0763 - val_accuracy: 0.7594\n",
      "Epoch 1678/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0496 - accuracy: 0.8431 - val_loss: 0.0771 - val_accuracy: 0.7583\n",
      "Epoch 1679/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0493 - accuracy: 0.8439 - val_loss: 0.0774 - val_accuracy: 0.7579\n",
      "Epoch 1680/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0495 - accuracy: 0.8431 - val_loss: 0.0776 - val_accuracy: 0.7586\n",
      "Epoch 1681/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0494 - accuracy: 0.8435 - val_loss: 0.0768 - val_accuracy: 0.7589\n",
      "Epoch 1682/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0494 - accuracy: 0.8433 - val_loss: 0.0764 - val_accuracy: 0.7605\n",
      "Epoch 1683/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0494 - accuracy: 0.8434 - val_loss: 0.0770 - val_accuracy: 0.7571\n",
      "Epoch 1684/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0495 - accuracy: 0.8433 - val_loss: 0.0769 - val_accuracy: 0.7579\n",
      "Epoch 1685/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0494 - accuracy: 0.8431 - val_loss: 0.0768 - val_accuracy: 0.7591\n",
      "Epoch 1686/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0495 - accuracy: 0.8427 - val_loss: 0.0761 - val_accuracy: 0.7608\n",
      "Epoch 1687/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0494 - accuracy: 0.8434 - val_loss: 0.0759 - val_accuracy: 0.7567\n",
      "Epoch 1688/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0495 - accuracy: 0.8430 - val_loss: 0.0773 - val_accuracy: 0.7548\n",
      "Epoch 1689/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0495 - accuracy: 0.8434 - val_loss: 0.0779 - val_accuracy: 0.7561\n",
      "Epoch 1690/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0497 - accuracy: 0.8424 - val_loss: 0.0765 - val_accuracy: 0.7568\n",
      "Epoch 1691/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0497 - accuracy: 0.8426 - val_loss: 0.0754 - val_accuracy: 0.7585\n",
      "Epoch 1692/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0495 - accuracy: 0.8429 - val_loss: 0.0761 - val_accuracy: 0.7576\n",
      "Epoch 1693/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0494 - accuracy: 0.8433 - val_loss: 0.0758 - val_accuracy: 0.7588\n",
      "Epoch 1694/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0495 - accuracy: 0.8430 - val_loss: 0.0784 - val_accuracy: 0.7578\n",
      "Epoch 1695/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0496 - accuracy: 0.8427 - val_loss: 0.0772 - val_accuracy: 0.7586\n",
      "Epoch 1696/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0496 - accuracy: 0.8427 - val_loss: 0.0765 - val_accuracy: 0.7575\n",
      "Epoch 1697/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0495 - accuracy: 0.8429 - val_loss: 0.0770 - val_accuracy: 0.7571\n",
      "Epoch 1698/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0495 - accuracy: 0.8428 - val_loss: 0.0760 - val_accuracy: 0.7582\n",
      "Epoch 1699/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0494 - accuracy: 0.8432 - val_loss: 0.0764 - val_accuracy: 0.7571\n",
      "Epoch 1700/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0495 - accuracy: 0.8430 - val_loss: 0.0767 - val_accuracy: 0.7583\n",
      "Epoch 1701/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0494 - accuracy: 0.8433 - val_loss: 0.0777 - val_accuracy: 0.7562\n",
      "Epoch 1702/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0494 - accuracy: 0.8433 - val_loss: 0.0764 - val_accuracy: 0.7592\n",
      "Epoch 1703/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0494 - accuracy: 0.8435 - val_loss: 0.0774 - val_accuracy: 0.7567\n",
      "Epoch 1704/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0493 - accuracy: 0.8430 - val_loss: 0.0769 - val_accuracy: 0.7562\n",
      "Epoch 1705/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0496 - accuracy: 0.8427 - val_loss: 0.0769 - val_accuracy: 0.7576\n",
      "Epoch 1706/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0496 - accuracy: 0.8429 - val_loss: 0.0772 - val_accuracy: 0.7589\n",
      "Epoch 1707/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0494 - accuracy: 0.8433 - val_loss: 0.0771 - val_accuracy: 0.7574\n",
      "Epoch 1708/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0495 - accuracy: 0.8429 - val_loss: 0.0765 - val_accuracy: 0.7595\n",
      "Epoch 1709/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0493 - accuracy: 0.8442 - val_loss: 0.0768 - val_accuracy: 0.7584\n",
      "Epoch 1710/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0495 - accuracy: 0.8433 - val_loss: 0.0770 - val_accuracy: 0.7593\n",
      "Epoch 1711/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0495 - accuracy: 0.8432 - val_loss: 0.0767 - val_accuracy: 0.7581\n",
      "Epoch 1712/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0498 - accuracy: 0.8421 - val_loss: 0.0766 - val_accuracy: 0.7579\n",
      "Epoch 1713/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0495 - accuracy: 0.8430 - val_loss: 0.0764 - val_accuracy: 0.7577\n",
      "Epoch 1714/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0496 - accuracy: 0.8428 - val_loss: 0.0771 - val_accuracy: 0.7566\n",
      "Epoch 1715/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0496 - accuracy: 0.8429 - val_loss: 0.0763 - val_accuracy: 0.7568\n",
      "Epoch 1716/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0496 - accuracy: 0.8426 - val_loss: 0.0778 - val_accuracy: 0.7581\n",
      "Epoch 1717/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0497 - accuracy: 0.8423 - val_loss: 0.0770 - val_accuracy: 0.7561\n",
      "Epoch 1718/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0497 - accuracy: 0.8426 - val_loss: 0.0766 - val_accuracy: 0.7569\n",
      "Epoch 1719/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0496 - accuracy: 0.8429 - val_loss: 0.0762 - val_accuracy: 0.7577\n",
      "Epoch 1720/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0496 - accuracy: 0.8430 - val_loss: 0.0770 - val_accuracy: 0.7574\n",
      "Epoch 1721/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0495 - accuracy: 0.8435 - val_loss: 0.0774 - val_accuracy: 0.7580\n",
      "Epoch 1722/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0495 - accuracy: 0.8434 - val_loss: 0.0776 - val_accuracy: 0.7571\n",
      "Epoch 1723/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0497 - accuracy: 0.8422 - val_loss: 0.0761 - val_accuracy: 0.7579\n",
      "Epoch 1724/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0497 - accuracy: 0.8425 - val_loss: 0.0770 - val_accuracy: 0.7566\n",
      "Epoch 1725/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0498 - accuracy: 0.8422 - val_loss: 0.0771 - val_accuracy: 0.7557\n",
      "Epoch 1726/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0498 - accuracy: 0.8420 - val_loss: 0.0773 - val_accuracy: 0.7572\n",
      "Epoch 1727/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0498 - accuracy: 0.8419 - val_loss: 0.0775 - val_accuracy: 0.7573\n",
      "Epoch 1728/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0497 - accuracy: 0.8421 - val_loss: 0.0768 - val_accuracy: 0.7566\n",
      "Epoch 1729/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0497 - accuracy: 0.8425 - val_loss: 0.0764 - val_accuracy: 0.7565\n",
      "Epoch 1730/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0496 - accuracy: 0.8427 - val_loss: 0.0766 - val_accuracy: 0.7569\n",
      "Epoch 1731/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0497 - accuracy: 0.8422 - val_loss: 0.0772 - val_accuracy: 0.7579\n",
      "Epoch 1732/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0496 - accuracy: 0.8429 - val_loss: 0.0772 - val_accuracy: 0.7589\n",
      "Epoch 1733/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0495 - accuracy: 0.8432 - val_loss: 0.0769 - val_accuracy: 0.7584\n",
      "Epoch 1734/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0496 - accuracy: 0.8430 - val_loss: 0.0776 - val_accuracy: 0.7564\n",
      "Epoch 1735/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0497 - accuracy: 0.8421 - val_loss: 0.0770 - val_accuracy: 0.7556\n",
      "Epoch 1736/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0497 - accuracy: 0.8426 - val_loss: 0.0768 - val_accuracy: 0.7564\n",
      "Epoch 1737/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0497 - accuracy: 0.8421 - val_loss: 0.0770 - val_accuracy: 0.7566\n",
      "Epoch 1738/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0497 - accuracy: 0.8427 - val_loss: 0.0763 - val_accuracy: 0.7556\n",
      "Epoch 1739/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0498 - accuracy: 0.8421 - val_loss: 0.0780 - val_accuracy: 0.7567\n",
      "Epoch 1740/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0498 - accuracy: 0.8420 - val_loss: 0.0770 - val_accuracy: 0.7563\n",
      "Epoch 1741/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0499 - accuracy: 0.8424 - val_loss: 0.0772 - val_accuracy: 0.7569\n",
      "Epoch 1742/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0498 - accuracy: 0.8421 - val_loss: 0.0770 - val_accuracy: 0.7560\n",
      "Epoch 1743/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0497 - accuracy: 0.8424 - val_loss: 0.0778 - val_accuracy: 0.7558\n",
      "Epoch 1744/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0498 - accuracy: 0.8422 - val_loss: 0.0770 - val_accuracy: 0.7584\n",
      "Epoch 1745/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0497 - accuracy: 0.8429 - val_loss: 0.0775 - val_accuracy: 0.7581\n",
      "Epoch 1746/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0498 - accuracy: 0.8421 - val_loss: 0.0763 - val_accuracy: 0.7587\n",
      "Epoch 1747/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0498 - accuracy: 0.8422 - val_loss: 0.0758 - val_accuracy: 0.7579\n",
      "Epoch 1748/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0499 - accuracy: 0.8419 - val_loss: 0.0767 - val_accuracy: 0.7566\n",
      "Epoch 1749/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0499 - accuracy: 0.8418 - val_loss: 0.0766 - val_accuracy: 0.7573\n",
      "Epoch 1750/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0500 - accuracy: 0.8417 - val_loss: 0.0769 - val_accuracy: 0.7587\n",
      "Epoch 1751/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0500 - accuracy: 0.8420 - val_loss: 0.0772 - val_accuracy: 0.7550\n",
      "Epoch 1752/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0500 - accuracy: 0.8416 - val_loss: 0.0770 - val_accuracy: 0.7569\n",
      "Epoch 1753/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0499 - accuracy: 0.8420 - val_loss: 0.0768 - val_accuracy: 0.7568\n",
      "Epoch 1754/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0499 - accuracy: 0.8420 - val_loss: 0.0766 - val_accuracy: 0.7571\n",
      "Epoch 1755/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0499 - accuracy: 0.8422 - val_loss: 0.0766 - val_accuracy: 0.7572\n",
      "Epoch 1756/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0499 - accuracy: 0.8423 - val_loss: 0.0770 - val_accuracy: 0.7569\n",
      "Epoch 1757/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0500 - accuracy: 0.8412 - val_loss: 0.0775 - val_accuracy: 0.7560\n",
      "Epoch 1758/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0499 - accuracy: 0.8420 - val_loss: 0.0771 - val_accuracy: 0.7583\n",
      "Epoch 1759/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0499 - accuracy: 0.8417 - val_loss: 0.0765 - val_accuracy: 0.7577\n",
      "Epoch 1760/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0500 - accuracy: 0.8419 - val_loss: 0.0779 - val_accuracy: 0.7531\n",
      "Epoch 1761/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0499 - accuracy: 0.8420 - val_loss: 0.0775 - val_accuracy: 0.7568\n",
      "Epoch 1762/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0498 - accuracy: 0.8424 - val_loss: 0.0777 - val_accuracy: 0.7583\n",
      "Epoch 1763/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0499 - accuracy: 0.8418 - val_loss: 0.0769 - val_accuracy: 0.7577\n",
      "Epoch 1764/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0499 - accuracy: 0.8419 - val_loss: 0.0780 - val_accuracy: 0.7577\n",
      "Epoch 1765/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0499 - accuracy: 0.8424 - val_loss: 0.0776 - val_accuracy: 0.7561\n",
      "Epoch 1766/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0499 - accuracy: 0.8424 - val_loss: 0.0776 - val_accuracy: 0.7554\n",
      "Epoch 1767/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0497 - accuracy: 0.8428 - val_loss: 0.0760 - val_accuracy: 0.7580\n",
      "Epoch 1768/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0499 - accuracy: 0.8422 - val_loss: 0.0766 - val_accuracy: 0.7562\n",
      "Epoch 1769/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0498 - accuracy: 0.8420 - val_loss: 0.0760 - val_accuracy: 0.7579\n",
      "Epoch 1770/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0500 - accuracy: 0.8417 - val_loss: 0.0768 - val_accuracy: 0.7573\n",
      "Epoch 1771/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0500 - accuracy: 0.8417 - val_loss: 0.0768 - val_accuracy: 0.7570\n",
      "Epoch 1772/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0500 - accuracy: 0.8418 - val_loss: 0.0764 - val_accuracy: 0.7562\n",
      "Epoch 1773/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0500 - accuracy: 0.8419 - val_loss: 0.0771 - val_accuracy: 0.7570\n",
      "Epoch 1774/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0499 - accuracy: 0.8421 - val_loss: 0.0772 - val_accuracy: 0.7573\n",
      "Epoch 1775/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0501 - accuracy: 0.8418 - val_loss: 0.0778 - val_accuracy: 0.7571\n",
      "Epoch 1776/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0499 - accuracy: 0.8420 - val_loss: 0.0770 - val_accuracy: 0.7558\n",
      "Epoch 1777/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0499 - accuracy: 0.8421 - val_loss: 0.0775 - val_accuracy: 0.7579\n",
      "Epoch 1778/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0499 - accuracy: 0.8419 - val_loss: 0.0779 - val_accuracy: 0.7572\n",
      "Epoch 1779/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0500 - accuracy: 0.8416 - val_loss: 0.0784 - val_accuracy: 0.7552\n",
      "Epoch 1780/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0500 - accuracy: 0.8423 - val_loss: 0.0773 - val_accuracy: 0.7561\n",
      "Epoch 1781/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0500 - accuracy: 0.8419 - val_loss: 0.0774 - val_accuracy: 0.7582\n",
      "Epoch 1782/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0502 - accuracy: 0.8412 - val_loss: 0.0777 - val_accuracy: 0.7571\n",
      "Epoch 1783/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0502 - accuracy: 0.8410 - val_loss: 0.0773 - val_accuracy: 0.7570\n",
      "Epoch 1784/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0499 - accuracy: 0.8420 - val_loss: 0.0774 - val_accuracy: 0.7548\n",
      "Epoch 1785/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0501 - accuracy: 0.8416 - val_loss: 0.0770 - val_accuracy: 0.7581\n",
      "Epoch 1786/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0498 - accuracy: 0.8421 - val_loss: 0.0777 - val_accuracy: 0.7549\n",
      "Epoch 1787/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0499 - accuracy: 0.8418 - val_loss: 0.0777 - val_accuracy: 0.7552\n",
      "Epoch 1788/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0500 - accuracy: 0.8415 - val_loss: 0.0769 - val_accuracy: 0.7572\n",
      "Epoch 1789/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0500 - accuracy: 0.8419 - val_loss: 0.0774 - val_accuracy: 0.7556\n",
      "Epoch 1790/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0501 - accuracy: 0.8414 - val_loss: 0.0774 - val_accuracy: 0.7559\n",
      "Epoch 1791/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0503 - accuracy: 0.8407 - val_loss: 0.0778 - val_accuracy: 0.7561\n",
      "Epoch 1792/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0502 - accuracy: 0.8414 - val_loss: 0.0765 - val_accuracy: 0.7574\n",
      "Epoch 1793/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0501 - accuracy: 0.8416 - val_loss: 0.0779 - val_accuracy: 0.7555\n",
      "Epoch 1794/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0502 - accuracy: 0.8409 - val_loss: 0.0775 - val_accuracy: 0.7575\n",
      "Epoch 1795/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0500 - accuracy: 0.8415 - val_loss: 0.0775 - val_accuracy: 0.7574\n",
      "Epoch 1796/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0501 - accuracy: 0.8415 - val_loss: 0.0777 - val_accuracy: 0.7564\n",
      "Epoch 1797/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0502 - accuracy: 0.8409 - val_loss: 0.0771 - val_accuracy: 0.7574\n",
      "Epoch 1798/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0501 - accuracy: 0.8413 - val_loss: 0.0767 - val_accuracy: 0.7562\n",
      "Epoch 1799/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0500 - accuracy: 0.8423 - val_loss: 0.0778 - val_accuracy: 0.7564\n",
      "Epoch 1800/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0503 - accuracy: 0.8409 - val_loss: 0.0770 - val_accuracy: 0.7567\n",
      "Epoch 1801/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0501 - accuracy: 0.8412 - val_loss: 0.0780 - val_accuracy: 0.7561\n",
      "Epoch 1802/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0502 - accuracy: 0.8413 - val_loss: 0.0772 - val_accuracy: 0.7570\n",
      "Epoch 1803/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0502 - accuracy: 0.8413 - val_loss: 0.0768 - val_accuracy: 0.7576\n",
      "Epoch 1804/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0501 - accuracy: 0.8416 - val_loss: 0.0775 - val_accuracy: 0.7546\n",
      "Epoch 1805/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0502 - accuracy: 0.8409 - val_loss: 0.0783 - val_accuracy: 0.7571\n",
      "Epoch 1806/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0501 - accuracy: 0.8414 - val_loss: 0.0787 - val_accuracy: 0.7567\n",
      "Epoch 1807/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0501 - accuracy: 0.8411 - val_loss: 0.0782 - val_accuracy: 0.7535\n",
      "Epoch 1808/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0502 - accuracy: 0.8412 - val_loss: 0.0770 - val_accuracy: 0.7563\n",
      "Epoch 1809/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0501 - accuracy: 0.8417 - val_loss: 0.0780 - val_accuracy: 0.7565\n",
      "Epoch 1810/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0502 - accuracy: 0.8412 - val_loss: 0.0773 - val_accuracy: 0.7567\n",
      "Epoch 1811/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0502 - accuracy: 0.8411 - val_loss: 0.0774 - val_accuracy: 0.7561\n",
      "Epoch 1812/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0501 - accuracy: 0.8413 - val_loss: 0.0773 - val_accuracy: 0.7535\n",
      "Epoch 1813/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0503 - accuracy: 0.8407 - val_loss: 0.0777 - val_accuracy: 0.7546\n",
      "Epoch 1814/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0503 - accuracy: 0.8411 - val_loss: 0.0781 - val_accuracy: 0.7566\n",
      "Epoch 1815/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0503 - accuracy: 0.8407 - val_loss: 0.0781 - val_accuracy: 0.7576\n",
      "Epoch 1816/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0502 - accuracy: 0.8409 - val_loss: 0.0772 - val_accuracy: 0.7558\n",
      "Epoch 1817/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0503 - accuracy: 0.8410 - val_loss: 0.0788 - val_accuracy: 0.7553\n",
      "Epoch 1818/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0502 - accuracy: 0.8412 - val_loss: 0.0794 - val_accuracy: 0.7550\n",
      "Epoch 1819/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0503 - accuracy: 0.8407 - val_loss: 0.0783 - val_accuracy: 0.7572\n",
      "Epoch 1820/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0503 - accuracy: 0.8411 - val_loss: 0.0775 - val_accuracy: 0.7568\n",
      "Epoch 1821/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0502 - accuracy: 0.8408 - val_loss: 0.0791 - val_accuracy: 0.7452\n",
      "Epoch 1822/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0502 - accuracy: 0.8411 - val_loss: 0.0781 - val_accuracy: 0.7535\n",
      "Epoch 1823/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0504 - accuracy: 0.8409 - val_loss: 0.0784 - val_accuracy: 0.7531\n",
      "Epoch 1824/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0504 - accuracy: 0.8407 - val_loss: 0.0776 - val_accuracy: 0.7549\n",
      "Epoch 1825/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0502 - accuracy: 0.8416 - val_loss: 0.0776 - val_accuracy: 0.7560\n",
      "Epoch 1826/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0502 - accuracy: 0.8410 - val_loss: 0.0785 - val_accuracy: 0.7550\n",
      "Epoch 1827/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0502 - accuracy: 0.8412 - val_loss: 0.0765 - val_accuracy: 0.7554\n",
      "Epoch 1828/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0504 - accuracy: 0.8408 - val_loss: 0.0788 - val_accuracy: 0.7553\n",
      "Epoch 1829/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0504 - accuracy: 0.8407 - val_loss: 0.0779 - val_accuracy: 0.7557\n",
      "Epoch 1830/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0504 - accuracy: 0.8408 - val_loss: 0.0777 - val_accuracy: 0.7564\n",
      "Epoch 1831/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0502 - accuracy: 0.8410 - val_loss: 0.0780 - val_accuracy: 0.7555\n",
      "Epoch 1832/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0503 - accuracy: 0.8411 - val_loss: 0.0786 - val_accuracy: 0.7537\n",
      "Epoch 1833/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0503 - accuracy: 0.8412 - val_loss: 0.0780 - val_accuracy: 0.7556\n",
      "Epoch 1834/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0502 - accuracy: 0.8412 - val_loss: 0.0781 - val_accuracy: 0.7551\n",
      "Epoch 1835/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0502 - accuracy: 0.8412 - val_loss: 0.0775 - val_accuracy: 0.7562\n",
      "Epoch 1836/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0501 - accuracy: 0.8411 - val_loss: 0.0776 - val_accuracy: 0.7568\n",
      "Epoch 1837/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0501 - accuracy: 0.8416 - val_loss: 0.0780 - val_accuracy: 0.7563\n",
      "Epoch 1838/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0503 - accuracy: 0.8410 - val_loss: 0.0770 - val_accuracy: 0.7567\n",
      "Epoch 1839/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0503 - accuracy: 0.8410 - val_loss: 0.0791 - val_accuracy: 0.7544\n",
      "Epoch 1840/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0504 - accuracy: 0.8405 - val_loss: 0.0777 - val_accuracy: 0.7553\n",
      "Epoch 1841/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0502 - accuracy: 0.8415 - val_loss: 0.0774 - val_accuracy: 0.7566\n",
      "Epoch 1842/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0503 - accuracy: 0.8408 - val_loss: 0.0779 - val_accuracy: 0.7560\n",
      "Epoch 1843/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0503 - accuracy: 0.8409 - val_loss: 0.0774 - val_accuracy: 0.7557\n",
      "Epoch 1844/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0504 - accuracy: 0.8411 - val_loss: 0.0780 - val_accuracy: 0.7544\n",
      "Epoch 1845/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0504 - accuracy: 0.8405 - val_loss: 0.0777 - val_accuracy: 0.7554\n",
      "Epoch 1846/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0503 - accuracy: 0.8412 - val_loss: 0.0794 - val_accuracy: 0.7549\n",
      "Epoch 1847/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0506 - accuracy: 0.8402 - val_loss: 0.0774 - val_accuracy: 0.7569\n",
      "Epoch 1848/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0502 - accuracy: 0.8411 - val_loss: 0.0780 - val_accuracy: 0.7559\n",
      "Epoch 1849/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0502 - accuracy: 0.8414 - val_loss: 0.0781 - val_accuracy: 0.7528\n",
      "Epoch 1850/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0507 - accuracy: 0.8400 - val_loss: 0.0778 - val_accuracy: 0.7551\n",
      "Epoch 1851/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0509 - accuracy: 0.8389 - val_loss: 0.0774 - val_accuracy: 0.7542\n",
      "Epoch 1852/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0505 - accuracy: 0.8402 - val_loss: 0.0789 - val_accuracy: 0.7537\n",
      "Epoch 1853/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0508 - accuracy: 0.8393 - val_loss: 0.0795 - val_accuracy: 0.7512\n",
      "Epoch 1854/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0508 - accuracy: 0.8393 - val_loss: 0.0770 - val_accuracy: 0.7548\n",
      "Epoch 1855/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0504 - accuracy: 0.8407 - val_loss: 0.0774 - val_accuracy: 0.7546\n",
      "Epoch 1856/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0503 - accuracy: 0.8408 - val_loss: 0.0763 - val_accuracy: 0.7556\n",
      "Epoch 1857/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0502 - accuracy: 0.8411 - val_loss: 0.0779 - val_accuracy: 0.7565\n",
      "Epoch 1858/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0504 - accuracy: 0.8406 - val_loss: 0.0765 - val_accuracy: 0.7567\n",
      "Epoch 1859/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0503 - accuracy: 0.8411 - val_loss: 0.0772 - val_accuracy: 0.7547\n",
      "Epoch 1860/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0503 - accuracy: 0.8410 - val_loss: 0.0771 - val_accuracy: 0.7562\n",
      "Epoch 1861/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0504 - accuracy: 0.8406 - val_loss: 0.0780 - val_accuracy: 0.7555\n",
      "Epoch 1862/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0504 - accuracy: 0.8401 - val_loss: 0.0780 - val_accuracy: 0.7565\n",
      "Epoch 1863/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0504 - accuracy: 0.8408 - val_loss: 0.0786 - val_accuracy: 0.7554\n",
      "Epoch 1864/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0505 - accuracy: 0.8401 - val_loss: 0.0776 - val_accuracy: 0.7554\n",
      "Epoch 1865/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0503 - accuracy: 0.8407 - val_loss: 0.0779 - val_accuracy: 0.7555\n",
      "Epoch 1866/5000\n",
      "11786/11786 [==============================] - 8s 688us/step - loss: 0.0504 - accuracy: 0.8409 - val_loss: 0.0783 - val_accuracy: 0.7562\n",
      "Epoch 1867/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0503 - accuracy: 0.8410 - val_loss: 0.0769 - val_accuracy: 0.7546\n",
      "Epoch 1868/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0503 - accuracy: 0.8411 - val_loss: 0.0770 - val_accuracy: 0.7566\n",
      "Epoch 1869/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0504 - accuracy: 0.8405 - val_loss: 0.0775 - val_accuracy: 0.7558\n",
      "Epoch 1870/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0505 - accuracy: 0.8403 - val_loss: 0.0790 - val_accuracy: 0.7503\n",
      "Epoch 1871/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0506 - accuracy: 0.8400 - val_loss: 0.0782 - val_accuracy: 0.7543\n",
      "Epoch 1872/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0505 - accuracy: 0.8405 - val_loss: 0.0796 - val_accuracy: 0.7546\n",
      "Epoch 1873/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0508 - accuracy: 0.8392 - val_loss: 0.0770 - val_accuracy: 0.7533\n",
      "Epoch 1874/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0505 - accuracy: 0.8402 - val_loss: 0.0788 - val_accuracy: 0.7548\n",
      "Epoch 1875/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0505 - accuracy: 0.8405 - val_loss: 0.0776 - val_accuracy: 0.7562\n",
      "Epoch 1876/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0503 - accuracy: 0.8406 - val_loss: 0.0786 - val_accuracy: 0.7545\n",
      "Epoch 1877/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0504 - accuracy: 0.8411 - val_loss: 0.0784 - val_accuracy: 0.7556\n",
      "Epoch 1878/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0504 - accuracy: 0.8408 - val_loss: 0.0782 - val_accuracy: 0.7560\n",
      "Epoch 1879/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0503 - accuracy: 0.8410 - val_loss: 0.0775 - val_accuracy: 0.7571\n",
      "Epoch 1880/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0505 - accuracy: 0.8403 - val_loss: 0.0779 - val_accuracy: 0.7545\n",
      "Epoch 1881/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0504 - accuracy: 0.8406 - val_loss: 0.0784 - val_accuracy: 0.7543\n",
      "Epoch 1882/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0504 - accuracy: 0.8407 - val_loss: 0.0778 - val_accuracy: 0.7549\n",
      "Epoch 1883/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0504 - accuracy: 0.8408 - val_loss: 0.0779 - val_accuracy: 0.7552\n",
      "Epoch 1884/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0506 - accuracy: 0.8400 - val_loss: 0.0783 - val_accuracy: 0.7529\n",
      "Epoch 1885/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0507 - accuracy: 0.8400 - val_loss: 0.0777 - val_accuracy: 0.7555\n",
      "Epoch 1886/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0506 - accuracy: 0.8404 - val_loss: 0.0789 - val_accuracy: 0.7549\n",
      "Epoch 1887/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0504 - accuracy: 0.8402 - val_loss: 0.0781 - val_accuracy: 0.7559\n",
      "Epoch 1888/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0506 - accuracy: 0.8401 - val_loss: 0.0786 - val_accuracy: 0.7559\n",
      "Epoch 1889/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0507 - accuracy: 0.8400 - val_loss: 0.0775 - val_accuracy: 0.7545\n",
      "Epoch 1890/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0507 - accuracy: 0.8402 - val_loss: 0.0780 - val_accuracy: 0.7534\n",
      "Epoch 1891/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0505 - accuracy: 0.8402 - val_loss: 0.0779 - val_accuracy: 0.7556\n",
      "Epoch 1892/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0504 - accuracy: 0.8404 - val_loss: 0.0773 - val_accuracy: 0.7556\n",
      "Epoch 1893/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0506 - accuracy: 0.8400 - val_loss: 0.0769 - val_accuracy: 0.7535\n",
      "Epoch 1894/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0504 - accuracy: 0.8405 - val_loss: 0.0789 - val_accuracy: 0.7530\n",
      "Epoch 1895/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0506 - accuracy: 0.8404 - val_loss: 0.0778 - val_accuracy: 0.7555\n",
      "Epoch 1896/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0506 - accuracy: 0.8400 - val_loss: 0.0784 - val_accuracy: 0.7541\n",
      "Epoch 1897/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0505 - accuracy: 0.8403 - val_loss: 0.0780 - val_accuracy: 0.7548\n",
      "Epoch 1898/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0509 - accuracy: 0.8391 - val_loss: 0.0782 - val_accuracy: 0.7533\n",
      "Epoch 1899/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0507 - accuracy: 0.8399 - val_loss: 0.0780 - val_accuracy: 0.7543\n",
      "Epoch 1900/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0506 - accuracy: 0.8400 - val_loss: 0.0795 - val_accuracy: 0.7540\n",
      "Epoch 1901/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0507 - accuracy: 0.8400 - val_loss: 0.0783 - val_accuracy: 0.7538\n",
      "Epoch 1902/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0508 - accuracy: 0.8395 - val_loss: 0.0780 - val_accuracy: 0.7559\n",
      "Epoch 1903/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0505 - accuracy: 0.8406 - val_loss: 0.0788 - val_accuracy: 0.7534\n",
      "Epoch 1904/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0505 - accuracy: 0.8402 - val_loss: 0.0783 - val_accuracy: 0.7564\n",
      "Epoch 1905/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0505 - accuracy: 0.8405 - val_loss: 0.0773 - val_accuracy: 0.7550\n",
      "Epoch 1906/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0505 - accuracy: 0.8405 - val_loss: 0.0779 - val_accuracy: 0.7557\n",
      "Epoch 1907/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0504 - accuracy: 0.8409 - val_loss: 0.0784 - val_accuracy: 0.7528\n",
      "Epoch 1908/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0506 - accuracy: 0.8400 - val_loss: 0.0777 - val_accuracy: 0.7531\n",
      "Epoch 1909/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0507 - accuracy: 0.8398 - val_loss: 0.0779 - val_accuracy: 0.7532\n",
      "Epoch 1910/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0511 - accuracy: 0.8391 - val_loss: 0.0794 - val_accuracy: 0.7537\n",
      "Epoch 1911/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0508 - accuracy: 0.8398 - val_loss: 0.0785 - val_accuracy: 0.7542\n",
      "Epoch 1912/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0507 - accuracy: 0.8398 - val_loss: 0.0785 - val_accuracy: 0.7542\n",
      "Epoch 1913/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0507 - accuracy: 0.8401 - val_loss: 0.0777 - val_accuracy: 0.7554\n",
      "Epoch 1914/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0506 - accuracy: 0.8402 - val_loss: 0.0779 - val_accuracy: 0.7544\n",
      "Epoch 1915/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0505 - accuracy: 0.8404 - val_loss: 0.0781 - val_accuracy: 0.7538\n",
      "Epoch 1916/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0505 - accuracy: 0.8404 - val_loss: 0.0773 - val_accuracy: 0.7547\n",
      "Epoch 1917/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0506 - accuracy: 0.8400 - val_loss: 0.0788 - val_accuracy: 0.7544\n",
      "Epoch 1918/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0507 - accuracy: 0.8398 - val_loss: 0.0787 - val_accuracy: 0.7545\n",
      "Epoch 1919/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0505 - accuracy: 0.8403 - val_loss: 0.0789 - val_accuracy: 0.7547\n",
      "Epoch 1920/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0506 - accuracy: 0.8403 - val_loss: 0.0785 - val_accuracy: 0.7540\n",
      "Epoch 1921/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0505 - accuracy: 0.8408 - val_loss: 0.0788 - val_accuracy: 0.7519\n",
      "Epoch 1922/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0505 - accuracy: 0.8411 - val_loss: 0.0775 - val_accuracy: 0.7564\n",
      "Epoch 1923/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0505 - accuracy: 0.8405 - val_loss: 0.0787 - val_accuracy: 0.7517\n",
      "Epoch 1924/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0506 - accuracy: 0.8402 - val_loss: 0.0776 - val_accuracy: 0.7550\n",
      "Epoch 1925/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0505 - accuracy: 0.8403 - val_loss: 0.0776 - val_accuracy: 0.7558\n",
      "Epoch 1926/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0505 - accuracy: 0.8407 - val_loss: 0.0784 - val_accuracy: 0.7541\n",
      "Epoch 1927/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0507 - accuracy: 0.8402 - val_loss: 0.0774 - val_accuracy: 0.7544\n",
      "Epoch 1928/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0508 - accuracy: 0.8395 - val_loss: 0.0793 - val_accuracy: 0.7546\n",
      "Epoch 1929/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0511 - accuracy: 0.8386 - val_loss: 0.0788 - val_accuracy: 0.7529\n",
      "Epoch 1930/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0509 - accuracy: 0.8394 - val_loss: 0.0786 - val_accuracy: 0.7542\n",
      "Epoch 1931/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0508 - accuracy: 0.8403 - val_loss: 0.0777 - val_accuracy: 0.7540\n",
      "Epoch 1932/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0508 - accuracy: 0.8398 - val_loss: 0.0776 - val_accuracy: 0.7553\n",
      "Epoch 1933/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0507 - accuracy: 0.8400 - val_loss: 0.0783 - val_accuracy: 0.7535\n",
      "Epoch 1934/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0509 - accuracy: 0.8395 - val_loss: 0.0779 - val_accuracy: 0.7547\n",
      "Epoch 1935/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0508 - accuracy: 0.8402 - val_loss: 0.0784 - val_accuracy: 0.7544\n",
      "Epoch 1936/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0507 - accuracy: 0.8400 - val_loss: 0.0771 - val_accuracy: 0.7542\n",
      "Epoch 1937/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0507 - accuracy: 0.8399 - val_loss: 0.0802 - val_accuracy: 0.7526\n",
      "Epoch 1938/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0506 - accuracy: 0.8407 - val_loss: 0.0782 - val_accuracy: 0.7555\n",
      "Epoch 1939/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0508 - accuracy: 0.8399 - val_loss: 0.0778 - val_accuracy: 0.7543\n",
      "Epoch 1940/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0507 - accuracy: 0.8403 - val_loss: 0.0796 - val_accuracy: 0.7525\n",
      "Epoch 1941/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0507 - accuracy: 0.8398 - val_loss: 0.0781 - val_accuracy: 0.7523\n",
      "Epoch 1942/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0508 - accuracy: 0.8399 - val_loss: 0.0777 - val_accuracy: 0.7537\n",
      "Epoch 1943/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0508 - accuracy: 0.8395 - val_loss: 0.0780 - val_accuracy: 0.7532\n",
      "Epoch 1944/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0508 - accuracy: 0.8399 - val_loss: 0.0775 - val_accuracy: 0.7536\n",
      "Epoch 1945/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0510 - accuracy: 0.8392 - val_loss: 0.0786 - val_accuracy: 0.7552\n",
      "Epoch 1946/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0510 - accuracy: 0.8392 - val_loss: 0.0791 - val_accuracy: 0.7548\n",
      "Epoch 1947/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0508 - accuracy: 0.8397 - val_loss: 0.0781 - val_accuracy: 0.7544\n",
      "Epoch 1948/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0508 - accuracy: 0.8397 - val_loss: 0.0791 - val_accuracy: 0.7547\n",
      "Epoch 1949/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0508 - accuracy: 0.8397 - val_loss: 0.0789 - val_accuracy: 0.7537\n",
      "Epoch 1950/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0507 - accuracy: 0.8400 - val_loss: 0.0778 - val_accuracy: 0.7536\n",
      "Epoch 1951/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0510 - accuracy: 0.8392 - val_loss: 0.0783 - val_accuracy: 0.7538\n",
      "Epoch 1952/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0508 - accuracy: 0.8398 - val_loss: 0.0778 - val_accuracy: 0.7554\n",
      "Epoch 1953/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0507 - accuracy: 0.8400 - val_loss: 0.0788 - val_accuracy: 0.7552\n",
      "Epoch 1954/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0509 - accuracy: 0.8393 - val_loss: 0.0792 - val_accuracy: 0.7543\n",
      "Epoch 1955/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0508 - accuracy: 0.8397 - val_loss: 0.0794 - val_accuracy: 0.7499\n",
      "Epoch 1956/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0509 - accuracy: 0.8394 - val_loss: 0.0786 - val_accuracy: 0.7519\n",
      "Epoch 1957/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0509 - accuracy: 0.8394 - val_loss: 0.0780 - val_accuracy: 0.7543\n",
      "Epoch 1958/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0509 - accuracy: 0.8393 - val_loss: 0.0788 - val_accuracy: 0.7515\n",
      "Epoch 1959/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0511 - accuracy: 0.8393 - val_loss: 0.0773 - val_accuracy: 0.7536\n",
      "Epoch 1960/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0510 - accuracy: 0.8390 - val_loss: 0.0788 - val_accuracy: 0.7521\n",
      "Epoch 1961/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0510 - accuracy: 0.8393 - val_loss: 0.0784 - val_accuracy: 0.7532\n",
      "Epoch 1962/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0510 - accuracy: 0.8392 - val_loss: 0.0778 - val_accuracy: 0.7540\n",
      "Epoch 1963/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0510 - accuracy: 0.8395 - val_loss: 0.0782 - val_accuracy: 0.7536\n",
      "Epoch 1964/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0508 - accuracy: 0.8399 - val_loss: 0.0775 - val_accuracy: 0.7527\n",
      "Epoch 1965/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0508 - accuracy: 0.8395 - val_loss: 0.0791 - val_accuracy: 0.7539\n",
      "Epoch 1966/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0508 - accuracy: 0.8397 - val_loss: 0.0795 - val_accuracy: 0.7516\n",
      "Epoch 1967/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0507 - accuracy: 0.8400 - val_loss: 0.0784 - val_accuracy: 0.7518\n",
      "Epoch 1968/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0509 - accuracy: 0.8394 - val_loss: 0.0788 - val_accuracy: 0.7547\n",
      "Epoch 1969/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0508 - accuracy: 0.8400 - val_loss: 0.0788 - val_accuracy: 0.7529\n",
      "Epoch 1970/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0510 - accuracy: 0.8389 - val_loss: 0.0784 - val_accuracy: 0.7539\n",
      "Epoch 1971/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0510 - accuracy: 0.8390 - val_loss: 0.0794 - val_accuracy: 0.7542\n",
      "Epoch 1972/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0509 - accuracy: 0.8393 - val_loss: 0.0789 - val_accuracy: 0.7532\n",
      "Epoch 1973/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0509 - accuracy: 0.8392 - val_loss: 0.0784 - val_accuracy: 0.7543\n",
      "Epoch 1974/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0510 - accuracy: 0.8390 - val_loss: 0.0781 - val_accuracy: 0.7539\n",
      "Epoch 1975/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0508 - accuracy: 0.8399 - val_loss: 0.0783 - val_accuracy: 0.7512\n",
      "Epoch 1976/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0509 - accuracy: 0.8392 - val_loss: 0.0787 - val_accuracy: 0.7537\n",
      "Epoch 1977/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0509 - accuracy: 0.8393 - val_loss: 0.0790 - val_accuracy: 0.7521\n",
      "Epoch 1978/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0508 - accuracy: 0.8397 - val_loss: 0.0786 - val_accuracy: 0.7535\n",
      "Epoch 1979/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0510 - accuracy: 0.8393 - val_loss: 0.0796 - val_accuracy: 0.7536\n",
      "Epoch 1980/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0509 - accuracy: 0.8393 - val_loss: 0.0780 - val_accuracy: 0.7549\n",
      "Epoch 1981/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0507 - accuracy: 0.8401 - val_loss: 0.0791 - val_accuracy: 0.7537\n",
      "Epoch 1982/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0509 - accuracy: 0.8398 - val_loss: 0.0785 - val_accuracy: 0.7539\n",
      "Epoch 1983/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0509 - accuracy: 0.8396 - val_loss: 0.0784 - val_accuracy: 0.7539\n",
      "Epoch 1984/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0509 - accuracy: 0.8392 - val_loss: 0.0793 - val_accuracy: 0.7520\n",
      "Epoch 1985/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0509 - accuracy: 0.8396 - val_loss: 0.0787 - val_accuracy: 0.7512\n",
      "Epoch 1986/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0509 - accuracy: 0.8391 - val_loss: 0.0788 - val_accuracy: 0.7546\n",
      "Epoch 1987/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0509 - accuracy: 0.8397 - val_loss: 0.0801 - val_accuracy: 0.7511\n",
      "Epoch 1988/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0508 - accuracy: 0.8395 - val_loss: 0.0786 - val_accuracy: 0.7538\n",
      "Epoch 1989/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0510 - accuracy: 0.8387 - val_loss: 0.0787 - val_accuracy: 0.7529\n",
      "Epoch 1990/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0508 - accuracy: 0.8396 - val_loss: 0.0790 - val_accuracy: 0.7544\n",
      "Epoch 1991/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0509 - accuracy: 0.8394 - val_loss: 0.0799 - val_accuracy: 0.7522\n",
      "Epoch 1992/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0510 - accuracy: 0.8388 - val_loss: 0.0787 - val_accuracy: 0.7526\n",
      "Epoch 1993/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0510 - accuracy: 0.8391 - val_loss: 0.0788 - val_accuracy: 0.7536\n",
      "Epoch 1994/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0513 - accuracy: 0.8382 - val_loss: 0.0806 - val_accuracy: 0.7518\n",
      "Epoch 1995/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0510 - accuracy: 0.8389 - val_loss: 0.0795 - val_accuracy: 0.7516\n",
      "Epoch 1996/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0507 - accuracy: 0.8402 - val_loss: 0.0784 - val_accuracy: 0.7545\n",
      "Epoch 1997/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0510 - accuracy: 0.8393 - val_loss: 0.0793 - val_accuracy: 0.7533\n",
      "Epoch 1998/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0508 - accuracy: 0.8398 - val_loss: 0.0781 - val_accuracy: 0.7535\n",
      "Epoch 1999/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0506 - accuracy: 0.8403 - val_loss: 0.0784 - val_accuracy: 0.7524\n",
      "Epoch 2000/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0507 - accuracy: 0.8396 - val_loss: 0.0792 - val_accuracy: 0.7532\n",
      "Epoch 2001/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0507 - accuracy: 0.8398 - val_loss: 0.0787 - val_accuracy: 0.7526\n",
      "Epoch 2002/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0508 - accuracy: 0.8395 - val_loss: 0.0780 - val_accuracy: 0.7537\n",
      "Epoch 2003/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0509 - accuracy: 0.8395 - val_loss: 0.0781 - val_accuracy: 0.7545\n",
      "Epoch 2004/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0506 - accuracy: 0.8401 - val_loss: 0.0785 - val_accuracy: 0.7550\n",
      "Epoch 2005/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0508 - accuracy: 0.8398 - val_loss: 0.0794 - val_accuracy: 0.7496\n",
      "Epoch 2006/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0509 - accuracy: 0.8395 - val_loss: 0.0783 - val_accuracy: 0.7535\n",
      "Epoch 2007/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0508 - accuracy: 0.8395 - val_loss: 0.0784 - val_accuracy: 0.7545\n",
      "Epoch 2008/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0508 - accuracy: 0.8399 - val_loss: 0.0784 - val_accuracy: 0.7540\n",
      "Epoch 2009/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0511 - accuracy: 0.8386 - val_loss: 0.0789 - val_accuracy: 0.7518\n",
      "Epoch 2010/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0508 - accuracy: 0.8395 - val_loss: 0.0780 - val_accuracy: 0.7530\n",
      "Epoch 2011/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0508 - accuracy: 0.8399 - val_loss: 0.0794 - val_accuracy: 0.7537\n",
      "Epoch 2012/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0508 - accuracy: 0.8397 - val_loss: 0.0784 - val_accuracy: 0.7515\n",
      "Epoch 2013/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0508 - accuracy: 0.8398 - val_loss: 0.0784 - val_accuracy: 0.7530\n",
      "Epoch 2014/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0509 - accuracy: 0.8395 - val_loss: 0.0785 - val_accuracy: 0.7533\n",
      "Epoch 2015/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0508 - accuracy: 0.8396 - val_loss: 0.0771 - val_accuracy: 0.7549\n",
      "Epoch 2016/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0510 - accuracy: 0.8394 - val_loss: 0.0799 - val_accuracy: 0.7533\n",
      "Epoch 2017/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0509 - accuracy: 0.8395 - val_loss: 0.0786 - val_accuracy: 0.7515\n",
      "Epoch 2018/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0509 - accuracy: 0.8388 - val_loss: 0.0795 - val_accuracy: 0.7522\n",
      "Epoch 2019/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0507 - accuracy: 0.8398 - val_loss: 0.0783 - val_accuracy: 0.7546\n",
      "Epoch 2020/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0507 - accuracy: 0.8398 - val_loss: 0.0784 - val_accuracy: 0.7536\n",
      "Epoch 2021/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0508 - accuracy: 0.8397 - val_loss: 0.0779 - val_accuracy: 0.7540\n",
      "Epoch 2022/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0506 - accuracy: 0.8403 - val_loss: 0.0796 - val_accuracy: 0.7528\n",
      "Epoch 2023/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0509 - accuracy: 0.8390 - val_loss: 0.0787 - val_accuracy: 0.7529\n",
      "Epoch 2024/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0508 - accuracy: 0.8392 - val_loss: 0.0777 - val_accuracy: 0.7543\n",
      "Epoch 2025/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0509 - accuracy: 0.8388 - val_loss: 0.0775 - val_accuracy: 0.7553\n",
      "Epoch 2026/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0508 - accuracy: 0.8398 - val_loss: 0.0780 - val_accuracy: 0.7538\n",
      "Epoch 2027/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0507 - accuracy: 0.8399 - val_loss: 0.0785 - val_accuracy: 0.7553\n",
      "Epoch 2028/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0509 - accuracy: 0.8395 - val_loss: 0.0784 - val_accuracy: 0.7531\n",
      "Epoch 2029/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0510 - accuracy: 0.8388 - val_loss: 0.0778 - val_accuracy: 0.7530\n",
      "Epoch 2030/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0508 - accuracy: 0.8394 - val_loss: 0.0774 - val_accuracy: 0.7542\n",
      "Epoch 2031/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0508 - accuracy: 0.8394 - val_loss: 0.0779 - val_accuracy: 0.7535\n",
      "Epoch 2032/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0508 - accuracy: 0.8391 - val_loss: 0.0781 - val_accuracy: 0.7544\n",
      "Epoch 2033/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0509 - accuracy: 0.8394 - val_loss: 0.0787 - val_accuracy: 0.7540\n",
      "Epoch 2034/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0512 - accuracy: 0.8381 - val_loss: 0.0791 - val_accuracy: 0.7544\n",
      "Epoch 2035/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0510 - accuracy: 0.8391 - val_loss: 0.0777 - val_accuracy: 0.7556\n",
      "Epoch 2036/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0508 - accuracy: 0.8393 - val_loss: 0.0787 - val_accuracy: 0.7547\n",
      "Epoch 2037/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0510 - accuracy: 0.8391 - val_loss: 0.0790 - val_accuracy: 0.7529\n",
      "Epoch 2038/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0511 - accuracy: 0.8389 - val_loss: 0.0786 - val_accuracy: 0.7524\n",
      "Epoch 2039/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0510 - accuracy: 0.8390 - val_loss: 0.0789 - val_accuracy: 0.7544\n",
      "Epoch 2040/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0510 - accuracy: 0.8392 - val_loss: 0.0781 - val_accuracy: 0.7537\n",
      "Epoch 2041/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0510 - accuracy: 0.8389 - val_loss: 0.0786 - val_accuracy: 0.7544\n",
      "Epoch 2042/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0509 - accuracy: 0.8392 - val_loss: 0.0785 - val_accuracy: 0.7535\n",
      "Epoch 2043/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0509 - accuracy: 0.8394 - val_loss: 0.0784 - val_accuracy: 0.7537\n",
      "Epoch 2044/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0509 - accuracy: 0.8394 - val_loss: 0.0794 - val_accuracy: 0.7538\n",
      "Epoch 2045/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0508 - accuracy: 0.8395 - val_loss: 0.0774 - val_accuracy: 0.7552\n",
      "Epoch 2046/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0509 - accuracy: 0.8393 - val_loss: 0.0775 - val_accuracy: 0.7550\n",
      "Epoch 2047/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0509 - accuracy: 0.8395 - val_loss: 0.0791 - val_accuracy: 0.7501\n",
      "Epoch 2048/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0510 - accuracy: 0.8391 - val_loss: 0.0782 - val_accuracy: 0.7541\n",
      "Epoch 2049/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0508 - accuracy: 0.8398 - val_loss: 0.0792 - val_accuracy: 0.7538\n",
      "Epoch 2050/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0509 - accuracy: 0.8391 - val_loss: 0.0786 - val_accuracy: 0.7537\n",
      "Epoch 2051/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0508 - accuracy: 0.8397 - val_loss: 0.0785 - val_accuracy: 0.7528\n",
      "Epoch 2052/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0511 - accuracy: 0.8387 - val_loss: 0.0801 - val_accuracy: 0.7541\n",
      "Epoch 2053/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0510 - accuracy: 0.8391 - val_loss: 0.0779 - val_accuracy: 0.7540\n",
      "Epoch 2054/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0510 - accuracy: 0.8389 - val_loss: 0.0783 - val_accuracy: 0.7537\n",
      "Epoch 2055/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0508 - accuracy: 0.8399 - val_loss: 0.0778 - val_accuracy: 0.7544\n",
      "Epoch 2056/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0508 - accuracy: 0.8395 - val_loss: 0.0801 - val_accuracy: 0.7538\n",
      "Epoch 2057/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0510 - accuracy: 0.8389 - val_loss: 0.0782 - val_accuracy: 0.7540\n",
      "Epoch 2058/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0509 - accuracy: 0.8392 - val_loss: 0.0793 - val_accuracy: 0.7539\n",
      "Epoch 2059/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0513 - accuracy: 0.8382 - val_loss: 0.0784 - val_accuracy: 0.7534\n",
      "Epoch 2060/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0510 - accuracy: 0.8391 - val_loss: 0.0793 - val_accuracy: 0.7530\n",
      "Epoch 2061/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0510 - accuracy: 0.8389 - val_loss: 0.0788 - val_accuracy: 0.7539\n",
      "Epoch 2062/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0505 - accuracy: 0.8401 - val_loss: 0.0782 - val_accuracy: 0.7561\n",
      "Epoch 2063/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0508 - accuracy: 0.8398 - val_loss: 0.0790 - val_accuracy: 0.7547\n",
      "Epoch 2064/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0509 - accuracy: 0.8393 - val_loss: 0.0797 - val_accuracy: 0.7522\n",
      "Epoch 2065/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0512 - accuracy: 0.8384 - val_loss: 0.0774 - val_accuracy: 0.7548\n",
      "Epoch 2066/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0510 - accuracy: 0.8390 - val_loss: 0.0796 - val_accuracy: 0.7528\n",
      "Epoch 2067/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0511 - accuracy: 0.8384 - val_loss: 0.0786 - val_accuracy: 0.7537\n",
      "Epoch 2068/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0508 - accuracy: 0.8397 - val_loss: 0.0777 - val_accuracy: 0.7534\n",
      "Epoch 2069/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0507 - accuracy: 0.8403 - val_loss: 0.0778 - val_accuracy: 0.7537\n",
      "Epoch 2070/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0507 - accuracy: 0.8398 - val_loss: 0.0781 - val_accuracy: 0.7552\n",
      "Epoch 2071/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0509 - accuracy: 0.8395 - val_loss: 0.0785 - val_accuracy: 0.7551\n",
      "Epoch 2072/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0507 - accuracy: 0.8403 - val_loss: 0.0783 - val_accuracy: 0.7544\n",
      "Epoch 2073/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0507 - accuracy: 0.8398 - val_loss: 0.0792 - val_accuracy: 0.7540\n",
      "Epoch 2074/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0507 - accuracy: 0.8400 - val_loss: 0.0791 - val_accuracy: 0.7545\n",
      "Epoch 2075/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0510 - accuracy: 0.8389 - val_loss: 0.0785 - val_accuracy: 0.7550\n",
      "Epoch 2076/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0508 - accuracy: 0.8397 - val_loss: 0.0778 - val_accuracy: 0.7541\n",
      "Epoch 2077/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0506 - accuracy: 0.8402 - val_loss: 0.0776 - val_accuracy: 0.7559\n",
      "Epoch 2078/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0506 - accuracy: 0.8400 - val_loss: 0.0779 - val_accuracy: 0.7548\n",
      "Epoch 2079/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0506 - accuracy: 0.8403 - val_loss: 0.0781 - val_accuracy: 0.7547\n",
      "Epoch 2080/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0505 - accuracy: 0.8405 - val_loss: 0.0778 - val_accuracy: 0.7555\n",
      "Epoch 2081/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0507 - accuracy: 0.8400 - val_loss: 0.0779 - val_accuracy: 0.7548\n",
      "Epoch 2082/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0508 - accuracy: 0.8395 - val_loss: 0.0769 - val_accuracy: 0.7557\n",
      "Epoch 2083/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0506 - accuracy: 0.8400 - val_loss: 0.0784 - val_accuracy: 0.7544\n",
      "Epoch 2084/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0507 - accuracy: 0.8405 - val_loss: 0.0786 - val_accuracy: 0.7547\n",
      "Epoch 2085/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0508 - accuracy: 0.8396 - val_loss: 0.0773 - val_accuracy: 0.7540\n",
      "Epoch 2086/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0508 - accuracy: 0.8398 - val_loss: 0.0792 - val_accuracy: 0.7556\n",
      "Epoch 2087/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0509 - accuracy: 0.8396 - val_loss: 0.0781 - val_accuracy: 0.7549\n",
      "Epoch 2088/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0507 - accuracy: 0.8397 - val_loss: 0.0784 - val_accuracy: 0.7542\n",
      "Epoch 2089/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0510 - accuracy: 0.8390 - val_loss: 0.0780 - val_accuracy: 0.7543\n",
      "Epoch 2090/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0510 - accuracy: 0.8392 - val_loss: 0.0783 - val_accuracy: 0.7546\n",
      "Epoch 2091/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0507 - accuracy: 0.8398 - val_loss: 0.0777 - val_accuracy: 0.7556\n",
      "Epoch 2092/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0508 - accuracy: 0.8395 - val_loss: 0.0780 - val_accuracy: 0.7556\n",
      "Epoch 2093/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0508 - accuracy: 0.8398 - val_loss: 0.0785 - val_accuracy: 0.7536\n",
      "Epoch 2094/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0508 - accuracy: 0.8396 - val_loss: 0.0781 - val_accuracy: 0.7556\n",
      "Epoch 2095/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0507 - accuracy: 0.8400 - val_loss: 0.0783 - val_accuracy: 0.7530\n",
      "Epoch 2096/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0509 - accuracy: 0.8392 - val_loss: 0.0783 - val_accuracy: 0.7548\n",
      "Epoch 2097/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0508 - accuracy: 0.8396 - val_loss: 0.0780 - val_accuracy: 0.7546\n",
      "Epoch 2098/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0507 - accuracy: 0.8400 - val_loss: 0.0787 - val_accuracy: 0.7538\n",
      "Epoch 2099/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0508 - accuracy: 0.8398 - val_loss: 0.0786 - val_accuracy: 0.7513\n",
      "Epoch 2100/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0508 - accuracy: 0.8395 - val_loss: 0.0786 - val_accuracy: 0.7548\n",
      "Epoch 2101/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0509 - accuracy: 0.8393 - val_loss: 0.0780 - val_accuracy: 0.7547\n",
      "Epoch 2102/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0510 - accuracy: 0.8390 - val_loss: 0.0790 - val_accuracy: 0.7536\n",
      "Epoch 2103/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0509 - accuracy: 0.8394 - val_loss: 0.0786 - val_accuracy: 0.7530\n",
      "Epoch 2104/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0509 - accuracy: 0.8391 - val_loss: 0.0777 - val_accuracy: 0.7557\n",
      "Epoch 2105/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0507 - accuracy: 0.8398 - val_loss: 0.0783 - val_accuracy: 0.7544\n",
      "Epoch 2106/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0507 - accuracy: 0.8401 - val_loss: 0.0786 - val_accuracy: 0.7529\n",
      "Epoch 2107/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0510 - accuracy: 0.8386 - val_loss: 0.0789 - val_accuracy: 0.7562\n",
      "Epoch 2108/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0510 - accuracy: 0.8384 - val_loss: 0.0786 - val_accuracy: 0.7535\n",
      "Epoch 2109/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0510 - accuracy: 0.8390 - val_loss: 0.0791 - val_accuracy: 0.7534\n",
      "Epoch 2110/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0509 - accuracy: 0.8393 - val_loss: 0.0787 - val_accuracy: 0.7546\n",
      "Epoch 2111/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0508 - accuracy: 0.8396 - val_loss: 0.0783 - val_accuracy: 0.7537\n",
      "Epoch 2112/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0509 - accuracy: 0.8391 - val_loss: 0.0792 - val_accuracy: 0.7544\n",
      "Epoch 2113/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0509 - accuracy: 0.8394 - val_loss: 0.0797 - val_accuracy: 0.7530\n",
      "Epoch 2114/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0507 - accuracy: 0.8401 - val_loss: 0.0780 - val_accuracy: 0.7563\n",
      "Epoch 2115/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0508 - accuracy: 0.8395 - val_loss: 0.0787 - val_accuracy: 0.7528\n",
      "Epoch 2116/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0510 - accuracy: 0.8386 - val_loss: 0.0786 - val_accuracy: 0.7536\n",
      "Epoch 2117/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0507 - accuracy: 0.8399 - val_loss: 0.0776 - val_accuracy: 0.7540\n",
      "Epoch 2118/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0510 - accuracy: 0.8393 - val_loss: 0.0783 - val_accuracy: 0.7536\n",
      "Epoch 2119/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0509 - accuracy: 0.8395 - val_loss: 0.0772 - val_accuracy: 0.7549\n",
      "Epoch 2120/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0509 - accuracy: 0.8393 - val_loss: 0.0781 - val_accuracy: 0.7521\n",
      "Epoch 2121/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0508 - accuracy: 0.8397 - val_loss: 0.0778 - val_accuracy: 0.7546\n",
      "Epoch 2122/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0508 - accuracy: 0.8396 - val_loss: 0.0777 - val_accuracy: 0.7545\n",
      "Epoch 2123/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0509 - accuracy: 0.8392 - val_loss: 0.0781 - val_accuracy: 0.7547\n",
      "Epoch 2124/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0510 - accuracy: 0.8390 - val_loss: 0.0783 - val_accuracy: 0.7514\n",
      "Epoch 2125/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0509 - accuracy: 0.8392 - val_loss: 0.0775 - val_accuracy: 0.7544\n",
      "Epoch 2126/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0509 - accuracy: 0.8393 - val_loss: 0.0779 - val_accuracy: 0.7544\n",
      "Epoch 2127/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0510 - accuracy: 0.8391 - val_loss: 0.0788 - val_accuracy: 0.7530\n",
      "Epoch 2128/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0512 - accuracy: 0.8387 - val_loss: 0.0785 - val_accuracy: 0.7547\n",
      "Epoch 2129/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0512 - accuracy: 0.8385 - val_loss: 0.0785 - val_accuracy: 0.7539\n",
      "Epoch 2130/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0510 - accuracy: 0.8394 - val_loss: 0.0782 - val_accuracy: 0.7548\n",
      "Epoch 2131/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0511 - accuracy: 0.8389 - val_loss: 0.0792 - val_accuracy: 0.7542\n",
      "Epoch 2132/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0513 - accuracy: 0.8384 - val_loss: 0.0787 - val_accuracy: 0.7507\n",
      "Epoch 2133/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0510 - accuracy: 0.8390 - val_loss: 0.0786 - val_accuracy: 0.7538\n",
      "Epoch 2134/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0510 - accuracy: 0.8392 - val_loss: 0.0787 - val_accuracy: 0.7555\n",
      "Epoch 2135/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0509 - accuracy: 0.8393 - val_loss: 0.0779 - val_accuracy: 0.7540\n",
      "Epoch 2136/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0511 - accuracy: 0.8388 - val_loss: 0.0787 - val_accuracy: 0.7549\n",
      "Epoch 2137/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0509 - accuracy: 0.8394 - val_loss: 0.0791 - val_accuracy: 0.7550\n",
      "Epoch 2138/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0510 - accuracy: 0.8389 - val_loss: 0.0789 - val_accuracy: 0.7542\n",
      "Epoch 2139/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0509 - accuracy: 0.8394 - val_loss: 0.0778 - val_accuracy: 0.7546\n",
      "Epoch 2140/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0510 - accuracy: 0.8395 - val_loss: 0.0779 - val_accuracy: 0.7549\n",
      "Epoch 2141/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0510 - accuracy: 0.8390 - val_loss: 0.0785 - val_accuracy: 0.7548\n",
      "Epoch 2142/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0509 - accuracy: 0.8393 - val_loss: 0.0782 - val_accuracy: 0.7552\n",
      "Epoch 2143/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0510 - accuracy: 0.8390 - val_loss: 0.0793 - val_accuracy: 0.7525\n",
      "Epoch 2144/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0510 - accuracy: 0.8391 - val_loss: 0.0783 - val_accuracy: 0.7528\n",
      "Epoch 2145/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0508 - accuracy: 0.8396 - val_loss: 0.0782 - val_accuracy: 0.7532\n",
      "Epoch 2146/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0509 - accuracy: 0.8394 - val_loss: 0.0773 - val_accuracy: 0.7548\n",
      "Epoch 2147/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0510 - accuracy: 0.8395 - val_loss: 0.0791 - val_accuracy: 0.7548\n",
      "Epoch 2148/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0508 - accuracy: 0.8395 - val_loss: 0.0779 - val_accuracy: 0.7535\n",
      "Epoch 2149/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0507 - accuracy: 0.8397 - val_loss: 0.0777 - val_accuracy: 0.7545\n",
      "Epoch 2150/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0510 - accuracy: 0.8389 - val_loss: 0.0793 - val_accuracy: 0.7540\n",
      "Epoch 2151/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0509 - accuracy: 0.8394 - val_loss: 0.0788 - val_accuracy: 0.7499\n",
      "Epoch 2152/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0509 - accuracy: 0.8391 - val_loss: 0.0784 - val_accuracy: 0.7533\n",
      "Epoch 2153/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0509 - accuracy: 0.8394 - val_loss: 0.0785 - val_accuracy: 0.7547\n",
      "Epoch 2154/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0508 - accuracy: 0.8399 - val_loss: 0.0780 - val_accuracy: 0.7547\n",
      "Epoch 2155/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0510 - accuracy: 0.8391 - val_loss: 0.0779 - val_accuracy: 0.7544\n",
      "Epoch 2156/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0511 - accuracy: 0.8388 - val_loss: 0.0787 - val_accuracy: 0.7531\n",
      "Epoch 2157/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0511 - accuracy: 0.8387 - val_loss: 0.0780 - val_accuracy: 0.7543\n",
      "Epoch 2158/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0510 - accuracy: 0.8393 - val_loss: 0.0787 - val_accuracy: 0.7545\n",
      "Epoch 2159/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0513 - accuracy: 0.8385 - val_loss: 0.0787 - val_accuracy: 0.7527\n",
      "Epoch 2160/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0514 - accuracy: 0.8385 - val_loss: 0.0789 - val_accuracy: 0.7533\n",
      "Epoch 2161/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0511 - accuracy: 0.8385 - val_loss: 0.0788 - val_accuracy: 0.7543\n",
      "Epoch 2162/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0511 - accuracy: 0.8389 - val_loss: 0.0783 - val_accuracy: 0.7522\n",
      "Epoch 2163/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0510 - accuracy: 0.8391 - val_loss: 0.0792 - val_accuracy: 0.7544\n",
      "Epoch 2164/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0512 - accuracy: 0.8385 - val_loss: 0.0787 - val_accuracy: 0.7513\n",
      "Epoch 2165/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0510 - accuracy: 0.8387 - val_loss: 0.0789 - val_accuracy: 0.7541\n",
      "Epoch 2166/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0510 - accuracy: 0.8390 - val_loss: 0.0795 - val_accuracy: 0.7554\n",
      "Epoch 2167/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0511 - accuracy: 0.8392 - val_loss: 0.0786 - val_accuracy: 0.7515\n",
      "Epoch 2168/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0512 - accuracy: 0.8385 - val_loss: 0.0780 - val_accuracy: 0.7539\n",
      "Epoch 2169/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0513 - accuracy: 0.8383 - val_loss: 0.0788 - val_accuracy: 0.7545\n",
      "Epoch 2170/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0512 - accuracy: 0.8384 - val_loss: 0.0799 - val_accuracy: 0.7517\n",
      "Epoch 2171/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0512 - accuracy: 0.8384 - val_loss: 0.0779 - val_accuracy: 0.7527\n",
      "Epoch 2172/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0513 - accuracy: 0.8383 - val_loss: 0.0788 - val_accuracy: 0.7532\n",
      "Epoch 2173/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0514 - accuracy: 0.8380 - val_loss: 0.0782 - val_accuracy: 0.7530\n",
      "Epoch 2174/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0512 - accuracy: 0.8382 - val_loss: 0.0783 - val_accuracy: 0.7532\n",
      "Epoch 2175/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0512 - accuracy: 0.8380 - val_loss: 0.0781 - val_accuracy: 0.7525\n",
      "Epoch 2176/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0515 - accuracy: 0.8377 - val_loss: 0.0782 - val_accuracy: 0.7527\n",
      "Epoch 2177/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0514 - accuracy: 0.8376 - val_loss: 0.0782 - val_accuracy: 0.7540\n",
      "Epoch 2178/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0513 - accuracy: 0.8382 - val_loss: 0.0794 - val_accuracy: 0.7520\n",
      "Epoch 2179/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0513 - accuracy: 0.8382 - val_loss: 0.0793 - val_accuracy: 0.7534\n",
      "Epoch 2180/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0513 - accuracy: 0.8383 - val_loss: 0.0781 - val_accuracy: 0.7533\n",
      "Epoch 2181/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0514 - accuracy: 0.8380 - val_loss: 0.0790 - val_accuracy: 0.7483\n",
      "Epoch 2182/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0512 - accuracy: 0.8385 - val_loss: 0.0787 - val_accuracy: 0.7515\n",
      "Epoch 2183/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0511 - accuracy: 0.8385 - val_loss: 0.0791 - val_accuracy: 0.7548\n",
      "Epoch 2184/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0510 - accuracy: 0.8395 - val_loss: 0.0792 - val_accuracy: 0.7532\n",
      "Epoch 2185/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0513 - accuracy: 0.8382 - val_loss: 0.0789 - val_accuracy: 0.7531\n",
      "Epoch 2186/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0512 - accuracy: 0.8386 - val_loss: 0.0784 - val_accuracy: 0.7524\n",
      "Epoch 2187/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0512 - accuracy: 0.8386 - val_loss: 0.0779 - val_accuracy: 0.7536\n",
      "Epoch 2188/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0512 - accuracy: 0.8387 - val_loss: 0.0787 - val_accuracy: 0.7535\n",
      "Epoch 2189/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0513 - accuracy: 0.8382 - val_loss: 0.0791 - val_accuracy: 0.7529\n",
      "Epoch 2190/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0513 - accuracy: 0.8382 - val_loss: 0.0791 - val_accuracy: 0.7544\n",
      "Epoch 2191/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0512 - accuracy: 0.8384 - val_loss: 0.0777 - val_accuracy: 0.7544\n",
      "Epoch 2192/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0512 - accuracy: 0.8388 - val_loss: 0.0784 - val_accuracy: 0.7541\n",
      "Epoch 2193/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0512 - accuracy: 0.8387 - val_loss: 0.0786 - val_accuracy: 0.7517\n",
      "Epoch 2194/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0513 - accuracy: 0.8387 - val_loss: 0.0780 - val_accuracy: 0.7550\n",
      "Epoch 2195/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0510 - accuracy: 0.8392 - val_loss: 0.0783 - val_accuracy: 0.7532\n",
      "Epoch 2196/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0513 - accuracy: 0.8383 - val_loss: 0.0791 - val_accuracy: 0.7511\n",
      "Epoch 2197/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0511 - accuracy: 0.8389 - val_loss: 0.0783 - val_accuracy: 0.7547\n",
      "Epoch 2198/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0511 - accuracy: 0.8389 - val_loss: 0.0780 - val_accuracy: 0.7534\n",
      "Epoch 2199/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0512 - accuracy: 0.8387 - val_loss: 0.0789 - val_accuracy: 0.7549\n",
      "Epoch 2200/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0512 - accuracy: 0.8386 - val_loss: 0.0793 - val_accuracy: 0.7535\n",
      "Epoch 2201/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0513 - accuracy: 0.8379 - val_loss: 0.0783 - val_accuracy: 0.7550\n",
      "Epoch 2202/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0510 - accuracy: 0.8391 - val_loss: 0.0775 - val_accuracy: 0.7550\n",
      "Epoch 2203/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0511 - accuracy: 0.8389 - val_loss: 0.0779 - val_accuracy: 0.7555\n",
      "Epoch 2204/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0512 - accuracy: 0.8391 - val_loss: 0.0786 - val_accuracy: 0.7542\n",
      "Epoch 2205/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0513 - accuracy: 0.8383 - val_loss: 0.0793 - val_accuracy: 0.7525\n",
      "Epoch 2206/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0513 - accuracy: 0.8388 - val_loss: 0.0788 - val_accuracy: 0.7551\n",
      "Epoch 2207/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0513 - accuracy: 0.8382 - val_loss: 0.0784 - val_accuracy: 0.7517\n",
      "Epoch 2208/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0512 - accuracy: 0.8387 - val_loss: 0.0777 - val_accuracy: 0.7531\n",
      "Epoch 2209/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0515 - accuracy: 0.8377 - val_loss: 0.0791 - val_accuracy: 0.7515\n",
      "Epoch 2210/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0514 - accuracy: 0.8384 - val_loss: 0.0781 - val_accuracy: 0.7531\n",
      "Epoch 2211/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0515 - accuracy: 0.8380 - val_loss: 0.0808 - val_accuracy: 0.7516\n",
      "Epoch 2212/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0515 - accuracy: 0.8375 - val_loss: 0.0792 - val_accuracy: 0.7522\n",
      "Epoch 2213/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0514 - accuracy: 0.8381 - val_loss: 0.0794 - val_accuracy: 0.7536\n",
      "Epoch 2214/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0515 - accuracy: 0.8383 - val_loss: 0.0798 - val_accuracy: 0.7526\n",
      "Epoch 2215/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0514 - accuracy: 0.8381 - val_loss: 0.0791 - val_accuracy: 0.7529\n",
      "Epoch 2216/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0514 - accuracy: 0.8384 - val_loss: 0.0781 - val_accuracy: 0.7514\n",
      "Epoch 2217/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0513 - accuracy: 0.8386 - val_loss: 0.0787 - val_accuracy: 0.7539\n",
      "Epoch 2218/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0513 - accuracy: 0.8380 - val_loss: 0.0783 - val_accuracy: 0.7553\n",
      "Epoch 2219/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0512 - accuracy: 0.8384 - val_loss: 0.0784 - val_accuracy: 0.7542\n",
      "Epoch 2220/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0512 - accuracy: 0.8389 - val_loss: 0.0782 - val_accuracy: 0.7532\n",
      "Epoch 2221/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0512 - accuracy: 0.8388 - val_loss: 0.0790 - val_accuracy: 0.7544\n",
      "Epoch 2222/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0511 - accuracy: 0.8389 - val_loss: 0.0789 - val_accuracy: 0.7546\n",
      "Epoch 2223/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0510 - accuracy: 0.8396 - val_loss: 0.0798 - val_accuracy: 0.7549\n",
      "Epoch 2224/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0511 - accuracy: 0.8392 - val_loss: 0.0786 - val_accuracy: 0.7550\n",
      "Epoch 2225/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0512 - accuracy: 0.8391 - val_loss: 0.0793 - val_accuracy: 0.7526\n",
      "Epoch 2226/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0511 - accuracy: 0.8392 - val_loss: 0.0779 - val_accuracy: 0.7536\n",
      "Epoch 2227/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0511 - accuracy: 0.8390 - val_loss: 0.0786 - val_accuracy: 0.7535\n",
      "Epoch 2228/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0512 - accuracy: 0.8386 - val_loss: 0.0780 - val_accuracy: 0.7540\n",
      "Epoch 2229/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0512 - accuracy: 0.8388 - val_loss: 0.0790 - val_accuracy: 0.7542\n",
      "Epoch 2230/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0511 - accuracy: 0.8390 - val_loss: 0.0784 - val_accuracy: 0.7553\n",
      "Epoch 2231/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0511 - accuracy: 0.8389 - val_loss: 0.0788 - val_accuracy: 0.7552\n",
      "Epoch 2232/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0511 - accuracy: 0.8394 - val_loss: 0.0786 - val_accuracy: 0.7527\n",
      "Epoch 2233/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0512 - accuracy: 0.8393 - val_loss: 0.0795 - val_accuracy: 0.7522\n",
      "Epoch 2234/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0514 - accuracy: 0.8383 - val_loss: 0.0787 - val_accuracy: 0.7534\n",
      "Epoch 2235/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0511 - accuracy: 0.8387 - val_loss: 0.0776 - val_accuracy: 0.7548\n",
      "Epoch 2236/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0511 - accuracy: 0.8391 - val_loss: 0.0792 - val_accuracy: 0.7536\n",
      "Epoch 2237/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0512 - accuracy: 0.8389 - val_loss: 0.0787 - val_accuracy: 0.7536\n",
      "Epoch 2238/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0513 - accuracy: 0.8387 - val_loss: 0.0781 - val_accuracy: 0.7551\n",
      "Epoch 2239/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0512 - accuracy: 0.8385 - val_loss: 0.0779 - val_accuracy: 0.7547\n",
      "Epoch 2240/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0512 - accuracy: 0.8385 - val_loss: 0.0779 - val_accuracy: 0.7534\n",
      "Epoch 2241/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0511 - accuracy: 0.8391 - val_loss: 0.0786 - val_accuracy: 0.7552\n",
      "Epoch 2242/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0510 - accuracy: 0.8392 - val_loss: 0.0777 - val_accuracy: 0.7547\n",
      "Epoch 2243/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0510 - accuracy: 0.8390 - val_loss: 0.0786 - val_accuracy: 0.7540\n",
      "Epoch 2244/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0513 - accuracy: 0.8388 - val_loss: 0.0786 - val_accuracy: 0.7553\n",
      "Epoch 2245/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0511 - accuracy: 0.8390 - val_loss: 0.0792 - val_accuracy: 0.7529\n",
      "Epoch 2246/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0512 - accuracy: 0.8385 - val_loss: 0.0784 - val_accuracy: 0.7543\n",
      "Epoch 2247/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0512 - accuracy: 0.8387 - val_loss: 0.0791 - val_accuracy: 0.7527\n",
      "Epoch 2248/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0512 - accuracy: 0.8386 - val_loss: 0.0771 - val_accuracy: 0.7551\n",
      "Epoch 2249/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0512 - accuracy: 0.8388 - val_loss: 0.0789 - val_accuracy: 0.7544\n",
      "Epoch 2250/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0512 - accuracy: 0.8385 - val_loss: 0.0777 - val_accuracy: 0.7552\n",
      "Epoch 2251/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0512 - accuracy: 0.8386 - val_loss: 0.0783 - val_accuracy: 0.7532\n",
      "Epoch 2252/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0512 - accuracy: 0.8388 - val_loss: 0.0779 - val_accuracy: 0.7529\n",
      "Epoch 2253/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0511 - accuracy: 0.8392 - val_loss: 0.0779 - val_accuracy: 0.7546\n",
      "Epoch 2254/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0510 - accuracy: 0.8397 - val_loss: 0.0777 - val_accuracy: 0.7544\n",
      "Epoch 2255/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0512 - accuracy: 0.8384 - val_loss: 0.0792 - val_accuracy: 0.7535\n",
      "Epoch 2256/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0511 - accuracy: 0.8392 - val_loss: 0.0786 - val_accuracy: 0.7531\n",
      "Epoch 2257/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0512 - accuracy: 0.8385 - val_loss: 0.0785 - val_accuracy: 0.7536\n",
      "Epoch 2258/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0513 - accuracy: 0.8386 - val_loss: 0.0784 - val_accuracy: 0.7528\n",
      "Epoch 2259/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0513 - accuracy: 0.8390 - val_loss: 0.0780 - val_accuracy: 0.7549\n",
      "Epoch 2260/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0511 - accuracy: 0.8395 - val_loss: 0.0780 - val_accuracy: 0.7541\n",
      "Epoch 2261/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0512 - accuracy: 0.8388 - val_loss: 0.0777 - val_accuracy: 0.7544\n",
      "Epoch 2262/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0511 - accuracy: 0.8392 - val_loss: 0.0786 - val_accuracy: 0.7539\n",
      "Epoch 2263/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0512 - accuracy: 0.8388 - val_loss: 0.0783 - val_accuracy: 0.7545\n",
      "Epoch 2264/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0512 - accuracy: 0.8387 - val_loss: 0.0781 - val_accuracy: 0.7549\n",
      "Epoch 2265/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0511 - accuracy: 0.8393 - val_loss: 0.0787 - val_accuracy: 0.7553\n",
      "Epoch 2266/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0512 - accuracy: 0.8388 - val_loss: 0.0790 - val_accuracy: 0.7519\n",
      "Epoch 2267/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0513 - accuracy: 0.8388 - val_loss: 0.0782 - val_accuracy: 0.7552\n",
      "Epoch 2268/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0512 - accuracy: 0.8388 - val_loss: 0.0784 - val_accuracy: 0.7533\n",
      "Epoch 2269/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0511 - accuracy: 0.8390 - val_loss: 0.0780 - val_accuracy: 0.7542\n",
      "Epoch 2270/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0511 - accuracy: 0.8389 - val_loss: 0.0799 - val_accuracy: 0.7530\n",
      "Epoch 2271/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0512 - accuracy: 0.8390 - val_loss: 0.0800 - val_accuracy: 0.7510\n",
      "Epoch 2272/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0513 - accuracy: 0.8384 - val_loss: 0.0774 - val_accuracy: 0.7553\n",
      "Epoch 2273/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0510 - accuracy: 0.8398 - val_loss: 0.0789 - val_accuracy: 0.7550\n",
      "Epoch 2274/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0512 - accuracy: 0.8388 - val_loss: 0.0777 - val_accuracy: 0.7549\n",
      "Epoch 2275/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0513 - accuracy: 0.8389 - val_loss: 0.0781 - val_accuracy: 0.7539\n",
      "Epoch 2276/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0512 - accuracy: 0.8392 - val_loss: 0.0799 - val_accuracy: 0.7522\n",
      "Epoch 2277/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0513 - accuracy: 0.8387 - val_loss: 0.0791 - val_accuracy: 0.7529\n",
      "Epoch 2278/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0512 - accuracy: 0.8388 - val_loss: 0.0805 - val_accuracy: 0.7520\n",
      "Epoch 2279/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0511 - accuracy: 0.8395 - val_loss: 0.0781 - val_accuracy: 0.7538\n",
      "Epoch 2280/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0511 - accuracy: 0.8389 - val_loss: 0.0786 - val_accuracy: 0.7547\n",
      "Epoch 2281/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0512 - accuracy: 0.8383 - val_loss: 0.0791 - val_accuracy: 0.7525\n",
      "Epoch 2282/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0512 - accuracy: 0.8383 - val_loss: 0.0780 - val_accuracy: 0.7539\n",
      "Epoch 2283/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0510 - accuracy: 0.8390 - val_loss: 0.0791 - val_accuracy: 0.7530\n",
      "Epoch 2284/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0512 - accuracy: 0.8388 - val_loss: 0.0782 - val_accuracy: 0.7536\n",
      "Epoch 2285/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0512 - accuracy: 0.8387 - val_loss: 0.0781 - val_accuracy: 0.7534\n",
      "Epoch 2286/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0513 - accuracy: 0.8382 - val_loss: 0.0784 - val_accuracy: 0.7521\n",
      "Epoch 2287/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0512 - accuracy: 0.8387 - val_loss: 0.0771 - val_accuracy: 0.7546\n",
      "Epoch 2288/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0511 - accuracy: 0.8389 - val_loss: 0.0787 - val_accuracy: 0.7531\n",
      "Epoch 2289/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0510 - accuracy: 0.8391 - val_loss: 0.0789 - val_accuracy: 0.7537\n",
      "Epoch 2290/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0510 - accuracy: 0.8394 - val_loss: 0.0781 - val_accuracy: 0.7540\n",
      "Epoch 2291/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0510 - accuracy: 0.8392 - val_loss: 0.0798 - val_accuracy: 0.7544\n",
      "Epoch 2292/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0513 - accuracy: 0.8384 - val_loss: 0.0785 - val_accuracy: 0.7542\n",
      "Epoch 2293/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0513 - accuracy: 0.8389 - val_loss: 0.0781 - val_accuracy: 0.7545\n",
      "Epoch 2294/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0512 - accuracy: 0.8391 - val_loss: 0.0781 - val_accuracy: 0.7553\n",
      "Epoch 2295/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0512 - accuracy: 0.8391 - val_loss: 0.0792 - val_accuracy: 0.7538\n",
      "Epoch 2296/5000\n",
      "11786/11786 [==============================] - 8s 691us/step - loss: 0.0512 - accuracy: 0.8390 - val_loss: 0.0788 - val_accuracy: 0.7545\n",
      "Epoch 2297/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0511 - accuracy: 0.8391 - val_loss: 0.0788 - val_accuracy: 0.7543\n",
      "Epoch 2298/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0512 - accuracy: 0.8388 - val_loss: 0.0791 - val_accuracy: 0.7537\n",
      "Epoch 2299/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0513 - accuracy: 0.8387 - val_loss: 0.0802 - val_accuracy: 0.7548\n",
      "Epoch 2300/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0513 - accuracy: 0.8384 - val_loss: 0.0773 - val_accuracy: 0.7523\n",
      "Epoch 2301/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0512 - accuracy: 0.8382 - val_loss: 0.0782 - val_accuracy: 0.7542\n",
      "Epoch 2302/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0510 - accuracy: 0.8393 - val_loss: 0.0777 - val_accuracy: 0.7551\n",
      "Epoch 2303/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0513 - accuracy: 0.8384 - val_loss: 0.0777 - val_accuracy: 0.7527\n",
      "Epoch 2304/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0512 - accuracy: 0.8389 - val_loss: 0.0786 - val_accuracy: 0.7535\n",
      "Epoch 2305/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0512 - accuracy: 0.8387 - val_loss: 0.0775 - val_accuracy: 0.7560\n",
      "Epoch 2306/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0512 - accuracy: 0.8389 - val_loss: 0.0777 - val_accuracy: 0.7555\n",
      "Epoch 2307/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0512 - accuracy: 0.8388 - val_loss: 0.0777 - val_accuracy: 0.7550\n",
      "Epoch 2308/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0512 - accuracy: 0.8389 - val_loss: 0.0791 - val_accuracy: 0.7562\n",
      "Epoch 2309/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0513 - accuracy: 0.8381 - val_loss: 0.0782 - val_accuracy: 0.7526\n",
      "Epoch 2310/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0513 - accuracy: 0.8385 - val_loss: 0.0787 - val_accuracy: 0.7541\n",
      "Epoch 2311/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0511 - accuracy: 0.8386 - val_loss: 0.0787 - val_accuracy: 0.7540\n",
      "Epoch 2312/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0512 - accuracy: 0.8385 - val_loss: 0.0801 - val_accuracy: 0.7540\n",
      "Epoch 2313/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0511 - accuracy: 0.8389 - val_loss: 0.0776 - val_accuracy: 0.7556\n",
      "Epoch 2314/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0511 - accuracy: 0.8390 - val_loss: 0.0787 - val_accuracy: 0.7537\n",
      "Epoch 2315/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0512 - accuracy: 0.8384 - val_loss: 0.0784 - val_accuracy: 0.7540\n",
      "Epoch 2316/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0511 - accuracy: 0.8390 - val_loss: 0.0782 - val_accuracy: 0.7552\n",
      "Epoch 2317/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0512 - accuracy: 0.8387 - val_loss: 0.0788 - val_accuracy: 0.7549\n",
      "Epoch 2318/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0513 - accuracy: 0.8382 - val_loss: 0.0788 - val_accuracy: 0.7546\n",
      "Epoch 2319/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0512 - accuracy: 0.8385 - val_loss: 0.0793 - val_accuracy: 0.7540\n",
      "Epoch 2320/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0513 - accuracy: 0.8385 - val_loss: 0.0780 - val_accuracy: 0.7534\n",
      "Epoch 2321/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0510 - accuracy: 0.8395 - val_loss: 0.0779 - val_accuracy: 0.7545\n",
      "Epoch 2322/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0512 - accuracy: 0.8387 - val_loss: 0.0793 - val_accuracy: 0.7539\n",
      "Epoch 2323/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0512 - accuracy: 0.8390 - val_loss: 0.0775 - val_accuracy: 0.7545\n",
      "Epoch 2324/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0512 - accuracy: 0.8386 - val_loss: 0.0788 - val_accuracy: 0.7543\n",
      "Epoch 2325/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0513 - accuracy: 0.8389 - val_loss: 0.0779 - val_accuracy: 0.7550\n",
      "Epoch 2326/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0514 - accuracy: 0.8384 - val_loss: 0.0793 - val_accuracy: 0.7530\n",
      "Epoch 2327/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0513 - accuracy: 0.8386 - val_loss: 0.0786 - val_accuracy: 0.7512\n",
      "Epoch 2328/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0514 - accuracy: 0.8383 - val_loss: 0.0779 - val_accuracy: 0.7531\n",
      "Epoch 2329/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0512 - accuracy: 0.8390 - val_loss: 0.0784 - val_accuracy: 0.7547\n",
      "Epoch 2330/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0513 - accuracy: 0.8384 - val_loss: 0.0788 - val_accuracy: 0.7549\n",
      "Epoch 2331/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0514 - accuracy: 0.8383 - val_loss: 0.0796 - val_accuracy: 0.7536\n",
      "Epoch 2332/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0512 - accuracy: 0.8391 - val_loss: 0.0775 - val_accuracy: 0.7562\n",
      "Epoch 2333/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0510 - accuracy: 0.8395 - val_loss: 0.0793 - val_accuracy: 0.7537\n",
      "Epoch 2334/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0512 - accuracy: 0.8389 - val_loss: 0.0782 - val_accuracy: 0.7548\n",
      "Epoch 2335/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0512 - accuracy: 0.8388 - val_loss: 0.0784 - val_accuracy: 0.7557\n",
      "Epoch 2336/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0513 - accuracy: 0.8381 - val_loss: 0.0782 - val_accuracy: 0.7553\n",
      "Epoch 2337/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0510 - accuracy: 0.8395 - val_loss: 0.0796 - val_accuracy: 0.7544\n",
      "Epoch 2338/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0510 - accuracy: 0.8390 - val_loss: 0.0790 - val_accuracy: 0.7538\n",
      "Epoch 2339/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0510 - accuracy: 0.8394 - val_loss: 0.0789 - val_accuracy: 0.7533\n",
      "Epoch 2340/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0512 - accuracy: 0.8393 - val_loss: 0.0788 - val_accuracy: 0.7542\n",
      "Epoch 2341/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0511 - accuracy: 0.8389 - val_loss: 0.0798 - val_accuracy: 0.7523\n",
      "Epoch 2342/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0513 - accuracy: 0.8387 - val_loss: 0.0786 - val_accuracy: 0.7529\n",
      "Epoch 2343/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0513 - accuracy: 0.8381 - val_loss: 0.0782 - val_accuracy: 0.7526\n",
      "Epoch 2344/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0512 - accuracy: 0.8389 - val_loss: 0.0797 - val_accuracy: 0.7514\n",
      "Epoch 2345/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0512 - accuracy: 0.8386 - val_loss: 0.0791 - val_accuracy: 0.7546\n",
      "Epoch 2346/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0512 - accuracy: 0.8387 - val_loss: 0.0790 - val_accuracy: 0.7547\n",
      "Epoch 2347/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0512 - accuracy: 0.8386 - val_loss: 0.0788 - val_accuracy: 0.7548\n",
      "Epoch 2348/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0512 - accuracy: 0.8392 - val_loss: 0.0785 - val_accuracy: 0.7553\n",
      "Epoch 2349/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0511 - accuracy: 0.8392 - val_loss: 0.0781 - val_accuracy: 0.7552\n",
      "Epoch 2350/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0512 - accuracy: 0.8384 - val_loss: 0.0788 - val_accuracy: 0.7534\n",
      "Epoch 2351/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0511 - accuracy: 0.8391 - val_loss: 0.0797 - val_accuracy: 0.7532\n",
      "Epoch 2352/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0510 - accuracy: 0.8393 - val_loss: 0.0789 - val_accuracy: 0.7534\n",
      "Epoch 2353/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0511 - accuracy: 0.8389 - val_loss: 0.0797 - val_accuracy: 0.7515\n",
      "Epoch 2354/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0512 - accuracy: 0.8388 - val_loss: 0.0788 - val_accuracy: 0.7540\n",
      "Epoch 2355/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0510 - accuracy: 0.8393 - val_loss: 0.0773 - val_accuracy: 0.7558\n",
      "Epoch 2356/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0512 - accuracy: 0.8392 - val_loss: 0.0775 - val_accuracy: 0.7543\n",
      "Epoch 2357/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0512 - accuracy: 0.8388 - val_loss: 0.0784 - val_accuracy: 0.7558\n",
      "Epoch 2358/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0512 - accuracy: 0.8392 - val_loss: 0.0781 - val_accuracy: 0.7547\n",
      "Epoch 2359/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0511 - accuracy: 0.8389 - val_loss: 0.0801 - val_accuracy: 0.7518\n",
      "Epoch 2360/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0511 - accuracy: 0.8392 - val_loss: 0.0781 - val_accuracy: 0.7552\n",
      "Epoch 2361/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0512 - accuracy: 0.8392 - val_loss: 0.0790 - val_accuracy: 0.7537\n",
      "Epoch 2362/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0511 - accuracy: 0.8391 - val_loss: 0.0785 - val_accuracy: 0.7552\n",
      "Epoch 2363/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0512 - accuracy: 0.8389 - val_loss: 0.0780 - val_accuracy: 0.7539\n",
      "Epoch 2364/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0512 - accuracy: 0.8389 - val_loss: 0.0792 - val_accuracy: 0.7543\n",
      "Epoch 2365/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0511 - accuracy: 0.8393 - val_loss: 0.0787 - val_accuracy: 0.7545\n",
      "Epoch 2366/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0512 - accuracy: 0.8391 - val_loss: 0.0787 - val_accuracy: 0.7542\n",
      "Epoch 2367/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0513 - accuracy: 0.8388 - val_loss: 0.0782 - val_accuracy: 0.7546\n",
      "Epoch 2368/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0512 - accuracy: 0.8390 - val_loss: 0.0785 - val_accuracy: 0.7539\n",
      "Epoch 2369/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0512 - accuracy: 0.8389 - val_loss: 0.0778 - val_accuracy: 0.7524\n",
      "Epoch 2370/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0512 - accuracy: 0.8390 - val_loss: 0.0792 - val_accuracy: 0.7537\n",
      "Epoch 2371/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0511 - accuracy: 0.8396 - val_loss: 0.0790 - val_accuracy: 0.7549\n",
      "Epoch 2372/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0513 - accuracy: 0.8389 - val_loss: 0.0783 - val_accuracy: 0.7546\n",
      "Epoch 2373/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0513 - accuracy: 0.8388 - val_loss: 0.0789 - val_accuracy: 0.7537\n",
      "Epoch 2374/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0512 - accuracy: 0.8393 - val_loss: 0.0783 - val_accuracy: 0.7550\n",
      "Epoch 2375/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0512 - accuracy: 0.8391 - val_loss: 0.0784 - val_accuracy: 0.7549\n",
      "Epoch 2376/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0513 - accuracy: 0.8388 - val_loss: 0.0793 - val_accuracy: 0.7536\n",
      "Epoch 2377/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0513 - accuracy: 0.8386 - val_loss: 0.0775 - val_accuracy: 0.7555\n",
      "Epoch 2378/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0512 - accuracy: 0.8388 - val_loss: 0.0786 - val_accuracy: 0.7553\n",
      "Epoch 2379/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0511 - accuracy: 0.8392 - val_loss: 0.0776 - val_accuracy: 0.7546\n",
      "Epoch 2380/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0511 - accuracy: 0.8391 - val_loss: 0.0794 - val_accuracy: 0.7554\n",
      "Epoch 2381/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0511 - accuracy: 0.8392 - val_loss: 0.0785 - val_accuracy: 0.7539\n",
      "Epoch 2382/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0513 - accuracy: 0.8386 - val_loss: 0.0791 - val_accuracy: 0.7535\n",
      "Epoch 2383/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0511 - accuracy: 0.8393 - val_loss: 0.0792 - val_accuracy: 0.7536\n",
      "Epoch 2384/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0513 - accuracy: 0.8390 - val_loss: 0.0794 - val_accuracy: 0.7539\n",
      "Epoch 2385/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0515 - accuracy: 0.8379 - val_loss: 0.0797 - val_accuracy: 0.7541\n",
      "Epoch 2386/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0515 - accuracy: 0.8374 - val_loss: 0.0782 - val_accuracy: 0.7540\n",
      "Epoch 2387/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0515 - accuracy: 0.8379 - val_loss: 0.0779 - val_accuracy: 0.7535\n",
      "Epoch 2388/5000\n",
      "11786/11786 [==============================] - 8s 690us/step - loss: 0.0513 - accuracy: 0.8380 - val_loss: 0.0780 - val_accuracy: 0.7543\n",
      "Epoch 2389/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0512 - accuracy: 0.8385 - val_loss: 0.0779 - val_accuracy: 0.7558\n",
      "Epoch 2390/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0511 - accuracy: 0.8386 - val_loss: 0.0780 - val_accuracy: 0.7553\n",
      "Epoch 2391/5000\n",
      "11786/11786 [==============================] - 8s 715us/step - loss: 0.0511 - accuracy: 0.8390 - val_loss: 0.0780 - val_accuracy: 0.7550\n",
      "Epoch 2392/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0509 - accuracy: 0.8397 - val_loss: 0.0791 - val_accuracy: 0.7522\n",
      "Epoch 2393/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0512 - accuracy: 0.8392 - val_loss: 0.0788 - val_accuracy: 0.7554\n",
      "Epoch 2394/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0512 - accuracy: 0.8391 - val_loss: 0.0787 - val_accuracy: 0.7541\n",
      "Epoch 2395/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0514 - accuracy: 0.8383 - val_loss: 0.0778 - val_accuracy: 0.7549\n",
      "Epoch 2396/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0512 - accuracy: 0.8384 - val_loss: 0.0782 - val_accuracy: 0.7529\n",
      "Epoch 2397/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0511 - accuracy: 0.8392 - val_loss: 0.0785 - val_accuracy: 0.7545\n",
      "Epoch 2398/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0510 - accuracy: 0.8396 - val_loss: 0.0788 - val_accuracy: 0.7544\n",
      "Epoch 2399/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0512 - accuracy: 0.8390 - val_loss: 0.0783 - val_accuracy: 0.7560\n",
      "Epoch 2400/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0511 - accuracy: 0.8392 - val_loss: 0.0786 - val_accuracy: 0.7556\n",
      "Epoch 2401/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0510 - accuracy: 0.8396 - val_loss: 0.0782 - val_accuracy: 0.7536\n",
      "Epoch 2402/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0512 - accuracy: 0.8391 - val_loss: 0.0782 - val_accuracy: 0.7538\n",
      "Epoch 2403/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0510 - accuracy: 0.8394 - val_loss: 0.0782 - val_accuracy: 0.7534\n",
      "Epoch 2404/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0512 - accuracy: 0.8394 - val_loss: 0.0807 - val_accuracy: 0.7543\n",
      "Epoch 2405/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0512 - accuracy: 0.8394 - val_loss: 0.0791 - val_accuracy: 0.7551\n",
      "Epoch 2406/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0512 - accuracy: 0.8390 - val_loss: 0.0789 - val_accuracy: 0.7530\n",
      "Epoch 2407/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0512 - accuracy: 0.8393 - val_loss: 0.0783 - val_accuracy: 0.7558\n",
      "Epoch 2408/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0511 - accuracy: 0.8394 - val_loss: 0.0780 - val_accuracy: 0.7553\n",
      "Epoch 2409/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0512 - accuracy: 0.8394 - val_loss: 0.0793 - val_accuracy: 0.7526\n",
      "Epoch 2410/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0511 - accuracy: 0.8393 - val_loss: 0.0789 - val_accuracy: 0.7557\n",
      "Epoch 2411/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0512 - accuracy: 0.8394 - val_loss: 0.0771 - val_accuracy: 0.7561\n",
      "Epoch 2412/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0510 - accuracy: 0.8399 - val_loss: 0.0791 - val_accuracy: 0.7541\n",
      "Epoch 2413/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0512 - accuracy: 0.8388 - val_loss: 0.0803 - val_accuracy: 0.7471\n",
      "Epoch 2414/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0513 - accuracy: 0.8386 - val_loss: 0.0788 - val_accuracy: 0.7520\n",
      "Epoch 2415/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0513 - accuracy: 0.8385 - val_loss: 0.0778 - val_accuracy: 0.7540\n",
      "Epoch 2416/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0513 - accuracy: 0.8390 - val_loss: 0.0791 - val_accuracy: 0.7545\n",
      "Epoch 2417/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0511 - accuracy: 0.8395 - val_loss: 0.0787 - val_accuracy: 0.7523\n",
      "Epoch 2418/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0512 - accuracy: 0.8388 - val_loss: 0.0787 - val_accuracy: 0.7543\n",
      "Epoch 2419/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0513 - accuracy: 0.8384 - val_loss: 0.0792 - val_accuracy: 0.7511\n",
      "Epoch 2420/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0512 - accuracy: 0.8388 - val_loss: 0.0790 - val_accuracy: 0.7550\n",
      "Epoch 2421/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0511 - accuracy: 0.8392 - val_loss: 0.0783 - val_accuracy: 0.7537\n",
      "Epoch 2422/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0512 - accuracy: 0.8394 - val_loss: 0.0791 - val_accuracy: 0.7563\n",
      "Epoch 2423/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0511 - accuracy: 0.8397 - val_loss: 0.0789 - val_accuracy: 0.7530\n",
      "Epoch 2424/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0511 - accuracy: 0.8394 - val_loss: 0.0795 - val_accuracy: 0.7493\n",
      "Epoch 2425/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0514 - accuracy: 0.8387 - val_loss: 0.0782 - val_accuracy: 0.7541\n",
      "Epoch 2426/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0511 - accuracy: 0.8392 - val_loss: 0.0782 - val_accuracy: 0.7555\n",
      "Epoch 2427/5000\n",
      "11786/11786 [==============================] - 8s 715us/step - loss: 0.0512 - accuracy: 0.8391 - val_loss: 0.0798 - val_accuracy: 0.7539\n",
      "Epoch 2428/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0512 - accuracy: 0.8392 - val_loss: 0.0785 - val_accuracy: 0.7536\n",
      "Epoch 2429/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0512 - accuracy: 0.8396 - val_loss: 0.0789 - val_accuracy: 0.7550\n",
      "Epoch 2430/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0511 - accuracy: 0.8395 - val_loss: 0.0784 - val_accuracy: 0.7549\n",
      "Epoch 2431/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0511 - accuracy: 0.8393 - val_loss: 0.0783 - val_accuracy: 0.7558\n",
      "Epoch 2432/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0512 - accuracy: 0.8392 - val_loss: 0.0782 - val_accuracy: 0.7535\n",
      "Epoch 2433/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0512 - accuracy: 0.8390 - val_loss: 0.0789 - val_accuracy: 0.7542\n",
      "Epoch 2434/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0513 - accuracy: 0.8385 - val_loss: 0.0784 - val_accuracy: 0.7554\n",
      "Epoch 2435/5000\n",
      "11786/11786 [==============================] - 8s 714us/step - loss: 0.0512 - accuracy: 0.8389 - val_loss: 0.0793 - val_accuracy: 0.7539\n",
      "Epoch 2436/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0512 - accuracy: 0.8391 - val_loss: 0.0795 - val_accuracy: 0.7541\n",
      "Epoch 2437/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0513 - accuracy: 0.8387 - val_loss: 0.0778 - val_accuracy: 0.7545\n",
      "Epoch 2438/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0512 - accuracy: 0.8391 - val_loss: 0.0788 - val_accuracy: 0.7543\n",
      "Epoch 2439/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0512 - accuracy: 0.8394 - val_loss: 0.0775 - val_accuracy: 0.7545\n",
      "Epoch 2440/5000\n",
      "11786/11786 [==============================] - 8s 718us/step - loss: 0.0514 - accuracy: 0.8386 - val_loss: 0.0788 - val_accuracy: 0.7542\n",
      "Epoch 2441/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0512 - accuracy: 0.8394 - val_loss: 0.0788 - val_accuracy: 0.7528\n",
      "Epoch 2442/5000\n",
      "11786/11786 [==============================] - 8s 714us/step - loss: 0.0512 - accuracy: 0.8389 - val_loss: 0.0781 - val_accuracy: 0.7538\n",
      "Epoch 2443/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0512 - accuracy: 0.8392 - val_loss: 0.0787 - val_accuracy: 0.7539\n",
      "Epoch 2444/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0513 - accuracy: 0.8388 - val_loss: 0.0793 - val_accuracy: 0.7544\n",
      "Epoch 2445/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0512 - accuracy: 0.8393 - val_loss: 0.0784 - val_accuracy: 0.7552\n",
      "Epoch 2446/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0513 - accuracy: 0.8393 - val_loss: 0.0791 - val_accuracy: 0.7547\n",
      "Epoch 2447/5000\n",
      "11786/11786 [==============================] - 8s 714us/step - loss: 0.0512 - accuracy: 0.8394 - val_loss: 0.0785 - val_accuracy: 0.7549\n",
      "Epoch 2448/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0513 - accuracy: 0.8391 - val_loss: 0.0787 - val_accuracy: 0.7546\n",
      "Epoch 2449/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0513 - accuracy: 0.8389 - val_loss: 0.0786 - val_accuracy: 0.7530\n",
      "Epoch 2450/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0515 - accuracy: 0.8385 - val_loss: 0.0791 - val_accuracy: 0.7544\n",
      "Epoch 2451/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0514 - accuracy: 0.8387 - val_loss: 0.0790 - val_accuracy: 0.7531\n",
      "Epoch 2452/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0513 - accuracy: 0.8390 - val_loss: 0.0793 - val_accuracy: 0.7540\n",
      "Epoch 2453/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0514 - accuracy: 0.8387 - val_loss: 0.0783 - val_accuracy: 0.7535\n",
      "Epoch 2454/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0511 - accuracy: 0.8399 - val_loss: 0.0790 - val_accuracy: 0.7534\n",
      "Epoch 2455/5000\n",
      "11786/11786 [==============================] - 8s 715us/step - loss: 0.0514 - accuracy: 0.8389 - val_loss: 0.0785 - val_accuracy: 0.7533\n",
      "Epoch 2456/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0514 - accuracy: 0.8390 - val_loss: 0.0791 - val_accuracy: 0.7546\n",
      "Epoch 2457/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0513 - accuracy: 0.8392 - val_loss: 0.0786 - val_accuracy: 0.7547\n",
      "Epoch 2458/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0515 - accuracy: 0.8383 - val_loss: 0.0792 - val_accuracy: 0.7528\n",
      "Epoch 2459/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0514 - accuracy: 0.8386 - val_loss: 0.0798 - val_accuracy: 0.7535\n",
      "Epoch 2460/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0516 - accuracy: 0.8382 - val_loss: 0.0787 - val_accuracy: 0.7523\n",
      "Epoch 2461/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0514 - accuracy: 0.8388 - val_loss: 0.0791 - val_accuracy: 0.7537\n",
      "Epoch 2462/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0515 - accuracy: 0.8384 - val_loss: 0.0792 - val_accuracy: 0.7531\n",
      "Epoch 2463/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0513 - accuracy: 0.8396 - val_loss: 0.0782 - val_accuracy: 0.7538\n",
      "Epoch 2464/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0514 - accuracy: 0.8389 - val_loss: 0.0781 - val_accuracy: 0.7550\n",
      "Epoch 2465/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0513 - accuracy: 0.8394 - val_loss: 0.0793 - val_accuracy: 0.7533\n",
      "Epoch 2466/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0515 - accuracy: 0.8387 - val_loss: 0.0786 - val_accuracy: 0.7545\n",
      "Epoch 2467/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0513 - accuracy: 0.8393 - val_loss: 0.0789 - val_accuracy: 0.7523\n",
      "Epoch 2468/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0516 - accuracy: 0.8384 - val_loss: 0.0789 - val_accuracy: 0.7541\n",
      "Epoch 2469/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0515 - accuracy: 0.8385 - val_loss: 0.0789 - val_accuracy: 0.7548\n",
      "Epoch 2470/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0514 - accuracy: 0.8388 - val_loss: 0.0783 - val_accuracy: 0.7532\n",
      "Epoch 2471/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0515 - accuracy: 0.8383 - val_loss: 0.0784 - val_accuracy: 0.7545\n",
      "Epoch 2472/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0515 - accuracy: 0.8388 - val_loss: 0.0784 - val_accuracy: 0.7547\n",
      "Epoch 2473/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0512 - accuracy: 0.8393 - val_loss: 0.0788 - val_accuracy: 0.7544\n",
      "Epoch 2474/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0512 - accuracy: 0.8392 - val_loss: 0.0797 - val_accuracy: 0.7527\n",
      "Epoch 2475/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0513 - accuracy: 0.8393 - val_loss: 0.0790 - val_accuracy: 0.7532\n",
      "Epoch 2476/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0515 - accuracy: 0.8382 - val_loss: 0.0784 - val_accuracy: 0.7532\n",
      "Epoch 2477/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0514 - accuracy: 0.8389 - val_loss: 0.0804 - val_accuracy: 0.7526\n",
      "Epoch 2478/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0513 - accuracy: 0.8388 - val_loss: 0.0781 - val_accuracy: 0.7548\n",
      "Epoch 2479/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0515 - accuracy: 0.8387 - val_loss: 0.0785 - val_accuracy: 0.7538\n",
      "Epoch 2480/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0514 - accuracy: 0.8388 - val_loss: 0.0782 - val_accuracy: 0.7558\n",
      "Epoch 2481/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0514 - accuracy: 0.8389 - val_loss: 0.0777 - val_accuracy: 0.7532\n",
      "Epoch 2482/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0514 - accuracy: 0.8389 - val_loss: 0.0791 - val_accuracy: 0.7527\n",
      "Epoch 2483/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0512 - accuracy: 0.8395 - val_loss: 0.0780 - val_accuracy: 0.7542\n",
      "Epoch 2484/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0513 - accuracy: 0.8395 - val_loss: 0.0782 - val_accuracy: 0.7547\n",
      "Epoch 2485/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0515 - accuracy: 0.8387 - val_loss: 0.0781 - val_accuracy: 0.7532\n",
      "Epoch 2486/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0515 - accuracy: 0.8387 - val_loss: 0.0781 - val_accuracy: 0.7549\n",
      "Epoch 2487/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0514 - accuracy: 0.8387 - val_loss: 0.0798 - val_accuracy: 0.7498\n",
      "Epoch 2488/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0515 - accuracy: 0.8384 - val_loss: 0.0795 - val_accuracy: 0.7538\n",
      "Epoch 2489/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0514 - accuracy: 0.8386 - val_loss: 0.0787 - val_accuracy: 0.7526\n",
      "Epoch 2490/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0513 - accuracy: 0.8388 - val_loss: 0.0784 - val_accuracy: 0.7543\n",
      "Epoch 2491/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0513 - accuracy: 0.8385 - val_loss: 0.0788 - val_accuracy: 0.7550\n",
      "Epoch 2492/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0512 - accuracy: 0.8390 - val_loss: 0.0795 - val_accuracy: 0.7502\n",
      "Epoch 2493/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0513 - accuracy: 0.8389 - val_loss: 0.0797 - val_accuracy: 0.7534\n",
      "Epoch 2494/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0512 - accuracy: 0.8390 - val_loss: 0.0783 - val_accuracy: 0.7537\n",
      "Epoch 2495/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0513 - accuracy: 0.8386 - val_loss: 0.0783 - val_accuracy: 0.7548\n",
      "Epoch 2496/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0514 - accuracy: 0.8387 - val_loss: 0.0799 - val_accuracy: 0.7546\n",
      "Epoch 2497/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0514 - accuracy: 0.8390 - val_loss: 0.0783 - val_accuracy: 0.7550\n",
      "Epoch 2498/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0513 - accuracy: 0.8390 - val_loss: 0.0780 - val_accuracy: 0.7557\n",
      "Epoch 2499/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0514 - accuracy: 0.8383 - val_loss: 0.0786 - val_accuracy: 0.7547\n",
      "Epoch 2500/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0513 - accuracy: 0.8387 - val_loss: 0.0788 - val_accuracy: 0.7531\n",
      "Epoch 2501/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0514 - accuracy: 0.8384 - val_loss: 0.0787 - val_accuracy: 0.7547\n",
      "Epoch 2502/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0514 - accuracy: 0.8386 - val_loss: 0.0801 - val_accuracy: 0.7530\n",
      "Epoch 2503/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0513 - accuracy: 0.8386 - val_loss: 0.0778 - val_accuracy: 0.7551\n",
      "Epoch 2504/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0514 - accuracy: 0.8389 - val_loss: 0.0785 - val_accuracy: 0.7547\n",
      "Epoch 2505/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0512 - accuracy: 0.8391 - val_loss: 0.0790 - val_accuracy: 0.7520\n",
      "Epoch 2506/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0516 - accuracy: 0.8381 - val_loss: 0.0799 - val_accuracy: 0.7505\n",
      "Epoch 2507/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0518 - accuracy: 0.8373 - val_loss: 0.0787 - val_accuracy: 0.7531\n",
      "Epoch 2508/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0517 - accuracy: 0.8376 - val_loss: 0.0791 - val_accuracy: 0.7532\n",
      "Epoch 2509/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0518 - accuracy: 0.8371 - val_loss: 0.0789 - val_accuracy: 0.7537\n",
      "Epoch 2510/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0515 - accuracy: 0.8381 - val_loss: 0.0790 - val_accuracy: 0.7546\n",
      "Epoch 2511/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0515 - accuracy: 0.8383 - val_loss: 0.0783 - val_accuracy: 0.7536\n",
      "Epoch 2512/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0514 - accuracy: 0.8385 - val_loss: 0.0797 - val_accuracy: 0.7531\n",
      "Epoch 2513/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0515 - accuracy: 0.8383 - val_loss: 0.0785 - val_accuracy: 0.7536\n",
      "Epoch 2514/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0514 - accuracy: 0.8388 - val_loss: 0.0788 - val_accuracy: 0.7506\n",
      "Epoch 2515/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0516 - accuracy: 0.8379 - val_loss: 0.0792 - val_accuracy: 0.7536\n",
      "Epoch 2516/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0514 - accuracy: 0.8385 - val_loss: 0.0796 - val_accuracy: 0.7535\n",
      "Epoch 2517/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0515 - accuracy: 0.8381 - val_loss: 0.0778 - val_accuracy: 0.7545\n",
      "Epoch 2518/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0514 - accuracy: 0.8385 - val_loss: 0.0774 - val_accuracy: 0.7553\n",
      "Epoch 2519/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0514 - accuracy: 0.8385 - val_loss: 0.0782 - val_accuracy: 0.7543\n",
      "Epoch 2520/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0514 - accuracy: 0.8388 - val_loss: 0.0784 - val_accuracy: 0.7533\n",
      "Epoch 2521/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0515 - accuracy: 0.8378 - val_loss: 0.0796 - val_accuracy: 0.7527\n",
      "Epoch 2522/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0515 - accuracy: 0.8386 - val_loss: 0.0796 - val_accuracy: 0.7539\n",
      "Epoch 2523/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0515 - accuracy: 0.8387 - val_loss: 0.0806 - val_accuracy: 0.7537\n",
      "Epoch 2524/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0514 - accuracy: 0.8385 - val_loss: 0.0791 - val_accuracy: 0.7521\n",
      "Epoch 2525/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0515 - accuracy: 0.8383 - val_loss: 0.0785 - val_accuracy: 0.7527\n",
      "Epoch 2526/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0513 - accuracy: 0.8390 - val_loss: 0.0776 - val_accuracy: 0.7544\n",
      "Epoch 2527/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0515 - accuracy: 0.8380 - val_loss: 0.0789 - val_accuracy: 0.7541\n",
      "Epoch 2528/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0514 - accuracy: 0.8381 - val_loss: 0.0783 - val_accuracy: 0.7527\n",
      "Epoch 2529/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0514 - accuracy: 0.8387 - val_loss: 0.0786 - val_accuracy: 0.7549\n",
      "Epoch 2530/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0513 - accuracy: 0.8390 - val_loss: 0.0785 - val_accuracy: 0.7535\n",
      "Epoch 2531/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0514 - accuracy: 0.8386 - val_loss: 0.0783 - val_accuracy: 0.7528\n",
      "Epoch 2532/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0513 - accuracy: 0.8389 - val_loss: 0.0783 - val_accuracy: 0.7545\n",
      "Epoch 2533/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0514 - accuracy: 0.8388 - val_loss: 0.0776 - val_accuracy: 0.7544\n",
      "Epoch 2534/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0514 - accuracy: 0.8390 - val_loss: 0.0798 - val_accuracy: 0.7533\n",
      "Epoch 2535/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0514 - accuracy: 0.8386 - val_loss: 0.0791 - val_accuracy: 0.7536\n",
      "Epoch 2536/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0515 - accuracy: 0.8387 - val_loss: 0.0786 - val_accuracy: 0.7547\n",
      "Epoch 2537/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0514 - accuracy: 0.8391 - val_loss: 0.0782 - val_accuracy: 0.7526\n",
      "Epoch 2538/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0515 - accuracy: 0.8385 - val_loss: 0.0785 - val_accuracy: 0.7531\n",
      "Epoch 2539/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0516 - accuracy: 0.8383 - val_loss: 0.0789 - val_accuracy: 0.7538\n",
      "Epoch 2540/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0515 - accuracy: 0.8388 - val_loss: 0.0790 - val_accuracy: 0.7549\n",
      "Epoch 2541/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0515 - accuracy: 0.8387 - val_loss: 0.0782 - val_accuracy: 0.7531\n",
      "Epoch 2542/5000\n",
      "11786/11786 [==============================] - 8s 715us/step - loss: 0.0515 - accuracy: 0.8384 - val_loss: 0.0779 - val_accuracy: 0.7539\n",
      "Epoch 2543/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0514 - accuracy: 0.8390 - val_loss: 0.0792 - val_accuracy: 0.7531\n",
      "Epoch 2544/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0513 - accuracy: 0.8390 - val_loss: 0.0788 - val_accuracy: 0.7523\n",
      "Epoch 2545/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0515 - accuracy: 0.8385 - val_loss: 0.0786 - val_accuracy: 0.7531\n",
      "Epoch 2546/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0515 - accuracy: 0.8387 - val_loss: 0.0782 - val_accuracy: 0.7540\n",
      "Epoch 2547/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0515 - accuracy: 0.8382 - val_loss: 0.0786 - val_accuracy: 0.7511\n",
      "Epoch 2548/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0515 - accuracy: 0.8384 - val_loss: 0.0778 - val_accuracy: 0.7540\n",
      "Epoch 2549/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0515 - accuracy: 0.8388 - val_loss: 0.0791 - val_accuracy: 0.7555\n",
      "Epoch 2550/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0514 - accuracy: 0.8387 - val_loss: 0.0786 - val_accuracy: 0.7538\n",
      "Epoch 2551/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0513 - accuracy: 0.8393 - val_loss: 0.0781 - val_accuracy: 0.7535\n",
      "Epoch 2552/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0513 - accuracy: 0.8390 - val_loss: 0.0774 - val_accuracy: 0.7561\n",
      "Epoch 2553/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0513 - accuracy: 0.8390 - val_loss: 0.0787 - val_accuracy: 0.7546\n",
      "Epoch 2554/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0513 - accuracy: 0.8389 - val_loss: 0.0784 - val_accuracy: 0.7546\n",
      "Epoch 2555/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0514 - accuracy: 0.8387 - val_loss: 0.0783 - val_accuracy: 0.7544\n",
      "Epoch 2556/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0513 - accuracy: 0.8391 - val_loss: 0.0788 - val_accuracy: 0.7547\n",
      "Epoch 2557/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0514 - accuracy: 0.8390 - val_loss: 0.0784 - val_accuracy: 0.7539\n",
      "Epoch 2558/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0514 - accuracy: 0.8390 - val_loss: 0.0793 - val_accuracy: 0.7525\n",
      "Epoch 2559/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0516 - accuracy: 0.8380 - val_loss: 0.0798 - val_accuracy: 0.7537\n",
      "Epoch 2560/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0515 - accuracy: 0.8386 - val_loss: 0.0790 - val_accuracy: 0.7522\n",
      "Epoch 2561/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0516 - accuracy: 0.8380 - val_loss: 0.0788 - val_accuracy: 0.7527\n",
      "Epoch 2562/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0516 - accuracy: 0.8381 - val_loss: 0.0788 - val_accuracy: 0.7518\n",
      "Epoch 2563/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0515 - accuracy: 0.8386 - val_loss: 0.0795 - val_accuracy: 0.7495\n",
      "Epoch 2564/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0515 - accuracy: 0.8389 - val_loss: 0.0796 - val_accuracy: 0.7514\n",
      "Epoch 2565/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0516 - accuracy: 0.8380 - val_loss: 0.0795 - val_accuracy: 0.7534\n",
      "Epoch 2566/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0516 - accuracy: 0.8388 - val_loss: 0.0786 - val_accuracy: 0.7528\n",
      "Epoch 2567/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0515 - accuracy: 0.8388 - val_loss: 0.0780 - val_accuracy: 0.7543\n",
      "Epoch 2568/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0517 - accuracy: 0.8382 - val_loss: 0.0795 - val_accuracy: 0.7539\n",
      "Epoch 2569/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0517 - accuracy: 0.8377 - val_loss: 0.0784 - val_accuracy: 0.7545\n",
      "Epoch 2570/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0515 - accuracy: 0.8384 - val_loss: 0.0782 - val_accuracy: 0.7540\n",
      "Epoch 2571/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0515 - accuracy: 0.8382 - val_loss: 0.0789 - val_accuracy: 0.7541\n",
      "Epoch 2572/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0515 - accuracy: 0.8389 - val_loss: 0.0782 - val_accuracy: 0.7541\n",
      "Epoch 2573/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0514 - accuracy: 0.8393 - val_loss: 0.0779 - val_accuracy: 0.7542\n",
      "Epoch 2574/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0515 - accuracy: 0.8384 - val_loss: 0.0795 - val_accuracy: 0.7538\n",
      "Epoch 2575/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0516 - accuracy: 0.8383 - val_loss: 0.0784 - val_accuracy: 0.7539\n",
      "Epoch 2576/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0516 - accuracy: 0.8384 - val_loss: 0.0784 - val_accuracy: 0.7537\n",
      "Epoch 2577/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0515 - accuracy: 0.8384 - val_loss: 0.0789 - val_accuracy: 0.7530\n",
      "Epoch 2578/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0516 - accuracy: 0.8381 - val_loss: 0.0786 - val_accuracy: 0.7555\n",
      "Epoch 2579/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0514 - accuracy: 0.8385 - val_loss: 0.0778 - val_accuracy: 0.7542\n",
      "Epoch 2580/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0515 - accuracy: 0.8384 - val_loss: 0.0788 - val_accuracy: 0.7536\n",
      "Epoch 2581/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0516 - accuracy: 0.8379 - val_loss: 0.0780 - val_accuracy: 0.7532\n",
      "Epoch 2582/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0515 - accuracy: 0.8382 - val_loss: 0.0779 - val_accuracy: 0.7544\n",
      "Epoch 2583/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0516 - accuracy: 0.8379 - val_loss: 0.0794 - val_accuracy: 0.7537\n",
      "Epoch 2584/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0516 - accuracy: 0.8378 - val_loss: 0.0789 - val_accuracy: 0.7535\n",
      "Epoch 2585/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0515 - accuracy: 0.8380 - val_loss: 0.0797 - val_accuracy: 0.7518\n",
      "Epoch 2586/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0515 - accuracy: 0.8384 - val_loss: 0.0791 - val_accuracy: 0.7534\n",
      "Epoch 2587/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0517 - accuracy: 0.8378 - val_loss: 0.0788 - val_accuracy: 0.7517\n",
      "Epoch 2588/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0516 - accuracy: 0.8379 - val_loss: 0.0788 - val_accuracy: 0.7547\n",
      "Epoch 2589/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0514 - accuracy: 0.8382 - val_loss: 0.0787 - val_accuracy: 0.7532\n",
      "Epoch 2590/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0516 - accuracy: 0.8376 - val_loss: 0.0781 - val_accuracy: 0.7538\n",
      "Epoch 2591/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0516 - accuracy: 0.8381 - val_loss: 0.0785 - val_accuracy: 0.7541\n",
      "Epoch 2592/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0515 - accuracy: 0.8387 - val_loss: 0.0789 - val_accuracy: 0.7543\n",
      "Epoch 2593/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0515 - accuracy: 0.8380 - val_loss: 0.0788 - val_accuracy: 0.7530\n",
      "Epoch 2594/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0515 - accuracy: 0.8380 - val_loss: 0.0794 - val_accuracy: 0.7529\n",
      "Epoch 2595/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0515 - accuracy: 0.8384 - val_loss: 0.0792 - val_accuracy: 0.7544\n",
      "Epoch 2596/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0518 - accuracy: 0.8372 - val_loss: 0.0780 - val_accuracy: 0.7536\n",
      "Epoch 2597/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0517 - accuracy: 0.8373 - val_loss: 0.0790 - val_accuracy: 0.7540\n",
      "Epoch 2598/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0517 - accuracy: 0.8373 - val_loss: 0.0789 - val_accuracy: 0.7543\n",
      "Epoch 2599/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0515 - accuracy: 0.8384 - val_loss: 0.0788 - val_accuracy: 0.7520\n",
      "Epoch 2600/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0515 - accuracy: 0.8380 - val_loss: 0.0785 - val_accuracy: 0.7513\n",
      "Epoch 2601/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0516 - accuracy: 0.8378 - val_loss: 0.0782 - val_accuracy: 0.7532\n",
      "Epoch 2602/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0516 - accuracy: 0.8381 - val_loss: 0.0787 - val_accuracy: 0.7525\n",
      "Epoch 2603/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0516 - accuracy: 0.8381 - val_loss: 0.0782 - val_accuracy: 0.7550\n",
      "Epoch 2604/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0515 - accuracy: 0.8382 - val_loss: 0.0791 - val_accuracy: 0.7537\n",
      "Epoch 2605/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0515 - accuracy: 0.8382 - val_loss: 0.0776 - val_accuracy: 0.7538\n",
      "Epoch 2606/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0517 - accuracy: 0.8372 - val_loss: 0.0788 - val_accuracy: 0.7524\n",
      "Epoch 2607/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0516 - accuracy: 0.8376 - val_loss: 0.0791 - val_accuracy: 0.7528\n",
      "Epoch 2608/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0513 - accuracy: 0.8386 - val_loss: 0.0781 - val_accuracy: 0.7554\n",
      "Epoch 2609/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0513 - accuracy: 0.8390 - val_loss: 0.0786 - val_accuracy: 0.7545\n",
      "Epoch 2610/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0514 - accuracy: 0.8387 - val_loss: 0.0784 - val_accuracy: 0.7527\n",
      "Epoch 2611/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0515 - accuracy: 0.8381 - val_loss: 0.0776 - val_accuracy: 0.7548\n",
      "Epoch 2612/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0515 - accuracy: 0.8383 - val_loss: 0.0790 - val_accuracy: 0.7537\n",
      "Epoch 2613/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0515 - accuracy: 0.8382 - val_loss: 0.0771 - val_accuracy: 0.7546\n",
      "Epoch 2614/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0515 - accuracy: 0.8385 - val_loss: 0.0796 - val_accuracy: 0.7540\n",
      "Epoch 2615/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0516 - accuracy: 0.8379 - val_loss: 0.0795 - val_accuracy: 0.7541\n",
      "Epoch 2616/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0515 - accuracy: 0.8383 - val_loss: 0.0780 - val_accuracy: 0.7563\n",
      "Epoch 2617/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0514 - accuracy: 0.8387 - val_loss: 0.0788 - val_accuracy: 0.7551\n",
      "Epoch 2618/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0514 - accuracy: 0.8383 - val_loss: 0.0781 - val_accuracy: 0.7557\n",
      "Epoch 2619/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0514 - accuracy: 0.8389 - val_loss: 0.0785 - val_accuracy: 0.7548\n",
      "Epoch 2620/5000\n",
      "11786/11786 [==============================] - 8s 714us/step - loss: 0.0516 - accuracy: 0.8380 - val_loss: 0.0785 - val_accuracy: 0.7560\n",
      "Epoch 2621/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0517 - accuracy: 0.8377 - val_loss: 0.0788 - val_accuracy: 0.7530\n",
      "Epoch 2622/5000\n",
      "11786/11786 [==============================] - 8s 718us/step - loss: 0.0517 - accuracy: 0.8382 - val_loss: 0.0787 - val_accuracy: 0.7538\n",
      "Epoch 2623/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0515 - accuracy: 0.8384 - val_loss: 0.0787 - val_accuracy: 0.7539\n",
      "Epoch 2624/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0516 - accuracy: 0.8380 - val_loss: 0.0788 - val_accuracy: 0.7526\n",
      "Epoch 2625/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0518 - accuracy: 0.8372 - val_loss: 0.0800 - val_accuracy: 0.7531\n",
      "Epoch 2626/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0517 - accuracy: 0.8379 - val_loss: 0.0785 - val_accuracy: 0.7540\n",
      "Epoch 2627/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0517 - accuracy: 0.8379 - val_loss: 0.0789 - val_accuracy: 0.7525\n",
      "Epoch 2628/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0518 - accuracy: 0.8374 - val_loss: 0.0784 - val_accuracy: 0.7545\n",
      "Epoch 2629/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0518 - accuracy: 0.8377 - val_loss: 0.0790 - val_accuracy: 0.7538\n",
      "Epoch 2630/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0518 - accuracy: 0.8378 - val_loss: 0.0790 - val_accuracy: 0.7529\n",
      "Epoch 2631/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0516 - accuracy: 0.8380 - val_loss: 0.0791 - val_accuracy: 0.7526\n",
      "Epoch 2632/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0518 - accuracy: 0.8376 - val_loss: 0.0779 - val_accuracy: 0.7538\n",
      "Epoch 2633/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0518 - accuracy: 0.8373 - val_loss: 0.0781 - val_accuracy: 0.7547\n",
      "Epoch 2634/5000\n",
      "11786/11786 [==============================] - 8s 717us/step - loss: 0.0517 - accuracy: 0.8380 - val_loss: 0.0779 - val_accuracy: 0.7527\n",
      "Epoch 2635/5000\n",
      "11786/11786 [==============================] - 8s 717us/step - loss: 0.0519 - accuracy: 0.8371 - val_loss: 0.0786 - val_accuracy: 0.7542\n",
      "Epoch 2636/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0515 - accuracy: 0.8381 - val_loss: 0.0781 - val_accuracy: 0.7547\n",
      "Epoch 2637/5000\n",
      "11786/11786 [==============================] - 8s 715us/step - loss: 0.0516 - accuracy: 0.8373 - val_loss: 0.0791 - val_accuracy: 0.7527\n",
      "Epoch 2638/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0517 - accuracy: 0.8376 - val_loss: 0.0777 - val_accuracy: 0.7551\n",
      "Epoch 2639/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0515 - accuracy: 0.8381 - val_loss: 0.0780 - val_accuracy: 0.7554\n",
      "Epoch 2640/5000\n",
      "11786/11786 [==============================] - 8s 716us/step - loss: 0.0516 - accuracy: 0.8382 - val_loss: 0.0783 - val_accuracy: 0.7540\n",
      "Epoch 2641/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0517 - accuracy: 0.8379 - val_loss: 0.0788 - val_accuracy: 0.7548\n",
      "Epoch 2642/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0518 - accuracy: 0.8370 - val_loss: 0.0790 - val_accuracy: 0.7533\n",
      "Epoch 2643/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0516 - accuracy: 0.8378 - val_loss: 0.0783 - val_accuracy: 0.7546\n",
      "Epoch 2644/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0516 - accuracy: 0.8381 - val_loss: 0.0782 - val_accuracy: 0.7535\n",
      "Epoch 2645/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0516 - accuracy: 0.8385 - val_loss: 0.0782 - val_accuracy: 0.7508\n",
      "Epoch 2646/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0518 - accuracy: 0.8374 - val_loss: 0.0786 - val_accuracy: 0.7529\n",
      "Epoch 2647/5000\n",
      "11786/11786 [==============================] - 8s 715us/step - loss: 0.0516 - accuracy: 0.8379 - val_loss: 0.0789 - val_accuracy: 0.7540\n",
      "Epoch 2648/5000\n",
      "11786/11786 [==============================] - 8s 715us/step - loss: 0.0517 - accuracy: 0.8376 - val_loss: 0.0787 - val_accuracy: 0.7543\n",
      "Epoch 2649/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0518 - accuracy: 0.8376 - val_loss: 0.0783 - val_accuracy: 0.7546\n",
      "Epoch 2650/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0518 - accuracy: 0.8373 - val_loss: 0.0781 - val_accuracy: 0.7535\n",
      "Epoch 2651/5000\n",
      "11786/11786 [==============================] - 8s 716us/step - loss: 0.0518 - accuracy: 0.8376 - val_loss: 0.0785 - val_accuracy: 0.7532\n",
      "Epoch 2652/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0519 - accuracy: 0.8376 - val_loss: 0.0780 - val_accuracy: 0.7547\n",
      "Epoch 2653/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0518 - accuracy: 0.8378 - val_loss: 0.0792 - val_accuracy: 0.7536\n",
      "Epoch 2654/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0519 - accuracy: 0.8373 - val_loss: 0.0776 - val_accuracy: 0.7546\n",
      "Epoch 2655/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0519 - accuracy: 0.8369 - val_loss: 0.0779 - val_accuracy: 0.7532\n",
      "Epoch 2656/5000\n",
      "11786/11786 [==============================] - 8s 719us/step - loss: 0.0519 - accuracy: 0.8373 - val_loss: 0.0780 - val_accuracy: 0.7530\n",
      "Epoch 2657/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0518 - accuracy: 0.8374 - val_loss: 0.0794 - val_accuracy: 0.7556\n",
      "Epoch 2658/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0516 - accuracy: 0.8380 - val_loss: 0.0794 - val_accuracy: 0.7536\n",
      "Epoch 2659/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0518 - accuracy: 0.8377 - val_loss: 0.0789 - val_accuracy: 0.7538\n",
      "Epoch 2660/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0520 - accuracy: 0.8369 - val_loss: 0.0786 - val_accuracy: 0.7528\n",
      "Epoch 2661/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0520 - accuracy: 0.8370 - val_loss: 0.0792 - val_accuracy: 0.7547\n",
      "Epoch 2662/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0517 - accuracy: 0.8381 - val_loss: 0.0792 - val_accuracy: 0.7538\n",
      "Epoch 2663/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0518 - accuracy: 0.8376 - val_loss: 0.0785 - val_accuracy: 0.7542\n",
      "Epoch 2664/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0518 - accuracy: 0.8376 - val_loss: 0.0785 - val_accuracy: 0.7547\n",
      "Epoch 2665/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0519 - accuracy: 0.8374 - val_loss: 0.0794 - val_accuracy: 0.7542\n",
      "Epoch 2666/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0520 - accuracy: 0.8374 - val_loss: 0.0792 - val_accuracy: 0.7528\n",
      "Epoch 2667/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0521 - accuracy: 0.8369 - val_loss: 0.0801 - val_accuracy: 0.7527\n",
      "Epoch 2668/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0521 - accuracy: 0.8369 - val_loss: 0.0795 - val_accuracy: 0.7544\n",
      "Epoch 2669/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0520 - accuracy: 0.8369 - val_loss: 0.0787 - val_accuracy: 0.7540\n",
      "Epoch 2670/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0519 - accuracy: 0.8373 - val_loss: 0.0803 - val_accuracy: 0.7529\n",
      "Epoch 2671/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0519 - accuracy: 0.8375 - val_loss: 0.0790 - val_accuracy: 0.7528\n",
      "Epoch 2672/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0521 - accuracy: 0.8371 - val_loss: 0.0786 - val_accuracy: 0.7524\n",
      "Epoch 2673/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0519 - accuracy: 0.8373 - val_loss: 0.0797 - val_accuracy: 0.7532\n",
      "Epoch 2674/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0521 - accuracy: 0.8369 - val_loss: 0.0782 - val_accuracy: 0.7538\n",
      "Epoch 2675/5000\n",
      "11786/11786 [==============================] - 8s 717us/step - loss: 0.0521 - accuracy: 0.8364 - val_loss: 0.0787 - val_accuracy: 0.7535\n",
      "Epoch 2676/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0520 - accuracy: 0.8369 - val_loss: 0.0786 - val_accuracy: 0.7526\n",
      "Epoch 2677/5000\n",
      "11786/11786 [==============================] - 8s 716us/step - loss: 0.0521 - accuracy: 0.8363 - val_loss: 0.0788 - val_accuracy: 0.7534\n",
      "Epoch 2678/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0521 - accuracy: 0.8362 - val_loss: 0.0779 - val_accuracy: 0.7542\n",
      "Epoch 2679/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0519 - accuracy: 0.8369 - val_loss: 0.0781 - val_accuracy: 0.7531\n",
      "Epoch 2680/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0519 - accuracy: 0.8371 - val_loss: 0.0780 - val_accuracy: 0.7540\n",
      "Epoch 2681/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0518 - accuracy: 0.8377 - val_loss: 0.0790 - val_accuracy: 0.7531\n",
      "Epoch 2682/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0519 - accuracy: 0.8372 - val_loss: 0.0788 - val_accuracy: 0.7542\n",
      "Epoch 2683/5000\n",
      "11786/11786 [==============================] - 8s 715us/step - loss: 0.0519 - accuracy: 0.8369 - val_loss: 0.0794 - val_accuracy: 0.7528\n",
      "Epoch 2684/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0519 - accuracy: 0.8374 - val_loss: 0.0782 - val_accuracy: 0.7533\n",
      "Epoch 2685/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0517 - accuracy: 0.8379 - val_loss: 0.0779 - val_accuracy: 0.7548\n",
      "Epoch 2686/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0518 - accuracy: 0.8378 - val_loss: 0.0793 - val_accuracy: 0.7555\n",
      "Epoch 2687/5000\n",
      "11786/11786 [==============================] - 8s 715us/step - loss: 0.0520 - accuracy: 0.8370 - val_loss: 0.0778 - val_accuracy: 0.7558\n",
      "Epoch 2688/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0519 - accuracy: 0.8378 - val_loss: 0.0787 - val_accuracy: 0.7540\n",
      "Epoch 2689/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0521 - accuracy: 0.8366 - val_loss: 0.0783 - val_accuracy: 0.7550\n",
      "Epoch 2690/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0522 - accuracy: 0.8361 - val_loss: 0.0805 - val_accuracy: 0.7474\n",
      "Epoch 2691/5000\n",
      "11786/11786 [==============================] - 8s 714us/step - loss: 0.0520 - accuracy: 0.8367 - val_loss: 0.0793 - val_accuracy: 0.7541\n",
      "Epoch 2692/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0519 - accuracy: 0.8374 - val_loss: 0.0784 - val_accuracy: 0.7546\n",
      "Epoch 2693/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0519 - accuracy: 0.8370 - val_loss: 0.0773 - val_accuracy: 0.7555\n",
      "Epoch 2694/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0519 - accuracy: 0.8375 - val_loss: 0.0783 - val_accuracy: 0.7540\n",
      "Epoch 2695/5000\n",
      "11786/11786 [==============================] - 8s 715us/step - loss: 0.0519 - accuracy: 0.8375 - val_loss: 0.0775 - val_accuracy: 0.7538\n",
      "Epoch 2696/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0520 - accuracy: 0.8366 - val_loss: 0.0794 - val_accuracy: 0.7543\n",
      "Epoch 2697/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0521 - accuracy: 0.8365 - val_loss: 0.0792 - val_accuracy: 0.7528\n",
      "Epoch 2698/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0522 - accuracy: 0.8365 - val_loss: 0.0792 - val_accuracy: 0.7520\n",
      "Epoch 2699/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0522 - accuracy: 0.8359 - val_loss: 0.0791 - val_accuracy: 0.7520\n",
      "Epoch 2700/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0520 - accuracy: 0.8368 - val_loss: 0.0790 - val_accuracy: 0.7536\n",
      "Epoch 2701/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0519 - accuracy: 0.8371 - val_loss: 0.0794 - val_accuracy: 0.7522\n",
      "Epoch 2702/5000\n",
      "11786/11786 [==============================] - 8s 718us/step - loss: 0.0521 - accuracy: 0.8365 - val_loss: 0.0796 - val_accuracy: 0.7501\n",
      "Epoch 2703/5000\n",
      "11786/11786 [==============================] - 8s 718us/step - loss: 0.0521 - accuracy: 0.8363 - val_loss: 0.0797 - val_accuracy: 0.7535\n",
      "Epoch 2704/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0520 - accuracy: 0.8372 - val_loss: 0.0784 - val_accuracy: 0.7557\n",
      "Epoch 2705/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0520 - accuracy: 0.8373 - val_loss: 0.0780 - val_accuracy: 0.7541\n",
      "Epoch 2706/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0521 - accuracy: 0.8369 - val_loss: 0.0788 - val_accuracy: 0.7539\n",
      "Epoch 2707/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0519 - accuracy: 0.8376 - val_loss: 0.0797 - val_accuracy: 0.7539\n",
      "Epoch 2708/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0520 - accuracy: 0.8367 - val_loss: 0.0783 - val_accuracy: 0.7527\n",
      "Epoch 2709/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0522 - accuracy: 0.8363 - val_loss: 0.0793 - val_accuracy: 0.7536\n",
      "Epoch 2710/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0519 - accuracy: 0.8371 - val_loss: 0.0784 - val_accuracy: 0.7543\n",
      "Epoch 2711/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0519 - accuracy: 0.8371 - val_loss: 0.0782 - val_accuracy: 0.7532\n",
      "Epoch 2712/5000\n",
      "11786/11786 [==============================] - 8s 717us/step - loss: 0.0522 - accuracy: 0.8364 - val_loss: 0.0786 - val_accuracy: 0.7509\n",
      "Epoch 2713/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0523 - accuracy: 0.8358 - val_loss: 0.0795 - val_accuracy: 0.7536\n",
      "Epoch 2714/5000\n",
      "11786/11786 [==============================] - 8s 715us/step - loss: 0.0520 - accuracy: 0.8372 - val_loss: 0.0790 - val_accuracy: 0.7517\n",
      "Epoch 2715/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0521 - accuracy: 0.8368 - val_loss: 0.0789 - val_accuracy: 0.7545\n",
      "Epoch 2716/5000\n",
      "11786/11786 [==============================] - 8s 715us/step - loss: 0.0520 - accuracy: 0.8371 - val_loss: 0.0788 - val_accuracy: 0.7523\n",
      "Epoch 2717/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0521 - accuracy: 0.8368 - val_loss: 0.0783 - val_accuracy: 0.7523\n",
      "Epoch 2718/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0521 - accuracy: 0.8369 - val_loss: 0.0790 - val_accuracy: 0.7537\n",
      "Epoch 2719/5000\n",
      "11786/11786 [==============================] - 8s 715us/step - loss: 0.0520 - accuracy: 0.8371 - val_loss: 0.0780 - val_accuracy: 0.7530\n",
      "Epoch 2720/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0520 - accuracy: 0.8370 - val_loss: 0.0785 - val_accuracy: 0.7528\n",
      "Epoch 2721/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0522 - accuracy: 0.8369 - val_loss: 0.0797 - val_accuracy: 0.7538\n",
      "Epoch 2722/5000\n",
      "11786/11786 [==============================] - 8s 721us/step - loss: 0.0522 - accuracy: 0.8367 - val_loss: 0.0796 - val_accuracy: 0.7530\n",
      "Epoch 2723/5000\n",
      "11786/11786 [==============================] - 8s 716us/step - loss: 0.0521 - accuracy: 0.8362 - val_loss: 0.0800 - val_accuracy: 0.7522\n",
      "Epoch 2724/5000\n",
      "11786/11786 [==============================] - 8s 715us/step - loss: 0.0521 - accuracy: 0.8367 - val_loss: 0.0794 - val_accuracy: 0.7528\n",
      "Epoch 2725/5000\n",
      "11786/11786 [==============================] - 8s 715us/step - loss: 0.0519 - accuracy: 0.8374 - val_loss: 0.0793 - val_accuracy: 0.7534\n",
      "Epoch 2726/5000\n",
      "11786/11786 [==============================] - 8s 718us/step - loss: 0.0520 - accuracy: 0.8372 - val_loss: 0.0774 - val_accuracy: 0.7531\n",
      "Epoch 2727/5000\n",
      "11786/11786 [==============================] - 8s 714us/step - loss: 0.0520 - accuracy: 0.8368 - val_loss: 0.0793 - val_accuracy: 0.7526\n",
      "Epoch 2728/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0519 - accuracy: 0.8370 - val_loss: 0.0785 - val_accuracy: 0.7538\n",
      "Epoch 2729/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0519 - accuracy: 0.8370 - val_loss: 0.0784 - val_accuracy: 0.7525\n",
      "Epoch 2730/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0519 - accuracy: 0.8375 - val_loss: 0.0783 - val_accuracy: 0.7530\n",
      "Epoch 2731/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0520 - accuracy: 0.8371 - val_loss: 0.0788 - val_accuracy: 0.7527\n",
      "Epoch 2732/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0520 - accuracy: 0.8373 - val_loss: 0.0772 - val_accuracy: 0.7550\n",
      "Epoch 2733/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0521 - accuracy: 0.8365 - val_loss: 0.0772 - val_accuracy: 0.7533\n",
      "Epoch 2734/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0522 - accuracy: 0.8367 - val_loss: 0.0786 - val_accuracy: 0.7530\n",
      "Epoch 2735/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0521 - accuracy: 0.8367 - val_loss: 0.0782 - val_accuracy: 0.7543\n",
      "Epoch 2736/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0521 - accuracy: 0.8370 - val_loss: 0.0787 - val_accuracy: 0.7546\n",
      "Epoch 2737/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0521 - accuracy: 0.8371 - val_loss: 0.0785 - val_accuracy: 0.7546\n",
      "Epoch 2738/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0521 - accuracy: 0.8370 - val_loss: 0.0782 - val_accuracy: 0.7552\n",
      "Epoch 2739/5000\n",
      "11786/11786 [==============================] - 8s 714us/step - loss: 0.0520 - accuracy: 0.8372 - val_loss: 0.0783 - val_accuracy: 0.7555\n",
      "Epoch 2740/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0520 - accuracy: 0.8372 - val_loss: 0.0778 - val_accuracy: 0.7530\n",
      "Epoch 2741/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0521 - accuracy: 0.8364 - val_loss: 0.0786 - val_accuracy: 0.7538\n",
      "Epoch 2742/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0522 - accuracy: 0.8360 - val_loss: 0.0784 - val_accuracy: 0.7542\n",
      "Epoch 2743/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0524 - accuracy: 0.8352 - val_loss: 0.0792 - val_accuracy: 0.7517\n",
      "Epoch 2744/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0521 - accuracy: 0.8361 - val_loss: 0.0796 - val_accuracy: 0.7525\n",
      "Epoch 2745/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0519 - accuracy: 0.8370 - val_loss: 0.0786 - val_accuracy: 0.7551\n",
      "Epoch 2746/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0521 - accuracy: 0.8369 - val_loss: 0.0793 - val_accuracy: 0.7546\n",
      "Epoch 2747/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0520 - accuracy: 0.8371 - val_loss: 0.0779 - val_accuracy: 0.7548\n",
      "Epoch 2748/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0520 - accuracy: 0.8369 - val_loss: 0.0788 - val_accuracy: 0.7540\n",
      "Epoch 2749/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0520 - accuracy: 0.8369 - val_loss: 0.0790 - val_accuracy: 0.7545\n",
      "Epoch 2750/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0519 - accuracy: 0.8371 - val_loss: 0.0794 - val_accuracy: 0.7530\n",
      "Epoch 2751/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0521 - accuracy: 0.8366 - val_loss: 0.0785 - val_accuracy: 0.7545\n",
      "Epoch 2752/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0519 - accuracy: 0.8373 - val_loss: 0.0785 - val_accuracy: 0.7553\n",
      "Epoch 2753/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0519 - accuracy: 0.8373 - val_loss: 0.0794 - val_accuracy: 0.7547\n",
      "Epoch 2754/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0520 - accuracy: 0.8372 - val_loss: 0.0774 - val_accuracy: 0.7542\n",
      "Epoch 2755/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0521 - accuracy: 0.8368 - val_loss: 0.0778 - val_accuracy: 0.7539\n",
      "Epoch 2756/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0520 - accuracy: 0.8374 - val_loss: 0.0783 - val_accuracy: 0.7528\n",
      "Epoch 2757/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0521 - accuracy: 0.8370 - val_loss: 0.0785 - val_accuracy: 0.7538\n",
      "Epoch 2758/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0521 - accuracy: 0.8374 - val_loss: 0.0813 - val_accuracy: 0.7513\n",
      "Epoch 2759/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0520 - accuracy: 0.8372 - val_loss: 0.0780 - val_accuracy: 0.7539\n",
      "Epoch 2760/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0520 - accuracy: 0.8373 - val_loss: 0.0798 - val_accuracy: 0.7541\n",
      "Epoch 2761/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0521 - accuracy: 0.8373 - val_loss: 0.0808 - val_accuracy: 0.7508\n",
      "Epoch 2762/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0522 - accuracy: 0.8367 - val_loss: 0.0796 - val_accuracy: 0.7522\n",
      "Epoch 2763/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0521 - accuracy: 0.8371 - val_loss: 0.0789 - val_accuracy: 0.7536\n",
      "Epoch 2764/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0522 - accuracy: 0.8367 - val_loss: 0.0783 - val_accuracy: 0.7536\n",
      "Epoch 2765/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0520 - accuracy: 0.8373 - val_loss: 0.0785 - val_accuracy: 0.7548\n",
      "Epoch 2766/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0523 - accuracy: 0.8363 - val_loss: 0.0778 - val_accuracy: 0.7548\n",
      "Epoch 2767/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0520 - accuracy: 0.8372 - val_loss: 0.0780 - val_accuracy: 0.7554\n",
      "Epoch 2768/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0521 - accuracy: 0.8371 - val_loss: 0.0778 - val_accuracy: 0.7529\n",
      "Epoch 2769/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0522 - accuracy: 0.8363 - val_loss: 0.0805 - val_accuracy: 0.7511\n",
      "Epoch 2770/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0522 - accuracy: 0.8364 - val_loss: 0.0794 - val_accuracy: 0.7525\n",
      "Epoch 2771/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0522 - accuracy: 0.8365 - val_loss: 0.0786 - val_accuracy: 0.7513\n",
      "Epoch 2772/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0523 - accuracy: 0.8364 - val_loss: 0.0786 - val_accuracy: 0.7528\n",
      "Epoch 2773/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0523 - accuracy: 0.8361 - val_loss: 0.0783 - val_accuracy: 0.7538\n",
      "Epoch 2774/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0522 - accuracy: 0.8366 - val_loss: 0.0784 - val_accuracy: 0.7552\n",
      "Epoch 2775/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0522 - accuracy: 0.8370 - val_loss: 0.0783 - val_accuracy: 0.7552\n",
      "Epoch 2776/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0521 - accuracy: 0.8372 - val_loss: 0.0795 - val_accuracy: 0.7537\n",
      "Epoch 2777/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0523 - accuracy: 0.8366 - val_loss: 0.0785 - val_accuracy: 0.7533\n",
      "Epoch 2778/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0521 - accuracy: 0.8371 - val_loss: 0.0791 - val_accuracy: 0.7530\n",
      "Epoch 2779/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0520 - accuracy: 0.8373 - val_loss: 0.0790 - val_accuracy: 0.7538\n",
      "Epoch 2780/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0521 - accuracy: 0.8371 - val_loss: 0.0785 - val_accuracy: 0.7543\n",
      "Epoch 2781/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0522 - accuracy: 0.8366 - val_loss: 0.0794 - val_accuracy: 0.7525\n",
      "Epoch 2782/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0524 - accuracy: 0.8359 - val_loss: 0.0791 - val_accuracy: 0.7532\n",
      "Epoch 2783/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0522 - accuracy: 0.8362 - val_loss: 0.0788 - val_accuracy: 0.7522\n",
      "Epoch 2784/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0523 - accuracy: 0.8364 - val_loss: 0.0798 - val_accuracy: 0.7526\n",
      "Epoch 2785/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0522 - accuracy: 0.8363 - val_loss: 0.0787 - val_accuracy: 0.7542\n",
      "Epoch 2786/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0523 - accuracy: 0.8364 - val_loss: 0.0793 - val_accuracy: 0.7538\n",
      "Epoch 2787/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0522 - accuracy: 0.8367 - val_loss: 0.0784 - val_accuracy: 0.7542\n",
      "Epoch 2788/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0521 - accuracy: 0.8367 - val_loss: 0.0790 - val_accuracy: 0.7531\n",
      "Epoch 2789/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0524 - accuracy: 0.8359 - val_loss: 0.0787 - val_accuracy: 0.7535\n",
      "Epoch 2790/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0522 - accuracy: 0.8368 - val_loss: 0.0789 - val_accuracy: 0.7538\n",
      "Epoch 2791/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0523 - accuracy: 0.8367 - val_loss: 0.0787 - val_accuracy: 0.7527\n",
      "Epoch 2792/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0521 - accuracy: 0.8371 - val_loss: 0.0789 - val_accuracy: 0.7534\n",
      "Epoch 2793/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0523 - accuracy: 0.8365 - val_loss: 0.0797 - val_accuracy: 0.7523\n",
      "Epoch 2794/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0523 - accuracy: 0.8365 - val_loss: 0.0791 - val_accuracy: 0.7522\n",
      "Epoch 2795/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0523 - accuracy: 0.8362 - val_loss: 0.0801 - val_accuracy: 0.7525\n",
      "Epoch 2796/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0523 - accuracy: 0.8358 - val_loss: 0.0787 - val_accuracy: 0.7528\n",
      "Epoch 2797/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0522 - accuracy: 0.8364 - val_loss: 0.0787 - val_accuracy: 0.7513\n",
      "Epoch 2798/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0523 - accuracy: 0.8360 - val_loss: 0.0798 - val_accuracy: 0.7528\n",
      "Epoch 2799/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0524 - accuracy: 0.8361 - val_loss: 0.0790 - val_accuracy: 0.7543\n",
      "Epoch 2800/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0522 - accuracy: 0.8366 - val_loss: 0.0783 - val_accuracy: 0.7540\n",
      "Epoch 2801/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0522 - accuracy: 0.8367 - val_loss: 0.0783 - val_accuracy: 0.7540\n",
      "Epoch 2802/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0522 - accuracy: 0.8367 - val_loss: 0.0788 - val_accuracy: 0.7545\n",
      "Epoch 2803/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0521 - accuracy: 0.8365 - val_loss: 0.0800 - val_accuracy: 0.7533\n",
      "Epoch 2804/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0521 - accuracy: 0.8370 - val_loss: 0.0791 - val_accuracy: 0.7549\n",
      "Epoch 2805/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0523 - accuracy: 0.8363 - val_loss: 0.0785 - val_accuracy: 0.7531\n",
      "Epoch 2806/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0522 - accuracy: 0.8367 - val_loss: 0.0790 - val_accuracy: 0.7544\n",
      "Epoch 2807/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0523 - accuracy: 0.8366 - val_loss: 0.0787 - val_accuracy: 0.7539\n",
      "Epoch 2808/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0521 - accuracy: 0.8369 - val_loss: 0.0787 - val_accuracy: 0.7543\n",
      "Epoch 2809/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0522 - accuracy: 0.8365 - val_loss: 0.0792 - val_accuracy: 0.7520\n",
      "Epoch 2810/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0522 - accuracy: 0.8365 - val_loss: 0.0794 - val_accuracy: 0.7534\n",
      "Epoch 2811/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0522 - accuracy: 0.8365 - val_loss: 0.0786 - val_accuracy: 0.7536\n",
      "Epoch 2812/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0524 - accuracy: 0.8360 - val_loss: 0.0794 - val_accuracy: 0.7528\n",
      "Epoch 2813/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0522 - accuracy: 0.8364 - val_loss: 0.0781 - val_accuracy: 0.7540\n",
      "Epoch 2814/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0523 - accuracy: 0.8365 - val_loss: 0.0787 - val_accuracy: 0.7526\n",
      "Epoch 2815/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0524 - accuracy: 0.8356 - val_loss: 0.0783 - val_accuracy: 0.7531\n",
      "Epoch 2816/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0523 - accuracy: 0.8362 - val_loss: 0.0793 - val_accuracy: 0.7516\n",
      "Epoch 2817/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0522 - accuracy: 0.8367 - val_loss: 0.0794 - val_accuracy: 0.7519\n",
      "Epoch 2818/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0522 - accuracy: 0.8370 - val_loss: 0.0794 - val_accuracy: 0.7529\n",
      "Epoch 2819/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0522 - accuracy: 0.8370 - val_loss: 0.0786 - val_accuracy: 0.7550\n",
      "Epoch 2820/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0523 - accuracy: 0.8360 - val_loss: 0.0795 - val_accuracy: 0.7539\n",
      "Epoch 2821/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0523 - accuracy: 0.8362 - val_loss: 0.0783 - val_accuracy: 0.7542\n",
      "Epoch 2822/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0523 - accuracy: 0.8364 - val_loss: 0.0783 - val_accuracy: 0.7538\n",
      "Epoch 2823/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0521 - accuracy: 0.8369 - val_loss: 0.0785 - val_accuracy: 0.7545\n",
      "Epoch 2824/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0523 - accuracy: 0.8363 - val_loss: 0.0791 - val_accuracy: 0.7526\n",
      "Epoch 2825/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0523 - accuracy: 0.8360 - val_loss: 0.0799 - val_accuracy: 0.7518\n",
      "Epoch 2826/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0525 - accuracy: 0.8357 - val_loss: 0.0792 - val_accuracy: 0.7516\n",
      "Epoch 2827/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0525 - accuracy: 0.8354 - val_loss: 0.0791 - val_accuracy: 0.7474\n",
      "Epoch 2828/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0524 - accuracy: 0.8360 - val_loss: 0.0805 - val_accuracy: 0.7519\n",
      "Epoch 2829/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0524 - accuracy: 0.8364 - val_loss: 0.0791 - val_accuracy: 0.7530\n",
      "Epoch 2830/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0525 - accuracy: 0.8358 - val_loss: 0.0796 - val_accuracy: 0.7536\n",
      "Epoch 2831/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0524 - accuracy: 0.8362 - val_loss: 0.0783 - val_accuracy: 0.7531\n",
      "Epoch 2832/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0523 - accuracy: 0.8361 - val_loss: 0.0799 - val_accuracy: 0.7547\n",
      "Epoch 2833/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0525 - accuracy: 0.8356 - val_loss: 0.0786 - val_accuracy: 0.7514\n",
      "Epoch 2834/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0525 - accuracy: 0.8357 - val_loss: 0.0787 - val_accuracy: 0.7524\n",
      "Epoch 2835/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0524 - accuracy: 0.8360 - val_loss: 0.0791 - val_accuracy: 0.7541\n",
      "Epoch 2836/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0524 - accuracy: 0.8362 - val_loss: 0.0801 - val_accuracy: 0.7501\n",
      "Epoch 2837/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0527 - accuracy: 0.8355 - val_loss: 0.0793 - val_accuracy: 0.7516\n",
      "Epoch 2838/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0524 - accuracy: 0.8356 - val_loss: 0.0794 - val_accuracy: 0.7545\n",
      "Epoch 2839/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0524 - accuracy: 0.8359 - val_loss: 0.0793 - val_accuracy: 0.7520\n",
      "Epoch 2840/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0526 - accuracy: 0.8352 - val_loss: 0.0793 - val_accuracy: 0.7512\n",
      "Epoch 2841/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0527 - accuracy: 0.8352 - val_loss: 0.0795 - val_accuracy: 0.7538\n",
      "Epoch 2842/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0527 - accuracy: 0.8351 - val_loss: 0.0800 - val_accuracy: 0.7519\n",
      "Epoch 2843/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0526 - accuracy: 0.8351 - val_loss: 0.0789 - val_accuracy: 0.7530\n",
      "Epoch 2844/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0526 - accuracy: 0.8348 - val_loss: 0.0788 - val_accuracy: 0.7535\n",
      "Epoch 2845/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0526 - accuracy: 0.8353 - val_loss: 0.0785 - val_accuracy: 0.7542\n",
      "Epoch 2846/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0525 - accuracy: 0.8354 - val_loss: 0.0785 - val_accuracy: 0.7534\n",
      "Epoch 2847/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0526 - accuracy: 0.8353 - val_loss: 0.0797 - val_accuracy: 0.7530\n",
      "Epoch 2848/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0526 - accuracy: 0.8351 - val_loss: 0.0787 - val_accuracy: 0.7512\n",
      "Epoch 2849/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0526 - accuracy: 0.8350 - val_loss: 0.0796 - val_accuracy: 0.7546\n",
      "Epoch 2850/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0526 - accuracy: 0.8349 - val_loss: 0.0783 - val_accuracy: 0.7510\n",
      "Epoch 2851/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0524 - accuracy: 0.8358 - val_loss: 0.0792 - val_accuracy: 0.7527\n",
      "Epoch 2852/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0524 - accuracy: 0.8359 - val_loss: 0.0803 - val_accuracy: 0.7539\n",
      "Epoch 2853/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0526 - accuracy: 0.8351 - val_loss: 0.0794 - val_accuracy: 0.7519\n",
      "Epoch 2854/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0526 - accuracy: 0.8350 - val_loss: 0.0796 - val_accuracy: 0.7536\n",
      "Epoch 2855/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0525 - accuracy: 0.8350 - val_loss: 0.0797 - val_accuracy: 0.7513\n",
      "Epoch 2856/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0524 - accuracy: 0.8359 - val_loss: 0.0804 - val_accuracy: 0.7521\n",
      "Epoch 2857/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0524 - accuracy: 0.8356 - val_loss: 0.0803 - val_accuracy: 0.7521\n",
      "Epoch 2858/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0526 - accuracy: 0.8351 - val_loss: 0.0792 - val_accuracy: 0.7505\n",
      "Epoch 2859/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0527 - accuracy: 0.8349 - val_loss: 0.0795 - val_accuracy: 0.7521\n",
      "Epoch 2860/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0528 - accuracy: 0.8348 - val_loss: 0.0806 - val_accuracy: 0.7519\n",
      "Epoch 2861/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0527 - accuracy: 0.8351 - val_loss: 0.0795 - val_accuracy: 0.7520\n",
      "Epoch 2862/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0526 - accuracy: 0.8355 - val_loss: 0.0798 - val_accuracy: 0.7532\n",
      "Epoch 2863/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0528 - accuracy: 0.8350 - val_loss: 0.0793 - val_accuracy: 0.7504\n",
      "Epoch 2864/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0526 - accuracy: 0.8355 - val_loss: 0.0794 - val_accuracy: 0.7533\n",
      "Epoch 2865/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0526 - accuracy: 0.8352 - val_loss: 0.0799 - val_accuracy: 0.7526\n",
      "Epoch 2866/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0526 - accuracy: 0.8356 - val_loss: 0.0800 - val_accuracy: 0.7524\n",
      "Epoch 2867/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0527 - accuracy: 0.8352 - val_loss: 0.0789 - val_accuracy: 0.7529\n",
      "Epoch 2868/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0526 - accuracy: 0.8354 - val_loss: 0.0800 - val_accuracy: 0.7517\n",
      "Epoch 2869/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0525 - accuracy: 0.8358 - val_loss: 0.0778 - val_accuracy: 0.7513\n",
      "Epoch 2870/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0528 - accuracy: 0.8344 - val_loss: 0.0787 - val_accuracy: 0.7526\n",
      "Epoch 2871/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0526 - accuracy: 0.8352 - val_loss: 0.0797 - val_accuracy: 0.7536\n",
      "Epoch 2872/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0527 - accuracy: 0.8351 - val_loss: 0.0783 - val_accuracy: 0.7521\n",
      "Epoch 2873/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0528 - accuracy: 0.8346 - val_loss: 0.0802 - val_accuracy: 0.7497\n",
      "Epoch 2874/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0527 - accuracy: 0.8349 - val_loss: 0.0792 - val_accuracy: 0.7525\n",
      "Epoch 2875/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0527 - accuracy: 0.8355 - val_loss: 0.0782 - val_accuracy: 0.7521\n",
      "Epoch 2876/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0526 - accuracy: 0.8358 - val_loss: 0.0793 - val_accuracy: 0.7504\n",
      "Epoch 2877/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0526 - accuracy: 0.8355 - val_loss: 0.0795 - val_accuracy: 0.7522\n",
      "Epoch 2878/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0527 - accuracy: 0.8352 - val_loss: 0.0804 - val_accuracy: 0.7500\n",
      "Epoch 2879/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0527 - accuracy: 0.8348 - val_loss: 0.0796 - val_accuracy: 0.7518\n",
      "Epoch 2880/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0526 - accuracy: 0.8356 - val_loss: 0.0798 - val_accuracy: 0.7525\n",
      "Epoch 2881/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0527 - accuracy: 0.8351 - val_loss: 0.0798 - val_accuracy: 0.7512\n",
      "Epoch 2882/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0527 - accuracy: 0.8349 - val_loss: 0.0805 - val_accuracy: 0.7502\n",
      "Epoch 2883/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0528 - accuracy: 0.8351 - val_loss: 0.0798 - val_accuracy: 0.7509\n",
      "Epoch 2884/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0530 - accuracy: 0.8344 - val_loss: 0.0786 - val_accuracy: 0.7521\n",
      "Epoch 2885/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0528 - accuracy: 0.8350 - val_loss: 0.0797 - val_accuracy: 0.7534\n",
      "Epoch 2886/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0528 - accuracy: 0.8350 - val_loss: 0.0787 - val_accuracy: 0.7525\n",
      "Epoch 2887/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0529 - accuracy: 0.8347 - val_loss: 0.0802 - val_accuracy: 0.7516\n",
      "Epoch 2888/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0530 - accuracy: 0.8347 - val_loss: 0.0807 - val_accuracy: 0.7514\n",
      "Epoch 2889/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0529 - accuracy: 0.8350 - val_loss: 0.0791 - val_accuracy: 0.7514\n",
      "Epoch 2890/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0528 - accuracy: 0.8350 - val_loss: 0.0788 - val_accuracy: 0.7528\n",
      "Epoch 2891/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0528 - accuracy: 0.8354 - val_loss: 0.0791 - val_accuracy: 0.7530\n",
      "Epoch 2892/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0528 - accuracy: 0.8352 - val_loss: 0.0792 - val_accuracy: 0.7517\n",
      "Epoch 2893/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0529 - accuracy: 0.8350 - val_loss: 0.0792 - val_accuracy: 0.7516\n",
      "Epoch 2894/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0529 - accuracy: 0.8348 - val_loss: 0.0799 - val_accuracy: 0.7505\n",
      "Epoch 2895/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0528 - accuracy: 0.8350 - val_loss: 0.0798 - val_accuracy: 0.7515\n",
      "Epoch 2896/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0530 - accuracy: 0.8345 - val_loss: 0.0788 - val_accuracy: 0.7534\n",
      "Epoch 2897/5000\n",
      "11786/11786 [==============================] - 9s 724us/step - loss: 0.0530 - accuracy: 0.8344 - val_loss: 0.0796 - val_accuracy: 0.7517\n",
      "Epoch 2898/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0529 - accuracy: 0.8345 - val_loss: 0.0786 - val_accuracy: 0.7516\n",
      "Epoch 2899/5000\n",
      "11786/11786 [==============================] - 8s 720us/step - loss: 0.0530 - accuracy: 0.8341 - val_loss: 0.0788 - val_accuracy: 0.7527\n",
      "Epoch 2900/5000\n",
      "11786/11786 [==============================] - 8s 716us/step - loss: 0.0529 - accuracy: 0.8344 - val_loss: 0.0798 - val_accuracy: 0.7509\n",
      "Epoch 2901/5000\n",
      "11786/11786 [==============================] - 8s 718us/step - loss: 0.0527 - accuracy: 0.8353 - val_loss: 0.0801 - val_accuracy: 0.7521\n",
      "Epoch 2902/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0527 - accuracy: 0.8351 - val_loss: 0.0801 - val_accuracy: 0.7502\n",
      "Epoch 2903/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0528 - accuracy: 0.8347 - val_loss: 0.0790 - val_accuracy: 0.7531\n",
      "Epoch 2904/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0528 - accuracy: 0.8350 - val_loss: 0.0793 - val_accuracy: 0.7517\n",
      "Epoch 2905/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0528 - accuracy: 0.8348 - val_loss: 0.0801 - val_accuracy: 0.7522\n",
      "Epoch 2906/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0526 - accuracy: 0.8351 - val_loss: 0.0792 - val_accuracy: 0.7520\n",
      "Epoch 2907/5000\n",
      "11786/11786 [==============================] - 9s 722us/step - loss: 0.0527 - accuracy: 0.8352 - val_loss: 0.0796 - val_accuracy: 0.7517\n",
      "Epoch 2908/5000\n",
      "11786/11786 [==============================] - 9s 722us/step - loss: 0.0527 - accuracy: 0.8352 - val_loss: 0.0803 - val_accuracy: 0.7507\n",
      "Epoch 2909/5000\n",
      "11786/11786 [==============================] - 8s 714us/step - loss: 0.0527 - accuracy: 0.8354 - val_loss: 0.0799 - val_accuracy: 0.7520\n",
      "Epoch 2910/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0528 - accuracy: 0.8350 - val_loss: 0.0800 - val_accuracy: 0.7501\n",
      "Epoch 2911/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0528 - accuracy: 0.8351 - val_loss: 0.0795 - val_accuracy: 0.7519\n",
      "Epoch 2912/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0530 - accuracy: 0.8340 - val_loss: 0.0795 - val_accuracy: 0.7521\n",
      "Epoch 2913/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0528 - accuracy: 0.8348 - val_loss: 0.0800 - val_accuracy: 0.7512\n",
      "Epoch 2914/5000\n",
      "11786/11786 [==============================] - 8s 715us/step - loss: 0.0529 - accuracy: 0.8343 - val_loss: 0.0790 - val_accuracy: 0.7529\n",
      "Epoch 2915/5000\n",
      "11786/11786 [==============================] - 8s 717us/step - loss: 0.0529 - accuracy: 0.8344 - val_loss: 0.0793 - val_accuracy: 0.7525\n",
      "Epoch 2916/5000\n",
      "11786/11786 [==============================] - 8s 715us/step - loss: 0.0529 - accuracy: 0.8345 - val_loss: 0.0792 - val_accuracy: 0.7525\n",
      "Epoch 2917/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0528 - accuracy: 0.8352 - val_loss: 0.0792 - val_accuracy: 0.7499\n",
      "Epoch 2918/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0530 - accuracy: 0.8336 - val_loss: 0.0797 - val_accuracy: 0.7512\n",
      "Epoch 2919/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0529 - accuracy: 0.8346 - val_loss: 0.0800 - val_accuracy: 0.7517\n",
      "Epoch 2920/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0530 - accuracy: 0.8342 - val_loss: 0.0784 - val_accuracy: 0.7524\n",
      "Epoch 2921/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0527 - accuracy: 0.8345 - val_loss: 0.0788 - val_accuracy: 0.7527\n",
      "Epoch 2922/5000\n",
      "11786/11786 [==============================] - 8s 717us/step - loss: 0.0528 - accuracy: 0.8344 - val_loss: 0.0783 - val_accuracy: 0.7534\n",
      "Epoch 2923/5000\n",
      "11786/11786 [==============================] - 8s 717us/step - loss: 0.0527 - accuracy: 0.8350 - val_loss: 0.0790 - val_accuracy: 0.7516\n",
      "Epoch 2924/5000\n",
      "11786/11786 [==============================] - 8s 714us/step - loss: 0.0529 - accuracy: 0.8343 - val_loss: 0.0793 - val_accuracy: 0.7503\n",
      "Epoch 2925/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0530 - accuracy: 0.8341 - val_loss: 0.0783 - val_accuracy: 0.7512\n",
      "Epoch 2926/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0530 - accuracy: 0.8339 - val_loss: 0.0792 - val_accuracy: 0.7507\n",
      "Epoch 2927/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0529 - accuracy: 0.8344 - val_loss: 0.0791 - val_accuracy: 0.7524\n",
      "Epoch 2928/5000\n",
      "11786/11786 [==============================] - 8s 719us/step - loss: 0.0528 - accuracy: 0.8343 - val_loss: 0.0793 - val_accuracy: 0.7516\n",
      "Epoch 2929/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0528 - accuracy: 0.8341 - val_loss: 0.0803 - val_accuracy: 0.7497\n",
      "Epoch 2930/5000\n",
      "11786/11786 [==============================] - 8s 714us/step - loss: 0.0528 - accuracy: 0.8346 - val_loss: 0.0781 - val_accuracy: 0.7509\n",
      "Epoch 2931/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0529 - accuracy: 0.8342 - val_loss: 0.0794 - val_accuracy: 0.7517\n",
      "Epoch 2932/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0529 - accuracy: 0.8346 - val_loss: 0.0795 - val_accuracy: 0.7509\n",
      "Epoch 2933/5000\n",
      "11786/11786 [==============================] - 8s 715us/step - loss: 0.0529 - accuracy: 0.8341 - val_loss: 0.0790 - val_accuracy: 0.7506\n",
      "Epoch 2934/5000\n",
      "11786/11786 [==============================] - 8s 714us/step - loss: 0.0528 - accuracy: 0.8345 - val_loss: 0.0783 - val_accuracy: 0.7522\n",
      "Epoch 2935/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0530 - accuracy: 0.8340 - val_loss: 0.0806 - val_accuracy: 0.7508\n",
      "Epoch 2936/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0528 - accuracy: 0.8344 - val_loss: 0.0788 - val_accuracy: 0.7517\n",
      "Epoch 2937/5000\n",
      "11786/11786 [==============================] - 8s 719us/step - loss: 0.0528 - accuracy: 0.8345 - val_loss: 0.0809 - val_accuracy: 0.7513\n",
      "Epoch 2938/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0530 - accuracy: 0.8339 - val_loss: 0.0798 - val_accuracy: 0.7513\n",
      "Epoch 2939/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0528 - accuracy: 0.8346 - val_loss: 0.0804 - val_accuracy: 0.7494\n",
      "Epoch 2940/5000\n",
      "11786/11786 [==============================] - 8s 716us/step - loss: 0.0531 - accuracy: 0.8334 - val_loss: 0.0802 - val_accuracy: 0.7491\n",
      "Epoch 2941/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0530 - accuracy: 0.8340 - val_loss: 0.0786 - val_accuracy: 0.7528\n",
      "Epoch 2942/5000\n",
      "11786/11786 [==============================] - 8s 715us/step - loss: 0.0528 - accuracy: 0.8351 - val_loss: 0.0799 - val_accuracy: 0.7522\n",
      "Epoch 2943/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0531 - accuracy: 0.8338 - val_loss: 0.0800 - val_accuracy: 0.7520\n",
      "Epoch 2944/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0529 - accuracy: 0.8345 - val_loss: 0.0798 - val_accuracy: 0.7498\n",
      "Epoch 2945/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0529 - accuracy: 0.8348 - val_loss: 0.0804 - val_accuracy: 0.7511\n",
      "Epoch 2946/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0528 - accuracy: 0.8351 - val_loss: 0.0806 - val_accuracy: 0.7454\n",
      "Epoch 2947/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0530 - accuracy: 0.8342 - val_loss: 0.0797 - val_accuracy: 0.7516\n",
      "Epoch 2948/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0529 - accuracy: 0.8346 - val_loss: 0.0796 - val_accuracy: 0.7520\n",
      "Epoch 2949/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0529 - accuracy: 0.8346 - val_loss: 0.0797 - val_accuracy: 0.7528\n",
      "Epoch 2950/5000\n",
      "11786/11786 [==============================] - 8s 718us/step - loss: 0.0529 - accuracy: 0.8340 - val_loss: 0.0799 - val_accuracy: 0.7516\n",
      "Epoch 2951/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0529 - accuracy: 0.8342 - val_loss: 0.0798 - val_accuracy: 0.7517\n",
      "Epoch 2952/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0528 - accuracy: 0.8346 - val_loss: 0.0816 - val_accuracy: 0.7384\n",
      "Epoch 2953/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0528 - accuracy: 0.8347 - val_loss: 0.0795 - val_accuracy: 0.7518\n",
      "Epoch 2954/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0528 - accuracy: 0.8348 - val_loss: 0.0798 - val_accuracy: 0.7525\n",
      "Epoch 2955/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0528 - accuracy: 0.8345 - val_loss: 0.0796 - val_accuracy: 0.7514\n",
      "Epoch 2956/5000\n",
      "11786/11786 [==============================] - 8s 719us/step - loss: 0.0530 - accuracy: 0.8343 - val_loss: 0.0791 - val_accuracy: 0.7495\n",
      "Epoch 2957/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0530 - accuracy: 0.8343 - val_loss: 0.0793 - val_accuracy: 0.7507\n",
      "Epoch 2958/5000\n",
      "11786/11786 [==============================] - 8s 718us/step - loss: 0.0529 - accuracy: 0.8347 - val_loss: 0.0800 - val_accuracy: 0.7520\n",
      "Epoch 2959/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0529 - accuracy: 0.8346 - val_loss: 0.0789 - val_accuracy: 0.7516\n",
      "Epoch 2960/5000\n",
      "11786/11786 [==============================] - 8s 715us/step - loss: 0.0530 - accuracy: 0.8339 - val_loss: 0.0800 - val_accuracy: 0.7507\n",
      "Epoch 2961/5000\n",
      "11786/11786 [==============================] - 8s 719us/step - loss: 0.0529 - accuracy: 0.8340 - val_loss: 0.0787 - val_accuracy: 0.7516\n",
      "Epoch 2962/5000\n",
      "11786/11786 [==============================] - 8s 716us/step - loss: 0.0529 - accuracy: 0.8341 - val_loss: 0.0800 - val_accuracy: 0.7526\n",
      "Epoch 2963/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0528 - accuracy: 0.8347 - val_loss: 0.0790 - val_accuracy: 0.7526\n",
      "Epoch 2964/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0529 - accuracy: 0.8343 - val_loss: 0.0797 - val_accuracy: 0.7507\n",
      "Epoch 2965/5000\n",
      "11786/11786 [==============================] - 8s 715us/step - loss: 0.0529 - accuracy: 0.8344 - val_loss: 0.0800 - val_accuracy: 0.7506\n",
      "Epoch 2966/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0530 - accuracy: 0.8343 - val_loss: 0.0802 - val_accuracy: 0.7476\n",
      "Epoch 2967/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0530 - accuracy: 0.8341 - val_loss: 0.0807 - val_accuracy: 0.7490\n",
      "Epoch 2968/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0530 - accuracy: 0.8344 - val_loss: 0.0793 - val_accuracy: 0.7496\n",
      "Epoch 2969/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0530 - accuracy: 0.8340 - val_loss: 0.0798 - val_accuracy: 0.7520\n",
      "Epoch 2970/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0530 - accuracy: 0.8345 - val_loss: 0.0810 - val_accuracy: 0.7511\n",
      "Epoch 2971/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0531 - accuracy: 0.8337 - val_loss: 0.0800 - val_accuracy: 0.7513\n",
      "Epoch 2972/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0530 - accuracy: 0.8341 - val_loss: 0.0792 - val_accuracy: 0.7517\n",
      "Epoch 2973/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0531 - accuracy: 0.8338 - val_loss: 0.0799 - val_accuracy: 0.7510\n",
      "Epoch 2974/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0529 - accuracy: 0.8342 - val_loss: 0.0799 - val_accuracy: 0.7509\n",
      "Epoch 2975/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0530 - accuracy: 0.8338 - val_loss: 0.0810 - val_accuracy: 0.7515\n",
      "Epoch 2976/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0531 - accuracy: 0.8336 - val_loss: 0.0802 - val_accuracy: 0.7506\n",
      "Epoch 2977/5000\n",
      "11786/11786 [==============================] - 8s 717us/step - loss: 0.0531 - accuracy: 0.8341 - val_loss: 0.0805 - val_accuracy: 0.7506\n",
      "Epoch 2978/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0530 - accuracy: 0.8339 - val_loss: 0.0805 - val_accuracy: 0.7483\n",
      "Epoch 2979/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0530 - accuracy: 0.8340 - val_loss: 0.0803 - val_accuracy: 0.7501\n",
      "Epoch 2980/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0530 - accuracy: 0.8339 - val_loss: 0.0797 - val_accuracy: 0.7506\n",
      "Epoch 2981/5000\n",
      "11786/11786 [==============================] - 9s 728us/step - loss: 0.0530 - accuracy: 0.8338 - val_loss: 0.0790 - val_accuracy: 0.7503\n",
      "Epoch 2982/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0529 - accuracy: 0.8344 - val_loss: 0.0811 - val_accuracy: 0.7483\n",
      "Epoch 2983/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0530 - accuracy: 0.8343 - val_loss: 0.0789 - val_accuracy: 0.7528\n",
      "Epoch 2984/5000\n",
      "11786/11786 [==============================] - 8s 718us/step - loss: 0.0530 - accuracy: 0.8341 - val_loss: 0.0799 - val_accuracy: 0.7521\n",
      "Epoch 2985/5000\n",
      "11786/11786 [==============================] - 8s 719us/step - loss: 0.0530 - accuracy: 0.8342 - val_loss: 0.0794 - val_accuracy: 0.7520\n",
      "Epoch 2986/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0529 - accuracy: 0.8349 - val_loss: 0.0799 - val_accuracy: 0.7497\n",
      "Epoch 2987/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0529 - accuracy: 0.8347 - val_loss: 0.0793 - val_accuracy: 0.7509\n",
      "Epoch 2988/5000\n",
      "11786/11786 [==============================] - 9s 722us/step - loss: 0.0531 - accuracy: 0.8338 - val_loss: 0.0802 - val_accuracy: 0.7506\n",
      "Epoch 2989/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0531 - accuracy: 0.8338 - val_loss: 0.0795 - val_accuracy: 0.7517\n",
      "Epoch 2990/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0531 - accuracy: 0.8342 - val_loss: 0.0798 - val_accuracy: 0.7518\n",
      "Epoch 2991/5000\n",
      "11786/11786 [==============================] - 8s 714us/step - loss: 0.0529 - accuracy: 0.8342 - val_loss: 0.0791 - val_accuracy: 0.7522\n",
      "Epoch 2992/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0528 - accuracy: 0.8346 - val_loss: 0.0791 - val_accuracy: 0.7518\n",
      "Epoch 2993/5000\n",
      "11786/11786 [==============================] - 9s 725us/step - loss: 0.0527 - accuracy: 0.8352 - val_loss: 0.0796 - val_accuracy: 0.7496\n",
      "Epoch 2994/5000\n",
      "11786/11786 [==============================] - 8s 716us/step - loss: 0.0528 - accuracy: 0.8346 - val_loss: 0.0793 - val_accuracy: 0.7530\n",
      "Epoch 2995/5000\n",
      "11786/11786 [==============================] - 8s 715us/step - loss: 0.0529 - accuracy: 0.8347 - val_loss: 0.0803 - val_accuracy: 0.7507\n",
      "Epoch 2996/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0529 - accuracy: 0.8344 - val_loss: 0.0802 - val_accuracy: 0.7480\n",
      "Epoch 2997/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0529 - accuracy: 0.8343 - val_loss: 0.0802 - val_accuracy: 0.7515\n",
      "Epoch 2998/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0530 - accuracy: 0.8343 - val_loss: 0.0810 - val_accuracy: 0.7496\n",
      "Epoch 2999/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0531 - accuracy: 0.8333 - val_loss: 0.0810 - val_accuracy: 0.7510\n",
      "Epoch 3000/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0530 - accuracy: 0.8343 - val_loss: 0.0802 - val_accuracy: 0.7507\n",
      "Epoch 3001/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0530 - accuracy: 0.8339 - val_loss: 0.0807 - val_accuracy: 0.7503\n",
      "Epoch 3002/5000\n",
      "11786/11786 [==============================] - 8s 718us/step - loss: 0.0528 - accuracy: 0.8348 - val_loss: 0.0796 - val_accuracy: 0.7518\n",
      "Epoch 3003/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0528 - accuracy: 0.8348 - val_loss: 0.0792 - val_accuracy: 0.7511\n",
      "Epoch 3004/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0529 - accuracy: 0.8342 - val_loss: 0.0804 - val_accuracy: 0.7508\n",
      "Epoch 3005/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0528 - accuracy: 0.8345 - val_loss: 0.0799 - val_accuracy: 0.7519\n",
      "Epoch 3006/5000\n",
      "11786/11786 [==============================] - 8s 714us/step - loss: 0.0529 - accuracy: 0.8340 - val_loss: 0.0794 - val_accuracy: 0.7518\n",
      "Epoch 3007/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0527 - accuracy: 0.8350 - val_loss: 0.0796 - val_accuracy: 0.7510\n",
      "Epoch 3008/5000\n",
      "11786/11786 [==============================] - 8s 715us/step - loss: 0.0528 - accuracy: 0.8346 - val_loss: 0.0798 - val_accuracy: 0.7509\n",
      "Epoch 3009/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0528 - accuracy: 0.8344 - val_loss: 0.0803 - val_accuracy: 0.7509\n",
      "Epoch 3010/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0529 - accuracy: 0.8342 - val_loss: 0.0785 - val_accuracy: 0.7509\n",
      "Epoch 3011/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0528 - accuracy: 0.8348 - val_loss: 0.0795 - val_accuracy: 0.7518\n",
      "Epoch 3012/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0527 - accuracy: 0.8348 - val_loss: 0.0806 - val_accuracy: 0.7514\n",
      "Epoch 3013/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0529 - accuracy: 0.8345 - val_loss: 0.0790 - val_accuracy: 0.7528\n",
      "Epoch 3014/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0529 - accuracy: 0.8344 - val_loss: 0.0786 - val_accuracy: 0.7538\n",
      "Epoch 3015/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0525 - accuracy: 0.8356 - val_loss: 0.0794 - val_accuracy: 0.7525\n",
      "Epoch 3016/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0527 - accuracy: 0.8354 - val_loss: 0.0792 - val_accuracy: 0.7479\n",
      "Epoch 3017/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0529 - accuracy: 0.8341 - val_loss: 0.0798 - val_accuracy: 0.7516\n",
      "Epoch 3018/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0529 - accuracy: 0.8345 - val_loss: 0.0794 - val_accuracy: 0.7507\n",
      "Epoch 3019/5000\n",
      "11786/11786 [==============================] - 8s 715us/step - loss: 0.0530 - accuracy: 0.8341 - val_loss: 0.0800 - val_accuracy: 0.7504\n",
      "Epoch 3020/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0530 - accuracy: 0.8339 - val_loss: 0.0791 - val_accuracy: 0.7518\n",
      "Epoch 3021/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0529 - accuracy: 0.8349 - val_loss: 0.0802 - val_accuracy: 0.7508\n",
      "Epoch 3022/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0528 - accuracy: 0.8350 - val_loss: 0.0803 - val_accuracy: 0.7503\n",
      "Epoch 3023/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0529 - accuracy: 0.8351 - val_loss: 0.0791 - val_accuracy: 0.7518\n",
      "Epoch 3024/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0529 - accuracy: 0.8348 - val_loss: 0.0789 - val_accuracy: 0.7532\n",
      "Epoch 3025/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0529 - accuracy: 0.8349 - val_loss: 0.0798 - val_accuracy: 0.7515\n",
      "Epoch 3026/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0530 - accuracy: 0.8340 - val_loss: 0.0796 - val_accuracy: 0.7490\n",
      "Epoch 3027/5000\n",
      "11786/11786 [==============================] - 8s 715us/step - loss: 0.0532 - accuracy: 0.8331 - val_loss: 0.0784 - val_accuracy: 0.7517\n",
      "Epoch 3028/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0531 - accuracy: 0.8336 - val_loss: 0.0783 - val_accuracy: 0.7497\n",
      "Epoch 3029/5000\n",
      "11786/11786 [==============================] - 8s 714us/step - loss: 0.0531 - accuracy: 0.8336 - val_loss: 0.0792 - val_accuracy: 0.7529\n",
      "Epoch 3030/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0530 - accuracy: 0.8339 - val_loss: 0.0812 - val_accuracy: 0.7507\n",
      "Epoch 3031/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0530 - accuracy: 0.8342 - val_loss: 0.0799 - val_accuracy: 0.7498\n",
      "Epoch 3032/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0530 - accuracy: 0.8343 - val_loss: 0.0794 - val_accuracy: 0.7538\n",
      "Epoch 3033/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0528 - accuracy: 0.8348 - val_loss: 0.0789 - val_accuracy: 0.7544\n",
      "Epoch 3034/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0529 - accuracy: 0.8346 - val_loss: 0.0801 - val_accuracy: 0.7492\n",
      "Epoch 3035/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0530 - accuracy: 0.8342 - val_loss: 0.0795 - val_accuracy: 0.7519\n",
      "Epoch 3036/5000\n",
      "11786/11786 [==============================] - 8s 715us/step - loss: 0.0531 - accuracy: 0.8338 - val_loss: 0.0803 - val_accuracy: 0.7484\n",
      "Epoch 3037/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0531 - accuracy: 0.8340 - val_loss: 0.0796 - val_accuracy: 0.7513\n",
      "Epoch 3038/5000\n",
      "11786/11786 [==============================] - 8s 716us/step - loss: 0.0532 - accuracy: 0.8337 - val_loss: 0.0784 - val_accuracy: 0.7509\n",
      "Epoch 3039/5000\n",
      "11786/11786 [==============================] - 8s 720us/step - loss: 0.0531 - accuracy: 0.8338 - val_loss: 0.0795 - val_accuracy: 0.7513\n",
      "Epoch 3040/5000\n",
      "11786/11786 [==============================] - 8s 718us/step - loss: 0.0531 - accuracy: 0.8340 - val_loss: 0.0798 - val_accuracy: 0.7500\n",
      "Epoch 3041/5000\n",
      "11786/11786 [==============================] - 8s 714us/step - loss: 0.0531 - accuracy: 0.8334 - val_loss: 0.0793 - val_accuracy: 0.7500\n",
      "Epoch 3042/5000\n",
      "11786/11786 [==============================] - 8s 721us/step - loss: 0.0532 - accuracy: 0.8336 - val_loss: 0.0789 - val_accuracy: 0.7521\n",
      "Epoch 3043/5000\n",
      "11786/11786 [==============================] - 8s 717us/step - loss: 0.0530 - accuracy: 0.8343 - val_loss: 0.0795 - val_accuracy: 0.7508\n",
      "Epoch 3044/5000\n",
      "11786/11786 [==============================] - 8s 714us/step - loss: 0.0530 - accuracy: 0.8341 - val_loss: 0.0796 - val_accuracy: 0.7519\n",
      "Epoch 3045/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0531 - accuracy: 0.8343 - val_loss: 0.0792 - val_accuracy: 0.7510\n",
      "Epoch 3046/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0530 - accuracy: 0.8342 - val_loss: 0.0802 - val_accuracy: 0.7483\n",
      "Epoch 3047/5000\n",
      "11786/11786 [==============================] - 8s 718us/step - loss: 0.0529 - accuracy: 0.8347 - val_loss: 0.0798 - val_accuracy: 0.7498\n",
      "Epoch 3048/5000\n",
      "11786/11786 [==============================] - 8s 718us/step - loss: 0.0529 - accuracy: 0.8341 - val_loss: 0.0795 - val_accuracy: 0.7503\n",
      "Epoch 3049/5000\n",
      "11786/11786 [==============================] - 8s 718us/step - loss: 0.0529 - accuracy: 0.8342 - val_loss: 0.0795 - val_accuracy: 0.7525\n",
      "Epoch 3050/5000\n",
      "11786/11786 [==============================] - 8s 717us/step - loss: 0.0531 - accuracy: 0.8342 - val_loss: 0.0800 - val_accuracy: 0.7507\n",
      "Epoch 3051/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0530 - accuracy: 0.8343 - val_loss: 0.0794 - val_accuracy: 0.7529\n",
      "Epoch 3052/5000\n",
      "11786/11786 [==============================] - 8s 715us/step - loss: 0.0530 - accuracy: 0.8343 - val_loss: 0.0797 - val_accuracy: 0.7480\n",
      "Epoch 3053/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0531 - accuracy: 0.8342 - val_loss: 0.0814 - val_accuracy: 0.7497\n",
      "Epoch 3054/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0530 - accuracy: 0.8344 - val_loss: 0.0798 - val_accuracy: 0.7523\n",
      "Epoch 3055/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0533 - accuracy: 0.8332 - val_loss: 0.0797 - val_accuracy: 0.7496\n",
      "Epoch 3056/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0532 - accuracy: 0.8337 - val_loss: 0.0794 - val_accuracy: 0.7499\n",
      "Epoch 3057/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0532 - accuracy: 0.8336 - val_loss: 0.0800 - val_accuracy: 0.7495\n",
      "Epoch 3058/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0531 - accuracy: 0.8341 - val_loss: 0.0797 - val_accuracy: 0.7502\n",
      "Epoch 3059/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0532 - accuracy: 0.8336 - val_loss: 0.0792 - val_accuracy: 0.7511\n",
      "Epoch 3060/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0532 - accuracy: 0.8333 - val_loss: 0.0785 - val_accuracy: 0.7510\n",
      "Epoch 3061/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0532 - accuracy: 0.8340 - val_loss: 0.0804 - val_accuracy: 0.7496\n",
      "Epoch 3062/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0532 - accuracy: 0.8334 - val_loss: 0.0791 - val_accuracy: 0.7527\n",
      "Epoch 3063/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0533 - accuracy: 0.8335 - val_loss: 0.0809 - val_accuracy: 0.7486\n",
      "Epoch 3064/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0531 - accuracy: 0.8339 - val_loss: 0.0803 - val_accuracy: 0.7510\n",
      "Epoch 3065/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0534 - accuracy: 0.8326 - val_loss: 0.0807 - val_accuracy: 0.7487\n",
      "Epoch 3066/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0533 - accuracy: 0.8332 - val_loss: 0.0798 - val_accuracy: 0.7497\n",
      "Epoch 3067/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0531 - accuracy: 0.8341 - val_loss: 0.0791 - val_accuracy: 0.7513\n",
      "Epoch 3068/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0531 - accuracy: 0.8338 - val_loss: 0.0794 - val_accuracy: 0.7525\n",
      "Epoch 3069/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0532 - accuracy: 0.8338 - val_loss: 0.0795 - val_accuracy: 0.7517\n",
      "Epoch 3070/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0533 - accuracy: 0.8335 - val_loss: 0.0796 - val_accuracy: 0.7501\n",
      "Epoch 3071/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0532 - accuracy: 0.8337 - val_loss: 0.0804 - val_accuracy: 0.7509\n",
      "Epoch 3072/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0532 - accuracy: 0.8338 - val_loss: 0.0792 - val_accuracy: 0.7518\n",
      "Epoch 3073/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0532 - accuracy: 0.8335 - val_loss: 0.0809 - val_accuracy: 0.7518\n",
      "Epoch 3074/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0532 - accuracy: 0.8334 - val_loss: 0.0796 - val_accuracy: 0.7525\n",
      "Epoch 3075/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0532 - accuracy: 0.8338 - val_loss: 0.0804 - val_accuracy: 0.7503\n",
      "Epoch 3076/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0533 - accuracy: 0.8335 - val_loss: 0.0797 - val_accuracy: 0.7505\n",
      "Epoch 3077/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0531 - accuracy: 0.8341 - val_loss: 0.0796 - val_accuracy: 0.7509\n",
      "Epoch 3078/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0532 - accuracy: 0.8333 - val_loss: 0.0806 - val_accuracy: 0.7509\n",
      "Epoch 3079/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0532 - accuracy: 0.8335 - val_loss: 0.0795 - val_accuracy: 0.7521\n",
      "Epoch 3080/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0532 - accuracy: 0.8339 - val_loss: 0.0796 - val_accuracy: 0.7508\n",
      "Epoch 3081/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0532 - accuracy: 0.8335 - val_loss: 0.0797 - val_accuracy: 0.7515\n",
      "Epoch 3082/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0532 - accuracy: 0.8342 - val_loss: 0.0800 - val_accuracy: 0.7508\n",
      "Epoch 3083/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0532 - accuracy: 0.8337 - val_loss: 0.0802 - val_accuracy: 0.7498\n",
      "Epoch 3084/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0534 - accuracy: 0.8333 - val_loss: 0.0794 - val_accuracy: 0.7498\n",
      "Epoch 3085/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0535 - accuracy: 0.8330 - val_loss: 0.0800 - val_accuracy: 0.7515\n",
      "Epoch 3086/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0534 - accuracy: 0.8331 - val_loss: 0.0793 - val_accuracy: 0.7490\n",
      "Epoch 3087/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0533 - accuracy: 0.8330 - val_loss: 0.0797 - val_accuracy: 0.7530\n",
      "Epoch 3088/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0533 - accuracy: 0.8334 - val_loss: 0.0808 - val_accuracy: 0.7500\n",
      "Epoch 3089/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0534 - accuracy: 0.8327 - val_loss: 0.0804 - val_accuracy: 0.7505\n",
      "Epoch 3090/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0533 - accuracy: 0.8337 - val_loss: 0.0809 - val_accuracy: 0.7499\n",
      "Epoch 3091/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0532 - accuracy: 0.8334 - val_loss: 0.0793 - val_accuracy: 0.7500\n",
      "Epoch 3092/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0533 - accuracy: 0.8334 - val_loss: 0.0802 - val_accuracy: 0.7492\n",
      "Epoch 3093/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0532 - accuracy: 0.8335 - val_loss: 0.0798 - val_accuracy: 0.7521\n",
      "Epoch 3094/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0531 - accuracy: 0.8340 - val_loss: 0.0799 - val_accuracy: 0.7484\n",
      "Epoch 3095/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0531 - accuracy: 0.8339 - val_loss: 0.0788 - val_accuracy: 0.7516\n",
      "Epoch 3096/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0530 - accuracy: 0.8341 - val_loss: 0.0787 - val_accuracy: 0.7514\n",
      "Epoch 3097/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0530 - accuracy: 0.8341 - val_loss: 0.0807 - val_accuracy: 0.7487\n",
      "Epoch 3098/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0530 - accuracy: 0.8346 - val_loss: 0.0803 - val_accuracy: 0.7509\n",
      "Epoch 3099/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0533 - accuracy: 0.8335 - val_loss: 0.0801 - val_accuracy: 0.7483\n",
      "Epoch 3100/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0532 - accuracy: 0.8338 - val_loss: 0.0815 - val_accuracy: 0.7498\n",
      "Epoch 3101/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0531 - accuracy: 0.8340 - val_loss: 0.0802 - val_accuracy: 0.7508\n",
      "Epoch 3102/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0532 - accuracy: 0.8339 - val_loss: 0.0790 - val_accuracy: 0.7518\n",
      "Epoch 3103/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0532 - accuracy: 0.8338 - val_loss: 0.0804 - val_accuracy: 0.7518\n",
      "Epoch 3104/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0534 - accuracy: 0.8336 - val_loss: 0.0809 - val_accuracy: 0.7499\n",
      "Epoch 3105/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0533 - accuracy: 0.8334 - val_loss: 0.0792 - val_accuracy: 0.7527\n",
      "Epoch 3106/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0533 - accuracy: 0.8335 - val_loss: 0.0792 - val_accuracy: 0.7511\n",
      "Epoch 3107/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0532 - accuracy: 0.8337 - val_loss: 0.0796 - val_accuracy: 0.7522\n",
      "Epoch 3108/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0530 - accuracy: 0.8341 - val_loss: 0.0800 - val_accuracy: 0.7515\n",
      "Epoch 3109/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0531 - accuracy: 0.8339 - val_loss: 0.0795 - val_accuracy: 0.7510\n",
      "Epoch 3110/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0532 - accuracy: 0.8337 - val_loss: 0.0798 - val_accuracy: 0.7510\n",
      "Epoch 3111/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0531 - accuracy: 0.8342 - val_loss: 0.0796 - val_accuracy: 0.7521\n",
      "Epoch 3112/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0534 - accuracy: 0.8334 - val_loss: 0.0798 - val_accuracy: 0.7491\n",
      "Epoch 3113/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0533 - accuracy: 0.8338 - val_loss: 0.0798 - val_accuracy: 0.7526\n",
      "Epoch 3114/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0531 - accuracy: 0.8341 - val_loss: 0.0788 - val_accuracy: 0.7522\n",
      "Epoch 3115/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0533 - accuracy: 0.8331 - val_loss: 0.0802 - val_accuracy: 0.7514\n",
      "Epoch 3116/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0534 - accuracy: 0.8334 - val_loss: 0.0795 - val_accuracy: 0.7505\n",
      "Epoch 3117/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0532 - accuracy: 0.8339 - val_loss: 0.0798 - val_accuracy: 0.7480\n",
      "Epoch 3118/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0532 - accuracy: 0.8336 - val_loss: 0.0799 - val_accuracy: 0.7500\n",
      "Epoch 3119/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0532 - accuracy: 0.8332 - val_loss: 0.0799 - val_accuracy: 0.7481\n",
      "Epoch 3120/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0534 - accuracy: 0.8328 - val_loss: 0.0794 - val_accuracy: 0.7498\n",
      "Epoch 3121/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0532 - accuracy: 0.8337 - val_loss: 0.0793 - val_accuracy: 0.7512\n",
      "Epoch 3122/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0532 - accuracy: 0.8332 - val_loss: 0.0793 - val_accuracy: 0.7536\n",
      "Epoch 3123/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0530 - accuracy: 0.8344 - val_loss: 0.0796 - val_accuracy: 0.7496\n",
      "Epoch 3124/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0532 - accuracy: 0.8330 - val_loss: 0.0790 - val_accuracy: 0.7521\n",
      "Epoch 3125/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0532 - accuracy: 0.8335 - val_loss: 0.0802 - val_accuracy: 0.7505\n",
      "Epoch 3126/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0532 - accuracy: 0.8338 - val_loss: 0.0800 - val_accuracy: 0.7500\n",
      "Epoch 3127/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0534 - accuracy: 0.8325 - val_loss: 0.0787 - val_accuracy: 0.7513\n",
      "Epoch 3128/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0532 - accuracy: 0.8332 - val_loss: 0.0784 - val_accuracy: 0.7519\n",
      "Epoch 3129/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0531 - accuracy: 0.8342 - val_loss: 0.0807 - val_accuracy: 0.7507\n",
      "Epoch 3130/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0535 - accuracy: 0.8323 - val_loss: 0.0788 - val_accuracy: 0.7514\n",
      "Epoch 3131/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0533 - accuracy: 0.8327 - val_loss: 0.0799 - val_accuracy: 0.7519\n",
      "Epoch 3132/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0530 - accuracy: 0.8340 - val_loss: 0.0800 - val_accuracy: 0.7498\n",
      "Epoch 3133/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0533 - accuracy: 0.8335 - val_loss: 0.0801 - val_accuracy: 0.7512\n",
      "Epoch 3134/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0532 - accuracy: 0.8334 - val_loss: 0.0801 - val_accuracy: 0.7487\n",
      "Epoch 3135/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0534 - accuracy: 0.8327 - val_loss: 0.0806 - val_accuracy: 0.7499\n",
      "Epoch 3136/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0532 - accuracy: 0.8334 - val_loss: 0.0799 - val_accuracy: 0.7519\n",
      "Epoch 3137/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0533 - accuracy: 0.8330 - val_loss: 0.0809 - val_accuracy: 0.7510\n",
      "Epoch 3138/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0533 - accuracy: 0.8330 - val_loss: 0.0794 - val_accuracy: 0.7514\n",
      "Epoch 3139/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0535 - accuracy: 0.8326 - val_loss: 0.0795 - val_accuracy: 0.7519\n",
      "Epoch 3140/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0531 - accuracy: 0.8338 - val_loss: 0.0791 - val_accuracy: 0.7517\n",
      "Epoch 3141/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0531 - accuracy: 0.8339 - val_loss: 0.0792 - val_accuracy: 0.7516\n",
      "Epoch 3142/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0533 - accuracy: 0.8335 - val_loss: 0.0798 - val_accuracy: 0.7502\n",
      "Epoch 3143/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0533 - accuracy: 0.8335 - val_loss: 0.0791 - val_accuracy: 0.7518\n",
      "Epoch 3144/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0533 - accuracy: 0.8330 - val_loss: 0.0811 - val_accuracy: 0.7509\n",
      "Epoch 3145/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0534 - accuracy: 0.8330 - val_loss: 0.0799 - val_accuracy: 0.7514\n",
      "Epoch 3146/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0532 - accuracy: 0.8337 - val_loss: 0.0803 - val_accuracy: 0.7528\n",
      "Epoch 3147/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0534 - accuracy: 0.8330 - val_loss: 0.0801 - val_accuracy: 0.7492\n",
      "Epoch 3148/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0535 - accuracy: 0.8324 - val_loss: 0.0798 - val_accuracy: 0.7507\n",
      "Epoch 3149/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0534 - accuracy: 0.8327 - val_loss: 0.0805 - val_accuracy: 0.7475\n",
      "Epoch 3150/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0533 - accuracy: 0.8333 - val_loss: 0.0794 - val_accuracy: 0.7483\n",
      "Epoch 3151/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0533 - accuracy: 0.8331 - val_loss: 0.0800 - val_accuracy: 0.7484\n",
      "Epoch 3152/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0534 - accuracy: 0.8331 - val_loss: 0.0797 - val_accuracy: 0.7517\n",
      "Epoch 3153/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0532 - accuracy: 0.8334 - val_loss: 0.0800 - val_accuracy: 0.7483\n",
      "Epoch 3154/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0532 - accuracy: 0.8328 - val_loss: 0.0786 - val_accuracy: 0.7512\n",
      "Epoch 3155/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0533 - accuracy: 0.8328 - val_loss: 0.0796 - val_accuracy: 0.7505\n",
      "Epoch 3156/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0533 - accuracy: 0.8331 - val_loss: 0.0799 - val_accuracy: 0.7498\n",
      "Epoch 3157/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0534 - accuracy: 0.8334 - val_loss: 0.0801 - val_accuracy: 0.7501\n",
      "Epoch 3158/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0536 - accuracy: 0.8326 - val_loss: 0.0807 - val_accuracy: 0.7484\n",
      "Epoch 3159/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0534 - accuracy: 0.8329 - val_loss: 0.0809 - val_accuracy: 0.7493\n",
      "Epoch 3160/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0535 - accuracy: 0.8327 - val_loss: 0.0796 - val_accuracy: 0.7520\n",
      "Epoch 3161/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0534 - accuracy: 0.8331 - val_loss: 0.0802 - val_accuracy: 0.7525\n",
      "Epoch 3162/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0535 - accuracy: 0.8321 - val_loss: 0.0799 - val_accuracy: 0.7505\n",
      "Epoch 3163/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0535 - accuracy: 0.8324 - val_loss: 0.0793 - val_accuracy: 0.7501\n",
      "Epoch 3164/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0535 - accuracy: 0.8327 - val_loss: 0.0795 - val_accuracy: 0.7509\n",
      "Epoch 3165/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0535 - accuracy: 0.8327 - val_loss: 0.0795 - val_accuracy: 0.7514\n",
      "Epoch 3166/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0534 - accuracy: 0.8331 - val_loss: 0.0792 - val_accuracy: 0.7492\n",
      "Epoch 3167/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0535 - accuracy: 0.8322 - val_loss: 0.0799 - val_accuracy: 0.7512\n",
      "Epoch 3168/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0535 - accuracy: 0.8327 - val_loss: 0.0804 - val_accuracy: 0.7484\n",
      "Epoch 3169/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0535 - accuracy: 0.8323 - val_loss: 0.0795 - val_accuracy: 0.7504\n",
      "Epoch 3170/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0535 - accuracy: 0.8323 - val_loss: 0.0805 - val_accuracy: 0.7480\n",
      "Epoch 3171/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0534 - accuracy: 0.8324 - val_loss: 0.0811 - val_accuracy: 0.7499\n",
      "Epoch 3172/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0533 - accuracy: 0.8330 - val_loss: 0.0796 - val_accuracy: 0.7505\n",
      "Epoch 3173/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0533 - accuracy: 0.8332 - val_loss: 0.0806 - val_accuracy: 0.7508\n",
      "Epoch 3174/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0536 - accuracy: 0.8318 - val_loss: 0.0795 - val_accuracy: 0.7484\n",
      "Epoch 3175/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0535 - accuracy: 0.8322 - val_loss: 0.0810 - val_accuracy: 0.7512\n",
      "Epoch 3176/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0537 - accuracy: 0.8318 - val_loss: 0.0792 - val_accuracy: 0.7496\n",
      "Epoch 3177/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0538 - accuracy: 0.8313 - val_loss: 0.0802 - val_accuracy: 0.7515\n",
      "Epoch 3178/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0537 - accuracy: 0.8317 - val_loss: 0.0792 - val_accuracy: 0.7500\n",
      "Epoch 3179/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0536 - accuracy: 0.8323 - val_loss: 0.0795 - val_accuracy: 0.7520\n",
      "Epoch 3180/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0534 - accuracy: 0.8326 - val_loss: 0.0796 - val_accuracy: 0.7501\n",
      "Epoch 3181/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0535 - accuracy: 0.8319 - val_loss: 0.0807 - val_accuracy: 0.7481\n",
      "Epoch 3182/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0537 - accuracy: 0.8318 - val_loss: 0.0796 - val_accuracy: 0.7507\n",
      "Epoch 3183/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0535 - accuracy: 0.8322 - val_loss: 0.0807 - val_accuracy: 0.7518\n",
      "Epoch 3184/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0533 - accuracy: 0.8328 - val_loss: 0.0791 - val_accuracy: 0.7492\n",
      "Epoch 3185/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0535 - accuracy: 0.8325 - val_loss: 0.0790 - val_accuracy: 0.7500\n",
      "Epoch 3186/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0535 - accuracy: 0.8322 - val_loss: 0.0789 - val_accuracy: 0.7514\n",
      "Epoch 3187/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0536 - accuracy: 0.8322 - val_loss: 0.0801 - val_accuracy: 0.7492\n",
      "Epoch 3188/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0534 - accuracy: 0.8326 - val_loss: 0.0798 - val_accuracy: 0.7516\n",
      "Epoch 3189/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0535 - accuracy: 0.8325 - val_loss: 0.0796 - val_accuracy: 0.7511\n",
      "Epoch 3190/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0535 - accuracy: 0.8323 - val_loss: 0.0798 - val_accuracy: 0.7496\n",
      "Epoch 3191/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0533 - accuracy: 0.8329 - val_loss: 0.0808 - val_accuracy: 0.7467\n",
      "Epoch 3192/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0534 - accuracy: 0.8327 - val_loss: 0.0795 - val_accuracy: 0.7509\n",
      "Epoch 3193/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0534 - accuracy: 0.8327 - val_loss: 0.0792 - val_accuracy: 0.7511\n",
      "Epoch 3194/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0535 - accuracy: 0.8324 - val_loss: 0.0803 - val_accuracy: 0.7504\n",
      "Epoch 3195/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0534 - accuracy: 0.8327 - val_loss: 0.0795 - val_accuracy: 0.7509\n",
      "Epoch 3196/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0534 - accuracy: 0.8328 - val_loss: 0.0797 - val_accuracy: 0.7481\n",
      "Epoch 3197/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0536 - accuracy: 0.8320 - val_loss: 0.0799 - val_accuracy: 0.7518\n",
      "Epoch 3198/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0535 - accuracy: 0.8322 - val_loss: 0.0797 - val_accuracy: 0.7518\n",
      "Epoch 3199/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0534 - accuracy: 0.8325 - val_loss: 0.0792 - val_accuracy: 0.7504\n",
      "Epoch 3200/5000\n",
      "11786/11786 [==============================] - 8s 715us/step - loss: 0.0534 - accuracy: 0.8324 - val_loss: 0.0804 - val_accuracy: 0.7506\n",
      "Epoch 3201/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0536 - accuracy: 0.8314 - val_loss: 0.0793 - val_accuracy: 0.7486\n",
      "Epoch 3202/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0537 - accuracy: 0.8313 - val_loss: 0.0805 - val_accuracy: 0.7485\n",
      "Epoch 3203/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0535 - accuracy: 0.8323 - val_loss: 0.0803 - val_accuracy: 0.7501\n",
      "Epoch 3204/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0534 - accuracy: 0.8324 - val_loss: 0.0795 - val_accuracy: 0.7504\n",
      "Epoch 3205/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0533 - accuracy: 0.8329 - val_loss: 0.0790 - val_accuracy: 0.7521\n",
      "Epoch 3206/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0535 - accuracy: 0.8320 - val_loss: 0.0809 - val_accuracy: 0.7509\n",
      "Epoch 3207/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0534 - accuracy: 0.8324 - val_loss: 0.0788 - val_accuracy: 0.7510\n",
      "Epoch 3208/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0534 - accuracy: 0.8327 - val_loss: 0.0797 - val_accuracy: 0.7505\n",
      "Epoch 3209/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0533 - accuracy: 0.8330 - val_loss: 0.0791 - val_accuracy: 0.7504\n",
      "Epoch 3210/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0533 - accuracy: 0.8331 - val_loss: 0.0801 - val_accuracy: 0.7495\n",
      "Epoch 3211/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0532 - accuracy: 0.8334 - val_loss: 0.0804 - val_accuracy: 0.7523\n",
      "Epoch 3212/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0534 - accuracy: 0.8321 - val_loss: 0.0792 - val_accuracy: 0.7507\n",
      "Epoch 3213/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0534 - accuracy: 0.8320 - val_loss: 0.0810 - val_accuracy: 0.7489\n",
      "Epoch 3214/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0534 - accuracy: 0.8320 - val_loss: 0.0796 - val_accuracy: 0.7506\n",
      "Epoch 3215/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0533 - accuracy: 0.8328 - val_loss: 0.0801 - val_accuracy: 0.7500\n",
      "Epoch 3216/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0534 - accuracy: 0.8325 - val_loss: 0.0803 - val_accuracy: 0.7514\n",
      "Epoch 3217/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0535 - accuracy: 0.8318 - val_loss: 0.0805 - val_accuracy: 0.7507\n",
      "Epoch 3218/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0534 - accuracy: 0.8322 - val_loss: 0.0808 - val_accuracy: 0.7512\n",
      "Epoch 3219/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0534 - accuracy: 0.8324 - val_loss: 0.0799 - val_accuracy: 0.7504\n",
      "Epoch 3220/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0533 - accuracy: 0.8324 - val_loss: 0.0803 - val_accuracy: 0.7495\n",
      "Epoch 3221/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0533 - accuracy: 0.8326 - val_loss: 0.0795 - val_accuracy: 0.7503\n",
      "Epoch 3222/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0534 - accuracy: 0.8323 - val_loss: 0.0811 - val_accuracy: 0.7495\n",
      "Epoch 3223/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0535 - accuracy: 0.8320 - val_loss: 0.0798 - val_accuracy: 0.7505\n",
      "Epoch 3224/5000\n",
      "11786/11786 [==============================] - 8s 716us/step - loss: 0.0534 - accuracy: 0.8326 - val_loss: 0.0793 - val_accuracy: 0.7495\n",
      "Epoch 3225/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0535 - accuracy: 0.8328 - val_loss: 0.0798 - val_accuracy: 0.7523\n",
      "Epoch 3226/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0535 - accuracy: 0.8319 - val_loss: 0.0803 - val_accuracy: 0.7489\n",
      "Epoch 3227/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0535 - accuracy: 0.8321 - val_loss: 0.0795 - val_accuracy: 0.7517\n",
      "Epoch 3228/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0536 - accuracy: 0.8321 - val_loss: 0.0794 - val_accuracy: 0.7506\n",
      "Epoch 3229/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0535 - accuracy: 0.8321 - val_loss: 0.0796 - val_accuracy: 0.7501\n",
      "Epoch 3230/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0535 - accuracy: 0.8318 - val_loss: 0.0799 - val_accuracy: 0.7477\n",
      "Epoch 3231/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0535 - accuracy: 0.8315 - val_loss: 0.0797 - val_accuracy: 0.7500\n",
      "Epoch 3232/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0537 - accuracy: 0.8317 - val_loss: 0.0798 - val_accuracy: 0.7511\n",
      "Epoch 3233/5000\n",
      "11786/11786 [==============================] - 9s 726us/step - loss: 0.0537 - accuracy: 0.8316 - val_loss: 0.0791 - val_accuracy: 0.7507\n",
      "Epoch 3234/5000\n",
      "11786/11786 [==============================] - 9s 725us/step - loss: 0.0535 - accuracy: 0.8322 - val_loss: 0.0801 - val_accuracy: 0.7496\n",
      "Epoch 3235/5000\n",
      "11786/11786 [==============================] - 9s 723us/step - loss: 0.0536 - accuracy: 0.8320 - val_loss: 0.0803 - val_accuracy: 0.7506\n",
      "Epoch 3236/5000\n",
      "11786/11786 [==============================] - 9s 722us/step - loss: 0.0536 - accuracy: 0.8322 - val_loss: 0.0810 - val_accuracy: 0.7490\n",
      "Epoch 3237/5000\n",
      "11786/11786 [==============================] - 9s 725us/step - loss: 0.0538 - accuracy: 0.8307 - val_loss: 0.0803 - val_accuracy: 0.7508\n",
      "Epoch 3238/5000\n",
      "11786/11786 [==============================] - 9s 729us/step - loss: 0.0537 - accuracy: 0.8314 - val_loss: 0.0801 - val_accuracy: 0.7493\n",
      "Epoch 3239/5000\n",
      "11786/11786 [==============================] - 9s 722us/step - loss: 0.0537 - accuracy: 0.8315 - val_loss: 0.0815 - val_accuracy: 0.7467\n",
      "Epoch 3240/5000\n",
      "11786/11786 [==============================] - 9s 734us/step - loss: 0.0536 - accuracy: 0.8318 - val_loss: 0.0795 - val_accuracy: 0.7510\n",
      "Epoch 3241/5000\n",
      "11786/11786 [==============================] - 8s 718us/step - loss: 0.0535 - accuracy: 0.8322 - val_loss: 0.0800 - val_accuracy: 0.7506\n",
      "Epoch 3242/5000\n",
      "11786/11786 [==============================] - 8s 718us/step - loss: 0.0535 - accuracy: 0.8322 - val_loss: 0.0802 - val_accuracy: 0.7483\n",
      "Epoch 3243/5000\n",
      "11786/11786 [==============================] - 9s 725us/step - loss: 0.0536 - accuracy: 0.8319 - val_loss: 0.0803 - val_accuracy: 0.7497\n",
      "Epoch 3244/5000\n",
      "11786/11786 [==============================] - 8s 719us/step - loss: 0.0536 - accuracy: 0.8319 - val_loss: 0.0802 - val_accuracy: 0.7502\n",
      "Epoch 3245/5000\n",
      "11786/11786 [==============================] - 9s 725us/step - loss: 0.0537 - accuracy: 0.8310 - val_loss: 0.0810 - val_accuracy: 0.7466\n",
      "Epoch 3246/5000\n",
      "11786/11786 [==============================] - 8s 719us/step - loss: 0.0536 - accuracy: 0.8316 - val_loss: 0.0811 - val_accuracy: 0.7476\n",
      "Epoch 3247/5000\n",
      "11786/11786 [==============================] - 9s 729us/step - loss: 0.0536 - accuracy: 0.8314 - val_loss: 0.0798 - val_accuracy: 0.7499\n",
      "Epoch 3248/5000\n",
      "11786/11786 [==============================] - 8s 721us/step - loss: 0.0537 - accuracy: 0.8316 - val_loss: 0.0796 - val_accuracy: 0.7472\n",
      "Epoch 3249/5000\n",
      "11786/11786 [==============================] - 8s 719us/step - loss: 0.0537 - accuracy: 0.8307 - val_loss: 0.0799 - val_accuracy: 0.7484\n",
      "Epoch 3250/5000\n",
      "11786/11786 [==============================] - 9s 722us/step - loss: 0.0538 - accuracy: 0.8309 - val_loss: 0.0816 - val_accuracy: 0.7487\n",
      "Epoch 3251/5000\n",
      "11786/11786 [==============================] - 8s 716us/step - loss: 0.0537 - accuracy: 0.8314 - val_loss: 0.0803 - val_accuracy: 0.7496\n",
      "Epoch 3252/5000\n",
      "11786/11786 [==============================] - 8s 719us/step - loss: 0.0536 - accuracy: 0.8316 - val_loss: 0.0787 - val_accuracy: 0.7506\n",
      "Epoch 3253/5000\n",
      "11786/11786 [==============================] - 8s 719us/step - loss: 0.0535 - accuracy: 0.8320 - val_loss: 0.0808 - val_accuracy: 0.7505\n",
      "Epoch 3254/5000\n",
      "11786/11786 [==============================] - 8s 720us/step - loss: 0.0536 - accuracy: 0.8315 - val_loss: 0.0798 - val_accuracy: 0.7513\n",
      "Epoch 3255/5000\n",
      "11786/11786 [==============================] - 8s 717us/step - loss: 0.0536 - accuracy: 0.8319 - val_loss: 0.0803 - val_accuracy: 0.7471\n",
      "Epoch 3256/5000\n",
      "11786/11786 [==============================] - 9s 723us/step - loss: 0.0536 - accuracy: 0.8315 - val_loss: 0.0796 - val_accuracy: 0.7501\n",
      "Epoch 3257/5000\n",
      "11786/11786 [==============================] - 9s 726us/step - loss: 0.0537 - accuracy: 0.8312 - val_loss: 0.0819 - val_accuracy: 0.7452\n",
      "Epoch 3258/5000\n",
      "11786/11786 [==============================] - 9s 725us/step - loss: 0.0538 - accuracy: 0.8305 - val_loss: 0.0801 - val_accuracy: 0.7492\n",
      "Epoch 3259/5000\n",
      "11786/11786 [==============================] - 9s 726us/step - loss: 0.0537 - accuracy: 0.8313 - val_loss: 0.0811 - val_accuracy: 0.7479\n",
      "Epoch 3260/5000\n",
      "11786/11786 [==============================] - 9s 722us/step - loss: 0.0538 - accuracy: 0.8304 - val_loss: 0.0806 - val_accuracy: 0.7486\n",
      "Epoch 3261/5000\n",
      "11786/11786 [==============================] - 9s 725us/step - loss: 0.0537 - accuracy: 0.8312 - val_loss: 0.0794 - val_accuracy: 0.7493\n",
      "Epoch 3262/5000\n",
      "11786/11786 [==============================] - 9s 727us/step - loss: 0.0536 - accuracy: 0.8316 - val_loss: 0.0797 - val_accuracy: 0.7495\n",
      "Epoch 3263/5000\n",
      "11786/11786 [==============================] - 8s 721us/step - loss: 0.0536 - accuracy: 0.8317 - val_loss: 0.0795 - val_accuracy: 0.7497\n",
      "Epoch 3264/5000\n",
      "11786/11786 [==============================] - 8s 718us/step - loss: 0.0537 - accuracy: 0.8311 - val_loss: 0.0804 - val_accuracy: 0.7432\n",
      "Epoch 3265/5000\n",
      "11786/11786 [==============================] - 9s 724us/step - loss: 0.0537 - accuracy: 0.8314 - val_loss: 0.0793 - val_accuracy: 0.7495\n",
      "Epoch 3266/5000\n",
      "11786/11786 [==============================] - 9s 721us/step - loss: 0.0535 - accuracy: 0.8325 - val_loss: 0.0796 - val_accuracy: 0.7498\n",
      "Epoch 3267/5000\n",
      "11786/11786 [==============================] - 9s 724us/step - loss: 0.0534 - accuracy: 0.8323 - val_loss: 0.0810 - val_accuracy: 0.7506\n",
      "Epoch 3268/5000\n",
      "11786/11786 [==============================] - 8s 719us/step - loss: 0.0536 - accuracy: 0.8315 - val_loss: 0.0802 - val_accuracy: 0.7488\n",
      "Epoch 3269/5000\n",
      "11786/11786 [==============================] - 8s 719us/step - loss: 0.0533 - accuracy: 0.8328 - val_loss: 0.0795 - val_accuracy: 0.7507\n",
      "Epoch 3270/5000\n",
      "11786/11786 [==============================] - 8s 719us/step - loss: 0.0535 - accuracy: 0.8324 - val_loss: 0.0802 - val_accuracy: 0.7496\n",
      "Epoch 3271/5000\n",
      "11786/11786 [==============================] - 8s 719us/step - loss: 0.0534 - accuracy: 0.8324 - val_loss: 0.0807 - val_accuracy: 0.7494\n",
      "Epoch 3272/5000\n",
      "11786/11786 [==============================] - 9s 725us/step - loss: 0.0535 - accuracy: 0.8325 - val_loss: 0.0792 - val_accuracy: 0.7495\n",
      "Epoch 3273/5000\n",
      "11786/11786 [==============================] - 9s 722us/step - loss: 0.0535 - accuracy: 0.8326 - val_loss: 0.0804 - val_accuracy: 0.7496\n",
      "Epoch 3274/5000\n",
      "11786/11786 [==============================] - 8s 717us/step - loss: 0.0537 - accuracy: 0.8320 - val_loss: 0.0810 - val_accuracy: 0.7497\n",
      "Epoch 3275/5000\n",
      "11786/11786 [==============================] - 9s 722us/step - loss: 0.0537 - accuracy: 0.8315 - val_loss: 0.0801 - val_accuracy: 0.7499\n",
      "Epoch 3276/5000\n",
      "11786/11786 [==============================] - 9s 722us/step - loss: 0.0537 - accuracy: 0.8317 - val_loss: 0.0803 - val_accuracy: 0.7477\n",
      "Epoch 3277/5000\n",
      "11786/11786 [==============================] - 9s 722us/step - loss: 0.0538 - accuracy: 0.8313 - val_loss: 0.0793 - val_accuracy: 0.7488\n",
      "Epoch 3278/5000\n",
      "11786/11786 [==============================] - 8s 719us/step - loss: 0.0537 - accuracy: 0.8320 - val_loss: 0.0803 - val_accuracy: 0.7491\n",
      "Epoch 3279/5000\n",
      "11786/11786 [==============================] - 9s 726us/step - loss: 0.0537 - accuracy: 0.8322 - val_loss: 0.0808 - val_accuracy: 0.7496\n",
      "Epoch 3280/5000\n",
      "11786/11786 [==============================] - 8s 717us/step - loss: 0.0538 - accuracy: 0.8315 - val_loss: 0.0801 - val_accuracy: 0.7489\n",
      "Epoch 3281/5000\n",
      "11786/11786 [==============================] - 9s 723us/step - loss: 0.0537 - accuracy: 0.8323 - val_loss: 0.0799 - val_accuracy: 0.7509\n",
      "Epoch 3282/5000\n",
      "11786/11786 [==============================] - 9s 731us/step - loss: 0.0538 - accuracy: 0.8318 - val_loss: 0.0796 - val_accuracy: 0.7505\n",
      "Epoch 3283/5000\n",
      "11786/11786 [==============================] - 9s 729us/step - loss: 0.0537 - accuracy: 0.8318 - val_loss: 0.0796 - val_accuracy: 0.7502\n",
      "Epoch 3284/5000\n",
      "11786/11786 [==============================] - 9s 732us/step - loss: 0.0539 - accuracy: 0.8310 - val_loss: 0.0801 - val_accuracy: 0.7486\n",
      "Epoch 3285/5000\n",
      "11786/11786 [==============================] - 9s 728us/step - loss: 0.0537 - accuracy: 0.8315 - val_loss: 0.0805 - val_accuracy: 0.7471\n",
      "Epoch 3286/5000\n",
      "11786/11786 [==============================] - 9s 727us/step - loss: 0.0537 - accuracy: 0.8317 - val_loss: 0.0801 - val_accuracy: 0.7509\n",
      "Epoch 3287/5000\n",
      "11786/11786 [==============================] - 9s 725us/step - loss: 0.0538 - accuracy: 0.8315 - val_loss: 0.0796 - val_accuracy: 0.7503\n",
      "Epoch 3288/5000\n",
      "11786/11786 [==============================] - 9s 722us/step - loss: 0.0537 - accuracy: 0.8322 - val_loss: 0.0800 - val_accuracy: 0.7502\n",
      "Epoch 3289/5000\n",
      "11786/11786 [==============================] - 9s 721us/step - loss: 0.0537 - accuracy: 0.8319 - val_loss: 0.0792 - val_accuracy: 0.7503\n",
      "Epoch 3290/5000\n",
      "11786/11786 [==============================] - 9s 727us/step - loss: 0.0537 - accuracy: 0.8321 - val_loss: 0.0804 - val_accuracy: 0.7476\n",
      "Epoch 3291/5000\n",
      "11786/11786 [==============================] - 8s 719us/step - loss: 0.0538 - accuracy: 0.8317 - val_loss: 0.0798 - val_accuracy: 0.7484\n",
      "Epoch 3292/5000\n",
      "11786/11786 [==============================] - 8s 721us/step - loss: 0.0537 - accuracy: 0.8316 - val_loss: 0.0813 - val_accuracy: 0.7472\n",
      "Epoch 3293/5000\n",
      "11786/11786 [==============================] - 9s 722us/step - loss: 0.0537 - accuracy: 0.8316 - val_loss: 0.0789 - val_accuracy: 0.7513\n",
      "Epoch 3294/5000\n",
      "11786/11786 [==============================] - 8s 717us/step - loss: 0.0537 - accuracy: 0.8319 - val_loss: 0.0800 - val_accuracy: 0.7508\n",
      "Epoch 3295/5000\n",
      "11786/11786 [==============================] - 8s 720us/step - loss: 0.0540 - accuracy: 0.8305 - val_loss: 0.0807 - val_accuracy: 0.7496\n",
      "Epoch 3296/5000\n",
      "11786/11786 [==============================] - 9s 722us/step - loss: 0.0537 - accuracy: 0.8317 - val_loss: 0.0792 - val_accuracy: 0.7481\n",
      "Epoch 3297/5000\n",
      "11786/11786 [==============================] - 9s 725us/step - loss: 0.0537 - accuracy: 0.8317 - val_loss: 0.0806 - val_accuracy: 0.7492\n",
      "Epoch 3298/5000\n",
      "11786/11786 [==============================] - 8s 717us/step - loss: 0.0538 - accuracy: 0.8312 - val_loss: 0.0800 - val_accuracy: 0.7514\n",
      "Epoch 3299/5000\n",
      "11786/11786 [==============================] - 8s 715us/step - loss: 0.0538 - accuracy: 0.8316 - val_loss: 0.0799 - val_accuracy: 0.7500\n",
      "Epoch 3300/5000\n",
      "11786/11786 [==============================] - 8s 716us/step - loss: 0.0539 - accuracy: 0.8314 - val_loss: 0.0808 - val_accuracy: 0.7505\n",
      "Epoch 3301/5000\n",
      "11786/11786 [==============================] - 9s 724us/step - loss: 0.0540 - accuracy: 0.8312 - val_loss: 0.0811 - val_accuracy: 0.7484\n",
      "Epoch 3302/5000\n",
      "11786/11786 [==============================] - 8s 721us/step - loss: 0.0540 - accuracy: 0.8310 - val_loss: 0.0809 - val_accuracy: 0.7474\n",
      "Epoch 3303/5000\n",
      "11786/11786 [==============================] - 8s 714us/step - loss: 0.0539 - accuracy: 0.8313 - val_loss: 0.0812 - val_accuracy: 0.7461\n",
      "Epoch 3304/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0538 - accuracy: 0.8311 - val_loss: 0.0791 - val_accuracy: 0.7486\n",
      "Epoch 3305/5000\n",
      "11786/11786 [==============================] - 8s 717us/step - loss: 0.0537 - accuracy: 0.8313 - val_loss: 0.0787 - val_accuracy: 0.7505\n",
      "Epoch 3306/5000\n",
      "11786/11786 [==============================] - 8s 720us/step - loss: 0.0538 - accuracy: 0.8312 - val_loss: 0.0809 - val_accuracy: 0.7469\n",
      "Epoch 3307/5000\n",
      "11786/11786 [==============================] - 9s 724us/step - loss: 0.0539 - accuracy: 0.8307 - val_loss: 0.0808 - val_accuracy: 0.7465\n",
      "Epoch 3308/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0540 - accuracy: 0.8309 - val_loss: 0.0799 - val_accuracy: 0.7487\n",
      "Epoch 3309/5000\n",
      "11786/11786 [==============================] - 9s 723us/step - loss: 0.0537 - accuracy: 0.8314 - val_loss: 0.0801 - val_accuracy: 0.7505\n",
      "Epoch 3310/5000\n",
      "11786/11786 [==============================] - 9s 722us/step - loss: 0.0540 - accuracy: 0.8313 - val_loss: 0.0811 - val_accuracy: 0.7487\n",
      "Epoch 3311/5000\n",
      "11786/11786 [==============================] - 9s 722us/step - loss: 0.0540 - accuracy: 0.8310 - val_loss: 0.0803 - val_accuracy: 0.7504\n",
      "Epoch 3312/5000\n",
      "11786/11786 [==============================] - 9s 722us/step - loss: 0.0540 - accuracy: 0.8307 - val_loss: 0.0810 - val_accuracy: 0.7470\n",
      "Epoch 3313/5000\n",
      "11786/11786 [==============================] - 8s 715us/step - loss: 0.0540 - accuracy: 0.8309 - val_loss: 0.0806 - val_accuracy: 0.7469\n",
      "Epoch 3314/5000\n",
      "11786/11786 [==============================] - 9s 729us/step - loss: 0.0540 - accuracy: 0.8306 - val_loss: 0.0813 - val_accuracy: 0.7495\n",
      "Epoch 3315/5000\n",
      "11786/11786 [==============================] - 9s 724us/step - loss: 0.0541 - accuracy: 0.8301 - val_loss: 0.0804 - val_accuracy: 0.7506\n",
      "Epoch 3316/5000\n",
      "11786/11786 [==============================] - 8s 721us/step - loss: 0.0541 - accuracy: 0.8304 - val_loss: 0.0799 - val_accuracy: 0.7503\n",
      "Epoch 3317/5000\n",
      "11786/11786 [==============================] - 9s 729us/step - loss: 0.0539 - accuracy: 0.8310 - val_loss: 0.0806 - val_accuracy: 0.7493\n",
      "Epoch 3318/5000\n",
      "11786/11786 [==============================] - 8s 718us/step - loss: 0.0541 - accuracy: 0.8300 - val_loss: 0.0800 - val_accuracy: 0.7478\n",
      "Epoch 3319/5000\n",
      "11786/11786 [==============================] - 9s 726us/step - loss: 0.0540 - accuracy: 0.8304 - val_loss: 0.0805 - val_accuracy: 0.7468\n",
      "Epoch 3320/5000\n",
      "11786/11786 [==============================] - 9s 729us/step - loss: 0.0541 - accuracy: 0.8304 - val_loss: 0.0813 - val_accuracy: 0.7465\n",
      "Epoch 3321/5000\n",
      "11786/11786 [==============================] - 8s 720us/step - loss: 0.0539 - accuracy: 0.8311 - val_loss: 0.0796 - val_accuracy: 0.7489\n",
      "Epoch 3322/5000\n",
      "11786/11786 [==============================] - 9s 724us/step - loss: 0.0538 - accuracy: 0.8313 - val_loss: 0.0806 - val_accuracy: 0.7478\n",
      "Epoch 3323/5000\n",
      "11786/11786 [==============================] - 9s 723us/step - loss: 0.0541 - accuracy: 0.8308 - val_loss: 0.0806 - val_accuracy: 0.7465\n",
      "Epoch 3324/5000\n",
      "11786/11786 [==============================] - 9s 727us/step - loss: 0.0540 - accuracy: 0.8310 - val_loss: 0.0803 - val_accuracy: 0.7481\n",
      "Epoch 3325/5000\n",
      "11786/11786 [==============================] - 9s 722us/step - loss: 0.0542 - accuracy: 0.8302 - val_loss: 0.0810 - val_accuracy: 0.7507\n",
      "Epoch 3326/5000\n",
      "11786/11786 [==============================] - 9s 724us/step - loss: 0.0541 - accuracy: 0.8305 - val_loss: 0.0796 - val_accuracy: 0.7489\n",
      "Epoch 3327/5000\n",
      "11786/11786 [==============================] - 9s 722us/step - loss: 0.0539 - accuracy: 0.8311 - val_loss: 0.0810 - val_accuracy: 0.7492\n",
      "Epoch 3328/5000\n",
      "11786/11786 [==============================] - 9s 725us/step - loss: 0.0540 - accuracy: 0.8307 - val_loss: 0.0808 - val_accuracy: 0.7492\n",
      "Epoch 3329/5000\n",
      "11786/11786 [==============================] - 8s 719us/step - loss: 0.0538 - accuracy: 0.8315 - val_loss: 0.0794 - val_accuracy: 0.7479\n",
      "Epoch 3330/5000\n",
      "11786/11786 [==============================] - 9s 722us/step - loss: 0.0539 - accuracy: 0.8312 - val_loss: 0.0794 - val_accuracy: 0.7505\n",
      "Epoch 3331/5000\n",
      "11786/11786 [==============================] - 8s 718us/step - loss: 0.0539 - accuracy: 0.8307 - val_loss: 0.0812 - val_accuracy: 0.7477\n",
      "Epoch 3332/5000\n",
      "11786/11786 [==============================] - 8s 721us/step - loss: 0.0539 - accuracy: 0.8310 - val_loss: 0.0798 - val_accuracy: 0.7499\n",
      "Epoch 3333/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0539 - accuracy: 0.8312 - val_loss: 0.0807 - val_accuracy: 0.7477\n",
      "Epoch 3334/5000\n",
      "11786/11786 [==============================] - 8s 720us/step - loss: 0.0538 - accuracy: 0.8318 - val_loss: 0.0812 - val_accuracy: 0.7501\n",
      "Epoch 3335/5000\n",
      "11786/11786 [==============================] - 8s 718us/step - loss: 0.0538 - accuracy: 0.8310 - val_loss: 0.0799 - val_accuracy: 0.7502\n",
      "Epoch 3336/5000\n",
      "11786/11786 [==============================] - 8s 716us/step - loss: 0.0539 - accuracy: 0.8313 - val_loss: 0.0803 - val_accuracy: 0.7494\n",
      "Epoch 3337/5000\n",
      "11786/11786 [==============================] - 9s 724us/step - loss: 0.0538 - accuracy: 0.8313 - val_loss: 0.0799 - val_accuracy: 0.7493\n",
      "Epoch 3338/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0540 - accuracy: 0.8309 - val_loss: 0.0802 - val_accuracy: 0.7489\n",
      "Epoch 3339/5000\n",
      "11786/11786 [==============================] - 9s 721us/step - loss: 0.0540 - accuracy: 0.8310 - val_loss: 0.0801 - val_accuracy: 0.7508\n",
      "Epoch 3340/5000\n",
      "11786/11786 [==============================] - 8s 720us/step - loss: 0.0539 - accuracy: 0.8315 - val_loss: 0.0806 - val_accuracy: 0.7492\n",
      "Epoch 3341/5000\n",
      "11786/11786 [==============================] - 9s 734us/step - loss: 0.0542 - accuracy: 0.8305 - val_loss: 0.0807 - val_accuracy: 0.7501\n",
      "Epoch 3342/5000\n",
      "11786/11786 [==============================] - 9s 723us/step - loss: 0.0541 - accuracy: 0.8302 - val_loss: 0.0807 - val_accuracy: 0.7454\n",
      "Epoch 3343/5000\n",
      "11786/11786 [==============================] - 8s 718us/step - loss: 0.0542 - accuracy: 0.8300 - val_loss: 0.0807 - val_accuracy: 0.7480\n",
      "Epoch 3344/5000\n",
      "11786/11786 [==============================] - 8s 720us/step - loss: 0.0541 - accuracy: 0.8304 - val_loss: 0.0796 - val_accuracy: 0.7505\n",
      "Epoch 3345/5000\n",
      "11786/11786 [==============================] - 9s 723us/step - loss: 0.0540 - accuracy: 0.8308 - val_loss: 0.0815 - val_accuracy: 0.7487\n",
      "Epoch 3346/5000\n",
      "11786/11786 [==============================] - 8s 717us/step - loss: 0.0540 - accuracy: 0.8308 - val_loss: 0.0802 - val_accuracy: 0.7504\n",
      "Epoch 3347/5000\n",
      "11786/11786 [==============================] - 9s 721us/step - loss: 0.0542 - accuracy: 0.8304 - val_loss: 0.0794 - val_accuracy: 0.7470\n",
      "Epoch 3348/5000\n",
      "11786/11786 [==============================] - 8s 720us/step - loss: 0.0543 - accuracy: 0.8298 - val_loss: 0.0802 - val_accuracy: 0.7506\n",
      "Epoch 3349/5000\n",
      "11786/11786 [==============================] - 8s 721us/step - loss: 0.0539 - accuracy: 0.8312 - val_loss: 0.0797 - val_accuracy: 0.7512\n",
      "Epoch 3350/5000\n",
      "11786/11786 [==============================] - 8s 721us/step - loss: 0.0539 - accuracy: 0.8314 - val_loss: 0.0801 - val_accuracy: 0.7494\n",
      "Epoch 3351/5000\n",
      "11786/11786 [==============================] - 9s 723us/step - loss: 0.0539 - accuracy: 0.8311 - val_loss: 0.0810 - val_accuracy: 0.7478\n",
      "Epoch 3352/5000\n",
      "11786/11786 [==============================] - 9s 723us/step - loss: 0.0540 - accuracy: 0.8308 - val_loss: 0.0806 - val_accuracy: 0.7481\n",
      "Epoch 3353/5000\n",
      "11786/11786 [==============================] - 8s 720us/step - loss: 0.0541 - accuracy: 0.8310 - val_loss: 0.0796 - val_accuracy: 0.7499\n",
      "Epoch 3354/5000\n",
      "11786/11786 [==============================] - 8s 718us/step - loss: 0.0539 - accuracy: 0.8312 - val_loss: 0.0798 - val_accuracy: 0.7492\n",
      "Epoch 3355/5000\n",
      "11786/11786 [==============================] - 9s 724us/step - loss: 0.0540 - accuracy: 0.8308 - val_loss: 0.0797 - val_accuracy: 0.7509\n",
      "Epoch 3356/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0539 - accuracy: 0.8311 - val_loss: 0.0801 - val_accuracy: 0.7495\n",
      "Epoch 3357/5000\n",
      "11786/11786 [==============================] - 8s 718us/step - loss: 0.0539 - accuracy: 0.8310 - val_loss: 0.0807 - val_accuracy: 0.7481\n",
      "Epoch 3358/5000\n",
      "11786/11786 [==============================] - 9s 723us/step - loss: 0.0539 - accuracy: 0.8313 - val_loss: 0.0804 - val_accuracy: 0.7493\n",
      "Epoch 3359/5000\n",
      "11786/11786 [==============================] - 8s 721us/step - loss: 0.0540 - accuracy: 0.8304 - val_loss: 0.0799 - val_accuracy: 0.7500\n",
      "Epoch 3360/5000\n",
      "11786/11786 [==============================] - 9s 729us/step - loss: 0.0539 - accuracy: 0.8310 - val_loss: 0.0802 - val_accuracy: 0.7484\n",
      "Epoch 3361/5000\n",
      "11786/11786 [==============================] - 9s 724us/step - loss: 0.0538 - accuracy: 0.8313 - val_loss: 0.0794 - val_accuracy: 0.7510\n",
      "Epoch 3362/5000\n",
      "11786/11786 [==============================] - 9s 727us/step - loss: 0.0540 - accuracy: 0.8309 - val_loss: 0.0796 - val_accuracy: 0.7485\n",
      "Epoch 3363/5000\n",
      "11786/11786 [==============================] - 8s 720us/step - loss: 0.0538 - accuracy: 0.8314 - val_loss: 0.0804 - val_accuracy: 0.7495\n",
      "Epoch 3364/5000\n",
      "11786/11786 [==============================] - 8s 715us/step - loss: 0.0539 - accuracy: 0.8310 - val_loss: 0.0797 - val_accuracy: 0.7500\n",
      "Epoch 3365/5000\n",
      "11786/11786 [==============================] - 8s 717us/step - loss: 0.0540 - accuracy: 0.8313 - val_loss: 0.0807 - val_accuracy: 0.7482\n",
      "Epoch 3366/5000\n",
      "11786/11786 [==============================] - 9s 727us/step - loss: 0.0540 - accuracy: 0.8313 - val_loss: 0.0807 - val_accuracy: 0.7486\n",
      "Epoch 3367/5000\n",
      "11786/11786 [==============================] - 8s 720us/step - loss: 0.0539 - accuracy: 0.8316 - val_loss: 0.0798 - val_accuracy: 0.7501\n",
      "Epoch 3368/5000\n",
      "11786/11786 [==============================] - 8s 720us/step - loss: 0.0539 - accuracy: 0.8312 - val_loss: 0.0805 - val_accuracy: 0.7489\n",
      "Epoch 3369/5000\n",
      "11786/11786 [==============================] - 8s 719us/step - loss: 0.0538 - accuracy: 0.8318 - val_loss: 0.0806 - val_accuracy: 0.7491\n",
      "Epoch 3370/5000\n",
      "11786/11786 [==============================] - 9s 722us/step - loss: 0.0538 - accuracy: 0.8318 - val_loss: 0.0798 - val_accuracy: 0.7508\n",
      "Epoch 3371/5000\n",
      "11786/11786 [==============================] - 8s 721us/step - loss: 0.0539 - accuracy: 0.8316 - val_loss: 0.0807 - val_accuracy: 0.7502\n",
      "Epoch 3372/5000\n",
      "11786/11786 [==============================] - 9s 722us/step - loss: 0.0538 - accuracy: 0.8316 - val_loss: 0.0806 - val_accuracy: 0.7511\n",
      "Epoch 3373/5000\n",
      "11786/11786 [==============================] - 8s 720us/step - loss: 0.0538 - accuracy: 0.8316 - val_loss: 0.0808 - val_accuracy: 0.7470\n",
      "Epoch 3374/5000\n",
      "11786/11786 [==============================] - 9s 723us/step - loss: 0.0540 - accuracy: 0.8306 - val_loss: 0.0799 - val_accuracy: 0.7508\n",
      "Epoch 3375/5000\n",
      "11786/11786 [==============================] - 9s 725us/step - loss: 0.0539 - accuracy: 0.8308 - val_loss: 0.0806 - val_accuracy: 0.7476\n",
      "Epoch 3376/5000\n",
      "11786/11786 [==============================] - 9s 725us/step - loss: 0.0538 - accuracy: 0.8310 - val_loss: 0.0800 - val_accuracy: 0.7489\n",
      "Epoch 3377/5000\n",
      "11786/11786 [==============================] - 8s 721us/step - loss: 0.0538 - accuracy: 0.8313 - val_loss: 0.0793 - val_accuracy: 0.7511\n",
      "Epoch 3378/5000\n",
      "11786/11786 [==============================] - 9s 727us/step - loss: 0.0539 - accuracy: 0.8312 - val_loss: 0.0813 - val_accuracy: 0.7500\n",
      "Epoch 3379/5000\n",
      "11786/11786 [==============================] - 9s 724us/step - loss: 0.0540 - accuracy: 0.8304 - val_loss: 0.0802 - val_accuracy: 0.7461\n",
      "Epoch 3380/5000\n",
      "11786/11786 [==============================] - 9s 724us/step - loss: 0.0539 - accuracy: 0.8314 - val_loss: 0.0798 - val_accuracy: 0.7499\n",
      "Epoch 3381/5000\n",
      "11786/11786 [==============================] - 9s 728us/step - loss: 0.0539 - accuracy: 0.8306 - val_loss: 0.0806 - val_accuracy: 0.7492\n",
      "Epoch 3382/5000\n",
      "11786/11786 [==============================] - 8s 716us/step - loss: 0.0538 - accuracy: 0.8311 - val_loss: 0.0796 - val_accuracy: 0.7505\n",
      "Epoch 3383/5000\n",
      "11786/11786 [==============================] - 8s 720us/step - loss: 0.0542 - accuracy: 0.8299 - val_loss: 0.0812 - val_accuracy: 0.7475\n",
      "Epoch 3384/5000\n",
      "11786/11786 [==============================] - 8s 718us/step - loss: 0.0538 - accuracy: 0.8310 - val_loss: 0.0800 - val_accuracy: 0.7502\n",
      "Epoch 3385/5000\n",
      "11786/11786 [==============================] - 8s 718us/step - loss: 0.0539 - accuracy: 0.8309 - val_loss: 0.0813 - val_accuracy: 0.7463\n",
      "Epoch 3386/5000\n",
      "11786/11786 [==============================] - 8s 716us/step - loss: 0.0539 - accuracy: 0.8312 - val_loss: 0.0801 - val_accuracy: 0.7494\n",
      "Epoch 3387/5000\n",
      "11786/11786 [==============================] - 9s 723us/step - loss: 0.0539 - accuracy: 0.8308 - val_loss: 0.0814 - val_accuracy: 0.7473\n",
      "Epoch 3388/5000\n",
      "11786/11786 [==============================] - 8s 718us/step - loss: 0.0540 - accuracy: 0.8306 - val_loss: 0.0793 - val_accuracy: 0.7489\n",
      "Epoch 3389/5000\n",
      "11786/11786 [==============================] - 8s 720us/step - loss: 0.0541 - accuracy: 0.8302 - val_loss: 0.0808 - val_accuracy: 0.7487\n",
      "Epoch 3390/5000\n",
      "11786/11786 [==============================] - 8s 716us/step - loss: 0.0540 - accuracy: 0.8303 - val_loss: 0.0803 - val_accuracy: 0.7497\n",
      "Epoch 3391/5000\n",
      "11786/11786 [==============================] - 8s 721us/step - loss: 0.0540 - accuracy: 0.8303 - val_loss: 0.0803 - val_accuracy: 0.7516\n",
      "Epoch 3392/5000\n",
      "11786/11786 [==============================] - 8s 718us/step - loss: 0.0540 - accuracy: 0.8305 - val_loss: 0.0813 - val_accuracy: 0.7494\n",
      "Epoch 3393/5000\n",
      "11786/11786 [==============================] - 8s 719us/step - loss: 0.0539 - accuracy: 0.8311 - val_loss: 0.0815 - val_accuracy: 0.7509\n",
      "Epoch 3394/5000\n",
      "11786/11786 [==============================] - 8s 720us/step - loss: 0.0540 - accuracy: 0.8311 - val_loss: 0.0803 - val_accuracy: 0.7487\n",
      "Epoch 3395/5000\n",
      "11786/11786 [==============================] - 9s 724us/step - loss: 0.0541 - accuracy: 0.8305 - val_loss: 0.0796 - val_accuracy: 0.7512\n",
      "Epoch 3396/5000\n",
      "11786/11786 [==============================] - 8s 717us/step - loss: 0.0542 - accuracy: 0.8305 - val_loss: 0.0802 - val_accuracy: 0.7479\n",
      "Epoch 3397/5000\n",
      "11786/11786 [==============================] - 8s 720us/step - loss: 0.0540 - accuracy: 0.8308 - val_loss: 0.0811 - val_accuracy: 0.7490\n",
      "Epoch 3398/5000\n",
      "11786/11786 [==============================] - 8s 715us/step - loss: 0.0541 - accuracy: 0.8305 - val_loss: 0.0812 - val_accuracy: 0.7490\n",
      "Epoch 3399/5000\n",
      "11786/11786 [==============================] - 9s 728us/step - loss: 0.0541 - accuracy: 0.8304 - val_loss: 0.0814 - val_accuracy: 0.7467\n",
      "Epoch 3400/5000\n",
      "11786/11786 [==============================] - 9s 723us/step - loss: 0.0541 - accuracy: 0.8305 - val_loss: 0.0802 - val_accuracy: 0.7505\n",
      "Epoch 3401/5000\n",
      "11786/11786 [==============================] - 9s 723us/step - loss: 0.0540 - accuracy: 0.8310 - val_loss: 0.0803 - val_accuracy: 0.7492\n",
      "Epoch 3402/5000\n",
      "11786/11786 [==============================] - 8s 718us/step - loss: 0.0541 - accuracy: 0.8306 - val_loss: 0.0808 - val_accuracy: 0.7506\n",
      "Epoch 3403/5000\n",
      "11786/11786 [==============================] - 9s 726us/step - loss: 0.0538 - accuracy: 0.8314 - val_loss: 0.0806 - val_accuracy: 0.7503\n",
      "Epoch 3404/5000\n",
      "11786/11786 [==============================] - 9s 724us/step - loss: 0.0539 - accuracy: 0.8312 - val_loss: 0.0805 - val_accuracy: 0.7486\n",
      "Epoch 3405/5000\n",
      "11786/11786 [==============================] - 8s 721us/step - loss: 0.0539 - accuracy: 0.8314 - val_loss: 0.0803 - val_accuracy: 0.7495\n",
      "Epoch 3406/5000\n",
      "11786/11786 [==============================] - 9s 728us/step - loss: 0.0538 - accuracy: 0.8317 - val_loss: 0.0798 - val_accuracy: 0.7497\n",
      "Epoch 3407/5000\n",
      "11786/11786 [==============================] - 8s 720us/step - loss: 0.0539 - accuracy: 0.8312 - val_loss: 0.0800 - val_accuracy: 0.7520\n",
      "Epoch 3408/5000\n",
      "11786/11786 [==============================] - 8s 717us/step - loss: 0.0539 - accuracy: 0.8313 - val_loss: 0.0801 - val_accuracy: 0.7503\n",
      "Epoch 3409/5000\n",
      "11786/11786 [==============================] - 8s 715us/step - loss: 0.0536 - accuracy: 0.8323 - val_loss: 0.0806 - val_accuracy: 0.7479\n",
      "Epoch 3410/5000\n",
      "11786/11786 [==============================] - 9s 722us/step - loss: 0.0539 - accuracy: 0.8311 - val_loss: 0.0806 - val_accuracy: 0.7491\n",
      "Epoch 3411/5000\n",
      "11786/11786 [==============================] - 8s 719us/step - loss: 0.0539 - accuracy: 0.8313 - val_loss: 0.0801 - val_accuracy: 0.7502\n",
      "Epoch 3412/5000\n",
      "11786/11786 [==============================] - 9s 729us/step - loss: 0.0540 - accuracy: 0.8311 - val_loss: 0.0796 - val_accuracy: 0.7521\n",
      "Epoch 3413/5000\n",
      "11786/11786 [==============================] - 8s 716us/step - loss: 0.0539 - accuracy: 0.8316 - val_loss: 0.0820 - val_accuracy: 0.7482\n",
      "Epoch 3414/5000\n",
      "11786/11786 [==============================] - 9s 723us/step - loss: 0.0540 - accuracy: 0.8311 - val_loss: 0.0798 - val_accuracy: 0.7478\n",
      "Epoch 3415/5000\n",
      "11786/11786 [==============================] - 9s 729us/step - loss: 0.0538 - accuracy: 0.8316 - val_loss: 0.0795 - val_accuracy: 0.7509\n",
      "Epoch 3416/5000\n",
      "11786/11786 [==============================] - 8s 714us/step - loss: 0.0539 - accuracy: 0.8316 - val_loss: 0.0801 - val_accuracy: 0.7481\n",
      "Epoch 3417/5000\n",
      "11786/11786 [==============================] - 8s 714us/step - loss: 0.0539 - accuracy: 0.8313 - val_loss: 0.0802 - val_accuracy: 0.7495\n",
      "Epoch 3418/5000\n",
      "11786/11786 [==============================] - 9s 724us/step - loss: 0.0538 - accuracy: 0.8319 - val_loss: 0.0805 - val_accuracy: 0.7491\n",
      "Epoch 3419/5000\n",
      "11786/11786 [==============================] - 9s 723us/step - loss: 0.0540 - accuracy: 0.8310 - val_loss: 0.0810 - val_accuracy: 0.7500\n",
      "Epoch 3420/5000\n",
      "11786/11786 [==============================] - 9s 726us/step - loss: 0.0537 - accuracy: 0.8319 - val_loss: 0.0803 - val_accuracy: 0.7504\n",
      "Epoch 3421/5000\n",
      "11786/11786 [==============================] - 8s 719us/step - loss: 0.0539 - accuracy: 0.8314 - val_loss: 0.0811 - val_accuracy: 0.7470\n",
      "Epoch 3422/5000\n",
      "11786/11786 [==============================] - 9s 722us/step - loss: 0.0540 - accuracy: 0.8304 - val_loss: 0.0798 - val_accuracy: 0.7505\n",
      "Epoch 3423/5000\n",
      "11786/11786 [==============================] - 8s 714us/step - loss: 0.0539 - accuracy: 0.8317 - val_loss: 0.0811 - val_accuracy: 0.7507\n",
      "Epoch 3424/5000\n",
      "11786/11786 [==============================] - 8s 717us/step - loss: 0.0538 - accuracy: 0.8317 - val_loss: 0.0802 - val_accuracy: 0.7488\n",
      "Epoch 3425/5000\n",
      "11786/11786 [==============================] - 9s 727us/step - loss: 0.0539 - accuracy: 0.8316 - val_loss: 0.0800 - val_accuracy: 0.7498\n",
      "Epoch 3426/5000\n",
      "11786/11786 [==============================] - 8s 720us/step - loss: 0.0539 - accuracy: 0.8313 - val_loss: 0.0804 - val_accuracy: 0.7514\n",
      "Epoch 3427/5000\n",
      "11786/11786 [==============================] - 9s 723us/step - loss: 0.0538 - accuracy: 0.8318 - val_loss: 0.0813 - val_accuracy: 0.7488\n",
      "Epoch 3428/5000\n",
      "11786/11786 [==============================] - 9s 727us/step - loss: 0.0541 - accuracy: 0.8309 - val_loss: 0.0801 - val_accuracy: 0.7498\n",
      "Epoch 3429/5000\n",
      "11786/11786 [==============================] - 8s 719us/step - loss: 0.0540 - accuracy: 0.8308 - val_loss: 0.0796 - val_accuracy: 0.7503\n",
      "Epoch 3430/5000\n",
      "11786/11786 [==============================] - 8s 719us/step - loss: 0.0540 - accuracy: 0.8306 - val_loss: 0.0804 - val_accuracy: 0.7499\n",
      "Epoch 3431/5000\n",
      "11786/11786 [==============================] - 9s 722us/step - loss: 0.0539 - accuracy: 0.8313 - val_loss: 0.0811 - val_accuracy: 0.7446\n",
      "Epoch 3432/5000\n",
      "11786/11786 [==============================] - 9s 728us/step - loss: 0.0539 - accuracy: 0.8309 - val_loss: 0.0805 - val_accuracy: 0.7497\n",
      "Epoch 3433/5000\n",
      "11786/11786 [==============================] - 8s 719us/step - loss: 0.0538 - accuracy: 0.8315 - val_loss: 0.0786 - val_accuracy: 0.7508\n",
      "Epoch 3434/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0539 - accuracy: 0.8307 - val_loss: 0.0797 - val_accuracy: 0.7480\n",
      "Epoch 3435/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0541 - accuracy: 0.8306 - val_loss: 0.0811 - val_accuracy: 0.7487\n",
      "Epoch 3436/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0541 - accuracy: 0.8303 - val_loss: 0.0793 - val_accuracy: 0.7495\n",
      "Epoch 3437/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0540 - accuracy: 0.8304 - val_loss: 0.0795 - val_accuracy: 0.7506\n",
      "Epoch 3438/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0540 - accuracy: 0.8306 - val_loss: 0.0798 - val_accuracy: 0.7511\n",
      "Epoch 3439/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0540 - accuracy: 0.8307 - val_loss: 0.0801 - val_accuracy: 0.7502\n",
      "Epoch 3440/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0537 - accuracy: 0.8318 - val_loss: 0.0793 - val_accuracy: 0.7509\n",
      "Epoch 3441/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0539 - accuracy: 0.8308 - val_loss: 0.0789 - val_accuracy: 0.7497\n",
      "Epoch 3442/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0540 - accuracy: 0.8306 - val_loss: 0.0810 - val_accuracy: 0.7499\n",
      "Epoch 3443/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0539 - accuracy: 0.8309 - val_loss: 0.0802 - val_accuracy: 0.7496\n",
      "Epoch 3444/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0538 - accuracy: 0.8309 - val_loss: 0.0798 - val_accuracy: 0.7503\n",
      "Epoch 3445/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0540 - accuracy: 0.8304 - val_loss: 0.0802 - val_accuracy: 0.7512\n",
      "Epoch 3446/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0538 - accuracy: 0.8313 - val_loss: 0.0805 - val_accuracy: 0.7501\n",
      "Epoch 3447/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0540 - accuracy: 0.8309 - val_loss: 0.0798 - val_accuracy: 0.7494\n",
      "Epoch 3448/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0539 - accuracy: 0.8311 - val_loss: 0.0803 - val_accuracy: 0.7506\n",
      "Epoch 3449/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0539 - accuracy: 0.8311 - val_loss: 0.0793 - val_accuracy: 0.7479\n",
      "Epoch 3450/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0540 - accuracy: 0.8308 - val_loss: 0.0794 - val_accuracy: 0.7478\n",
      "Epoch 3451/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0541 - accuracy: 0.8303 - val_loss: 0.0813 - val_accuracy: 0.7477\n",
      "Epoch 3452/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0540 - accuracy: 0.8307 - val_loss: 0.0809 - val_accuracy: 0.7499\n",
      "Epoch 3453/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0539 - accuracy: 0.8311 - val_loss: 0.0797 - val_accuracy: 0.7505\n",
      "Epoch 3454/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0539 - accuracy: 0.8310 - val_loss: 0.0797 - val_accuracy: 0.7491\n",
      "Epoch 3455/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0541 - accuracy: 0.8305 - val_loss: 0.0798 - val_accuracy: 0.7474\n",
      "Epoch 3456/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0541 - accuracy: 0.8301 - val_loss: 0.0808 - val_accuracy: 0.7480\n",
      "Epoch 3457/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0540 - accuracy: 0.8303 - val_loss: 0.0809 - val_accuracy: 0.7487\n",
      "Epoch 3458/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0541 - accuracy: 0.8302 - val_loss: 0.0800 - val_accuracy: 0.7512\n",
      "Epoch 3459/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0543 - accuracy: 0.8296 - val_loss: 0.0795 - val_accuracy: 0.7488\n",
      "Epoch 3460/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0542 - accuracy: 0.8297 - val_loss: 0.0803 - val_accuracy: 0.7478\n",
      "Epoch 3461/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0540 - accuracy: 0.8303 - val_loss: 0.0803 - val_accuracy: 0.7495\n",
      "Epoch 3462/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0539 - accuracy: 0.8311 - val_loss: 0.0807 - val_accuracy: 0.7506\n",
      "Epoch 3463/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0539 - accuracy: 0.8312 - val_loss: 0.0802 - val_accuracy: 0.7518\n",
      "Epoch 3464/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0541 - accuracy: 0.8306 - val_loss: 0.0804 - val_accuracy: 0.7512\n",
      "Epoch 3465/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0539 - accuracy: 0.8314 - val_loss: 0.0798 - val_accuracy: 0.7487\n",
      "Epoch 3466/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0538 - accuracy: 0.8315 - val_loss: 0.0811 - val_accuracy: 0.7487\n",
      "Epoch 3467/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0540 - accuracy: 0.8310 - val_loss: 0.0807 - val_accuracy: 0.7490\n",
      "Epoch 3468/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0540 - accuracy: 0.8313 - val_loss: 0.0815 - val_accuracy: 0.7487\n",
      "Epoch 3469/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0541 - accuracy: 0.8305 - val_loss: 0.0798 - val_accuracy: 0.7487\n",
      "Epoch 3470/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0538 - accuracy: 0.8317 - val_loss: 0.0804 - val_accuracy: 0.7478\n",
      "Epoch 3471/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0539 - accuracy: 0.8309 - val_loss: 0.0808 - val_accuracy: 0.7501\n",
      "Epoch 3472/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0539 - accuracy: 0.8313 - val_loss: 0.0810 - val_accuracy: 0.7498\n",
      "Epoch 3473/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0541 - accuracy: 0.8311 - val_loss: 0.0802 - val_accuracy: 0.7492\n",
      "Epoch 3474/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0538 - accuracy: 0.8316 - val_loss: 0.0807 - val_accuracy: 0.7486\n",
      "Epoch 3475/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0539 - accuracy: 0.8312 - val_loss: 0.0794 - val_accuracy: 0.7493\n",
      "Epoch 3476/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0540 - accuracy: 0.8308 - val_loss: 0.0813 - val_accuracy: 0.7498\n",
      "Epoch 3477/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0540 - accuracy: 0.8309 - val_loss: 0.0807 - val_accuracy: 0.7495\n",
      "Epoch 3478/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0541 - accuracy: 0.8305 - val_loss: 0.0798 - val_accuracy: 0.7495\n",
      "Epoch 3479/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0540 - accuracy: 0.8309 - val_loss: 0.0801 - val_accuracy: 0.7464\n",
      "Epoch 3480/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0540 - accuracy: 0.8309 - val_loss: 0.0806 - val_accuracy: 0.7503\n",
      "Epoch 3481/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0540 - accuracy: 0.8308 - val_loss: 0.0802 - val_accuracy: 0.7494\n",
      "Epoch 3482/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0540 - accuracy: 0.8306 - val_loss: 0.0801 - val_accuracy: 0.7483\n",
      "Epoch 3483/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0541 - accuracy: 0.8303 - val_loss: 0.0799 - val_accuracy: 0.7500\n",
      "Epoch 3484/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0542 - accuracy: 0.8296 - val_loss: 0.0803 - val_accuracy: 0.7496\n",
      "Epoch 3485/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0543 - accuracy: 0.8292 - val_loss: 0.0800 - val_accuracy: 0.7469\n",
      "Epoch 3486/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0542 - accuracy: 0.8297 - val_loss: 0.0814 - val_accuracy: 0.7493\n",
      "Epoch 3487/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0542 - accuracy: 0.8298 - val_loss: 0.0810 - val_accuracy: 0.7440\n",
      "Epoch 3488/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0543 - accuracy: 0.8294 - val_loss: 0.0816 - val_accuracy: 0.7467\n",
      "Epoch 3489/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0544 - accuracy: 0.8295 - val_loss: 0.0797 - val_accuracy: 0.7486\n",
      "Epoch 3490/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0543 - accuracy: 0.8296 - val_loss: 0.0795 - val_accuracy: 0.7500\n",
      "Epoch 3491/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0542 - accuracy: 0.8295 - val_loss: 0.0804 - val_accuracy: 0.7480\n",
      "Epoch 3492/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0542 - accuracy: 0.8297 - val_loss: 0.0808 - val_accuracy: 0.7494\n",
      "Epoch 3493/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0542 - accuracy: 0.8296 - val_loss: 0.0804 - val_accuracy: 0.7479\n",
      "Epoch 3494/5000\n",
      "11786/11786 [==============================] - 9s 721us/step - loss: 0.0541 - accuracy: 0.8298 - val_loss: 0.0801 - val_accuracy: 0.7477\n",
      "Epoch 3495/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0541 - accuracy: 0.8298 - val_loss: 0.0811 - val_accuracy: 0.7499\n",
      "Epoch 3496/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0540 - accuracy: 0.8305 - val_loss: 0.0813 - val_accuracy: 0.7495\n",
      "Epoch 3497/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0541 - accuracy: 0.8305 - val_loss: 0.0806 - val_accuracy: 0.7483\n",
      "Epoch 3498/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0541 - accuracy: 0.8308 - val_loss: 0.0804 - val_accuracy: 0.7502\n",
      "Epoch 3499/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0541 - accuracy: 0.8306 - val_loss: 0.0807 - val_accuracy: 0.7515\n",
      "Epoch 3500/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0541 - accuracy: 0.8302 - val_loss: 0.0806 - val_accuracy: 0.7497\n",
      "Epoch 3501/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0541 - accuracy: 0.8304 - val_loss: 0.0806 - val_accuracy: 0.7481\n",
      "Epoch 3502/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0541 - accuracy: 0.8308 - val_loss: 0.0794 - val_accuracy: 0.7500\n",
      "Epoch 3503/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0540 - accuracy: 0.8311 - val_loss: 0.0798 - val_accuracy: 0.7496\n",
      "Epoch 3504/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0540 - accuracy: 0.8311 - val_loss: 0.0804 - val_accuracy: 0.7481\n",
      "Epoch 3505/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0541 - accuracy: 0.8305 - val_loss: 0.0799 - val_accuracy: 0.7496\n",
      "Epoch 3506/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0537 - accuracy: 0.8320 - val_loss: 0.0814 - val_accuracy: 0.7477\n",
      "Epoch 3507/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0542 - accuracy: 0.8298 - val_loss: 0.0810 - val_accuracy: 0.7498\n",
      "Epoch 3508/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0541 - accuracy: 0.8300 - val_loss: 0.0805 - val_accuracy: 0.7479\n",
      "Epoch 3509/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0541 - accuracy: 0.8303 - val_loss: 0.0807 - val_accuracy: 0.7483\n",
      "Epoch 3510/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0541 - accuracy: 0.8301 - val_loss: 0.0808 - val_accuracy: 0.7470\n",
      "Epoch 3511/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0539 - accuracy: 0.8313 - val_loss: 0.0803 - val_accuracy: 0.7510\n",
      "Epoch 3512/5000\n",
      "11786/11786 [==============================] - 9s 734us/step - loss: 0.0539 - accuracy: 0.8312 - val_loss: 0.0798 - val_accuracy: 0.7476\n",
      "Epoch 3513/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0540 - accuracy: 0.8310 - val_loss: 0.0808 - val_accuracy: 0.7476\n",
      "Epoch 3514/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0541 - accuracy: 0.8307 - val_loss: 0.0798 - val_accuracy: 0.7487\n",
      "Epoch 3515/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0542 - accuracy: 0.8299 - val_loss: 0.0804 - val_accuracy: 0.7482\n",
      "Epoch 3516/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0542 - accuracy: 0.8301 - val_loss: 0.0800 - val_accuracy: 0.7495\n",
      "Epoch 3517/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0540 - accuracy: 0.8307 - val_loss: 0.0813 - val_accuracy: 0.7489\n",
      "Epoch 3518/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0543 - accuracy: 0.8300 - val_loss: 0.0805 - val_accuracy: 0.7483\n",
      "Epoch 3519/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0543 - accuracy: 0.8297 - val_loss: 0.0802 - val_accuracy: 0.7483\n",
      "Epoch 3520/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0543 - accuracy: 0.8290 - val_loss: 0.0795 - val_accuracy: 0.7496\n",
      "Epoch 3521/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0543 - accuracy: 0.8294 - val_loss: 0.0801 - val_accuracy: 0.7472\n",
      "Epoch 3522/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0544 - accuracy: 0.8288 - val_loss: 0.0807 - val_accuracy: 0.7473\n",
      "Epoch 3523/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0544 - accuracy: 0.8287 - val_loss: 0.0804 - val_accuracy: 0.7477\n",
      "Epoch 3524/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0544 - accuracy: 0.8292 - val_loss: 0.0807 - val_accuracy: 0.7479\n",
      "Epoch 3525/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0544 - accuracy: 0.8290 - val_loss: 0.0809 - val_accuracy: 0.7448\n",
      "Epoch 3526/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0543 - accuracy: 0.8295 - val_loss: 0.0802 - val_accuracy: 0.7487\n",
      "Epoch 3527/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0542 - accuracy: 0.8298 - val_loss: 0.0815 - val_accuracy: 0.7457\n",
      "Epoch 3528/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0542 - accuracy: 0.8298 - val_loss: 0.0801 - val_accuracy: 0.7506\n",
      "Epoch 3529/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0542 - accuracy: 0.8302 - val_loss: 0.0819 - val_accuracy: 0.7485\n",
      "Epoch 3530/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0542 - accuracy: 0.8297 - val_loss: 0.0814 - val_accuracy: 0.7446\n",
      "Epoch 3531/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0542 - accuracy: 0.8299 - val_loss: 0.0809 - val_accuracy: 0.7462\n",
      "Epoch 3532/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0542 - accuracy: 0.8304 - val_loss: 0.0809 - val_accuracy: 0.7483\n",
      "Epoch 3533/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0542 - accuracy: 0.8305 - val_loss: 0.0806 - val_accuracy: 0.7479\n",
      "Epoch 3534/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0543 - accuracy: 0.8299 - val_loss: 0.0809 - val_accuracy: 0.7468\n",
      "Epoch 3535/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0542 - accuracy: 0.8302 - val_loss: 0.0798 - val_accuracy: 0.7497\n",
      "Epoch 3536/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0543 - accuracy: 0.8303 - val_loss: 0.0798 - val_accuracy: 0.7473\n",
      "Epoch 3537/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0541 - accuracy: 0.8305 - val_loss: 0.0819 - val_accuracy: 0.7474\n",
      "Epoch 3538/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0544 - accuracy: 0.8299 - val_loss: 0.0807 - val_accuracy: 0.7481\n",
      "Epoch 3539/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0542 - accuracy: 0.8303 - val_loss: 0.0800 - val_accuracy: 0.7484\n",
      "Epoch 3540/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0542 - accuracy: 0.8303 - val_loss: 0.0801 - val_accuracy: 0.7480\n",
      "Epoch 3541/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0543 - accuracy: 0.8303 - val_loss: 0.0814 - val_accuracy: 0.7481\n",
      "Epoch 3542/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0541 - accuracy: 0.8308 - val_loss: 0.0815 - val_accuracy: 0.7483\n",
      "Epoch 3543/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0545 - accuracy: 0.8293 - val_loss: 0.0803 - val_accuracy: 0.7474\n",
      "Epoch 3544/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0545 - accuracy: 0.8287 - val_loss: 0.0811 - val_accuracy: 0.7485\n",
      "Epoch 3545/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0544 - accuracy: 0.8296 - val_loss: 0.0805 - val_accuracy: 0.7486\n",
      "Epoch 3546/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0543 - accuracy: 0.8300 - val_loss: 0.0791 - val_accuracy: 0.7495\n",
      "Epoch 3547/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0542 - accuracy: 0.8307 - val_loss: 0.0810 - val_accuracy: 0.7496\n",
      "Epoch 3548/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0543 - accuracy: 0.8300 - val_loss: 0.0796 - val_accuracy: 0.7503\n",
      "Epoch 3549/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0544 - accuracy: 0.8297 - val_loss: 0.0801 - val_accuracy: 0.7489\n",
      "Epoch 3550/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0543 - accuracy: 0.8302 - val_loss: 0.0799 - val_accuracy: 0.7485\n",
      "Epoch 3551/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0542 - accuracy: 0.8300 - val_loss: 0.0811 - val_accuracy: 0.7458\n",
      "Epoch 3552/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0544 - accuracy: 0.8293 - val_loss: 0.0807 - val_accuracy: 0.7488\n",
      "Epoch 3553/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0544 - accuracy: 0.8303 - val_loss: 0.0797 - val_accuracy: 0.7484\n",
      "Epoch 3554/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0542 - accuracy: 0.8303 - val_loss: 0.0809 - val_accuracy: 0.7481\n",
      "Epoch 3555/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0542 - accuracy: 0.8300 - val_loss: 0.0809 - val_accuracy: 0.7489\n",
      "Epoch 3556/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0542 - accuracy: 0.8310 - val_loss: 0.0812 - val_accuracy: 0.7495\n",
      "Epoch 3557/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0542 - accuracy: 0.8309 - val_loss: 0.0812 - val_accuracy: 0.7502\n",
      "Epoch 3558/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0543 - accuracy: 0.8304 - val_loss: 0.0809 - val_accuracy: 0.7487\n",
      "Epoch 3559/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0541 - accuracy: 0.8308 - val_loss: 0.0794 - val_accuracy: 0.7499\n",
      "Epoch 3560/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0541 - accuracy: 0.8313 - val_loss: 0.0809 - val_accuracy: 0.7486\n",
      "Epoch 3561/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0542 - accuracy: 0.8306 - val_loss: 0.0811 - val_accuracy: 0.7488\n",
      "Epoch 3562/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0542 - accuracy: 0.8308 - val_loss: 0.0827 - val_accuracy: 0.7475\n",
      "Epoch 3563/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0542 - accuracy: 0.8302 - val_loss: 0.0804 - val_accuracy: 0.7481\n",
      "Epoch 3564/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0542 - accuracy: 0.8308 - val_loss: 0.0805 - val_accuracy: 0.7471\n",
      "Epoch 3565/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0542 - accuracy: 0.8309 - val_loss: 0.0799 - val_accuracy: 0.7499\n",
      "Epoch 3566/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0543 - accuracy: 0.8302 - val_loss: 0.0816 - val_accuracy: 0.7477\n",
      "Epoch 3567/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0543 - accuracy: 0.8300 - val_loss: 0.0792 - val_accuracy: 0.7484\n",
      "Epoch 3568/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0543 - accuracy: 0.8302 - val_loss: 0.0808 - val_accuracy: 0.7471\n",
      "Epoch 3569/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0544 - accuracy: 0.8296 - val_loss: 0.0808 - val_accuracy: 0.7489\n",
      "Epoch 3570/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0543 - accuracy: 0.8301 - val_loss: 0.0806 - val_accuracy: 0.7472\n",
      "Epoch 3571/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0541 - accuracy: 0.8307 - val_loss: 0.0808 - val_accuracy: 0.7503\n",
      "Epoch 3572/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0541 - accuracy: 0.8306 - val_loss: 0.0801 - val_accuracy: 0.7494\n",
      "Epoch 3573/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0541 - accuracy: 0.8311 - val_loss: 0.0811 - val_accuracy: 0.7483\n",
      "Epoch 3574/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0542 - accuracy: 0.8305 - val_loss: 0.0801 - val_accuracy: 0.7496\n",
      "Epoch 3575/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0543 - accuracy: 0.8306 - val_loss: 0.0796 - val_accuracy: 0.7480\n",
      "Epoch 3576/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0543 - accuracy: 0.8300 - val_loss: 0.0794 - val_accuracy: 0.7498\n",
      "Epoch 3577/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0543 - accuracy: 0.8302 - val_loss: 0.0806 - val_accuracy: 0.7482\n",
      "Epoch 3578/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0543 - accuracy: 0.8299 - val_loss: 0.0804 - val_accuracy: 0.7484\n",
      "Epoch 3579/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0544 - accuracy: 0.8294 - val_loss: 0.0800 - val_accuracy: 0.7488\n",
      "Epoch 3580/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0542 - accuracy: 0.8298 - val_loss: 0.0810 - val_accuracy: 0.7480\n",
      "Epoch 3581/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0543 - accuracy: 0.8299 - val_loss: 0.0811 - val_accuracy: 0.7497\n",
      "Epoch 3582/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0543 - accuracy: 0.8307 - val_loss: 0.0808 - val_accuracy: 0.7487\n",
      "Epoch 3583/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0544 - accuracy: 0.8302 - val_loss: 0.0798 - val_accuracy: 0.7492\n",
      "Epoch 3584/5000\n",
      "11786/11786 [==============================] - 8s 720us/step - loss: 0.0543 - accuracy: 0.8302 - val_loss: 0.0801 - val_accuracy: 0.7482\n",
      "Epoch 3585/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0544 - accuracy: 0.8298 - val_loss: 0.0821 - val_accuracy: 0.7450\n",
      "Epoch 3586/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0544 - accuracy: 0.8293 - val_loss: 0.0817 - val_accuracy: 0.7469\n",
      "Epoch 3587/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0545 - accuracy: 0.8294 - val_loss: 0.0809 - val_accuracy: 0.7466\n",
      "Epoch 3588/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0545 - accuracy: 0.8293 - val_loss: 0.0804 - val_accuracy: 0.7488\n",
      "Epoch 3589/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0544 - accuracy: 0.8295 - val_loss: 0.0807 - val_accuracy: 0.7490\n",
      "Epoch 3590/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0545 - accuracy: 0.8291 - val_loss: 0.0800 - val_accuracy: 0.7485\n",
      "Epoch 3591/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0546 - accuracy: 0.8286 - val_loss: 0.0816 - val_accuracy: 0.7479\n",
      "Epoch 3592/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0546 - accuracy: 0.8289 - val_loss: 0.0804 - val_accuracy: 0.7487\n",
      "Epoch 3593/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0544 - accuracy: 0.8294 - val_loss: 0.0805 - val_accuracy: 0.7482\n",
      "Epoch 3594/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0544 - accuracy: 0.8298 - val_loss: 0.0797 - val_accuracy: 0.7483\n",
      "Epoch 3595/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0545 - accuracy: 0.8295 - val_loss: 0.0810 - val_accuracy: 0.7487\n",
      "Epoch 3596/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0545 - accuracy: 0.8291 - val_loss: 0.0817 - val_accuracy: 0.7460\n",
      "Epoch 3597/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0545 - accuracy: 0.8289 - val_loss: 0.0806 - val_accuracy: 0.7484\n",
      "Epoch 3598/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0544 - accuracy: 0.8296 - val_loss: 0.0799 - val_accuracy: 0.7506\n",
      "Epoch 3599/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0544 - accuracy: 0.8294 - val_loss: 0.0806 - val_accuracy: 0.7498\n",
      "Epoch 3600/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0541 - accuracy: 0.8303 - val_loss: 0.0804 - val_accuracy: 0.7495\n",
      "Epoch 3601/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0542 - accuracy: 0.8306 - val_loss: 0.0799 - val_accuracy: 0.7480\n",
      "Epoch 3602/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0543 - accuracy: 0.8296 - val_loss: 0.0810 - val_accuracy: 0.7467\n",
      "Epoch 3603/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0544 - accuracy: 0.8293 - val_loss: 0.0809 - val_accuracy: 0.7481\n",
      "Epoch 3604/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0543 - accuracy: 0.8300 - val_loss: 0.0803 - val_accuracy: 0.7497\n",
      "Epoch 3605/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0542 - accuracy: 0.8304 - val_loss: 0.0806 - val_accuracy: 0.7512\n",
      "Epoch 3606/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0542 - accuracy: 0.8304 - val_loss: 0.0804 - val_accuracy: 0.7507\n",
      "Epoch 3607/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0542 - accuracy: 0.8305 - val_loss: 0.0797 - val_accuracy: 0.7464\n",
      "Epoch 3608/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0542 - accuracy: 0.8300 - val_loss: 0.0800 - val_accuracy: 0.7484\n",
      "Epoch 3609/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0543 - accuracy: 0.8297 - val_loss: 0.0803 - val_accuracy: 0.7477\n",
      "Epoch 3610/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0544 - accuracy: 0.8297 - val_loss: 0.0794 - val_accuracy: 0.7498\n",
      "Epoch 3611/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0541 - accuracy: 0.8308 - val_loss: 0.0799 - val_accuracy: 0.7493\n",
      "Epoch 3612/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0542 - accuracy: 0.8302 - val_loss: 0.0806 - val_accuracy: 0.7473\n",
      "Epoch 3613/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0541 - accuracy: 0.8310 - val_loss: 0.0798 - val_accuracy: 0.7503\n",
      "Epoch 3614/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0542 - accuracy: 0.8309 - val_loss: 0.0801 - val_accuracy: 0.7459\n",
      "Epoch 3615/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0541 - accuracy: 0.8314 - val_loss: 0.0802 - val_accuracy: 0.7503\n",
      "Epoch 3616/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0543 - accuracy: 0.8303 - val_loss: 0.0802 - val_accuracy: 0.7500\n",
      "Epoch 3617/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0544 - accuracy: 0.8300 - val_loss: 0.0797 - val_accuracy: 0.7495\n",
      "Epoch 3618/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0543 - accuracy: 0.8303 - val_loss: 0.0804 - val_accuracy: 0.7461\n",
      "Epoch 3619/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0543 - accuracy: 0.8308 - val_loss: 0.0811 - val_accuracy: 0.7461\n",
      "Epoch 3620/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0543 - accuracy: 0.8301 - val_loss: 0.0798 - val_accuracy: 0.7488\n",
      "Epoch 3621/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0545 - accuracy: 0.8297 - val_loss: 0.0809 - val_accuracy: 0.7482\n",
      "Epoch 3622/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0543 - accuracy: 0.8295 - val_loss: 0.0805 - val_accuracy: 0.7488\n",
      "Epoch 3623/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0543 - accuracy: 0.8303 - val_loss: 0.0803 - val_accuracy: 0.7482\n",
      "Epoch 3624/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0542 - accuracy: 0.8302 - val_loss: 0.0797 - val_accuracy: 0.7489\n",
      "Epoch 3625/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0542 - accuracy: 0.8307 - val_loss: 0.0799 - val_accuracy: 0.7490\n",
      "Epoch 3626/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0543 - accuracy: 0.8305 - val_loss: 0.0811 - val_accuracy: 0.7470\n",
      "Epoch 3627/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0543 - accuracy: 0.8300 - val_loss: 0.0804 - val_accuracy: 0.7484\n",
      "Epoch 3628/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0544 - accuracy: 0.8295 - val_loss: 0.0803 - val_accuracy: 0.7488\n",
      "Epoch 3629/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0542 - accuracy: 0.8306 - val_loss: 0.0798 - val_accuracy: 0.7483\n",
      "Epoch 3630/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0543 - accuracy: 0.8299 - val_loss: 0.0812 - val_accuracy: 0.7487\n",
      "Epoch 3631/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0542 - accuracy: 0.8302 - val_loss: 0.0794 - val_accuracy: 0.7504\n",
      "Epoch 3632/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0542 - accuracy: 0.8303 - val_loss: 0.0808 - val_accuracy: 0.7480\n",
      "Epoch 3633/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0542 - accuracy: 0.8304 - val_loss: 0.0804 - val_accuracy: 0.7498\n",
      "Epoch 3634/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0542 - accuracy: 0.8303 - val_loss: 0.0807 - val_accuracy: 0.7481\n",
      "Epoch 3635/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0545 - accuracy: 0.8289 - val_loss: 0.0809 - val_accuracy: 0.7480\n",
      "Epoch 3636/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0545 - accuracy: 0.8293 - val_loss: 0.0806 - val_accuracy: 0.7478\n",
      "Epoch 3637/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0543 - accuracy: 0.8293 - val_loss: 0.0802 - val_accuracy: 0.7480\n",
      "Epoch 3638/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0543 - accuracy: 0.8298 - val_loss: 0.0808 - val_accuracy: 0.7489\n",
      "Epoch 3639/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0543 - accuracy: 0.8299 - val_loss: 0.0820 - val_accuracy: 0.7481\n",
      "Epoch 3640/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0544 - accuracy: 0.8293 - val_loss: 0.0810 - val_accuracy: 0.7490\n",
      "Epoch 3641/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0541 - accuracy: 0.8305 - val_loss: 0.0805 - val_accuracy: 0.7488\n",
      "Epoch 3642/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0540 - accuracy: 0.8303 - val_loss: 0.0811 - val_accuracy: 0.7483\n",
      "Epoch 3643/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0541 - accuracy: 0.8304 - val_loss: 0.0804 - val_accuracy: 0.7487\n",
      "Epoch 3644/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0543 - accuracy: 0.8296 - val_loss: 0.0803 - val_accuracy: 0.7490\n",
      "Epoch 3645/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0543 - accuracy: 0.8297 - val_loss: 0.0803 - val_accuracy: 0.7491\n",
      "Epoch 3646/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0543 - accuracy: 0.8296 - val_loss: 0.0799 - val_accuracy: 0.7493\n",
      "Epoch 3647/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0542 - accuracy: 0.8300 - val_loss: 0.0800 - val_accuracy: 0.7495\n",
      "Epoch 3648/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0543 - accuracy: 0.8298 - val_loss: 0.0812 - val_accuracy: 0.7486\n",
      "Epoch 3649/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0543 - accuracy: 0.8301 - val_loss: 0.0792 - val_accuracy: 0.7497\n",
      "Epoch 3650/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0542 - accuracy: 0.8304 - val_loss: 0.0789 - val_accuracy: 0.7497\n",
      "Epoch 3651/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0542 - accuracy: 0.8301 - val_loss: 0.0795 - val_accuracy: 0.7486\n",
      "Epoch 3652/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0545 - accuracy: 0.8295 - val_loss: 0.0810 - val_accuracy: 0.7486\n",
      "Epoch 3653/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0545 - accuracy: 0.8289 - val_loss: 0.0808 - val_accuracy: 0.7483\n",
      "Epoch 3654/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0544 - accuracy: 0.8293 - val_loss: 0.0807 - val_accuracy: 0.7490\n",
      "Epoch 3655/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0545 - accuracy: 0.8294 - val_loss: 0.0797 - val_accuracy: 0.7487\n",
      "Epoch 3656/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0545 - accuracy: 0.8290 - val_loss: 0.0805 - val_accuracy: 0.7491\n",
      "Epoch 3657/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0543 - accuracy: 0.8303 - val_loss: 0.0797 - val_accuracy: 0.7505\n",
      "Epoch 3658/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0543 - accuracy: 0.8302 - val_loss: 0.0807 - val_accuracy: 0.7501\n",
      "Epoch 3659/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0542 - accuracy: 0.8301 - val_loss: 0.0797 - val_accuracy: 0.7506\n",
      "Epoch 3660/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0541 - accuracy: 0.8307 - val_loss: 0.0808 - val_accuracy: 0.7493\n",
      "Epoch 3661/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0543 - accuracy: 0.8297 - val_loss: 0.0810 - val_accuracy: 0.7479\n",
      "Epoch 3662/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0543 - accuracy: 0.8297 - val_loss: 0.0807 - val_accuracy: 0.7469\n",
      "Epoch 3663/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0544 - accuracy: 0.8292 - val_loss: 0.0799 - val_accuracy: 0.7481\n",
      "Epoch 3664/5000\n",
      "11786/11786 [==============================] - 8s 716us/step - loss: 0.0543 - accuracy: 0.8296 - val_loss: 0.0808 - val_accuracy: 0.7452\n",
      "Epoch 3665/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0544 - accuracy: 0.8292 - val_loss: 0.0817 - val_accuracy: 0.7448\n",
      "Epoch 3666/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0545 - accuracy: 0.8283 - val_loss: 0.0819 - val_accuracy: 0.7478\n",
      "Epoch 3667/5000\n",
      "11786/11786 [==============================] - 8s 717us/step - loss: 0.0544 - accuracy: 0.8294 - val_loss: 0.0819 - val_accuracy: 0.7482\n",
      "Epoch 3668/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0545 - accuracy: 0.8292 - val_loss: 0.0805 - val_accuracy: 0.7456\n",
      "Epoch 3669/5000\n",
      "11786/11786 [==============================] - 8s 714us/step - loss: 0.0542 - accuracy: 0.8303 - val_loss: 0.0796 - val_accuracy: 0.7487\n",
      "Epoch 3670/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0543 - accuracy: 0.8291 - val_loss: 0.0800 - val_accuracy: 0.7493\n",
      "Epoch 3671/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0543 - accuracy: 0.8290 - val_loss: 0.0806 - val_accuracy: 0.7485\n",
      "Epoch 3672/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0544 - accuracy: 0.8293 - val_loss: 0.0797 - val_accuracy: 0.7458\n",
      "Epoch 3673/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0543 - accuracy: 0.8297 - val_loss: 0.0809 - val_accuracy: 0.7483\n",
      "Epoch 3674/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0544 - accuracy: 0.8292 - val_loss: 0.0816 - val_accuracy: 0.7474\n",
      "Epoch 3675/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0544 - accuracy: 0.8294 - val_loss: 0.0811 - val_accuracy: 0.7460\n",
      "Epoch 3676/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0543 - accuracy: 0.8294 - val_loss: 0.0802 - val_accuracy: 0.7496\n",
      "Epoch 3677/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0543 - accuracy: 0.8296 - val_loss: 0.0808 - val_accuracy: 0.7474\n",
      "Epoch 3678/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0543 - accuracy: 0.8298 - val_loss: 0.0812 - val_accuracy: 0.7482\n",
      "Epoch 3679/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0543 - accuracy: 0.8297 - val_loss: 0.0805 - val_accuracy: 0.7483\n",
      "Epoch 3680/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0544 - accuracy: 0.8292 - val_loss: 0.0807 - val_accuracy: 0.7472\n",
      "Epoch 3681/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0544 - accuracy: 0.8294 - val_loss: 0.0810 - val_accuracy: 0.7458\n",
      "Epoch 3682/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0543 - accuracy: 0.8297 - val_loss: 0.0807 - val_accuracy: 0.7488\n",
      "Epoch 3683/5000\n",
      "11786/11786 [==============================] - 8s 715us/step - loss: 0.0545 - accuracy: 0.8290 - val_loss: 0.0804 - val_accuracy: 0.7481\n",
      "Epoch 3684/5000\n",
      "11786/11786 [==============================] - 8s 715us/step - loss: 0.0545 - accuracy: 0.8286 - val_loss: 0.0809 - val_accuracy: 0.7466\n",
      "Epoch 3685/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0544 - accuracy: 0.8292 - val_loss: 0.0817 - val_accuracy: 0.7450\n",
      "Epoch 3686/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0544 - accuracy: 0.8296 - val_loss: 0.0804 - val_accuracy: 0.7472\n",
      "Epoch 3687/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0546 - accuracy: 0.8280 - val_loss: 0.0808 - val_accuracy: 0.7475\n",
      "Epoch 3688/5000\n",
      "11786/11786 [==============================] - 8s 715us/step - loss: 0.0545 - accuracy: 0.8285 - val_loss: 0.0809 - val_accuracy: 0.7488\n",
      "Epoch 3689/5000\n",
      "11786/11786 [==============================] - 8s 715us/step - loss: 0.0544 - accuracy: 0.8290 - val_loss: 0.0809 - val_accuracy: 0.7470\n",
      "Epoch 3690/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0545 - accuracy: 0.8289 - val_loss: 0.0802 - val_accuracy: 0.7482\n",
      "Epoch 3691/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0544 - accuracy: 0.8291 - val_loss: 0.0811 - val_accuracy: 0.7458\n",
      "Epoch 3692/5000\n",
      "11786/11786 [==============================] - 8s 715us/step - loss: 0.0546 - accuracy: 0.8286 - val_loss: 0.0801 - val_accuracy: 0.7491\n",
      "Epoch 3693/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0545 - accuracy: 0.8289 - val_loss: 0.0803 - val_accuracy: 0.7465\n",
      "Epoch 3694/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0546 - accuracy: 0.8286 - val_loss: 0.0811 - val_accuracy: 0.7460\n",
      "Epoch 3695/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0546 - accuracy: 0.8281 - val_loss: 0.0806 - val_accuracy: 0.7464\n",
      "Epoch 3696/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0545 - accuracy: 0.8282 - val_loss: 0.0802 - val_accuracy: 0.7475\n",
      "Epoch 3697/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0546 - accuracy: 0.8280 - val_loss: 0.0807 - val_accuracy: 0.7457\n",
      "Epoch 3698/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0546 - accuracy: 0.8279 - val_loss: 0.0798 - val_accuracy: 0.7472\n",
      "Epoch 3699/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0546 - accuracy: 0.8284 - val_loss: 0.0809 - val_accuracy: 0.7468\n",
      "Epoch 3700/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0544 - accuracy: 0.8285 - val_loss: 0.0808 - val_accuracy: 0.7467\n",
      "Epoch 3701/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0546 - accuracy: 0.8282 - val_loss: 0.0811 - val_accuracy: 0.7472\n",
      "Epoch 3702/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0546 - accuracy: 0.8284 - val_loss: 0.0822 - val_accuracy: 0.7456\n",
      "Epoch 3703/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0544 - accuracy: 0.8288 - val_loss: 0.0809 - val_accuracy: 0.7480\n",
      "Epoch 3704/5000\n",
      "11786/11786 [==============================] - 8s 714us/step - loss: 0.0544 - accuracy: 0.8286 - val_loss: 0.0810 - val_accuracy: 0.7467\n",
      "Epoch 3705/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0545 - accuracy: 0.8286 - val_loss: 0.0804 - val_accuracy: 0.7465\n",
      "Epoch 3706/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0544 - accuracy: 0.8286 - val_loss: 0.0824 - val_accuracy: 0.7460\n",
      "Epoch 3707/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0544 - accuracy: 0.8289 - val_loss: 0.0801 - val_accuracy: 0.7495\n",
      "Epoch 3708/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0545 - accuracy: 0.8286 - val_loss: 0.0811 - val_accuracy: 0.7474\n",
      "Epoch 3709/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0545 - accuracy: 0.8280 - val_loss: 0.0805 - val_accuracy: 0.7462\n",
      "Epoch 3710/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0545 - accuracy: 0.8282 - val_loss: 0.0802 - val_accuracy: 0.7465\n",
      "Epoch 3711/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0544 - accuracy: 0.8284 - val_loss: 0.0811 - val_accuracy: 0.7474\n",
      "Epoch 3712/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0544 - accuracy: 0.8284 - val_loss: 0.0798 - val_accuracy: 0.7480\n",
      "Epoch 3713/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0543 - accuracy: 0.8286 - val_loss: 0.0805 - val_accuracy: 0.7460\n",
      "Epoch 3714/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0545 - accuracy: 0.8286 - val_loss: 0.0796 - val_accuracy: 0.7481\n",
      "Epoch 3715/5000\n",
      "11786/11786 [==============================] - 8s 716us/step - loss: 0.0542 - accuracy: 0.8294 - val_loss: 0.0814 - val_accuracy: 0.7474\n",
      "Epoch 3716/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0543 - accuracy: 0.8294 - val_loss: 0.0805 - val_accuracy: 0.7463\n",
      "Epoch 3717/5000\n",
      "11786/11786 [==============================] - 9s 725us/step - loss: 0.0545 - accuracy: 0.8285 - val_loss: 0.0802 - val_accuracy: 0.7484\n",
      "Epoch 3718/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0544 - accuracy: 0.8286 - val_loss: 0.0804 - val_accuracy: 0.7462\n",
      "Epoch 3719/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0544 - accuracy: 0.8290 - val_loss: 0.0807 - val_accuracy: 0.7485\n",
      "Epoch 3720/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0544 - accuracy: 0.8283 - val_loss: 0.0820 - val_accuracy: 0.7454\n",
      "Epoch 3721/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0546 - accuracy: 0.8279 - val_loss: 0.0794 - val_accuracy: 0.7486\n",
      "Epoch 3722/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0544 - accuracy: 0.8286 - val_loss: 0.0802 - val_accuracy: 0.7476\n",
      "Epoch 3723/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0544 - accuracy: 0.8291 - val_loss: 0.0809 - val_accuracy: 0.7474\n",
      "Epoch 3724/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0547 - accuracy: 0.8273 - val_loss: 0.0800 - val_accuracy: 0.7474\n",
      "Epoch 3725/5000\n",
      "11786/11786 [==============================] - 8s 720us/step - loss: 0.0546 - accuracy: 0.8276 - val_loss: 0.0807 - val_accuracy: 0.7445\n",
      "Epoch 3726/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0546 - accuracy: 0.8278 - val_loss: 0.0810 - val_accuracy: 0.7483\n",
      "Epoch 3727/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0547 - accuracy: 0.8277 - val_loss: 0.0798 - val_accuracy: 0.7473\n",
      "Epoch 3728/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0545 - accuracy: 0.8283 - val_loss: 0.0806 - val_accuracy: 0.7478\n",
      "Epoch 3729/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0545 - accuracy: 0.8284 - val_loss: 0.0803 - val_accuracy: 0.7474\n",
      "Epoch 3730/5000\n",
      "11786/11786 [==============================] - 8s 714us/step - loss: 0.0547 - accuracy: 0.8280 - val_loss: 0.0805 - val_accuracy: 0.7478\n",
      "Epoch 3731/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0546 - accuracy: 0.8282 - val_loss: 0.0799 - val_accuracy: 0.7463\n",
      "Epoch 3732/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0548 - accuracy: 0.8275 - val_loss: 0.0809 - val_accuracy: 0.7453\n",
      "Epoch 3733/5000\n",
      "11786/11786 [==============================] - 8s 717us/step - loss: 0.0546 - accuracy: 0.8277 - val_loss: 0.0805 - val_accuracy: 0.7445\n",
      "Epoch 3734/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0547 - accuracy: 0.8278 - val_loss: 0.0801 - val_accuracy: 0.7467\n",
      "Epoch 3735/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0546 - accuracy: 0.8285 - val_loss: 0.0818 - val_accuracy: 0.7467\n",
      "Epoch 3736/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0549 - accuracy: 0.8272 - val_loss: 0.0803 - val_accuracy: 0.7464\n",
      "Epoch 3737/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0548 - accuracy: 0.8276 - val_loss: 0.0811 - val_accuracy: 0.7464\n",
      "Epoch 3738/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0549 - accuracy: 0.8270 - val_loss: 0.0815 - val_accuracy: 0.7451\n",
      "Epoch 3739/5000\n",
      "11786/11786 [==============================] - 8s 718us/step - loss: 0.0548 - accuracy: 0.8269 - val_loss: 0.0805 - val_accuracy: 0.7451\n",
      "Epoch 3740/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0547 - accuracy: 0.8279 - val_loss: 0.0804 - val_accuracy: 0.7475\n",
      "Epoch 3741/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0546 - accuracy: 0.8278 - val_loss: 0.0805 - val_accuracy: 0.7479\n",
      "Epoch 3742/5000\n",
      "11786/11786 [==============================] - 8s 718us/step - loss: 0.0547 - accuracy: 0.8281 - val_loss: 0.0817 - val_accuracy: 0.7448\n",
      "Epoch 3743/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0545 - accuracy: 0.8281 - val_loss: 0.0798 - val_accuracy: 0.7458\n",
      "Epoch 3744/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0547 - accuracy: 0.8280 - val_loss: 0.0804 - val_accuracy: 0.7456\n",
      "Epoch 3745/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0546 - accuracy: 0.8281 - val_loss: 0.0796 - val_accuracy: 0.7472\n",
      "Epoch 3746/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0547 - accuracy: 0.8280 - val_loss: 0.0804 - val_accuracy: 0.7470\n",
      "Epoch 3747/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0547 - accuracy: 0.8273 - val_loss: 0.0799 - val_accuracy: 0.7454\n",
      "Epoch 3748/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0545 - accuracy: 0.8283 - val_loss: 0.0806 - val_accuracy: 0.7461\n",
      "Epoch 3749/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0545 - accuracy: 0.8286 - val_loss: 0.0803 - val_accuracy: 0.7479\n",
      "Epoch 3750/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0546 - accuracy: 0.8286 - val_loss: 0.0803 - val_accuracy: 0.7484\n",
      "Epoch 3751/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0548 - accuracy: 0.8274 - val_loss: 0.0799 - val_accuracy: 0.7479\n",
      "Epoch 3752/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0547 - accuracy: 0.8275 - val_loss: 0.0802 - val_accuracy: 0.7460\n",
      "Epoch 3753/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0550 - accuracy: 0.8265 - val_loss: 0.0814 - val_accuracy: 0.7437\n",
      "Epoch 3754/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0547 - accuracy: 0.8274 - val_loss: 0.0794 - val_accuracy: 0.7481\n",
      "Epoch 3755/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0549 - accuracy: 0.8270 - val_loss: 0.0794 - val_accuracy: 0.7466\n",
      "Epoch 3756/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0547 - accuracy: 0.8273 - val_loss: 0.0793 - val_accuracy: 0.7470\n",
      "Epoch 3757/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0548 - accuracy: 0.8273 - val_loss: 0.0800 - val_accuracy: 0.7469\n",
      "Epoch 3758/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0547 - accuracy: 0.8279 - val_loss: 0.0803 - val_accuracy: 0.7481\n",
      "Epoch 3759/5000\n",
      "11786/11786 [==============================] - 8s 715us/step - loss: 0.0547 - accuracy: 0.8280 - val_loss: 0.0799 - val_accuracy: 0.7473\n",
      "Epoch 3760/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0547 - accuracy: 0.8278 - val_loss: 0.0810 - val_accuracy: 0.7475\n",
      "Epoch 3761/5000\n",
      "11786/11786 [==============================] - 8s 715us/step - loss: 0.0547 - accuracy: 0.8281 - val_loss: 0.0799 - val_accuracy: 0.7468\n",
      "Epoch 3762/5000\n",
      "11786/11786 [==============================] - 8s 717us/step - loss: 0.0548 - accuracy: 0.8272 - val_loss: 0.0812 - val_accuracy: 0.7460\n",
      "Epoch 3763/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0548 - accuracy: 0.8275 - val_loss: 0.0807 - val_accuracy: 0.7455\n",
      "Epoch 3764/5000\n",
      "11786/11786 [==============================] - 8s 720us/step - loss: 0.0548 - accuracy: 0.8273 - val_loss: 0.0793 - val_accuracy: 0.7479\n",
      "Epoch 3765/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0547 - accuracy: 0.8275 - val_loss: 0.0801 - val_accuracy: 0.7462\n",
      "Epoch 3766/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0546 - accuracy: 0.8279 - val_loss: 0.0800 - val_accuracy: 0.7472\n",
      "Epoch 3767/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0549 - accuracy: 0.8269 - val_loss: 0.0816 - val_accuracy: 0.7466\n",
      "Epoch 3768/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0549 - accuracy: 0.8268 - val_loss: 0.0807 - val_accuracy: 0.7456\n",
      "Epoch 3769/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0549 - accuracy: 0.8262 - val_loss: 0.0807 - val_accuracy: 0.7451\n",
      "Epoch 3770/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0549 - accuracy: 0.8264 - val_loss: 0.0800 - val_accuracy: 0.7459\n",
      "Epoch 3771/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0548 - accuracy: 0.8263 - val_loss: 0.0805 - val_accuracy: 0.7454\n",
      "Epoch 3772/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0547 - accuracy: 0.8265 - val_loss: 0.0817 - val_accuracy: 0.7423\n",
      "Epoch 3773/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0550 - accuracy: 0.8254 - val_loss: 0.0803 - val_accuracy: 0.7426\n",
      "Epoch 3774/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0550 - accuracy: 0.8259 - val_loss: 0.0818 - val_accuracy: 0.7457\n",
      "Epoch 3775/5000\n",
      "11786/11786 [==============================] - 8s 719us/step - loss: 0.0549 - accuracy: 0.8261 - val_loss: 0.0806 - val_accuracy: 0.7442\n",
      "Epoch 3776/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0548 - accuracy: 0.8255 - val_loss: 0.0800 - val_accuracy: 0.7453\n",
      "Epoch 3777/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0548 - accuracy: 0.8262 - val_loss: 0.0804 - val_accuracy: 0.7448\n",
      "Epoch 3778/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0548 - accuracy: 0.8262 - val_loss: 0.0794 - val_accuracy: 0.7469\n",
      "Epoch 3779/5000\n",
      "11786/11786 [==============================] - 8s 716us/step - loss: 0.0546 - accuracy: 0.8269 - val_loss: 0.0799 - val_accuracy: 0.7464\n",
      "Epoch 3780/5000\n",
      "11786/11786 [==============================] - 8s 717us/step - loss: 0.0546 - accuracy: 0.8263 - val_loss: 0.0807 - val_accuracy: 0.7456\n",
      "Epoch 3781/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0547 - accuracy: 0.8257 - val_loss: 0.0805 - val_accuracy: 0.7439\n",
      "Epoch 3782/5000\n",
      "11786/11786 [==============================] - 8s 716us/step - loss: 0.0548 - accuracy: 0.8259 - val_loss: 0.0807 - val_accuracy: 0.7456\n",
      "Epoch 3783/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0548 - accuracy: 0.8265 - val_loss: 0.0805 - val_accuracy: 0.7443\n",
      "Epoch 3784/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0547 - accuracy: 0.8262 - val_loss: 0.0811 - val_accuracy: 0.7442\n",
      "Epoch 3785/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0550 - accuracy: 0.8253 - val_loss: 0.0814 - val_accuracy: 0.7432\n",
      "Epoch 3786/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0548 - accuracy: 0.8257 - val_loss: 0.0802 - val_accuracy: 0.7419\n",
      "Epoch 3787/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0549 - accuracy: 0.8253 - val_loss: 0.0806 - val_accuracy: 0.7436\n",
      "Epoch 3788/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0549 - accuracy: 0.8255 - val_loss: 0.0804 - val_accuracy: 0.7442\n",
      "Epoch 3789/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0549 - accuracy: 0.8255 - val_loss: 0.0808 - val_accuracy: 0.7411\n",
      "Epoch 3790/5000\n",
      "11786/11786 [==============================] - 8s 719us/step - loss: 0.0546 - accuracy: 0.8266 - val_loss: 0.0813 - val_accuracy: 0.7442\n",
      "Epoch 3791/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0546 - accuracy: 0.8270 - val_loss: 0.0804 - val_accuracy: 0.7464\n",
      "Epoch 3792/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0545 - accuracy: 0.8272 - val_loss: 0.0793 - val_accuracy: 0.7466\n",
      "Epoch 3793/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0547 - accuracy: 0.8263 - val_loss: 0.0814 - val_accuracy: 0.7427\n",
      "Epoch 3794/5000\n",
      "11786/11786 [==============================] - 8s 715us/step - loss: 0.0547 - accuracy: 0.8261 - val_loss: 0.0802 - val_accuracy: 0.7453\n",
      "Epoch 3795/5000\n",
      "11786/11786 [==============================] - 8s 719us/step - loss: 0.0546 - accuracy: 0.8264 - val_loss: 0.0809 - val_accuracy: 0.7467\n",
      "Epoch 3796/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0545 - accuracy: 0.8269 - val_loss: 0.0807 - val_accuracy: 0.7473\n",
      "Epoch 3797/5000\n",
      "11786/11786 [==============================] - 8s 714us/step - loss: 0.0545 - accuracy: 0.8272 - val_loss: 0.0807 - val_accuracy: 0.7473\n",
      "Epoch 3798/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0545 - accuracy: 0.8271 - val_loss: 0.0800 - val_accuracy: 0.7476\n",
      "Epoch 3799/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0545 - accuracy: 0.8270 - val_loss: 0.0813 - val_accuracy: 0.7463\n",
      "Epoch 3800/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0545 - accuracy: 0.8275 - val_loss: 0.0818 - val_accuracy: 0.7464\n",
      "Epoch 3801/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0544 - accuracy: 0.8278 - val_loss: 0.0804 - val_accuracy: 0.7471\n",
      "Epoch 3802/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0546 - accuracy: 0.8274 - val_loss: 0.0806 - val_accuracy: 0.7468\n",
      "Epoch 3803/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0547 - accuracy: 0.8269 - val_loss: 0.0807 - val_accuracy: 0.7428\n",
      "Epoch 3804/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0545 - accuracy: 0.8276 - val_loss: 0.0802 - val_accuracy: 0.7465\n",
      "Epoch 3805/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0546 - accuracy: 0.8270 - val_loss: 0.0804 - val_accuracy: 0.7478\n",
      "Epoch 3806/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0544 - accuracy: 0.8277 - val_loss: 0.0812 - val_accuracy: 0.7459\n",
      "Epoch 3807/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0544 - accuracy: 0.8280 - val_loss: 0.0799 - val_accuracy: 0.7472\n",
      "Epoch 3808/5000\n",
      "11786/11786 [==============================] - 8s 715us/step - loss: 0.0544 - accuracy: 0.8279 - val_loss: 0.0805 - val_accuracy: 0.7456\n",
      "Epoch 3809/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0545 - accuracy: 0.8275 - val_loss: 0.0801 - val_accuracy: 0.7464\n",
      "Epoch 3810/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0545 - accuracy: 0.8277 - val_loss: 0.0801 - val_accuracy: 0.7471\n",
      "Epoch 3811/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0545 - accuracy: 0.8276 - val_loss: 0.0798 - val_accuracy: 0.7460\n",
      "Epoch 3812/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0544 - accuracy: 0.8277 - val_loss: 0.0804 - val_accuracy: 0.7487\n",
      "Epoch 3813/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0544 - accuracy: 0.8279 - val_loss: 0.0801 - val_accuracy: 0.7485\n",
      "Epoch 3814/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0545 - accuracy: 0.8276 - val_loss: 0.0811 - val_accuracy: 0.7456\n",
      "Epoch 3815/5000\n",
      "11786/11786 [==============================] - 8s 714us/step - loss: 0.0546 - accuracy: 0.8272 - val_loss: 0.0809 - val_accuracy: 0.7483\n",
      "Epoch 3816/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0545 - accuracy: 0.8272 - val_loss: 0.0818 - val_accuracy: 0.7430\n",
      "Epoch 3817/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0546 - accuracy: 0.8272 - val_loss: 0.0798 - val_accuracy: 0.7458\n",
      "Epoch 3818/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0546 - accuracy: 0.8268 - val_loss: 0.0804 - val_accuracy: 0.7475\n",
      "Epoch 3819/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0544 - accuracy: 0.8275 - val_loss: 0.0808 - val_accuracy: 0.7464\n",
      "Epoch 3820/5000\n",
      "11786/11786 [==============================] - 8s 719us/step - loss: 0.0545 - accuracy: 0.8270 - val_loss: 0.0804 - val_accuracy: 0.7472\n",
      "Epoch 3821/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0545 - accuracy: 0.8269 - val_loss: 0.0789 - val_accuracy: 0.7472\n",
      "Epoch 3822/5000\n",
      "11786/11786 [==============================] - 8s 714us/step - loss: 0.0547 - accuracy: 0.8263 - val_loss: 0.0800 - val_accuracy: 0.7458\n",
      "Epoch 3823/5000\n",
      "11786/11786 [==============================] - 8s 718us/step - loss: 0.0546 - accuracy: 0.8268 - val_loss: 0.0802 - val_accuracy: 0.7443\n",
      "Epoch 3824/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0544 - accuracy: 0.8270 - val_loss: 0.0809 - val_accuracy: 0.7432\n",
      "Epoch 3825/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0547 - accuracy: 0.8261 - val_loss: 0.0799 - val_accuracy: 0.7467\n",
      "Epoch 3826/5000\n",
      "11786/11786 [==============================] - 8s 715us/step - loss: 0.0544 - accuracy: 0.8269 - val_loss: 0.0801 - val_accuracy: 0.7456\n",
      "Epoch 3827/5000\n",
      "11786/11786 [==============================] - 8s 715us/step - loss: 0.0545 - accuracy: 0.8274 - val_loss: 0.0807 - val_accuracy: 0.7463\n",
      "Epoch 3828/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0546 - accuracy: 0.8265 - val_loss: 0.0797 - val_accuracy: 0.7465\n",
      "Epoch 3829/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0546 - accuracy: 0.8260 - val_loss: 0.0805 - val_accuracy: 0.7461\n",
      "Epoch 3830/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0543 - accuracy: 0.8274 - val_loss: 0.0803 - val_accuracy: 0.7459\n",
      "Epoch 3831/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0545 - accuracy: 0.8269 - val_loss: 0.0796 - val_accuracy: 0.7464\n",
      "Epoch 3832/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0545 - accuracy: 0.8274 - val_loss: 0.0808 - val_accuracy: 0.7474\n",
      "Epoch 3833/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0546 - accuracy: 0.8267 - val_loss: 0.0799 - val_accuracy: 0.7458\n",
      "Epoch 3834/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0545 - accuracy: 0.8268 - val_loss: 0.0794 - val_accuracy: 0.7463\n",
      "Epoch 3835/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0544 - accuracy: 0.8271 - val_loss: 0.0802 - val_accuracy: 0.7471\n",
      "Epoch 3836/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0545 - accuracy: 0.8274 - val_loss: 0.0802 - val_accuracy: 0.7458\n",
      "Epoch 3837/5000\n",
      "11786/11786 [==============================] - 8s 719us/step - loss: 0.0541 - accuracy: 0.8286 - val_loss: 0.0792 - val_accuracy: 0.7484\n",
      "Epoch 3838/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0542 - accuracy: 0.8280 - val_loss: 0.0805 - val_accuracy: 0.7494\n",
      "Epoch 3839/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0541 - accuracy: 0.8288 - val_loss: 0.0801 - val_accuracy: 0.7454\n",
      "Epoch 3840/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0543 - accuracy: 0.8279 - val_loss: 0.0818 - val_accuracy: 0.7394\n",
      "Epoch 3841/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0543 - accuracy: 0.8280 - val_loss: 0.0805 - val_accuracy: 0.7474\n",
      "Epoch 3842/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0542 - accuracy: 0.8282 - val_loss: 0.0796 - val_accuracy: 0.7490\n",
      "Epoch 3843/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0541 - accuracy: 0.8288 - val_loss: 0.0786 - val_accuracy: 0.7483\n",
      "Epoch 3844/5000\n",
      "11786/11786 [==============================] - 8s 717us/step - loss: 0.0541 - accuracy: 0.8283 - val_loss: 0.0803 - val_accuracy: 0.7461\n",
      "Epoch 3845/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0542 - accuracy: 0.8281 - val_loss: 0.0809 - val_accuracy: 0.7465\n",
      "Epoch 3846/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0540 - accuracy: 0.8289 - val_loss: 0.0803 - val_accuracy: 0.7486\n",
      "Epoch 3847/5000\n",
      "11786/11786 [==============================] - 8s 716us/step - loss: 0.0542 - accuracy: 0.8283 - val_loss: 0.0805 - val_accuracy: 0.7470\n",
      "Epoch 3848/5000\n",
      "11786/11786 [==============================] - 8s 718us/step - loss: 0.0543 - accuracy: 0.8272 - val_loss: 0.0812 - val_accuracy: 0.7428\n",
      "Epoch 3849/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0543 - accuracy: 0.8278 - val_loss: 0.0796 - val_accuracy: 0.7450\n",
      "Epoch 3850/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0543 - accuracy: 0.8270 - val_loss: 0.0792 - val_accuracy: 0.7455\n",
      "Epoch 3851/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0542 - accuracy: 0.8278 - val_loss: 0.0796 - val_accuracy: 0.7474\n",
      "Epoch 3852/5000\n",
      "11786/11786 [==============================] - 8s 716us/step - loss: 0.0543 - accuracy: 0.8272 - val_loss: 0.0803 - val_accuracy: 0.7460\n",
      "Epoch 3853/5000\n",
      "11786/11786 [==============================] - 8s 715us/step - loss: 0.0543 - accuracy: 0.8269 - val_loss: 0.0795 - val_accuracy: 0.7454\n",
      "Epoch 3854/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0544 - accuracy: 0.8268 - val_loss: 0.0796 - val_accuracy: 0.7468\n",
      "Epoch 3855/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0541 - accuracy: 0.8276 - val_loss: 0.0799 - val_accuracy: 0.7460\n",
      "Epoch 3856/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0542 - accuracy: 0.8282 - val_loss: 0.0804 - val_accuracy: 0.7475\n",
      "Epoch 3857/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0540 - accuracy: 0.8285 - val_loss: 0.0796 - val_accuracy: 0.7493\n",
      "Epoch 3858/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0537 - accuracy: 0.8295 - val_loss: 0.0807 - val_accuracy: 0.7456\n",
      "Epoch 3859/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0539 - accuracy: 0.8286 - val_loss: 0.0801 - val_accuracy: 0.7471\n",
      "Epoch 3860/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0537 - accuracy: 0.8292 - val_loss: 0.0799 - val_accuracy: 0.7476\n",
      "Epoch 3861/5000\n",
      "11786/11786 [==============================] - 8s 715us/step - loss: 0.0540 - accuracy: 0.8284 - val_loss: 0.0799 - val_accuracy: 0.7475\n",
      "Epoch 3862/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0540 - accuracy: 0.8280 - val_loss: 0.0796 - val_accuracy: 0.7488\n",
      "Epoch 3863/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0539 - accuracy: 0.8290 - val_loss: 0.0810 - val_accuracy: 0.7434\n",
      "Epoch 3864/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0542 - accuracy: 0.8277 - val_loss: 0.0793 - val_accuracy: 0.7491\n",
      "Epoch 3865/5000\n",
      "11786/11786 [==============================] - 8s 714us/step - loss: 0.0539 - accuracy: 0.8291 - val_loss: 0.0793 - val_accuracy: 0.7478\n",
      "Epoch 3866/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0542 - accuracy: 0.8274 - val_loss: 0.0796 - val_accuracy: 0.7477\n",
      "Epoch 3867/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0541 - accuracy: 0.8282 - val_loss: 0.0794 - val_accuracy: 0.7487\n",
      "Epoch 3868/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0540 - accuracy: 0.8287 - val_loss: 0.0798 - val_accuracy: 0.7470\n",
      "Epoch 3869/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0541 - accuracy: 0.8286 - val_loss: 0.0802 - val_accuracy: 0.7483\n",
      "Epoch 3870/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0540 - accuracy: 0.8287 - val_loss: 0.0792 - val_accuracy: 0.7476\n",
      "Epoch 3871/5000\n",
      "11786/11786 [==============================] - 8s 714us/step - loss: 0.0540 - accuracy: 0.8280 - val_loss: 0.0805 - val_accuracy: 0.7455\n",
      "Epoch 3872/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0539 - accuracy: 0.8286 - val_loss: 0.0797 - val_accuracy: 0.7489\n",
      "Epoch 3873/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0539 - accuracy: 0.8289 - val_loss: 0.0797 - val_accuracy: 0.7477\n",
      "Epoch 3874/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0540 - accuracy: 0.8284 - val_loss: 0.0798 - val_accuracy: 0.7485\n",
      "Epoch 3875/5000\n",
      "11786/11786 [==============================] - 9s 722us/step - loss: 0.0540 - accuracy: 0.8291 - val_loss: 0.0796 - val_accuracy: 0.7482\n",
      "Epoch 3876/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0541 - accuracy: 0.8285 - val_loss: 0.0805 - val_accuracy: 0.7487\n",
      "Epoch 3877/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0539 - accuracy: 0.8291 - val_loss: 0.0797 - val_accuracy: 0.7488\n",
      "Epoch 3878/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0538 - accuracy: 0.8294 - val_loss: 0.0791 - val_accuracy: 0.7490\n",
      "Epoch 3879/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0539 - accuracy: 0.8293 - val_loss: 0.0794 - val_accuracy: 0.7484\n",
      "Epoch 3880/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0537 - accuracy: 0.8297 - val_loss: 0.0799 - val_accuracy: 0.7479\n",
      "Epoch 3881/5000\n",
      "11786/11786 [==============================] - 8s 714us/step - loss: 0.0539 - accuracy: 0.8287 - val_loss: 0.0799 - val_accuracy: 0.7480\n",
      "Epoch 3882/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0539 - accuracy: 0.8289 - val_loss: 0.0800 - val_accuracy: 0.7468\n",
      "Epoch 3883/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0538 - accuracy: 0.8290 - val_loss: 0.0798 - val_accuracy: 0.7477\n",
      "Epoch 3884/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0539 - accuracy: 0.8290 - val_loss: 0.0798 - val_accuracy: 0.7496\n",
      "Epoch 3885/5000\n",
      "11786/11786 [==============================] - 9s 721us/step - loss: 0.0540 - accuracy: 0.8290 - val_loss: 0.0800 - val_accuracy: 0.7472\n",
      "Epoch 3886/5000\n",
      "11786/11786 [==============================] - 8s 717us/step - loss: 0.0540 - accuracy: 0.8290 - val_loss: 0.0795 - val_accuracy: 0.7485\n",
      "Epoch 3887/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0541 - accuracy: 0.8284 - val_loss: 0.0805 - val_accuracy: 0.7475\n",
      "Epoch 3888/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0540 - accuracy: 0.8286 - val_loss: 0.0795 - val_accuracy: 0.7492\n",
      "Epoch 3889/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0542 - accuracy: 0.8280 - val_loss: 0.0792 - val_accuracy: 0.7472\n",
      "Epoch 3890/5000\n",
      "11786/11786 [==============================] - 8s 715us/step - loss: 0.0539 - accuracy: 0.8283 - val_loss: 0.0791 - val_accuracy: 0.7471\n",
      "Epoch 3891/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0542 - accuracy: 0.8276 - val_loss: 0.0802 - val_accuracy: 0.7489\n",
      "Epoch 3892/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0542 - accuracy: 0.8279 - val_loss: 0.0799 - val_accuracy: 0.7476\n",
      "Epoch 3893/5000\n",
      "11786/11786 [==============================] - 8s 716us/step - loss: 0.0541 - accuracy: 0.8280 - val_loss: 0.0800 - val_accuracy: 0.7491\n",
      "Epoch 3894/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0540 - accuracy: 0.8282 - val_loss: 0.0806 - val_accuracy: 0.7461\n",
      "Epoch 3895/5000\n",
      "11786/11786 [==============================] - 8s 716us/step - loss: 0.0541 - accuracy: 0.8280 - val_loss: 0.0815 - val_accuracy: 0.7466\n",
      "Epoch 3896/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0540 - accuracy: 0.8279 - val_loss: 0.0789 - val_accuracy: 0.7476\n",
      "Epoch 3897/5000\n",
      "11786/11786 [==============================] - 9s 723us/step - loss: 0.0542 - accuracy: 0.8275 - val_loss: 0.0787 - val_accuracy: 0.7477\n",
      "Epoch 3898/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0540 - accuracy: 0.8283 - val_loss: 0.0793 - val_accuracy: 0.7476\n",
      "Epoch 3899/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0542 - accuracy: 0.8272 - val_loss: 0.0801 - val_accuracy: 0.7477\n",
      "Epoch 3900/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0542 - accuracy: 0.8273 - val_loss: 0.0799 - val_accuracy: 0.7480\n",
      "Epoch 3901/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0540 - accuracy: 0.8282 - val_loss: 0.0800 - val_accuracy: 0.7456\n",
      "Epoch 3902/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0541 - accuracy: 0.8281 - val_loss: 0.0790 - val_accuracy: 0.7480\n",
      "Epoch 3903/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0542 - accuracy: 0.8276 - val_loss: 0.0794 - val_accuracy: 0.7477\n",
      "Epoch 3904/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0540 - accuracy: 0.8283 - val_loss: 0.0810 - val_accuracy: 0.7475\n",
      "Epoch 3905/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0540 - accuracy: 0.8284 - val_loss: 0.0807 - val_accuracy: 0.7475\n",
      "Epoch 3906/5000\n",
      "11786/11786 [==============================] - 8s 717us/step - loss: 0.0540 - accuracy: 0.8288 - val_loss: 0.0795 - val_accuracy: 0.7489\n",
      "Epoch 3907/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0539 - accuracy: 0.8286 - val_loss: 0.0801 - val_accuracy: 0.7475\n",
      "Epoch 3908/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0541 - accuracy: 0.8283 - val_loss: 0.0799 - val_accuracy: 0.7462\n",
      "Epoch 3909/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0540 - accuracy: 0.8282 - val_loss: 0.0807 - val_accuracy: 0.7484\n",
      "Epoch 3910/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0541 - accuracy: 0.8274 - val_loss: 0.0804 - val_accuracy: 0.7476\n",
      "Epoch 3911/5000\n",
      "11786/11786 [==============================] - 8s 717us/step - loss: 0.0541 - accuracy: 0.8282 - val_loss: 0.0796 - val_accuracy: 0.7490\n",
      "Epoch 3912/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0540 - accuracy: 0.8283 - val_loss: 0.0801 - val_accuracy: 0.7453\n",
      "Epoch 3913/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0541 - accuracy: 0.8277 - val_loss: 0.0798 - val_accuracy: 0.7485\n",
      "Epoch 3914/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0541 - accuracy: 0.8279 - val_loss: 0.0792 - val_accuracy: 0.7492\n",
      "Epoch 3915/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0541 - accuracy: 0.8282 - val_loss: 0.0795 - val_accuracy: 0.7471\n",
      "Epoch 3916/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0541 - accuracy: 0.8277 - val_loss: 0.0824 - val_accuracy: 0.7456\n",
      "Epoch 3917/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0540 - accuracy: 0.8281 - val_loss: 0.0793 - val_accuracy: 0.7496\n",
      "Epoch 3918/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0540 - accuracy: 0.8285 - val_loss: 0.0798 - val_accuracy: 0.7489\n",
      "Epoch 3919/5000\n",
      "11786/11786 [==============================] - 8s 719us/step - loss: 0.0540 - accuracy: 0.8290 - val_loss: 0.0789 - val_accuracy: 0.7491\n",
      "Epoch 3920/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0539 - accuracy: 0.8288 - val_loss: 0.0799 - val_accuracy: 0.7480\n",
      "Epoch 3921/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0540 - accuracy: 0.8280 - val_loss: 0.0798 - val_accuracy: 0.7493\n",
      "Epoch 3922/5000\n",
      "11786/11786 [==============================] - 8s 714us/step - loss: 0.0541 - accuracy: 0.8276 - val_loss: 0.0795 - val_accuracy: 0.7473\n",
      "Epoch 3923/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0540 - accuracy: 0.8283 - val_loss: 0.0803 - val_accuracy: 0.7471\n",
      "Epoch 3924/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0540 - accuracy: 0.8286 - val_loss: 0.0796 - val_accuracy: 0.7483\n",
      "Epoch 3925/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0540 - accuracy: 0.8287 - val_loss: 0.0789 - val_accuracy: 0.7481\n",
      "Epoch 3926/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0541 - accuracy: 0.8277 - val_loss: 0.0803 - val_accuracy: 0.7450\n",
      "Epoch 3927/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0541 - accuracy: 0.8275 - val_loss: 0.0792 - val_accuracy: 0.7475\n",
      "Epoch 3928/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0540 - accuracy: 0.8282 - val_loss: 0.0810 - val_accuracy: 0.7481\n",
      "Epoch 3929/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0541 - accuracy: 0.8284 - val_loss: 0.0804 - val_accuracy: 0.7487\n",
      "Epoch 3930/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0539 - accuracy: 0.8287 - val_loss: 0.0800 - val_accuracy: 0.7479\n",
      "Epoch 3931/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0539 - accuracy: 0.8286 - val_loss: 0.0805 - val_accuracy: 0.7478\n",
      "Epoch 3932/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0540 - accuracy: 0.8282 - val_loss: 0.0792 - val_accuracy: 0.7485\n",
      "Epoch 3933/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0541 - accuracy: 0.8283 - val_loss: 0.0791 - val_accuracy: 0.7481\n",
      "Epoch 3934/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0541 - accuracy: 0.8277 - val_loss: 0.0797 - val_accuracy: 0.7478\n",
      "Epoch 3935/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0541 - accuracy: 0.8276 - val_loss: 0.0802 - val_accuracy: 0.7464\n",
      "Epoch 3936/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0542 - accuracy: 0.8274 - val_loss: 0.0806 - val_accuracy: 0.7489\n",
      "Epoch 3937/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0543 - accuracy: 0.8270 - val_loss: 0.0791 - val_accuracy: 0.7460\n",
      "Epoch 3938/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0542 - accuracy: 0.8271 - val_loss: 0.0798 - val_accuracy: 0.7472\n",
      "Epoch 3939/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0541 - accuracy: 0.8280 - val_loss: 0.0807 - val_accuracy: 0.7457\n",
      "Epoch 3940/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0540 - accuracy: 0.8280 - val_loss: 0.0790 - val_accuracy: 0.7464\n",
      "Epoch 3941/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0541 - accuracy: 0.8279 - val_loss: 0.0799 - val_accuracy: 0.7478\n",
      "Epoch 3942/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0542 - accuracy: 0.8279 - val_loss: 0.0797 - val_accuracy: 0.7472\n",
      "Epoch 3943/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0543 - accuracy: 0.8272 - val_loss: 0.0803 - val_accuracy: 0.7477\n",
      "Epoch 3944/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0542 - accuracy: 0.8275 - val_loss: 0.0799 - val_accuracy: 0.7490\n",
      "Epoch 3945/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0542 - accuracy: 0.8275 - val_loss: 0.0798 - val_accuracy: 0.7476\n",
      "Epoch 3946/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0539 - accuracy: 0.8286 - val_loss: 0.0802 - val_accuracy: 0.7482\n",
      "Epoch 3947/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0537 - accuracy: 0.8295 - val_loss: 0.0797 - val_accuracy: 0.7463\n",
      "Epoch 3948/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0540 - accuracy: 0.8281 - val_loss: 0.0796 - val_accuracy: 0.7495\n",
      "Epoch 3949/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0540 - accuracy: 0.8282 - val_loss: 0.0797 - val_accuracy: 0.7473\n",
      "Epoch 3950/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0541 - accuracy: 0.8281 - val_loss: 0.0811 - val_accuracy: 0.7460\n",
      "Epoch 3951/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0540 - accuracy: 0.8282 - val_loss: 0.0795 - val_accuracy: 0.7481\n",
      "Epoch 3952/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0542 - accuracy: 0.8274 - val_loss: 0.0795 - val_accuracy: 0.7463\n",
      "Epoch 3953/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0541 - accuracy: 0.8274 - val_loss: 0.0802 - val_accuracy: 0.7469\n",
      "Epoch 3954/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0543 - accuracy: 0.8269 - val_loss: 0.0807 - val_accuracy: 0.7474\n",
      "Epoch 3955/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0542 - accuracy: 0.8268 - val_loss: 0.0799 - val_accuracy: 0.7456\n",
      "Epoch 3956/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0541 - accuracy: 0.8281 - val_loss: 0.0801 - val_accuracy: 0.7464\n",
      "Epoch 3957/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0542 - accuracy: 0.8276 - val_loss: 0.0800 - val_accuracy: 0.7461\n",
      "Epoch 3958/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0542 - accuracy: 0.8273 - val_loss: 0.0812 - val_accuracy: 0.7450\n",
      "Epoch 3959/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0541 - accuracy: 0.8276 - val_loss: 0.0799 - val_accuracy: 0.7464\n",
      "Epoch 3960/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0542 - accuracy: 0.8264 - val_loss: 0.0799 - val_accuracy: 0.7466\n",
      "Epoch 3961/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0541 - accuracy: 0.8271 - val_loss: 0.0790 - val_accuracy: 0.7454\n",
      "Epoch 3962/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0542 - accuracy: 0.8268 - val_loss: 0.0796 - val_accuracy: 0.7474\n",
      "Epoch 3963/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0540 - accuracy: 0.8274 - val_loss: 0.0808 - val_accuracy: 0.7455\n",
      "Epoch 3964/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0541 - accuracy: 0.8274 - val_loss: 0.0796 - val_accuracy: 0.7469\n",
      "Epoch 3965/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0541 - accuracy: 0.8282 - val_loss: 0.0791 - val_accuracy: 0.7456\n",
      "Epoch 3966/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0541 - accuracy: 0.8272 - val_loss: 0.0803 - val_accuracy: 0.7479\n",
      "Epoch 3967/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0541 - accuracy: 0.8272 - val_loss: 0.0792 - val_accuracy: 0.7466\n",
      "Epoch 3968/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0541 - accuracy: 0.8276 - val_loss: 0.0805 - val_accuracy: 0.7440\n",
      "Epoch 3969/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0539 - accuracy: 0.8278 - val_loss: 0.0786 - val_accuracy: 0.7479\n",
      "Epoch 3970/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0540 - accuracy: 0.8279 - val_loss: 0.0799 - val_accuracy: 0.7475\n",
      "Epoch 3971/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0542 - accuracy: 0.8273 - val_loss: 0.0803 - val_accuracy: 0.7448\n",
      "Epoch 3972/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0541 - accuracy: 0.8279 - val_loss: 0.0788 - val_accuracy: 0.7473\n",
      "Epoch 3973/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0541 - accuracy: 0.8276 - val_loss: 0.0800 - val_accuracy: 0.7479\n",
      "Epoch 3974/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0542 - accuracy: 0.8271 - val_loss: 0.0808 - val_accuracy: 0.7421\n",
      "Epoch 3975/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0541 - accuracy: 0.8282 - val_loss: 0.0795 - val_accuracy: 0.7460\n",
      "Epoch 3976/5000\n",
      "11786/11786 [==============================] - 8s 716us/step - loss: 0.0541 - accuracy: 0.8274 - val_loss: 0.0799 - val_accuracy: 0.7481\n",
      "Epoch 3977/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0543 - accuracy: 0.8272 - val_loss: 0.0802 - val_accuracy: 0.7475\n",
      "Epoch 3978/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0542 - accuracy: 0.8269 - val_loss: 0.0802 - val_accuracy: 0.7468\n",
      "Epoch 3979/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0540 - accuracy: 0.8276 - val_loss: 0.0799 - val_accuracy: 0.7474\n",
      "Epoch 3980/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0540 - accuracy: 0.8278 - val_loss: 0.0805 - val_accuracy: 0.7463\n",
      "Epoch 3981/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0540 - accuracy: 0.8277 - val_loss: 0.0808 - val_accuracy: 0.7449\n",
      "Epoch 3982/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0541 - accuracy: 0.8274 - val_loss: 0.0787 - val_accuracy: 0.7479\n",
      "Epoch 3983/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0540 - accuracy: 0.8274 - val_loss: 0.0795 - val_accuracy: 0.7484\n",
      "Epoch 3984/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0541 - accuracy: 0.8275 - val_loss: 0.0794 - val_accuracy: 0.7460\n",
      "Epoch 3985/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0540 - accuracy: 0.8279 - val_loss: 0.0802 - val_accuracy: 0.7479\n",
      "Epoch 3986/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0542 - accuracy: 0.8273 - val_loss: 0.0806 - val_accuracy: 0.7472\n",
      "Epoch 3987/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0541 - accuracy: 0.8276 - val_loss: 0.0794 - val_accuracy: 0.7462\n",
      "Epoch 3988/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0540 - accuracy: 0.8272 - val_loss: 0.0802 - val_accuracy: 0.7470\n",
      "Epoch 3989/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0542 - accuracy: 0.8271 - val_loss: 0.0799 - val_accuracy: 0.7467\n",
      "Epoch 3990/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0542 - accuracy: 0.8268 - val_loss: 0.0790 - val_accuracy: 0.7479\n",
      "Epoch 3991/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0542 - accuracy: 0.8272 - val_loss: 0.0803 - val_accuracy: 0.7448\n",
      "Epoch 3992/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0540 - accuracy: 0.8274 - val_loss: 0.0796 - val_accuracy: 0.7488\n",
      "Epoch 3993/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0540 - accuracy: 0.8277 - val_loss: 0.0791 - val_accuracy: 0.7460\n",
      "Epoch 3994/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0541 - accuracy: 0.8278 - val_loss: 0.0797 - val_accuracy: 0.7471\n",
      "Epoch 3995/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0542 - accuracy: 0.8269 - val_loss: 0.0801 - val_accuracy: 0.7447\n",
      "Epoch 3996/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0541 - accuracy: 0.8272 - val_loss: 0.0795 - val_accuracy: 0.7452\n",
      "Epoch 3997/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0541 - accuracy: 0.8279 - val_loss: 0.0798 - val_accuracy: 0.7456\n",
      "Epoch 3998/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0541 - accuracy: 0.8270 - val_loss: 0.0793 - val_accuracy: 0.7485\n",
      "Epoch 3999/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0541 - accuracy: 0.8270 - val_loss: 0.0800 - val_accuracy: 0.7472\n",
      "Epoch 4000/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0541 - accuracy: 0.8275 - val_loss: 0.0802 - val_accuracy: 0.7435\n",
      "Epoch 4001/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0542 - accuracy: 0.8272 - val_loss: 0.0792 - val_accuracy: 0.7475\n",
      "Epoch 4002/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0543 - accuracy: 0.8268 - val_loss: 0.0807 - val_accuracy: 0.7442\n",
      "Epoch 4003/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0542 - accuracy: 0.8272 - val_loss: 0.0801 - val_accuracy: 0.7464\n",
      "Epoch 4004/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0542 - accuracy: 0.8271 - val_loss: 0.0801 - val_accuracy: 0.7475\n",
      "Epoch 4005/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0541 - accuracy: 0.8275 - val_loss: 0.0815 - val_accuracy: 0.7447\n",
      "Epoch 4006/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0543 - accuracy: 0.8274 - val_loss: 0.0807 - val_accuracy: 0.7462\n",
      "Epoch 4007/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0542 - accuracy: 0.8271 - val_loss: 0.0800 - val_accuracy: 0.7478\n",
      "Epoch 4008/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0541 - accuracy: 0.8282 - val_loss: 0.0801 - val_accuracy: 0.7474\n",
      "Epoch 4009/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0542 - accuracy: 0.8274 - val_loss: 0.0808 - val_accuracy: 0.7471\n",
      "Epoch 4010/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0542 - accuracy: 0.8277 - val_loss: 0.0797 - val_accuracy: 0.7480\n",
      "Epoch 4011/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0543 - accuracy: 0.8266 - val_loss: 0.0795 - val_accuracy: 0.7474\n",
      "Epoch 4012/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0542 - accuracy: 0.8279 - val_loss: 0.0805 - val_accuracy: 0.7469\n",
      "Epoch 4013/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0543 - accuracy: 0.8274 - val_loss: 0.0802 - val_accuracy: 0.7461\n",
      "Epoch 4014/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0544 - accuracy: 0.8262 - val_loss: 0.0812 - val_accuracy: 0.7439\n",
      "Epoch 4015/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0545 - accuracy: 0.8257 - val_loss: 0.0804 - val_accuracy: 0.7446\n",
      "Epoch 4016/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0544 - accuracy: 0.8265 - val_loss: 0.0807 - val_accuracy: 0.7431\n",
      "Epoch 4017/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0546 - accuracy: 0.8254 - val_loss: 0.0799 - val_accuracy: 0.7458\n",
      "Epoch 4018/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0545 - accuracy: 0.8257 - val_loss: 0.0808 - val_accuracy: 0.7428\n",
      "Epoch 4019/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0542 - accuracy: 0.8269 - val_loss: 0.0796 - val_accuracy: 0.7464\n",
      "Epoch 4020/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0543 - accuracy: 0.8269 - val_loss: 0.0814 - val_accuracy: 0.7451\n",
      "Epoch 4021/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0543 - accuracy: 0.8266 - val_loss: 0.0795 - val_accuracy: 0.7452\n",
      "Epoch 4022/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0544 - accuracy: 0.8267 - val_loss: 0.0801 - val_accuracy: 0.7444\n",
      "Epoch 4023/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0544 - accuracy: 0.8265 - val_loss: 0.0789 - val_accuracy: 0.7456\n",
      "Epoch 4024/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0544 - accuracy: 0.8264 - val_loss: 0.0807 - val_accuracy: 0.7485\n",
      "Epoch 4025/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0544 - accuracy: 0.8271 - val_loss: 0.0817 - val_accuracy: 0.7466\n",
      "Epoch 4026/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0545 - accuracy: 0.8262 - val_loss: 0.0801 - val_accuracy: 0.7470\n",
      "Epoch 4027/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0545 - accuracy: 0.8259 - val_loss: 0.0797 - val_accuracy: 0.7474\n",
      "Epoch 4028/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0544 - accuracy: 0.8261 - val_loss: 0.0795 - val_accuracy: 0.7463\n",
      "Epoch 4029/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0545 - accuracy: 0.8255 - val_loss: 0.0794 - val_accuracy: 0.7473\n",
      "Epoch 4030/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0544 - accuracy: 0.8261 - val_loss: 0.0807 - val_accuracy: 0.7447\n",
      "Epoch 4031/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0544 - accuracy: 0.8264 - val_loss: 0.0790 - val_accuracy: 0.7468\n",
      "Epoch 4032/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0541 - accuracy: 0.8278 - val_loss: 0.0787 - val_accuracy: 0.7495\n",
      "Epoch 4033/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0542 - accuracy: 0.8271 - val_loss: 0.0803 - val_accuracy: 0.7450\n",
      "Epoch 4034/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0543 - accuracy: 0.8272 - val_loss: 0.0798 - val_accuracy: 0.7453\n",
      "Epoch 4035/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0543 - accuracy: 0.8270 - val_loss: 0.0794 - val_accuracy: 0.7473\n",
      "Epoch 4036/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0542 - accuracy: 0.8276 - val_loss: 0.0794 - val_accuracy: 0.7483\n",
      "Epoch 4037/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0544 - accuracy: 0.8261 - val_loss: 0.0802 - val_accuracy: 0.7443\n",
      "Epoch 4038/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0543 - accuracy: 0.8272 - val_loss: 0.0800 - val_accuracy: 0.7432\n",
      "Epoch 4039/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0544 - accuracy: 0.8261 - val_loss: 0.0799 - val_accuracy: 0.7475\n",
      "Epoch 4040/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0543 - accuracy: 0.8267 - val_loss: 0.0806 - val_accuracy: 0.7422\n",
      "Epoch 4041/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0543 - accuracy: 0.8265 - val_loss: 0.0800 - val_accuracy: 0.7442\n",
      "Epoch 4042/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0544 - accuracy: 0.8264 - val_loss: 0.0803 - val_accuracy: 0.7466\n",
      "Epoch 4043/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0544 - accuracy: 0.8266 - val_loss: 0.0803 - val_accuracy: 0.7466\n",
      "Epoch 4044/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0544 - accuracy: 0.8268 - val_loss: 0.0801 - val_accuracy: 0.7469\n",
      "Epoch 4045/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0545 - accuracy: 0.8262 - val_loss: 0.0797 - val_accuracy: 0.7451\n",
      "Epoch 4046/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0544 - accuracy: 0.8262 - val_loss: 0.0799 - val_accuracy: 0.7439\n",
      "Epoch 4047/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0544 - accuracy: 0.8266 - val_loss: 0.0797 - val_accuracy: 0.7454\n",
      "Epoch 4048/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0545 - accuracy: 0.8260 - val_loss: 0.0796 - val_accuracy: 0.7465\n",
      "Epoch 4049/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0545 - accuracy: 0.8263 - val_loss: 0.0800 - val_accuracy: 0.7480\n",
      "Epoch 4050/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0544 - accuracy: 0.8259 - val_loss: 0.0792 - val_accuracy: 0.7476\n",
      "Epoch 4051/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0544 - accuracy: 0.8261 - val_loss: 0.0804 - val_accuracy: 0.7455\n",
      "Epoch 4052/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0545 - accuracy: 0.8254 - val_loss: 0.0800 - val_accuracy: 0.7456\n",
      "Epoch 4053/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0545 - accuracy: 0.8255 - val_loss: 0.0805 - val_accuracy: 0.7465\n",
      "Epoch 4054/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0545 - accuracy: 0.8258 - val_loss: 0.0807 - val_accuracy: 0.7468\n",
      "Epoch 4055/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0545 - accuracy: 0.8260 - val_loss: 0.0806 - val_accuracy: 0.7461\n",
      "Epoch 4056/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0547 - accuracy: 0.8250 - val_loss: 0.0803 - val_accuracy: 0.7459\n",
      "Epoch 4057/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0547 - accuracy: 0.8255 - val_loss: 0.0793 - val_accuracy: 0.7448\n",
      "Epoch 4058/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0546 - accuracy: 0.8256 - val_loss: 0.0804 - val_accuracy: 0.7439\n",
      "Epoch 4059/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0545 - accuracy: 0.8256 - val_loss: 0.0793 - val_accuracy: 0.7461\n",
      "Epoch 4060/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0542 - accuracy: 0.8271 - val_loss: 0.0804 - val_accuracy: 0.7462\n",
      "Epoch 4061/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0545 - accuracy: 0.8257 - val_loss: 0.0810 - val_accuracy: 0.7437\n",
      "Epoch 4062/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0544 - accuracy: 0.8262 - val_loss: 0.0799 - val_accuracy: 0.7479\n",
      "Epoch 4063/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0543 - accuracy: 0.8266 - val_loss: 0.0798 - val_accuracy: 0.7483\n",
      "Epoch 4064/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0544 - accuracy: 0.8263 - val_loss: 0.0794 - val_accuracy: 0.7456\n",
      "Epoch 4065/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0544 - accuracy: 0.8265 - val_loss: 0.0806 - val_accuracy: 0.7432\n",
      "Epoch 4066/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0544 - accuracy: 0.8259 - val_loss: 0.0800 - val_accuracy: 0.7455\n",
      "Epoch 4067/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0545 - accuracy: 0.8266 - val_loss: 0.0799 - val_accuracy: 0.7452\n",
      "Epoch 4068/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0545 - accuracy: 0.8269 - val_loss: 0.0805 - val_accuracy: 0.7440\n",
      "Epoch 4069/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0543 - accuracy: 0.8266 - val_loss: 0.0792 - val_accuracy: 0.7475\n",
      "Epoch 4070/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0542 - accuracy: 0.8272 - val_loss: 0.0799 - val_accuracy: 0.7474\n",
      "Epoch 4071/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0543 - accuracy: 0.8268 - val_loss: 0.0806 - val_accuracy: 0.7440\n",
      "Epoch 4072/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0543 - accuracy: 0.8268 - val_loss: 0.0792 - val_accuracy: 0.7474\n",
      "Epoch 4073/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0543 - accuracy: 0.8268 - val_loss: 0.0797 - val_accuracy: 0.7474\n",
      "Epoch 4074/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0544 - accuracy: 0.8270 - val_loss: 0.0800 - val_accuracy: 0.7456\n",
      "Epoch 4075/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0543 - accuracy: 0.8266 - val_loss: 0.0801 - val_accuracy: 0.7433\n",
      "Epoch 4076/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0546 - accuracy: 0.8253 - val_loss: 0.0796 - val_accuracy: 0.7472\n",
      "Epoch 4077/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0543 - accuracy: 0.8270 - val_loss: 0.0808 - val_accuracy: 0.7459\n",
      "Epoch 4078/5000\n",
      "11786/11786 [==============================] - 8s 717us/step - loss: 0.0544 - accuracy: 0.8263 - val_loss: 0.0803 - val_accuracy: 0.7453\n",
      "Epoch 4079/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0544 - accuracy: 0.8267 - val_loss: 0.0800 - val_accuracy: 0.7455\n",
      "Epoch 4080/5000\n",
      "11786/11786 [==============================] - 8s 714us/step - loss: 0.0542 - accuracy: 0.8268 - val_loss: 0.0800 - val_accuracy: 0.7453\n",
      "Epoch 4081/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0543 - accuracy: 0.8263 - val_loss: 0.0795 - val_accuracy: 0.7483\n",
      "Epoch 4082/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0544 - accuracy: 0.8260 - val_loss: 0.0797 - val_accuracy: 0.7465\n",
      "Epoch 4083/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0542 - accuracy: 0.8270 - val_loss: 0.0805 - val_accuracy: 0.7480\n",
      "Epoch 4084/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0544 - accuracy: 0.8263 - val_loss: 0.0820 - val_accuracy: 0.7441\n",
      "Epoch 4085/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0545 - accuracy: 0.8263 - val_loss: 0.0805 - val_accuracy: 0.7462\n",
      "Epoch 4086/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0544 - accuracy: 0.8264 - val_loss: 0.0794 - val_accuracy: 0.7453\n",
      "Epoch 4087/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0542 - accuracy: 0.8272 - val_loss: 0.0792 - val_accuracy: 0.7438\n",
      "Epoch 4088/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0545 - accuracy: 0.8264 - val_loss: 0.0792 - val_accuracy: 0.7447\n",
      "Epoch 4089/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0545 - accuracy: 0.8257 - val_loss: 0.0791 - val_accuracy: 0.7453\n",
      "Epoch 4090/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0545 - accuracy: 0.8258 - val_loss: 0.0815 - val_accuracy: 0.7444\n",
      "Epoch 4091/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0544 - accuracy: 0.8263 - val_loss: 0.0786 - val_accuracy: 0.7470\n",
      "Epoch 4092/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0544 - accuracy: 0.8262 - val_loss: 0.0807 - val_accuracy: 0.7460\n",
      "Epoch 4093/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0546 - accuracy: 0.8258 - val_loss: 0.0801 - val_accuracy: 0.7441\n",
      "Epoch 4094/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0544 - accuracy: 0.8264 - val_loss: 0.0799 - val_accuracy: 0.7459\n",
      "Epoch 4095/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0545 - accuracy: 0.8261 - val_loss: 0.0798 - val_accuracy: 0.7472\n",
      "Epoch 4096/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0545 - accuracy: 0.8263 - val_loss: 0.0800 - val_accuracy: 0.7455\n",
      "Epoch 4097/5000\n",
      "11786/11786 [==============================] - 8s 715us/step - loss: 0.0546 - accuracy: 0.8264 - val_loss: 0.0810 - val_accuracy: 0.7440\n",
      "Epoch 4098/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0545 - accuracy: 0.8257 - val_loss: 0.0795 - val_accuracy: 0.7456\n",
      "Epoch 4099/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0548 - accuracy: 0.8249 - val_loss: 0.0792 - val_accuracy: 0.7475\n",
      "Epoch 4100/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0544 - accuracy: 0.8262 - val_loss: 0.0795 - val_accuracy: 0.7472\n",
      "Epoch 4101/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0545 - accuracy: 0.8264 - val_loss: 0.0798 - val_accuracy: 0.7440\n",
      "Epoch 4102/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0543 - accuracy: 0.8267 - val_loss: 0.0792 - val_accuracy: 0.7472\n",
      "Epoch 4103/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0544 - accuracy: 0.8262 - val_loss: 0.0801 - val_accuracy: 0.7458\n",
      "Epoch 4104/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0546 - accuracy: 0.8260 - val_loss: 0.0794 - val_accuracy: 0.7444\n",
      "Epoch 4105/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0546 - accuracy: 0.8263 - val_loss: 0.0798 - val_accuracy: 0.7444\n",
      "Epoch 4106/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0546 - accuracy: 0.8260 - val_loss: 0.0799 - val_accuracy: 0.7473\n",
      "Epoch 4107/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0544 - accuracy: 0.8267 - val_loss: 0.0797 - val_accuracy: 0.7469\n",
      "Epoch 4108/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0547 - accuracy: 0.8257 - val_loss: 0.0815 - val_accuracy: 0.7440\n",
      "Epoch 4109/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0544 - accuracy: 0.8261 - val_loss: 0.0797 - val_accuracy: 0.7464\n",
      "Epoch 4110/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0545 - accuracy: 0.8262 - val_loss: 0.0809 - val_accuracy: 0.7448\n",
      "Epoch 4111/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0544 - accuracy: 0.8259 - val_loss: 0.0801 - val_accuracy: 0.7471\n",
      "Epoch 4112/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0546 - accuracy: 0.8250 - val_loss: 0.0811 - val_accuracy: 0.7429\n",
      "Epoch 4113/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0545 - accuracy: 0.8260 - val_loss: 0.0796 - val_accuracy: 0.7473\n",
      "Epoch 4114/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0544 - accuracy: 0.8266 - val_loss: 0.0796 - val_accuracy: 0.7477\n",
      "Epoch 4115/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0544 - accuracy: 0.8272 - val_loss: 0.0803 - val_accuracy: 0.7453\n",
      "Epoch 4116/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0546 - accuracy: 0.8259 - val_loss: 0.0814 - val_accuracy: 0.7448\n",
      "Epoch 4117/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0545 - accuracy: 0.8261 - val_loss: 0.0807 - val_accuracy: 0.7452\n",
      "Epoch 4118/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0545 - accuracy: 0.8260 - val_loss: 0.0805 - val_accuracy: 0.7439\n",
      "Epoch 4119/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0542 - accuracy: 0.8271 - val_loss: 0.0802 - val_accuracy: 0.7460\n",
      "Epoch 4120/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0544 - accuracy: 0.8261 - val_loss: 0.0804 - val_accuracy: 0.7442\n",
      "Epoch 4121/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0544 - accuracy: 0.8258 - val_loss: 0.0793 - val_accuracy: 0.7464\n",
      "Epoch 4122/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0547 - accuracy: 0.8248 - val_loss: 0.0796 - val_accuracy: 0.7445\n",
      "Epoch 4123/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0546 - accuracy: 0.8254 - val_loss: 0.0816 - val_accuracy: 0.7437\n",
      "Epoch 4124/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0546 - accuracy: 0.8253 - val_loss: 0.0811 - val_accuracy: 0.7439\n",
      "Epoch 4125/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0546 - accuracy: 0.8251 - val_loss: 0.0809 - val_accuracy: 0.7446\n",
      "Epoch 4126/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0546 - accuracy: 0.8252 - val_loss: 0.0804 - val_accuracy: 0.7433\n",
      "Epoch 4127/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0545 - accuracy: 0.8254 - val_loss: 0.0805 - val_accuracy: 0.7446\n",
      "Epoch 4128/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0544 - accuracy: 0.8259 - val_loss: 0.0809 - val_accuracy: 0.7446\n",
      "Epoch 4129/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0546 - accuracy: 0.8250 - val_loss: 0.0792 - val_accuracy: 0.7463\n",
      "Epoch 4130/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0545 - accuracy: 0.8257 - val_loss: 0.0795 - val_accuracy: 0.7474\n",
      "Epoch 4131/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0545 - accuracy: 0.8257 - val_loss: 0.0792 - val_accuracy: 0.7437\n",
      "Epoch 4132/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0546 - accuracy: 0.8251 - val_loss: 0.0812 - val_accuracy: 0.7442\n",
      "Epoch 4133/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0546 - accuracy: 0.8250 - val_loss: 0.0809 - val_accuracy: 0.7433\n",
      "Epoch 4134/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0546 - accuracy: 0.8252 - val_loss: 0.0801 - val_accuracy: 0.7456\n",
      "Epoch 4135/5000\n",
      "11786/11786 [==============================] - 8s 714us/step - loss: 0.0546 - accuracy: 0.8256 - val_loss: 0.0813 - val_accuracy: 0.7426\n",
      "Epoch 4136/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0546 - accuracy: 0.8255 - val_loss: 0.0802 - val_accuracy: 0.7470\n",
      "Epoch 4137/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0546 - accuracy: 0.8254 - val_loss: 0.0815 - val_accuracy: 0.7445\n",
      "Epoch 4138/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0546 - accuracy: 0.8253 - val_loss: 0.0794 - val_accuracy: 0.7461\n",
      "Epoch 4139/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0545 - accuracy: 0.8256 - val_loss: 0.0802 - val_accuracy: 0.7460\n",
      "Epoch 4140/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0545 - accuracy: 0.8257 - val_loss: 0.0806 - val_accuracy: 0.7459\n",
      "Epoch 4141/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0545 - accuracy: 0.8260 - val_loss: 0.0800 - val_accuracy: 0.7446\n",
      "Epoch 4142/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0545 - accuracy: 0.8254 - val_loss: 0.0788 - val_accuracy: 0.7463\n",
      "Epoch 4143/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0546 - accuracy: 0.8257 - val_loss: 0.0808 - val_accuracy: 0.7456\n",
      "Epoch 4144/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0543 - accuracy: 0.8266 - val_loss: 0.0806 - val_accuracy: 0.7463\n",
      "Epoch 4145/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0544 - accuracy: 0.8265 - val_loss: 0.0797 - val_accuracy: 0.7462\n",
      "Epoch 4146/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0545 - accuracy: 0.8264 - val_loss: 0.0808 - val_accuracy: 0.7474\n",
      "Epoch 4147/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0546 - accuracy: 0.8260 - val_loss: 0.0800 - val_accuracy: 0.7456\n",
      "Epoch 4148/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0547 - accuracy: 0.8256 - val_loss: 0.0802 - val_accuracy: 0.7451\n",
      "Epoch 4149/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0546 - accuracy: 0.8257 - val_loss: 0.0793 - val_accuracy: 0.7423\n",
      "Epoch 4150/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0546 - accuracy: 0.8255 - val_loss: 0.0798 - val_accuracy: 0.7464\n",
      "Epoch 4151/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0545 - accuracy: 0.8257 - val_loss: 0.0803 - val_accuracy: 0.7439\n",
      "Epoch 4152/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0544 - accuracy: 0.8256 - val_loss: 0.0800 - val_accuracy: 0.7467\n",
      "Epoch 4153/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0546 - accuracy: 0.8256 - val_loss: 0.0787 - val_accuracy: 0.7467\n",
      "Epoch 4154/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0545 - accuracy: 0.8261 - val_loss: 0.0800 - val_accuracy: 0.7473\n",
      "Epoch 4155/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0546 - accuracy: 0.8259 - val_loss: 0.0800 - val_accuracy: 0.7446\n",
      "Epoch 4156/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0545 - accuracy: 0.8258 - val_loss: 0.0799 - val_accuracy: 0.7482\n",
      "Epoch 4157/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0546 - accuracy: 0.8256 - val_loss: 0.0800 - val_accuracy: 0.7465\n",
      "Epoch 4158/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0545 - accuracy: 0.8258 - val_loss: 0.0802 - val_accuracy: 0.7486\n",
      "Epoch 4159/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0545 - accuracy: 0.8263 - val_loss: 0.0815 - val_accuracy: 0.7451\n",
      "Epoch 4160/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0544 - accuracy: 0.8265 - val_loss: 0.0800 - val_accuracy: 0.7457\n",
      "Epoch 4161/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0545 - accuracy: 0.8267 - val_loss: 0.0804 - val_accuracy: 0.7455\n",
      "Epoch 4162/5000\n",
      "11786/11786 [==============================] - 8s 714us/step - loss: 0.0544 - accuracy: 0.8264 - val_loss: 0.0791 - val_accuracy: 0.7471\n",
      "Epoch 4163/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0547 - accuracy: 0.8251 - val_loss: 0.0815 - val_accuracy: 0.7448\n",
      "Epoch 4164/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0546 - accuracy: 0.8251 - val_loss: 0.0804 - val_accuracy: 0.7467\n",
      "Epoch 4165/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0545 - accuracy: 0.8256 - val_loss: 0.0821 - val_accuracy: 0.7431\n",
      "Epoch 4166/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0546 - accuracy: 0.8255 - val_loss: 0.0802 - val_accuracy: 0.7465\n",
      "Epoch 4167/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0547 - accuracy: 0.8251 - val_loss: 0.0803 - val_accuracy: 0.7464\n",
      "Epoch 4168/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0545 - accuracy: 0.8259 - val_loss: 0.0806 - val_accuracy: 0.7474\n",
      "Epoch 4169/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0546 - accuracy: 0.8260 - val_loss: 0.0804 - val_accuracy: 0.7461\n",
      "Epoch 4170/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0547 - accuracy: 0.8257 - val_loss: 0.0797 - val_accuracy: 0.7466\n",
      "Epoch 4171/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0546 - accuracy: 0.8260 - val_loss: 0.0803 - val_accuracy: 0.7458\n",
      "Epoch 4172/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0548 - accuracy: 0.8251 - val_loss: 0.0805 - val_accuracy: 0.7448\n",
      "Epoch 4173/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0548 - accuracy: 0.8251 - val_loss: 0.0802 - val_accuracy: 0.7450\n",
      "Epoch 4174/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0546 - accuracy: 0.8256 - val_loss: 0.0802 - val_accuracy: 0.7460\n",
      "Epoch 4175/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0547 - accuracy: 0.8249 - val_loss: 0.0799 - val_accuracy: 0.7454\n",
      "Epoch 4176/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0548 - accuracy: 0.8253 - val_loss: 0.0810 - val_accuracy: 0.7450\n",
      "Epoch 4177/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0547 - accuracy: 0.8253 - val_loss: 0.0796 - val_accuracy: 0.7451\n",
      "Epoch 4178/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0547 - accuracy: 0.8255 - val_loss: 0.0811 - val_accuracy: 0.7451\n",
      "Epoch 4179/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0547 - accuracy: 0.8258 - val_loss: 0.0803 - val_accuracy: 0.7448\n",
      "Epoch 4180/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0547 - accuracy: 0.8255 - val_loss: 0.0797 - val_accuracy: 0.7460\n",
      "Epoch 4181/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0547 - accuracy: 0.8253 - val_loss: 0.0810 - val_accuracy: 0.7443\n",
      "Epoch 4182/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0548 - accuracy: 0.8250 - val_loss: 0.0805 - val_accuracy: 0.7442\n",
      "Epoch 4183/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0546 - accuracy: 0.8260 - val_loss: 0.0793 - val_accuracy: 0.7462\n",
      "Epoch 4184/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0546 - accuracy: 0.8258 - val_loss: 0.0817 - val_accuracy: 0.7432\n",
      "Epoch 4185/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0546 - accuracy: 0.8257 - val_loss: 0.0815 - val_accuracy: 0.7449\n",
      "Epoch 4186/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0545 - accuracy: 0.8261 - val_loss: 0.0800 - val_accuracy: 0.7436\n",
      "Epoch 4187/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0546 - accuracy: 0.8260 - val_loss: 0.0812 - val_accuracy: 0.7457\n",
      "Epoch 4188/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0546 - accuracy: 0.8267 - val_loss: 0.0803 - val_accuracy: 0.7445\n",
      "Epoch 4189/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0547 - accuracy: 0.8260 - val_loss: 0.0806 - val_accuracy: 0.7443\n",
      "Epoch 4190/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0546 - accuracy: 0.8260 - val_loss: 0.0802 - val_accuracy: 0.7464\n",
      "Epoch 4191/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0546 - accuracy: 0.8263 - val_loss: 0.0803 - val_accuracy: 0.7453\n",
      "Epoch 4192/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0548 - accuracy: 0.8254 - val_loss: 0.0805 - val_accuracy: 0.7475\n",
      "Epoch 4193/5000\n",
      "11786/11786 [==============================] - 8s 714us/step - loss: 0.0545 - accuracy: 0.8257 - val_loss: 0.0803 - val_accuracy: 0.7448\n",
      "Epoch 4194/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0544 - accuracy: 0.8263 - val_loss: 0.0794 - val_accuracy: 0.7474\n",
      "Epoch 4195/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0545 - accuracy: 0.8261 - val_loss: 0.0805 - val_accuracy: 0.7478\n",
      "Epoch 4196/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0545 - accuracy: 0.8262 - val_loss: 0.0806 - val_accuracy: 0.7460\n",
      "Epoch 4197/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0546 - accuracy: 0.8262 - val_loss: 0.0793 - val_accuracy: 0.7433\n",
      "Epoch 4198/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0546 - accuracy: 0.8263 - val_loss: 0.0817 - val_accuracy: 0.7446\n",
      "Epoch 4199/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0545 - accuracy: 0.8261 - val_loss: 0.0812 - val_accuracy: 0.7452\n",
      "Epoch 4200/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0545 - accuracy: 0.8264 - val_loss: 0.0810 - val_accuracy: 0.7458\n",
      "Epoch 4201/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0546 - accuracy: 0.8261 - val_loss: 0.0804 - val_accuracy: 0.7471\n",
      "Epoch 4202/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0547 - accuracy: 0.8258 - val_loss: 0.0804 - val_accuracy: 0.7476\n",
      "Epoch 4203/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0549 - accuracy: 0.8253 - val_loss: 0.0792 - val_accuracy: 0.7448\n",
      "Epoch 4204/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0547 - accuracy: 0.8259 - val_loss: 0.0809 - val_accuracy: 0.7453\n",
      "Epoch 4205/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0546 - accuracy: 0.8260 - val_loss: 0.0799 - val_accuracy: 0.7457\n",
      "Epoch 4206/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0547 - accuracy: 0.8252 - val_loss: 0.0803 - val_accuracy: 0.7463\n",
      "Epoch 4207/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0547 - accuracy: 0.8257 - val_loss: 0.0803 - val_accuracy: 0.7432\n",
      "Epoch 4208/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0548 - accuracy: 0.8255 - val_loss: 0.0796 - val_accuracy: 0.7461\n",
      "Epoch 4209/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0547 - accuracy: 0.8251 - val_loss: 0.0805 - val_accuracy: 0.7439\n",
      "Epoch 4210/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0547 - accuracy: 0.8255 - val_loss: 0.0801 - val_accuracy: 0.7446\n",
      "Epoch 4211/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0548 - accuracy: 0.8256 - val_loss: 0.0809 - val_accuracy: 0.7471\n",
      "Epoch 4212/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0547 - accuracy: 0.8261 - val_loss: 0.0807 - val_accuracy: 0.7456\n",
      "Epoch 4213/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0547 - accuracy: 0.8254 - val_loss: 0.0818 - val_accuracy: 0.7426\n",
      "Epoch 4214/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0547 - accuracy: 0.8258 - val_loss: 0.0807 - val_accuracy: 0.7452\n",
      "Epoch 4215/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0548 - accuracy: 0.8251 - val_loss: 0.0804 - val_accuracy: 0.7471\n",
      "Epoch 4216/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0548 - accuracy: 0.8248 - val_loss: 0.0796 - val_accuracy: 0.7458\n",
      "Epoch 4217/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0549 - accuracy: 0.8243 - val_loss: 0.0802 - val_accuracy: 0.7462\n",
      "Epoch 4218/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0548 - accuracy: 0.8251 - val_loss: 0.0811 - val_accuracy: 0.7461\n",
      "Epoch 4219/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0547 - accuracy: 0.8251 - val_loss: 0.0791 - val_accuracy: 0.7456\n",
      "Epoch 4220/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0548 - accuracy: 0.8243 - val_loss: 0.0805 - val_accuracy: 0.7459\n",
      "Epoch 4221/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0548 - accuracy: 0.8249 - val_loss: 0.0800 - val_accuracy: 0.7456\n",
      "Epoch 4222/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0547 - accuracy: 0.8253 - val_loss: 0.0803 - val_accuracy: 0.7423\n",
      "Epoch 4223/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0550 - accuracy: 0.8247 - val_loss: 0.0799 - val_accuracy: 0.7450\n",
      "Epoch 4224/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0547 - accuracy: 0.8255 - val_loss: 0.0809 - val_accuracy: 0.7469\n",
      "Epoch 4225/5000\n",
      "11786/11786 [==============================] - 9s 735us/step - loss: 0.0546 - accuracy: 0.8260 - val_loss: 0.0800 - val_accuracy: 0.7443\n",
      "Epoch 4226/5000\n",
      "11786/11786 [==============================] - 9s 732us/step - loss: 0.0547 - accuracy: 0.8248 - val_loss: 0.0813 - val_accuracy: 0.7424\n",
      "Epoch 4227/5000\n",
      "11786/11786 [==============================] - 9s 734us/step - loss: 0.0550 - accuracy: 0.8238 - val_loss: 0.0814 - val_accuracy: 0.7458\n",
      "Epoch 4228/5000\n",
      "11786/11786 [==============================] - 9s 735us/step - loss: 0.0548 - accuracy: 0.8252 - val_loss: 0.0804 - val_accuracy: 0.7444\n",
      "Epoch 4229/5000\n",
      "11786/11786 [==============================] - 9s 734us/step - loss: 0.0548 - accuracy: 0.8247 - val_loss: 0.0799 - val_accuracy: 0.7443\n",
      "Epoch 4230/5000\n",
      "11786/11786 [==============================] - 8s 716us/step - loss: 0.0547 - accuracy: 0.8254 - val_loss: 0.0794 - val_accuracy: 0.7463\n",
      "Epoch 4231/5000\n",
      "11786/11786 [==============================] - 9s 733us/step - loss: 0.0546 - accuracy: 0.8257 - val_loss: 0.0807 - val_accuracy: 0.7461\n",
      "Epoch 4232/5000\n",
      "11786/11786 [==============================] - 9s 745us/step - loss: 0.0546 - accuracy: 0.8257 - val_loss: 0.0799 - val_accuracy: 0.7464\n",
      "Epoch 4233/5000\n",
      "11786/11786 [==============================] - 9s 731us/step - loss: 0.0545 - accuracy: 0.8265 - val_loss: 0.0808 - val_accuracy: 0.7464\n",
      "Epoch 4234/5000\n",
      "11786/11786 [==============================] - 9s 731us/step - loss: 0.0546 - accuracy: 0.8262 - val_loss: 0.0804 - val_accuracy: 0.7458\n",
      "Epoch 4235/5000\n",
      "11786/11786 [==============================] - 9s 734us/step - loss: 0.0547 - accuracy: 0.8255 - val_loss: 0.0814 - val_accuracy: 0.7429\n",
      "Epoch 4236/5000\n",
      "11786/11786 [==============================] - 9s 733us/step - loss: 0.0548 - accuracy: 0.8250 - val_loss: 0.0806 - val_accuracy: 0.7444\n",
      "Epoch 4237/5000\n",
      "11786/11786 [==============================] - 9s 729us/step - loss: 0.0548 - accuracy: 0.8255 - val_loss: 0.0805 - val_accuracy: 0.7449\n",
      "Epoch 4238/5000\n",
      "11786/11786 [==============================] - 9s 731us/step - loss: 0.0548 - accuracy: 0.8255 - val_loss: 0.0801 - val_accuracy: 0.7462\n",
      "Epoch 4239/5000\n",
      "11786/11786 [==============================] - 9s 728us/step - loss: 0.0548 - accuracy: 0.8255 - val_loss: 0.0801 - val_accuracy: 0.7448\n",
      "Epoch 4240/5000\n",
      "11786/11786 [==============================] - 9s 736us/step - loss: 0.0550 - accuracy: 0.8247 - val_loss: 0.0803 - val_accuracy: 0.7450\n",
      "Epoch 4241/5000\n",
      "11786/11786 [==============================] - 9s 734us/step - loss: 0.0548 - accuracy: 0.8252 - val_loss: 0.0816 - val_accuracy: 0.7441\n",
      "Epoch 4242/5000\n",
      "11786/11786 [==============================] - 9s 730us/step - loss: 0.0548 - accuracy: 0.8254 - val_loss: 0.0796 - val_accuracy: 0.7437\n",
      "Epoch 4243/5000\n",
      "11786/11786 [==============================] - 9s 734us/step - loss: 0.0550 - accuracy: 0.8245 - val_loss: 0.0802 - val_accuracy: 0.7466\n",
      "Epoch 4244/5000\n",
      "11786/11786 [==============================] - 9s 741us/step - loss: 0.0547 - accuracy: 0.8256 - val_loss: 0.0803 - val_accuracy: 0.7477\n",
      "Epoch 4245/5000\n",
      "11786/11786 [==============================] - 9s 739us/step - loss: 0.0547 - accuracy: 0.8254 - val_loss: 0.0806 - val_accuracy: 0.7463\n",
      "Epoch 4246/5000\n",
      "11786/11786 [==============================] - 9s 732us/step - loss: 0.0547 - accuracy: 0.8260 - val_loss: 0.0802 - val_accuracy: 0.7462\n",
      "Epoch 4247/5000\n",
      "11786/11786 [==============================] - 9s 729us/step - loss: 0.0548 - accuracy: 0.8256 - val_loss: 0.0814 - val_accuracy: 0.7471\n",
      "Epoch 4248/5000\n",
      "11786/11786 [==============================] - 9s 737us/step - loss: 0.0548 - accuracy: 0.8254 - val_loss: 0.0796 - val_accuracy: 0.7451\n",
      "Epoch 4249/5000\n",
      "11786/11786 [==============================] - 9s 740us/step - loss: 0.0547 - accuracy: 0.8260 - val_loss: 0.0803 - val_accuracy: 0.7477\n",
      "Epoch 4250/5000\n",
      "11786/11786 [==============================] - 9s 730us/step - loss: 0.0548 - accuracy: 0.8259 - val_loss: 0.0800 - val_accuracy: 0.7462\n",
      "Epoch 4251/5000\n",
      "11786/11786 [==============================] - 9s 732us/step - loss: 0.0548 - accuracy: 0.8252 - val_loss: 0.0794 - val_accuracy: 0.7441\n",
      "Epoch 4252/5000\n",
      "11786/11786 [==============================] - 9s 731us/step - loss: 0.0548 - accuracy: 0.8254 - val_loss: 0.0813 - val_accuracy: 0.7480\n",
      "Epoch 4253/5000\n",
      "11786/11786 [==============================] - 9s 728us/step - loss: 0.0547 - accuracy: 0.8259 - val_loss: 0.0804 - val_accuracy: 0.7460\n",
      "Epoch 4254/5000\n",
      "11786/11786 [==============================] - 9s 735us/step - loss: 0.0545 - accuracy: 0.8260 - val_loss: 0.0804 - val_accuracy: 0.7470\n",
      "Epoch 4255/5000\n",
      "11786/11786 [==============================] - 9s 736us/step - loss: 0.0547 - accuracy: 0.8255 - val_loss: 0.0809 - val_accuracy: 0.7377\n",
      "Epoch 4256/5000\n",
      "11786/11786 [==============================] - 9s 743us/step - loss: 0.0548 - accuracy: 0.8251 - val_loss: 0.0827 - val_accuracy: 0.7416\n",
      "Epoch 4257/5000\n",
      "11786/11786 [==============================] - 9s 733us/step - loss: 0.0548 - accuracy: 0.8248 - val_loss: 0.0804 - val_accuracy: 0.7459\n",
      "Epoch 4258/5000\n",
      "11786/11786 [==============================] - 9s 725us/step - loss: 0.0547 - accuracy: 0.8254 - val_loss: 0.0796 - val_accuracy: 0.7463\n",
      "Epoch 4259/5000\n",
      "11786/11786 [==============================] - 9s 738us/step - loss: 0.0547 - accuracy: 0.8259 - val_loss: 0.0804 - val_accuracy: 0.7485\n",
      "Epoch 4260/5000\n",
      "11786/11786 [==============================] - 9s 733us/step - loss: 0.0546 - accuracy: 0.8263 - val_loss: 0.0805 - val_accuracy: 0.7461\n",
      "Epoch 4261/5000\n",
      "11786/11786 [==============================] - 9s 742us/step - loss: 0.0548 - accuracy: 0.8255 - val_loss: 0.0805 - val_accuracy: 0.7460\n",
      "Epoch 4262/5000\n",
      "11786/11786 [==============================] - 9s 732us/step - loss: 0.0548 - accuracy: 0.8249 - val_loss: 0.0806 - val_accuracy: 0.7438\n",
      "Epoch 4263/5000\n",
      "11786/11786 [==============================] - 8s 720us/step - loss: 0.0549 - accuracy: 0.8249 - val_loss: 0.0801 - val_accuracy: 0.7464\n",
      "Epoch 4264/5000\n",
      "11786/11786 [==============================] - 9s 734us/step - loss: 0.0550 - accuracy: 0.8242 - val_loss: 0.0802 - val_accuracy: 0.7454\n",
      "Epoch 4265/5000\n",
      "11786/11786 [==============================] - 9s 725us/step - loss: 0.0551 - accuracy: 0.8243 - val_loss: 0.0805 - val_accuracy: 0.7449\n",
      "Epoch 4266/5000\n",
      "11786/11786 [==============================] - 9s 738us/step - loss: 0.0550 - accuracy: 0.8248 - val_loss: 0.0818 - val_accuracy: 0.7460\n",
      "Epoch 4267/5000\n",
      "11786/11786 [==============================] - 9s 729us/step - loss: 0.0549 - accuracy: 0.8249 - val_loss: 0.0800 - val_accuracy: 0.7442\n",
      "Epoch 4268/5000\n",
      "11786/11786 [==============================] - 9s 732us/step - loss: 0.0549 - accuracy: 0.8249 - val_loss: 0.0803 - val_accuracy: 0.7472\n",
      "Epoch 4269/5000\n",
      "11786/11786 [==============================] - 9s 733us/step - loss: 0.0549 - accuracy: 0.8249 - val_loss: 0.0804 - val_accuracy: 0.7437\n",
      "Epoch 4270/5000\n",
      "11786/11786 [==============================] - 9s 728us/step - loss: 0.0549 - accuracy: 0.8246 - val_loss: 0.0806 - val_accuracy: 0.7449\n",
      "Epoch 4271/5000\n",
      "11786/11786 [==============================] - 9s 740us/step - loss: 0.0547 - accuracy: 0.8259 - val_loss: 0.0804 - val_accuracy: 0.7471\n",
      "Epoch 4272/5000\n",
      "11786/11786 [==============================] - 9s 726us/step - loss: 0.0548 - accuracy: 0.8256 - val_loss: 0.0804 - val_accuracy: 0.7429\n",
      "Epoch 4273/5000\n",
      "11786/11786 [==============================] - 9s 726us/step - loss: 0.0548 - accuracy: 0.8255 - val_loss: 0.0803 - val_accuracy: 0.7462\n",
      "Epoch 4274/5000\n",
      "11786/11786 [==============================] - 9s 742us/step - loss: 0.0550 - accuracy: 0.8246 - val_loss: 0.0802 - val_accuracy: 0.7467\n",
      "Epoch 4275/5000\n",
      "11786/11786 [==============================] - 9s 731us/step - loss: 0.0550 - accuracy: 0.8243 - val_loss: 0.0802 - val_accuracy: 0.7432\n",
      "Epoch 4276/5000\n",
      "11786/11786 [==============================] - 9s 728us/step - loss: 0.0549 - accuracy: 0.8252 - val_loss: 0.0795 - val_accuracy: 0.7462\n",
      "Epoch 4277/5000\n",
      "11786/11786 [==============================] - 9s 738us/step - loss: 0.0547 - accuracy: 0.8263 - val_loss: 0.0800 - val_accuracy: 0.7464\n",
      "Epoch 4278/5000\n",
      "11786/11786 [==============================] - 9s 736us/step - loss: 0.0547 - accuracy: 0.8265 - val_loss: 0.0809 - val_accuracy: 0.7461\n",
      "Epoch 4279/5000\n",
      "11786/11786 [==============================] - 9s 734us/step - loss: 0.0546 - accuracy: 0.8261 - val_loss: 0.0806 - val_accuracy: 0.7470\n",
      "Epoch 4280/5000\n",
      "11786/11786 [==============================] - 9s 735us/step - loss: 0.0548 - accuracy: 0.8256 - val_loss: 0.0805 - val_accuracy: 0.7451\n",
      "Epoch 4281/5000\n",
      "11786/11786 [==============================] - 9s 737us/step - loss: 0.0548 - accuracy: 0.8257 - val_loss: 0.0802 - val_accuracy: 0.7451\n",
      "Epoch 4282/5000\n",
      "11786/11786 [==============================] - 9s 728us/step - loss: 0.0549 - accuracy: 0.8251 - val_loss: 0.0807 - val_accuracy: 0.7458\n",
      "Epoch 4283/5000\n",
      "11786/11786 [==============================] - 9s 731us/step - loss: 0.0549 - accuracy: 0.8248 - val_loss: 0.0801 - val_accuracy: 0.7444\n",
      "Epoch 4284/5000\n",
      "11786/11786 [==============================] - 9s 741us/step - loss: 0.0548 - accuracy: 0.8252 - val_loss: 0.0820 - val_accuracy: 0.7429\n",
      "Epoch 4285/5000\n",
      "11786/11786 [==============================] - 9s 742us/step - loss: 0.0549 - accuracy: 0.8248 - val_loss: 0.0807 - val_accuracy: 0.7423\n",
      "Epoch 4286/5000\n",
      "11786/11786 [==============================] - 9s 727us/step - loss: 0.0548 - accuracy: 0.8255 - val_loss: 0.0808 - val_accuracy: 0.7440\n",
      "Epoch 4287/5000\n",
      "11786/11786 [==============================] - 9s 733us/step - loss: 0.0550 - accuracy: 0.8245 - val_loss: 0.0809 - val_accuracy: 0.7456\n",
      "Epoch 4288/5000\n",
      "11786/11786 [==============================] - 9s 736us/step - loss: 0.0549 - accuracy: 0.8252 - val_loss: 0.0803 - val_accuracy: 0.7464\n",
      "Epoch 4289/5000\n",
      "11786/11786 [==============================] - 9s 736us/step - loss: 0.0549 - accuracy: 0.8253 - val_loss: 0.0804 - val_accuracy: 0.7463\n",
      "Epoch 4290/5000\n",
      "11786/11786 [==============================] - 9s 737us/step - loss: 0.0548 - accuracy: 0.8250 - val_loss: 0.0792 - val_accuracy: 0.7445\n",
      "Epoch 4291/5000\n",
      "11786/11786 [==============================] - 9s 740us/step - loss: 0.0549 - accuracy: 0.8253 - val_loss: 0.0807 - val_accuracy: 0.7442\n",
      "Epoch 4292/5000\n",
      "11786/11786 [==============================] - 9s 730us/step - loss: 0.0548 - accuracy: 0.8249 - val_loss: 0.0809 - val_accuracy: 0.7430\n",
      "Epoch 4293/5000\n",
      "11786/11786 [==============================] - 9s 739us/step - loss: 0.0549 - accuracy: 0.8250 - val_loss: 0.0803 - val_accuracy: 0.7419\n",
      "Epoch 4294/5000\n",
      "11786/11786 [==============================] - 9s 728us/step - loss: 0.0550 - accuracy: 0.8251 - val_loss: 0.0808 - val_accuracy: 0.7460\n",
      "Epoch 4295/5000\n",
      "11786/11786 [==============================] - 9s 725us/step - loss: 0.0551 - accuracy: 0.8246 - val_loss: 0.0803 - val_accuracy: 0.7443\n",
      "Epoch 4296/5000\n",
      "11786/11786 [==============================] - 9s 726us/step - loss: 0.0548 - accuracy: 0.8254 - val_loss: 0.0803 - val_accuracy: 0.7454\n",
      "Epoch 4297/5000\n",
      "11786/11786 [==============================] - 9s 742us/step - loss: 0.0550 - accuracy: 0.8252 - val_loss: 0.0819 - val_accuracy: 0.7459\n",
      "Epoch 4298/5000\n",
      "11786/11786 [==============================] - 9s 731us/step - loss: 0.0551 - accuracy: 0.8250 - val_loss: 0.0806 - val_accuracy: 0.7448\n",
      "Epoch 4299/5000\n",
      "11786/11786 [==============================] - 9s 733us/step - loss: 0.0549 - accuracy: 0.8254 - val_loss: 0.0802 - val_accuracy: 0.7462\n",
      "Epoch 4300/5000\n",
      "11786/11786 [==============================] - 9s 731us/step - loss: 0.0548 - accuracy: 0.8257 - val_loss: 0.0812 - val_accuracy: 0.7458\n",
      "Epoch 4301/5000\n",
      "11786/11786 [==============================] - 9s 724us/step - loss: 0.0547 - accuracy: 0.8263 - val_loss: 0.0801 - val_accuracy: 0.7451\n",
      "Epoch 4302/5000\n",
      "11786/11786 [==============================] - 9s 738us/step - loss: 0.0550 - accuracy: 0.8254 - val_loss: 0.0800 - val_accuracy: 0.7464\n",
      "Epoch 4303/5000\n",
      "11786/11786 [==============================] - 9s 740us/step - loss: 0.0550 - accuracy: 0.8252 - val_loss: 0.0798 - val_accuracy: 0.7423\n",
      "Epoch 4304/5000\n",
      "11786/11786 [==============================] - 9s 728us/step - loss: 0.0550 - accuracy: 0.8250 - val_loss: 0.0818 - val_accuracy: 0.7435\n",
      "Epoch 4305/5000\n",
      "11786/11786 [==============================] - 9s 735us/step - loss: 0.0549 - accuracy: 0.8258 - val_loss: 0.0805 - val_accuracy: 0.7466\n",
      "Epoch 4306/5000\n",
      "11786/11786 [==============================] - 9s 733us/step - loss: 0.0549 - accuracy: 0.8256 - val_loss: 0.0801 - val_accuracy: 0.7460\n",
      "Epoch 4307/5000\n",
      "11786/11786 [==============================] - 9s 727us/step - loss: 0.0548 - accuracy: 0.8262 - val_loss: 0.0791 - val_accuracy: 0.7497\n",
      "Epoch 4308/5000\n",
      "11786/11786 [==============================] - 9s 731us/step - loss: 0.0548 - accuracy: 0.8258 - val_loss: 0.0802 - val_accuracy: 0.7438\n",
      "Epoch 4309/5000\n",
      "11786/11786 [==============================] - 9s 725us/step - loss: 0.0549 - accuracy: 0.8252 - val_loss: 0.0816 - val_accuracy: 0.7423\n",
      "Epoch 4310/5000\n",
      "11786/11786 [==============================] - 9s 738us/step - loss: 0.0551 - accuracy: 0.8248 - val_loss: 0.0809 - val_accuracy: 0.7431\n",
      "Epoch 4311/5000\n",
      "11786/11786 [==============================] - 9s 734us/step - loss: 0.0549 - accuracy: 0.8250 - val_loss: 0.0812 - val_accuracy: 0.7453\n",
      "Epoch 4312/5000\n",
      "11786/11786 [==============================] - 9s 744us/step - loss: 0.0550 - accuracy: 0.8247 - val_loss: 0.0798 - val_accuracy: 0.7435\n",
      "Epoch 4313/5000\n",
      "11786/11786 [==============================] - 9s 741us/step - loss: 0.0551 - accuracy: 0.8243 - val_loss: 0.0809 - val_accuracy: 0.7427\n",
      "Epoch 4314/5000\n",
      "11786/11786 [==============================] - 9s 736us/step - loss: 0.0551 - accuracy: 0.8246 - val_loss: 0.0801 - val_accuracy: 0.7447\n",
      "Epoch 4315/5000\n",
      "11786/11786 [==============================] - 9s 729us/step - loss: 0.0551 - accuracy: 0.8245 - val_loss: 0.0806 - val_accuracy: 0.7450\n",
      "Epoch 4316/5000\n",
      "11786/11786 [==============================] - 9s 737us/step - loss: 0.0549 - accuracy: 0.8254 - val_loss: 0.0802 - val_accuracy: 0.7465\n",
      "Epoch 4317/5000\n",
      "11786/11786 [==============================] - 9s 736us/step - loss: 0.0551 - accuracy: 0.8241 - val_loss: 0.0805 - val_accuracy: 0.7450\n",
      "Epoch 4318/5000\n",
      "11786/11786 [==============================] - 9s 736us/step - loss: 0.0551 - accuracy: 0.8250 - val_loss: 0.0805 - val_accuracy: 0.7443\n",
      "Epoch 4319/5000\n",
      "11786/11786 [==============================] - 9s 735us/step - loss: 0.0553 - accuracy: 0.8236 - val_loss: 0.0817 - val_accuracy: 0.7420\n",
      "Epoch 4320/5000\n",
      "11786/11786 [==============================] - 9s 736us/step - loss: 0.0553 - accuracy: 0.8237 - val_loss: 0.0806 - val_accuracy: 0.7450\n",
      "Epoch 4321/5000\n",
      "11786/11786 [==============================] - 9s 736us/step - loss: 0.0549 - accuracy: 0.8255 - val_loss: 0.0811 - val_accuracy: 0.7463\n",
      "Epoch 4322/5000\n",
      "11786/11786 [==============================] - 9s 746us/step - loss: 0.0551 - accuracy: 0.8243 - val_loss: 0.0809 - val_accuracy: 0.7450\n",
      "Epoch 4323/5000\n",
      "11786/11786 [==============================] - 9s 733us/step - loss: 0.0552 - accuracy: 0.8241 - val_loss: 0.0790 - val_accuracy: 0.7458\n",
      "Epoch 4324/5000\n",
      "11786/11786 [==============================] - 9s 733us/step - loss: 0.0552 - accuracy: 0.8237 - val_loss: 0.0804 - val_accuracy: 0.7459\n",
      "Epoch 4325/5000\n",
      "11786/11786 [==============================] - 9s 735us/step - loss: 0.0553 - accuracy: 0.8237 - val_loss: 0.0808 - val_accuracy: 0.7437\n",
      "Epoch 4326/5000\n",
      "11786/11786 [==============================] - 9s 734us/step - loss: 0.0551 - accuracy: 0.8248 - val_loss: 0.0797 - val_accuracy: 0.7443\n",
      "Epoch 4327/5000\n",
      "11786/11786 [==============================] - 9s 729us/step - loss: 0.0551 - accuracy: 0.8244 - val_loss: 0.0802 - val_accuracy: 0.7454\n",
      "Epoch 4328/5000\n",
      "11786/11786 [==============================] - 9s 736us/step - loss: 0.0552 - accuracy: 0.8240 - val_loss: 0.0813 - val_accuracy: 0.7449\n",
      "Epoch 4329/5000\n",
      "11786/11786 [==============================] - 9s 738us/step - loss: 0.0558 - accuracy: 0.8221 - val_loss: 0.0811 - val_accuracy: 0.7438\n",
      "Epoch 4330/5000\n",
      "11786/11786 [==============================] - 9s 738us/step - loss: 0.0558 - accuracy: 0.8224 - val_loss: 0.0800 - val_accuracy: 0.7415\n",
      "Epoch 4331/5000\n",
      "11786/11786 [==============================] - 9s 740us/step - loss: 0.0557 - accuracy: 0.8229 - val_loss: 0.0801 - val_accuracy: 0.7436\n",
      "Epoch 4332/5000\n",
      "11786/11786 [==============================] - 9s 734us/step - loss: 0.0558 - accuracy: 0.8224 - val_loss: 0.0807 - val_accuracy: 0.7443\n",
      "Epoch 4333/5000\n",
      "11786/11786 [==============================] - 9s 741us/step - loss: 0.0554 - accuracy: 0.8235 - val_loss: 0.0815 - val_accuracy: 0.7421\n",
      "Epoch 4334/5000\n",
      "11786/11786 [==============================] - 9s 731us/step - loss: 0.0556 - accuracy: 0.8227 - val_loss: 0.0793 - val_accuracy: 0.7459\n",
      "Epoch 4335/5000\n",
      "11786/11786 [==============================] - 9s 733us/step - loss: 0.0555 - accuracy: 0.8231 - val_loss: 0.0800 - val_accuracy: 0.7432\n",
      "Epoch 4336/5000\n",
      "11786/11786 [==============================] - 9s 737us/step - loss: 0.0556 - accuracy: 0.8230 - val_loss: 0.0818 - val_accuracy: 0.7423\n",
      "Epoch 4337/5000\n",
      "11786/11786 [==============================] - 9s 734us/step - loss: 0.0554 - accuracy: 0.8230 - val_loss: 0.0809 - val_accuracy: 0.7462\n",
      "Epoch 4338/5000\n",
      "11786/11786 [==============================] - 9s 733us/step - loss: 0.0552 - accuracy: 0.8239 - val_loss: 0.0800 - val_accuracy: 0.7454\n",
      "Epoch 4339/5000\n",
      "11786/11786 [==============================] - 9s 738us/step - loss: 0.0554 - accuracy: 0.8228 - val_loss: 0.0795 - val_accuracy: 0.7437\n",
      "Epoch 4340/5000\n",
      "11786/11786 [==============================] - 9s 732us/step - loss: 0.0551 - accuracy: 0.8239 - val_loss: 0.0815 - val_accuracy: 0.7446\n",
      "Epoch 4341/5000\n",
      "11786/11786 [==============================] - 9s 729us/step - loss: 0.0553 - accuracy: 0.8237 - val_loss: 0.0807 - val_accuracy: 0.7440\n",
      "Epoch 4342/5000\n",
      "11786/11786 [==============================] - 9s 740us/step - loss: 0.0552 - accuracy: 0.8236 - val_loss: 0.0803 - val_accuracy: 0.7439\n",
      "Epoch 4343/5000\n",
      "11786/11786 [==============================] - 9s 732us/step - loss: 0.0552 - accuracy: 0.8240 - val_loss: 0.0800 - val_accuracy: 0.7451\n",
      "Epoch 4344/5000\n",
      "11786/11786 [==============================] - 9s 733us/step - loss: 0.0553 - accuracy: 0.8243 - val_loss: 0.0800 - val_accuracy: 0.7448\n",
      "Epoch 4345/5000\n",
      "11786/11786 [==============================] - 9s 736us/step - loss: 0.0553 - accuracy: 0.8239 - val_loss: 0.0817 - val_accuracy: 0.7436\n",
      "Epoch 4346/5000\n",
      "11786/11786 [==============================] - 9s 732us/step - loss: 0.0555 - accuracy: 0.8227 - val_loss: 0.0818 - val_accuracy: 0.7411\n",
      "Epoch 4347/5000\n",
      "11786/11786 [==============================] - 9s 735us/step - loss: 0.0558 - accuracy: 0.8222 - val_loss: 0.0821 - val_accuracy: 0.7398\n",
      "Epoch 4348/5000\n",
      "11786/11786 [==============================] - 9s 723us/step - loss: 0.0555 - accuracy: 0.8231 - val_loss: 0.0808 - val_accuracy: 0.7458\n",
      "Epoch 4349/5000\n",
      "11786/11786 [==============================] - 9s 734us/step - loss: 0.0552 - accuracy: 0.8239 - val_loss: 0.0806 - val_accuracy: 0.7430\n",
      "Epoch 4350/5000\n",
      "11786/11786 [==============================] - 9s 733us/step - loss: 0.0550 - accuracy: 0.8245 - val_loss: 0.0803 - val_accuracy: 0.7449\n",
      "Epoch 4351/5000\n",
      "11786/11786 [==============================] - 9s 741us/step - loss: 0.0550 - accuracy: 0.8250 - val_loss: 0.0808 - val_accuracy: 0.7451\n",
      "Epoch 4352/5000\n",
      "11786/11786 [==============================] - 9s 739us/step - loss: 0.0551 - accuracy: 0.8248 - val_loss: 0.0802 - val_accuracy: 0.7444\n",
      "Epoch 4353/5000\n",
      "11786/11786 [==============================] - 9s 728us/step - loss: 0.0554 - accuracy: 0.8237 - val_loss: 0.0807 - val_accuracy: 0.7448\n",
      "Epoch 4354/5000\n",
      "11786/11786 [==============================] - 9s 738us/step - loss: 0.0551 - accuracy: 0.8248 - val_loss: 0.0799 - val_accuracy: 0.7469\n",
      "Epoch 4355/5000\n",
      "11786/11786 [==============================] - 9s 735us/step - loss: 0.0551 - accuracy: 0.8243 - val_loss: 0.0798 - val_accuracy: 0.7449\n",
      "Epoch 4356/5000\n",
      "11786/11786 [==============================] - 9s 736us/step - loss: 0.0549 - accuracy: 0.8252 - val_loss: 0.0803 - val_accuracy: 0.7450\n",
      "Epoch 4357/5000\n",
      "11786/11786 [==============================] - 9s 731us/step - loss: 0.0551 - accuracy: 0.8249 - val_loss: 0.0799 - val_accuracy: 0.7461\n",
      "Epoch 4358/5000\n",
      "11786/11786 [==============================] - 9s 729us/step - loss: 0.0553 - accuracy: 0.8234 - val_loss: 0.0796 - val_accuracy: 0.7448\n",
      "Epoch 4359/5000\n",
      "11786/11786 [==============================] - 9s 733us/step - loss: 0.0553 - accuracy: 0.8229 - val_loss: 0.0810 - val_accuracy: 0.7406\n",
      "Epoch 4360/5000\n",
      "11786/11786 [==============================] - 9s 734us/step - loss: 0.0555 - accuracy: 0.8233 - val_loss: 0.0803 - val_accuracy: 0.7443\n",
      "Epoch 4361/5000\n",
      "11786/11786 [==============================] - 9s 740us/step - loss: 0.0555 - accuracy: 0.8225 - val_loss: 0.0809 - val_accuracy: 0.7436\n",
      "Epoch 4362/5000\n",
      "11786/11786 [==============================] - 9s 725us/step - loss: 0.0555 - accuracy: 0.8228 - val_loss: 0.0806 - val_accuracy: 0.7456\n",
      "Epoch 4363/5000\n",
      "11786/11786 [==============================] - 9s 737us/step - loss: 0.0553 - accuracy: 0.8232 - val_loss: 0.0803 - val_accuracy: 0.7438\n",
      "Epoch 4364/5000\n",
      "11786/11786 [==============================] - 9s 733us/step - loss: 0.0554 - accuracy: 0.8226 - val_loss: 0.0816 - val_accuracy: 0.7404\n",
      "Epoch 4365/5000\n",
      "11786/11786 [==============================] - 9s 734us/step - loss: 0.0556 - accuracy: 0.8221 - val_loss: 0.0804 - val_accuracy: 0.7429\n",
      "Epoch 4366/5000\n",
      "11786/11786 [==============================] - 9s 736us/step - loss: 0.0553 - accuracy: 0.8235 - val_loss: 0.0802 - val_accuracy: 0.7455\n",
      "Epoch 4367/5000\n",
      "11786/11786 [==============================] - 9s 729us/step - loss: 0.0555 - accuracy: 0.8229 - val_loss: 0.0808 - val_accuracy: 0.7448\n",
      "Epoch 4368/5000\n",
      "11786/11786 [==============================] - 9s 740us/step - loss: 0.0553 - accuracy: 0.8235 - val_loss: 0.0808 - val_accuracy: 0.7414\n",
      "Epoch 4369/5000\n",
      "11786/11786 [==============================] - 9s 733us/step - loss: 0.0551 - accuracy: 0.8237 - val_loss: 0.0806 - val_accuracy: 0.7408\n",
      "Epoch 4370/5000\n",
      "11786/11786 [==============================] - 9s 729us/step - loss: 0.0551 - accuracy: 0.8238 - val_loss: 0.0805 - val_accuracy: 0.7463\n",
      "Epoch 4371/5000\n",
      "11786/11786 [==============================] - 9s 735us/step - loss: 0.0550 - accuracy: 0.8244 - val_loss: 0.0801 - val_accuracy: 0.7439\n",
      "Epoch 4372/5000\n",
      "11786/11786 [==============================] - 9s 733us/step - loss: 0.0553 - accuracy: 0.8234 - val_loss: 0.0805 - val_accuracy: 0.7434\n",
      "Epoch 4373/5000\n",
      "11786/11786 [==============================] - 9s 737us/step - loss: 0.0552 - accuracy: 0.8239 - val_loss: 0.0809 - val_accuracy: 0.7464\n",
      "Epoch 4374/5000\n",
      "11786/11786 [==============================] - 9s 729us/step - loss: 0.0555 - accuracy: 0.8228 - val_loss: 0.0802 - val_accuracy: 0.7443\n",
      "Epoch 4375/5000\n",
      "11786/11786 [==============================] - 9s 727us/step - loss: 0.0552 - accuracy: 0.8240 - val_loss: 0.0808 - val_accuracy: 0.7422\n",
      "Epoch 4376/5000\n",
      "11786/11786 [==============================] - 9s 732us/step - loss: 0.0553 - accuracy: 0.8233 - val_loss: 0.0798 - val_accuracy: 0.7463\n",
      "Epoch 4377/5000\n",
      "11786/11786 [==============================] - 9s 734us/step - loss: 0.0554 - accuracy: 0.8233 - val_loss: 0.0815 - val_accuracy: 0.7435\n",
      "Epoch 4378/5000\n",
      "11786/11786 [==============================] - 9s 747us/step - loss: 0.0554 - accuracy: 0.8230 - val_loss: 0.0805 - val_accuracy: 0.7424\n",
      "Epoch 4379/5000\n",
      "11786/11786 [==============================] - 9s 725us/step - loss: 0.0553 - accuracy: 0.8231 - val_loss: 0.0807 - val_accuracy: 0.7418\n",
      "Epoch 4380/5000\n",
      "11786/11786 [==============================] - 9s 739us/step - loss: 0.0553 - accuracy: 0.8237 - val_loss: 0.0795 - val_accuracy: 0.7453\n",
      "Epoch 4381/5000\n",
      "11786/11786 [==============================] - 9s 732us/step - loss: 0.0555 - accuracy: 0.8227 - val_loss: 0.0802 - val_accuracy: 0.7429\n",
      "Epoch 4382/5000\n",
      "11786/11786 [==============================] - 9s 740us/step - loss: 0.0553 - accuracy: 0.8232 - val_loss: 0.0823 - val_accuracy: 0.7433\n",
      "Epoch 4383/5000\n",
      "11786/11786 [==============================] - 9s 737us/step - loss: 0.0555 - accuracy: 0.8230 - val_loss: 0.0800 - val_accuracy: 0.7438\n",
      "Epoch 4384/5000\n",
      "11786/11786 [==============================] - 9s 732us/step - loss: 0.0554 - accuracy: 0.8226 - val_loss: 0.0811 - val_accuracy: 0.7425\n",
      "Epoch 4385/5000\n",
      "11786/11786 [==============================] - 9s 731us/step - loss: 0.0557 - accuracy: 0.8219 - val_loss: 0.0798 - val_accuracy: 0.7445\n",
      "Epoch 4386/5000\n",
      "11786/11786 [==============================] - 9s 734us/step - loss: 0.0556 - accuracy: 0.8223 - val_loss: 0.0813 - val_accuracy: 0.7426\n",
      "Epoch 4387/5000\n",
      "11786/11786 [==============================] - 9s 737us/step - loss: 0.0555 - accuracy: 0.8222 - val_loss: 0.0806 - val_accuracy: 0.7454\n",
      "Epoch 4388/5000\n",
      "11786/11786 [==============================] - 9s 735us/step - loss: 0.0555 - accuracy: 0.8227 - val_loss: 0.0810 - val_accuracy: 0.7419\n",
      "Epoch 4389/5000\n",
      "11786/11786 [==============================] - 9s 731us/step - loss: 0.0556 - accuracy: 0.8223 - val_loss: 0.0814 - val_accuracy: 0.7406\n",
      "Epoch 4390/5000\n",
      "11786/11786 [==============================] - 9s 730us/step - loss: 0.0555 - accuracy: 0.8228 - val_loss: 0.0806 - val_accuracy: 0.7428\n",
      "Epoch 4391/5000\n",
      "11786/11786 [==============================] - 9s 744us/step - loss: 0.0553 - accuracy: 0.8231 - val_loss: 0.0805 - val_accuracy: 0.7435\n",
      "Epoch 4392/5000\n",
      "11786/11786 [==============================] - 9s 740us/step - loss: 0.0555 - accuracy: 0.8226 - val_loss: 0.0799 - val_accuracy: 0.7425\n",
      "Epoch 4393/5000\n",
      "11786/11786 [==============================] - 9s 737us/step - loss: 0.0556 - accuracy: 0.8223 - val_loss: 0.0818 - val_accuracy: 0.7430\n",
      "Epoch 4394/5000\n",
      "11786/11786 [==============================] - 9s 735us/step - loss: 0.0556 - accuracy: 0.8226 - val_loss: 0.0809 - val_accuracy: 0.7430\n",
      "Epoch 4395/5000\n",
      "11786/11786 [==============================] - 9s 732us/step - loss: 0.0555 - accuracy: 0.8229 - val_loss: 0.0808 - val_accuracy: 0.7446\n",
      "Epoch 4396/5000\n",
      "11786/11786 [==============================] - 9s 734us/step - loss: 0.0554 - accuracy: 0.8229 - val_loss: 0.0812 - val_accuracy: 0.7440\n",
      "Epoch 4397/5000\n",
      "11786/11786 [==============================] - 9s 733us/step - loss: 0.0555 - accuracy: 0.8227 - val_loss: 0.0800 - val_accuracy: 0.7417\n",
      "Epoch 4398/5000\n",
      "11786/11786 [==============================] - 9s 729us/step - loss: 0.0554 - accuracy: 0.8234 - val_loss: 0.0819 - val_accuracy: 0.7452\n",
      "Epoch 4399/5000\n",
      "11786/11786 [==============================] - 9s 741us/step - loss: 0.0555 - accuracy: 0.8229 - val_loss: 0.0814 - val_accuracy: 0.7438\n",
      "Epoch 4400/5000\n",
      "11786/11786 [==============================] - 9s 731us/step - loss: 0.0552 - accuracy: 0.8237 - val_loss: 0.0809 - val_accuracy: 0.7453\n",
      "Epoch 4401/5000\n",
      "11786/11786 [==============================] - 9s 742us/step - loss: 0.0555 - accuracy: 0.8229 - val_loss: 0.0805 - val_accuracy: 0.7438\n",
      "Epoch 4402/5000\n",
      "11786/11786 [==============================] - 9s 737us/step - loss: 0.0557 - accuracy: 0.8215 - val_loss: 0.0807 - val_accuracy: 0.7439\n",
      "Epoch 4403/5000\n",
      "11786/11786 [==============================] - 9s 732us/step - loss: 0.0555 - accuracy: 0.8227 - val_loss: 0.0832 - val_accuracy: 0.7398\n",
      "Epoch 4404/5000\n",
      "11786/11786 [==============================] - 9s 741us/step - loss: 0.0556 - accuracy: 0.8227 - val_loss: 0.0815 - val_accuracy: 0.7449\n",
      "Epoch 4405/5000\n",
      "11786/11786 [==============================] - 9s 749us/step - loss: 0.0559 - accuracy: 0.8210 - val_loss: 0.0802 - val_accuracy: 0.7417\n",
      "Epoch 4406/5000\n",
      "11786/11786 [==============================] - 8s 721us/step - loss: 0.0556 - accuracy: 0.8222 - val_loss: 0.0806 - val_accuracy: 0.7435\n",
      "Epoch 4407/5000\n",
      "11786/11786 [==============================] - 9s 732us/step - loss: 0.0555 - accuracy: 0.8222 - val_loss: 0.0814 - val_accuracy: 0.7439\n",
      "Epoch 4408/5000\n",
      "11786/11786 [==============================] - 9s 727us/step - loss: 0.0557 - accuracy: 0.8221 - val_loss: 0.0804 - val_accuracy: 0.7423\n",
      "Epoch 4409/5000\n",
      "11786/11786 [==============================] - 9s 735us/step - loss: 0.0556 - accuracy: 0.8218 - val_loss: 0.0811 - val_accuracy: 0.7444\n",
      "Epoch 4410/5000\n",
      "11786/11786 [==============================] - 9s 740us/step - loss: 0.0557 - accuracy: 0.8217 - val_loss: 0.0813 - val_accuracy: 0.7445\n",
      "Epoch 4411/5000\n",
      "11786/11786 [==============================] - 9s 731us/step - loss: 0.0556 - accuracy: 0.8226 - val_loss: 0.0829 - val_accuracy: 0.7425\n",
      "Epoch 4412/5000\n",
      "11786/11786 [==============================] - 9s 736us/step - loss: 0.0555 - accuracy: 0.8226 - val_loss: 0.0801 - val_accuracy: 0.7421\n",
      "Epoch 4413/5000\n",
      "11786/11786 [==============================] - 9s 734us/step - loss: 0.0557 - accuracy: 0.8216 - val_loss: 0.0814 - val_accuracy: 0.7437\n",
      "Epoch 4414/5000\n",
      "11786/11786 [==============================] - 9s 739us/step - loss: 0.0558 - accuracy: 0.8215 - val_loss: 0.0808 - val_accuracy: 0.7447\n",
      "Epoch 4415/5000\n",
      "11786/11786 [==============================] - 9s 734us/step - loss: 0.0555 - accuracy: 0.8227 - val_loss: 0.0813 - val_accuracy: 0.7422\n",
      "Epoch 4416/5000\n",
      "11786/11786 [==============================] - 9s 741us/step - loss: 0.0554 - accuracy: 0.8226 - val_loss: 0.0813 - val_accuracy: 0.7445\n",
      "Epoch 4417/5000\n",
      "11786/11786 [==============================] - 9s 741us/step - loss: 0.0555 - accuracy: 0.8230 - val_loss: 0.0805 - val_accuracy: 0.7443\n",
      "Epoch 4418/5000\n",
      "11786/11786 [==============================] - 9s 730us/step - loss: 0.0554 - accuracy: 0.8236 - val_loss: 0.0806 - val_accuracy: 0.7432\n",
      "Epoch 4419/5000\n",
      "11786/11786 [==============================] - 9s 725us/step - loss: 0.0554 - accuracy: 0.8240 - val_loss: 0.0825 - val_accuracy: 0.7417\n",
      "Epoch 4420/5000\n",
      "11786/11786 [==============================] - 9s 736us/step - loss: 0.0553 - accuracy: 0.8240 - val_loss: 0.0796 - val_accuracy: 0.7469\n",
      "Epoch 4421/5000\n",
      "11786/11786 [==============================] - 9s 744us/step - loss: 0.0553 - accuracy: 0.8238 - val_loss: 0.0804 - val_accuracy: 0.7452\n",
      "Epoch 4422/5000\n",
      "11786/11786 [==============================] - 9s 730us/step - loss: 0.0552 - accuracy: 0.8234 - val_loss: 0.0809 - val_accuracy: 0.7430\n",
      "Epoch 4423/5000\n",
      "11786/11786 [==============================] - 9s 732us/step - loss: 0.0553 - accuracy: 0.8232 - val_loss: 0.0796 - val_accuracy: 0.7450\n",
      "Epoch 4424/5000\n",
      "11786/11786 [==============================] - 9s 729us/step - loss: 0.0551 - accuracy: 0.8246 - val_loss: 0.0815 - val_accuracy: 0.7456\n",
      "Epoch 4425/5000\n",
      "11786/11786 [==============================] - 9s 739us/step - loss: 0.0553 - accuracy: 0.8232 - val_loss: 0.0804 - val_accuracy: 0.7445\n",
      "Epoch 4426/5000\n",
      "11786/11786 [==============================] - 9s 733us/step - loss: 0.0555 - accuracy: 0.8229 - val_loss: 0.0797 - val_accuracy: 0.7421\n",
      "Epoch 4427/5000\n",
      "11786/11786 [==============================] - 9s 744us/step - loss: 0.0553 - accuracy: 0.8236 - val_loss: 0.0812 - val_accuracy: 0.7427\n",
      "Epoch 4428/5000\n",
      "11786/11786 [==============================] - 9s 730us/step - loss: 0.0552 - accuracy: 0.8237 - val_loss: 0.0798 - val_accuracy: 0.7444\n",
      "Epoch 4429/5000\n",
      "11786/11786 [==============================] - 9s 741us/step - loss: 0.0551 - accuracy: 0.8242 - val_loss: 0.0808 - val_accuracy: 0.7438\n",
      "Epoch 4430/5000\n",
      "11786/11786 [==============================] - 9s 735us/step - loss: 0.0556 - accuracy: 0.8229 - val_loss: 0.0810 - val_accuracy: 0.7450\n",
      "Epoch 4431/5000\n",
      "11786/11786 [==============================] - 9s 732us/step - loss: 0.0555 - accuracy: 0.8227 - val_loss: 0.0804 - val_accuracy: 0.7421\n",
      "Epoch 4432/5000\n",
      "11786/11786 [==============================] - 9s 726us/step - loss: 0.0554 - accuracy: 0.8233 - val_loss: 0.0806 - val_accuracy: 0.7441\n",
      "Epoch 4433/5000\n",
      "11786/11786 [==============================] - 9s 728us/step - loss: 0.0555 - accuracy: 0.8225 - val_loss: 0.0822 - val_accuracy: 0.7400\n",
      "Epoch 4434/5000\n",
      "11786/11786 [==============================] - 9s 727us/step - loss: 0.0555 - accuracy: 0.8229 - val_loss: 0.0808 - val_accuracy: 0.7450\n",
      "Epoch 4435/5000\n",
      "11786/11786 [==============================] - 9s 736us/step - loss: 0.0554 - accuracy: 0.8234 - val_loss: 0.0804 - val_accuracy: 0.7448\n",
      "Epoch 4436/5000\n",
      "11786/11786 [==============================] - 8s 718us/step - loss: 0.0556 - accuracy: 0.8229 - val_loss: 0.0811 - val_accuracy: 0.7433\n",
      "Epoch 4437/5000\n",
      "11786/11786 [==============================] - 9s 733us/step - loss: 0.0552 - accuracy: 0.8240 - val_loss: 0.0811 - val_accuracy: 0.7435\n",
      "Epoch 4438/5000\n",
      "11786/11786 [==============================] - 9s 734us/step - loss: 0.0558 - accuracy: 0.8224 - val_loss: 0.0806 - val_accuracy: 0.7440\n",
      "Epoch 4439/5000\n",
      "11786/11786 [==============================] - 9s 741us/step - loss: 0.0556 - accuracy: 0.8225 - val_loss: 0.0799 - val_accuracy: 0.7424\n",
      "Epoch 4440/5000\n",
      "11786/11786 [==============================] - 9s 733us/step - loss: 0.0556 - accuracy: 0.8230 - val_loss: 0.0823 - val_accuracy: 0.7422\n",
      "Epoch 4441/5000\n",
      "11786/11786 [==============================] - 9s 733us/step - loss: 0.0555 - accuracy: 0.8230 - val_loss: 0.0804 - val_accuracy: 0.7444\n",
      "Epoch 4442/5000\n",
      "11786/11786 [==============================] - 9s 741us/step - loss: 0.0555 - accuracy: 0.8225 - val_loss: 0.0814 - val_accuracy: 0.7440\n",
      "Epoch 4443/5000\n",
      "11786/11786 [==============================] - 9s 737us/step - loss: 0.0555 - accuracy: 0.8225 - val_loss: 0.0806 - val_accuracy: 0.7431\n",
      "Epoch 4444/5000\n",
      "11786/11786 [==============================] - 9s 732us/step - loss: 0.0555 - accuracy: 0.8230 - val_loss: 0.0801 - val_accuracy: 0.7461\n",
      "Epoch 4445/5000\n",
      "11786/11786 [==============================] - 9s 730us/step - loss: 0.0553 - accuracy: 0.8230 - val_loss: 0.0809 - val_accuracy: 0.7458\n",
      "Epoch 4446/5000\n",
      "11786/11786 [==============================] - 9s 736us/step - loss: 0.0551 - accuracy: 0.8240 - val_loss: 0.0802 - val_accuracy: 0.7380\n",
      "Epoch 4447/5000\n",
      "11786/11786 [==============================] - 9s 732us/step - loss: 0.0553 - accuracy: 0.8233 - val_loss: 0.0794 - val_accuracy: 0.7463\n",
      "Epoch 4448/5000\n",
      "11786/11786 [==============================] - 9s 731us/step - loss: 0.0554 - accuracy: 0.8231 - val_loss: 0.0803 - val_accuracy: 0.7473\n",
      "Epoch 4449/5000\n",
      "11786/11786 [==============================] - 9s 738us/step - loss: 0.0553 - accuracy: 0.8231 - val_loss: 0.0810 - val_accuracy: 0.7436\n",
      "Epoch 4450/5000\n",
      "11786/11786 [==============================] - 9s 726us/step - loss: 0.0557 - accuracy: 0.8218 - val_loss: 0.0811 - val_accuracy: 0.7410\n",
      "Epoch 4451/5000\n",
      "11786/11786 [==============================] - 9s 729us/step - loss: 0.0556 - accuracy: 0.8224 - val_loss: 0.0809 - val_accuracy: 0.7423\n",
      "Epoch 4452/5000\n",
      "11786/11786 [==============================] - 9s 737us/step - loss: 0.0556 - accuracy: 0.8226 - val_loss: 0.0811 - val_accuracy: 0.7411\n",
      "Epoch 4453/5000\n",
      "11786/11786 [==============================] - 9s 733us/step - loss: 0.0557 - accuracy: 0.8218 - val_loss: 0.0822 - val_accuracy: 0.7386\n",
      "Epoch 4454/5000\n",
      "11786/11786 [==============================] - 9s 733us/step - loss: 0.0558 - accuracy: 0.8216 - val_loss: 0.0808 - val_accuracy: 0.7433\n",
      "Epoch 4455/5000\n",
      "11786/11786 [==============================] - 9s 733us/step - loss: 0.0557 - accuracy: 0.8220 - val_loss: 0.0812 - val_accuracy: 0.7442\n",
      "Epoch 4456/5000\n",
      "11786/11786 [==============================] - 9s 738us/step - loss: 0.0553 - accuracy: 0.8233 - val_loss: 0.0809 - val_accuracy: 0.7438\n",
      "Epoch 4457/5000\n",
      "11786/11786 [==============================] - 9s 736us/step - loss: 0.0554 - accuracy: 0.8236 - val_loss: 0.0804 - val_accuracy: 0.7433\n",
      "Epoch 4458/5000\n",
      "11786/11786 [==============================] - 9s 734us/step - loss: 0.0556 - accuracy: 0.8231 - val_loss: 0.0811 - val_accuracy: 0.7450\n",
      "Epoch 4459/5000\n",
      "11786/11786 [==============================] - 9s 731us/step - loss: 0.0554 - accuracy: 0.8233 - val_loss: 0.0806 - val_accuracy: 0.7453\n",
      "Epoch 4460/5000\n",
      "11786/11786 [==============================] - 9s 742us/step - loss: 0.0553 - accuracy: 0.8237 - val_loss: 0.0811 - val_accuracy: 0.7438\n",
      "Epoch 4461/5000\n",
      "11786/11786 [==============================] - 9s 739us/step - loss: 0.0554 - accuracy: 0.8236 - val_loss: 0.0810 - val_accuracy: 0.7428\n",
      "Epoch 4462/5000\n",
      "11786/11786 [==============================] - 9s 734us/step - loss: 0.0555 - accuracy: 0.8230 - val_loss: 0.0797 - val_accuracy: 0.7437\n",
      "Epoch 4463/5000\n",
      "11786/11786 [==============================] - 9s 730us/step - loss: 0.0553 - accuracy: 0.8234 - val_loss: 0.0807 - val_accuracy: 0.7442\n",
      "Epoch 4464/5000\n",
      "11786/11786 [==============================] - 9s 733us/step - loss: 0.0554 - accuracy: 0.8228 - val_loss: 0.0803 - val_accuracy: 0.7445\n",
      "Epoch 4465/5000\n",
      "11786/11786 [==============================] - 9s 726us/step - loss: 0.0555 - accuracy: 0.8226 - val_loss: 0.0810 - val_accuracy: 0.7433\n",
      "Epoch 4466/5000\n",
      "11786/11786 [==============================] - 9s 738us/step - loss: 0.0556 - accuracy: 0.8227 - val_loss: 0.0807 - val_accuracy: 0.7456\n",
      "Epoch 4467/5000\n",
      "11786/11786 [==============================] - 9s 733us/step - loss: 0.0555 - accuracy: 0.8229 - val_loss: 0.0810 - val_accuracy: 0.7433\n",
      "Epoch 4468/5000\n",
      "11786/11786 [==============================] - 8s 721us/step - loss: 0.0556 - accuracy: 0.8226 - val_loss: 0.0812 - val_accuracy: 0.7418\n",
      "Epoch 4469/5000\n",
      "11786/11786 [==============================] - 9s 729us/step - loss: 0.0556 - accuracy: 0.8222 - val_loss: 0.0802 - val_accuracy: 0.7454\n",
      "Epoch 4470/5000\n",
      "11786/11786 [==============================] - 9s 726us/step - loss: 0.0553 - accuracy: 0.8238 - val_loss: 0.0798 - val_accuracy: 0.7460\n",
      "Epoch 4471/5000\n",
      "11786/11786 [==============================] - 9s 738us/step - loss: 0.0553 - accuracy: 0.8236 - val_loss: 0.0799 - val_accuracy: 0.7453\n",
      "Epoch 4472/5000\n",
      "11786/11786 [==============================] - 9s 733us/step - loss: 0.0555 - accuracy: 0.8236 - val_loss: 0.0808 - val_accuracy: 0.7435\n",
      "Epoch 4473/5000\n",
      "11786/11786 [==============================] - 9s 729us/step - loss: 0.0553 - accuracy: 0.8240 - val_loss: 0.0803 - val_accuracy: 0.7445\n",
      "Epoch 4474/5000\n",
      "11786/11786 [==============================] - 9s 737us/step - loss: 0.0557 - accuracy: 0.8223 - val_loss: 0.0808 - val_accuracy: 0.7413\n",
      "Epoch 4475/5000\n",
      "11786/11786 [==============================] - 9s 731us/step - loss: 0.0552 - accuracy: 0.8239 - val_loss: 0.0801 - val_accuracy: 0.7456\n",
      "Epoch 4476/5000\n",
      "11786/11786 [==============================] - 9s 737us/step - loss: 0.0554 - accuracy: 0.8230 - val_loss: 0.0800 - val_accuracy: 0.7465\n",
      "Epoch 4477/5000\n",
      "11786/11786 [==============================] - 9s 740us/step - loss: 0.0554 - accuracy: 0.8229 - val_loss: 0.0804 - val_accuracy: 0.7435\n",
      "Epoch 4478/5000\n",
      "11786/11786 [==============================] - 9s 735us/step - loss: 0.0555 - accuracy: 0.8229 - val_loss: 0.0816 - val_accuracy: 0.7417\n",
      "Epoch 4479/5000\n",
      "11786/11786 [==============================] - 9s 728us/step - loss: 0.0555 - accuracy: 0.8223 - val_loss: 0.0799 - val_accuracy: 0.7447\n",
      "Epoch 4480/5000\n",
      "11786/11786 [==============================] - 9s 724us/step - loss: 0.0553 - accuracy: 0.8241 - val_loss: 0.0807 - val_accuracy: 0.7436\n",
      "Epoch 4481/5000\n",
      "11786/11786 [==============================] - 9s 729us/step - loss: 0.0554 - accuracy: 0.8236 - val_loss: 0.0797 - val_accuracy: 0.7452\n",
      "Epoch 4482/5000\n",
      "11786/11786 [==============================] - 9s 738us/step - loss: 0.0554 - accuracy: 0.8234 - val_loss: 0.0807 - val_accuracy: 0.7448\n",
      "Epoch 4483/5000\n",
      "11786/11786 [==============================] - 9s 742us/step - loss: 0.0555 - accuracy: 0.8230 - val_loss: 0.0831 - val_accuracy: 0.7426\n",
      "Epoch 4484/5000\n",
      "11786/11786 [==============================] - 9s 732us/step - loss: 0.0557 - accuracy: 0.8227 - val_loss: 0.0801 - val_accuracy: 0.7458\n",
      "Epoch 4485/5000\n",
      "11786/11786 [==============================] - 9s 737us/step - loss: 0.0556 - accuracy: 0.8230 - val_loss: 0.0809 - val_accuracy: 0.7434\n",
      "Epoch 4486/5000\n",
      "11786/11786 [==============================] - 9s 737us/step - loss: 0.0555 - accuracy: 0.8233 - val_loss: 0.0798 - val_accuracy: 0.7453\n",
      "Epoch 4487/5000\n",
      "11786/11786 [==============================] - 9s 730us/step - loss: 0.0556 - accuracy: 0.8232 - val_loss: 0.0816 - val_accuracy: 0.7447\n",
      "Epoch 4488/5000\n",
      "11786/11786 [==============================] - 9s 742us/step - loss: 0.0555 - accuracy: 0.8232 - val_loss: 0.0805 - val_accuracy: 0.7444\n",
      "Epoch 4489/5000\n",
      "11786/11786 [==============================] - 9s 727us/step - loss: 0.0555 - accuracy: 0.8232 - val_loss: 0.0802 - val_accuracy: 0.7420\n",
      "Epoch 4490/5000\n",
      "11786/11786 [==============================] - 9s 731us/step - loss: 0.0554 - accuracy: 0.8233 - val_loss: 0.0815 - val_accuracy: 0.7458\n",
      "Epoch 4491/5000\n",
      "11786/11786 [==============================] - 9s 730us/step - loss: 0.0555 - accuracy: 0.8237 - val_loss: 0.0804 - val_accuracy: 0.7467\n",
      "Epoch 4492/5000\n",
      "11786/11786 [==============================] - 9s 745us/step - loss: 0.0553 - accuracy: 0.8241 - val_loss: 0.0814 - val_accuracy: 0.7441\n",
      "Epoch 4493/5000\n",
      "11786/11786 [==============================] - 9s 730us/step - loss: 0.0554 - accuracy: 0.8238 - val_loss: 0.0803 - val_accuracy: 0.7443\n",
      "Epoch 4494/5000\n",
      "11786/11786 [==============================] - 9s 734us/step - loss: 0.0553 - accuracy: 0.8247 - val_loss: 0.0804 - val_accuracy: 0.7462\n",
      "Epoch 4495/5000\n",
      "11786/11786 [==============================] - 9s 736us/step - loss: 0.0551 - accuracy: 0.8254 - val_loss: 0.0795 - val_accuracy: 0.7488\n",
      "Epoch 4496/5000\n",
      "11786/11786 [==============================] - 9s 726us/step - loss: 0.0551 - accuracy: 0.8250 - val_loss: 0.0809 - val_accuracy: 0.7461\n",
      "Epoch 4497/5000\n",
      "11786/11786 [==============================] - 9s 730us/step - loss: 0.0553 - accuracy: 0.8247 - val_loss: 0.0806 - val_accuracy: 0.7468\n",
      "Epoch 4498/5000\n",
      "11786/11786 [==============================] - 9s 739us/step - loss: 0.0552 - accuracy: 0.8247 - val_loss: 0.0807 - val_accuracy: 0.7465\n",
      "Epoch 4499/5000\n",
      "11786/11786 [==============================] - 9s 742us/step - loss: 0.0553 - accuracy: 0.8239 - val_loss: 0.0797 - val_accuracy: 0.7483\n",
      "Epoch 4500/5000\n",
      "11786/11786 [==============================] - 9s 725us/step - loss: 0.0555 - accuracy: 0.8236 - val_loss: 0.0801 - val_accuracy: 0.7474\n",
      "Epoch 4501/5000\n",
      "11786/11786 [==============================] - 9s 732us/step - loss: 0.0555 - accuracy: 0.8236 - val_loss: 0.0806 - val_accuracy: 0.7460\n",
      "Epoch 4502/5000\n",
      "11786/11786 [==============================] - 9s 734us/step - loss: 0.0554 - accuracy: 0.8237 - val_loss: 0.0799 - val_accuracy: 0.7453\n",
      "Epoch 4503/5000\n",
      "11786/11786 [==============================] - 9s 737us/step - loss: 0.0556 - accuracy: 0.8229 - val_loss: 0.0793 - val_accuracy: 0.7464\n",
      "Epoch 4504/5000\n",
      "11786/11786 [==============================] - 9s 730us/step - loss: 0.0558 - accuracy: 0.8224 - val_loss: 0.0812 - val_accuracy: 0.7451\n",
      "Epoch 4505/5000\n",
      "11786/11786 [==============================] - 9s 734us/step - loss: 0.0554 - accuracy: 0.8239 - val_loss: 0.0802 - val_accuracy: 0.7458\n",
      "Epoch 4506/5000\n",
      "11786/11786 [==============================] - 9s 739us/step - loss: 0.0556 - accuracy: 0.8226 - val_loss: 0.0804 - val_accuracy: 0.7438\n",
      "Epoch 4507/5000\n",
      "11786/11786 [==============================] - 9s 728us/step - loss: 0.0555 - accuracy: 0.8233 - val_loss: 0.0811 - val_accuracy: 0.7460\n",
      "Epoch 4508/5000\n",
      "11786/11786 [==============================] - 9s 731us/step - loss: 0.0556 - accuracy: 0.8223 - val_loss: 0.0799 - val_accuracy: 0.7456\n",
      "Epoch 4509/5000\n",
      "11786/11786 [==============================] - 9s 735us/step - loss: 0.0555 - accuracy: 0.8230 - val_loss: 0.0795 - val_accuracy: 0.7459\n",
      "Epoch 4510/5000\n",
      "11786/11786 [==============================] - 9s 740us/step - loss: 0.0555 - accuracy: 0.8236 - val_loss: 0.0793 - val_accuracy: 0.7473\n",
      "Epoch 4511/5000\n",
      "11786/11786 [==============================] - 9s 731us/step - loss: 0.0557 - accuracy: 0.8221 - val_loss: 0.0812 - val_accuracy: 0.7434\n",
      "Epoch 4512/5000\n",
      "11786/11786 [==============================] - 9s 735us/step - loss: 0.0555 - accuracy: 0.8225 - val_loss: 0.0797 - val_accuracy: 0.7441\n",
      "Epoch 4513/5000\n",
      "11786/11786 [==============================] - 9s 733us/step - loss: 0.0557 - accuracy: 0.8221 - val_loss: 0.0811 - val_accuracy: 0.7436\n",
      "Epoch 4514/5000\n",
      "11786/11786 [==============================] - 9s 731us/step - loss: 0.0555 - accuracy: 0.8228 - val_loss: 0.0797 - val_accuracy: 0.7436\n",
      "Epoch 4515/5000\n",
      "11786/11786 [==============================] - 9s 728us/step - loss: 0.0556 - accuracy: 0.8227 - val_loss: 0.0809 - val_accuracy: 0.7449\n",
      "Epoch 4516/5000\n",
      "11786/11786 [==============================] - 9s 728us/step - loss: 0.0558 - accuracy: 0.8224 - val_loss: 0.0796 - val_accuracy: 0.7467\n",
      "Epoch 4517/5000\n",
      "11786/11786 [==============================] - 9s 726us/step - loss: 0.0556 - accuracy: 0.8222 - val_loss: 0.0806 - val_accuracy: 0.7468\n",
      "Epoch 4518/5000\n",
      "11786/11786 [==============================] - 9s 728us/step - loss: 0.0556 - accuracy: 0.8218 - val_loss: 0.0806 - val_accuracy: 0.7444\n",
      "Epoch 4519/5000\n",
      "11786/11786 [==============================] - 9s 739us/step - loss: 0.0557 - accuracy: 0.8221 - val_loss: 0.0806 - val_accuracy: 0.7446\n",
      "Epoch 4520/5000\n",
      "11786/11786 [==============================] - 9s 731us/step - loss: 0.0556 - accuracy: 0.8224 - val_loss: 0.0796 - val_accuracy: 0.7448\n",
      "Epoch 4521/5000\n",
      "11786/11786 [==============================] - 9s 738us/step - loss: 0.0556 - accuracy: 0.8225 - val_loss: 0.0788 - val_accuracy: 0.7451\n",
      "Epoch 4522/5000\n",
      "11786/11786 [==============================] - 9s 735us/step - loss: 0.0557 - accuracy: 0.8224 - val_loss: 0.0805 - val_accuracy: 0.7434\n",
      "Epoch 4523/5000\n",
      "11786/11786 [==============================] - 9s 731us/step - loss: 0.0556 - accuracy: 0.8225 - val_loss: 0.0800 - val_accuracy: 0.7460\n",
      "Epoch 4524/5000\n",
      "11786/11786 [==============================] - 9s 737us/step - loss: 0.0557 - accuracy: 0.8217 - val_loss: 0.0801 - val_accuracy: 0.7448\n",
      "Epoch 4525/5000\n",
      "11786/11786 [==============================] - 9s 737us/step - loss: 0.0555 - accuracy: 0.8227 - val_loss: 0.0799 - val_accuracy: 0.7430\n",
      "Epoch 4526/5000\n",
      "11786/11786 [==============================] - 9s 736us/step - loss: 0.0556 - accuracy: 0.8221 - val_loss: 0.0810 - val_accuracy: 0.7443\n",
      "Epoch 4527/5000\n",
      "11786/11786 [==============================] - 9s 730us/step - loss: 0.0556 - accuracy: 0.8225 - val_loss: 0.0819 - val_accuracy: 0.7394\n",
      "Epoch 4528/5000\n",
      "11786/11786 [==============================] - 9s 729us/step - loss: 0.0554 - accuracy: 0.8237 - val_loss: 0.0793 - val_accuracy: 0.7461\n",
      "Epoch 4529/5000\n",
      "11786/11786 [==============================] - 9s 745us/step - loss: 0.0555 - accuracy: 0.8227 - val_loss: 0.0804 - val_accuracy: 0.7462\n",
      "Epoch 4530/5000\n",
      "11786/11786 [==============================] - 9s 724us/step - loss: 0.0557 - accuracy: 0.8224 - val_loss: 0.0795 - val_accuracy: 0.7465\n",
      "Epoch 4531/5000\n",
      "11786/11786 [==============================] - 9s 742us/step - loss: 0.0557 - accuracy: 0.8222 - val_loss: 0.0821 - val_accuracy: 0.7424\n",
      "Epoch 4532/5000\n",
      "11786/11786 [==============================] - 9s 727us/step - loss: 0.0555 - accuracy: 0.8232 - val_loss: 0.0801 - val_accuracy: 0.7452\n",
      "Epoch 4533/5000\n",
      "11786/11786 [==============================] - 9s 739us/step - loss: 0.0557 - accuracy: 0.8227 - val_loss: 0.0813 - val_accuracy: 0.7462\n",
      "Epoch 4534/5000\n",
      "11786/11786 [==============================] - 9s 736us/step - loss: 0.0556 - accuracy: 0.8228 - val_loss: 0.0798 - val_accuracy: 0.7478\n",
      "Epoch 4535/5000\n",
      "11786/11786 [==============================] - 9s 738us/step - loss: 0.0555 - accuracy: 0.8235 - val_loss: 0.0814 - val_accuracy: 0.7443\n",
      "Epoch 4536/5000\n",
      "11786/11786 [==============================] - 9s 745us/step - loss: 0.0555 - accuracy: 0.8236 - val_loss: 0.0799 - val_accuracy: 0.7451\n",
      "Epoch 4537/5000\n",
      "11786/11786 [==============================] - 9s 733us/step - loss: 0.0555 - accuracy: 0.8234 - val_loss: 0.0800 - val_accuracy: 0.7444\n",
      "Epoch 4538/5000\n",
      "11786/11786 [==============================] - 9s 727us/step - loss: 0.0555 - accuracy: 0.8230 - val_loss: 0.0793 - val_accuracy: 0.7465\n",
      "Epoch 4539/5000\n",
      "11786/11786 [==============================] - 9s 738us/step - loss: 0.0555 - accuracy: 0.8232 - val_loss: 0.0814 - val_accuracy: 0.7385\n",
      "Epoch 4540/5000\n",
      "11786/11786 [==============================] - 9s 737us/step - loss: 0.0553 - accuracy: 0.8237 - val_loss: 0.0800 - val_accuracy: 0.7456\n",
      "Epoch 4541/5000\n",
      "11786/11786 [==============================] - 9s 744us/step - loss: 0.0554 - accuracy: 0.8235 - val_loss: 0.0813 - val_accuracy: 0.7450\n",
      "Epoch 4542/5000\n",
      "11786/11786 [==============================] - 9s 737us/step - loss: 0.0557 - accuracy: 0.8223 - val_loss: 0.0791 - val_accuracy: 0.7459\n",
      "Epoch 4543/5000\n",
      "11786/11786 [==============================] - 9s 739us/step - loss: 0.0555 - accuracy: 0.8234 - val_loss: 0.0810 - val_accuracy: 0.7448\n",
      "Epoch 4544/5000\n",
      "11786/11786 [==============================] - 9s 734us/step - loss: 0.0556 - accuracy: 0.8236 - val_loss: 0.0801 - val_accuracy: 0.7466\n",
      "Epoch 4545/5000\n",
      "11786/11786 [==============================] - 9s 730us/step - loss: 0.0555 - accuracy: 0.8232 - val_loss: 0.0801 - val_accuracy: 0.7468\n",
      "Epoch 4546/5000\n",
      "11786/11786 [==============================] - 9s 744us/step - loss: 0.0556 - accuracy: 0.8225 - val_loss: 0.0804 - val_accuracy: 0.7453\n",
      "Epoch 4547/5000\n",
      "11786/11786 [==============================] - 9s 734us/step - loss: 0.0555 - accuracy: 0.8233 - val_loss: 0.0803 - val_accuracy: 0.7453\n",
      "Epoch 4548/5000\n",
      "11786/11786 [==============================] - 9s 730us/step - loss: 0.0556 - accuracy: 0.8230 - val_loss: 0.0802 - val_accuracy: 0.7458\n",
      "Epoch 4549/5000\n",
      "11786/11786 [==============================] - 9s 730us/step - loss: 0.0557 - accuracy: 0.8222 - val_loss: 0.0815 - val_accuracy: 0.7457\n",
      "Epoch 4550/5000\n",
      "11786/11786 [==============================] - 9s 741us/step - loss: 0.0559 - accuracy: 0.8209 - val_loss: 0.0802 - val_accuracy: 0.7442\n",
      "Epoch 4551/5000\n",
      "11786/11786 [==============================] - 9s 732us/step - loss: 0.0557 - accuracy: 0.8220 - val_loss: 0.0800 - val_accuracy: 0.7442\n",
      "Epoch 4552/5000\n",
      "11786/11786 [==============================] - 9s 732us/step - loss: 0.0558 - accuracy: 0.8217 - val_loss: 0.0802 - val_accuracy: 0.7458\n",
      "Epoch 4553/5000\n",
      "11786/11786 [==============================] - 9s 728us/step - loss: 0.0559 - accuracy: 0.8214 - val_loss: 0.0799 - val_accuracy: 0.7440\n",
      "Epoch 4554/5000\n",
      "11786/11786 [==============================] - 9s 733us/step - loss: 0.0557 - accuracy: 0.8218 - val_loss: 0.0797 - val_accuracy: 0.7457\n",
      "Epoch 4555/5000\n",
      "11786/11786 [==============================] - 9s 733us/step - loss: 0.0560 - accuracy: 0.8204 - val_loss: 0.0810 - val_accuracy: 0.7427\n",
      "Epoch 4556/5000\n",
      "11786/11786 [==============================] - 9s 735us/step - loss: 0.0559 - accuracy: 0.8210 - val_loss: 0.0795 - val_accuracy: 0.7439\n",
      "Epoch 4557/5000\n",
      "11786/11786 [==============================] - 9s 734us/step - loss: 0.0559 - accuracy: 0.8208 - val_loss: 0.0806 - val_accuracy: 0.7444\n",
      "Epoch 4558/5000\n",
      "11786/11786 [==============================] - 9s 733us/step - loss: 0.0559 - accuracy: 0.8213 - val_loss: 0.0810 - val_accuracy: 0.7459\n",
      "Epoch 4559/5000\n",
      "11786/11786 [==============================] - 9s 735us/step - loss: 0.0558 - accuracy: 0.8218 - val_loss: 0.0808 - val_accuracy: 0.7438\n",
      "Epoch 4560/5000\n",
      "11786/11786 [==============================] - 9s 732us/step - loss: 0.0557 - accuracy: 0.8216 - val_loss: 0.0801 - val_accuracy: 0.7462\n",
      "Epoch 4561/5000\n",
      "11786/11786 [==============================] - 9s 726us/step - loss: 0.0557 - accuracy: 0.8218 - val_loss: 0.0812 - val_accuracy: 0.7430\n",
      "Epoch 4562/5000\n",
      "11786/11786 [==============================] - 9s 730us/step - loss: 0.0558 - accuracy: 0.8216 - val_loss: 0.0810 - val_accuracy: 0.7416\n",
      "Epoch 4563/5000\n",
      "11786/11786 [==============================] - 9s 735us/step - loss: 0.0558 - accuracy: 0.8218 - val_loss: 0.0799 - val_accuracy: 0.7448\n",
      "Epoch 4564/5000\n",
      "11786/11786 [==============================] - 9s 738us/step - loss: 0.0558 - accuracy: 0.8219 - val_loss: 0.0815 - val_accuracy: 0.7455\n",
      "Epoch 4565/5000\n",
      "11786/11786 [==============================] - 9s 735us/step - loss: 0.0558 - accuracy: 0.8218 - val_loss: 0.0811 - val_accuracy: 0.7445\n",
      "Epoch 4566/5000\n",
      "11786/11786 [==============================] - 9s 723us/step - loss: 0.0558 - accuracy: 0.8216 - val_loss: 0.0799 - val_accuracy: 0.7443\n",
      "Epoch 4567/5000\n",
      "11786/11786 [==============================] - 9s 738us/step - loss: 0.0556 - accuracy: 0.8220 - val_loss: 0.0809 - val_accuracy: 0.7442\n",
      "Epoch 4568/5000\n",
      "11786/11786 [==============================] - 9s 733us/step - loss: 0.0558 - accuracy: 0.8214 - val_loss: 0.0810 - val_accuracy: 0.7439\n",
      "Epoch 4569/5000\n",
      "11786/11786 [==============================] - 8s 720us/step - loss: 0.0557 - accuracy: 0.8216 - val_loss: 0.0810 - val_accuracy: 0.7437\n",
      "Epoch 4570/5000\n",
      "11786/11786 [==============================] - 9s 728us/step - loss: 0.0557 - accuracy: 0.8220 - val_loss: 0.0792 - val_accuracy: 0.7452\n",
      "Epoch 4571/5000\n",
      "11786/11786 [==============================] - 9s 736us/step - loss: 0.0556 - accuracy: 0.8228 - val_loss: 0.0808 - val_accuracy: 0.7438\n",
      "Epoch 4572/5000\n",
      "11786/11786 [==============================] - 9s 737us/step - loss: 0.0555 - accuracy: 0.8228 - val_loss: 0.0812 - val_accuracy: 0.7431\n",
      "Epoch 4573/5000\n",
      "11786/11786 [==============================] - 9s 739us/step - loss: 0.0557 - accuracy: 0.8221 - val_loss: 0.0802 - val_accuracy: 0.7457\n",
      "Epoch 4574/5000\n",
      "11786/11786 [==============================] - 9s 734us/step - loss: 0.0556 - accuracy: 0.8232 - val_loss: 0.0794 - val_accuracy: 0.7474\n",
      "Epoch 4575/5000\n",
      "11786/11786 [==============================] - 9s 737us/step - loss: 0.0557 - accuracy: 0.8225 - val_loss: 0.0800 - val_accuracy: 0.7446\n",
      "Epoch 4576/5000\n",
      "11786/11786 [==============================] - 9s 730us/step - loss: 0.0558 - accuracy: 0.8219 - val_loss: 0.0802 - val_accuracy: 0.7471\n",
      "Epoch 4577/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0557 - accuracy: 0.8216 - val_loss: 0.0802 - val_accuracy: 0.7442\n",
      "Epoch 4578/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0558 - accuracy: 0.8214 - val_loss: 0.0817 - val_accuracy: 0.7430\n",
      "Epoch 4579/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0559 - accuracy: 0.8214 - val_loss: 0.0808 - val_accuracy: 0.7421\n",
      "Epoch 4580/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0557 - accuracy: 0.8226 - val_loss: 0.0800 - val_accuracy: 0.7447\n",
      "Epoch 4581/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0559 - accuracy: 0.8221 - val_loss: 0.0812 - val_accuracy: 0.7427\n",
      "Epoch 4582/5000\n",
      "11786/11786 [==============================] - 8s 715us/step - loss: 0.0559 - accuracy: 0.8212 - val_loss: 0.0799 - val_accuracy: 0.7445\n",
      "Epoch 4583/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0560 - accuracy: 0.8207 - val_loss: 0.0795 - val_accuracy: 0.7418\n",
      "Epoch 4584/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0558 - accuracy: 0.8214 - val_loss: 0.0792 - val_accuracy: 0.7452\n",
      "Epoch 4585/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0559 - accuracy: 0.8215 - val_loss: 0.0805 - val_accuracy: 0.7438\n",
      "Epoch 4586/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0558 - accuracy: 0.8221 - val_loss: 0.0803 - val_accuracy: 0.7447\n",
      "Epoch 4587/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0558 - accuracy: 0.8213 - val_loss: 0.0806 - val_accuracy: 0.7442\n",
      "Epoch 4588/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0558 - accuracy: 0.8216 - val_loss: 0.0806 - val_accuracy: 0.7418\n",
      "Epoch 4589/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0558 - accuracy: 0.8212 - val_loss: 0.0797 - val_accuracy: 0.7446\n",
      "Epoch 4590/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0559 - accuracy: 0.8214 - val_loss: 0.0803 - val_accuracy: 0.7449\n",
      "Epoch 4591/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0558 - accuracy: 0.8217 - val_loss: 0.0818 - val_accuracy: 0.7442\n",
      "Epoch 4592/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0559 - accuracy: 0.8216 - val_loss: 0.0805 - val_accuracy: 0.7435\n",
      "Epoch 4593/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0560 - accuracy: 0.8211 - val_loss: 0.0818 - val_accuracy: 0.7444\n",
      "Epoch 4594/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0560 - accuracy: 0.8211 - val_loss: 0.0816 - val_accuracy: 0.7415\n",
      "Epoch 4595/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0559 - accuracy: 0.8213 - val_loss: 0.0803 - val_accuracy: 0.7450\n",
      "Epoch 4596/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0559 - accuracy: 0.8211 - val_loss: 0.0810 - val_accuracy: 0.7416\n",
      "Epoch 4597/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0561 - accuracy: 0.8209 - val_loss: 0.0818 - val_accuracy: 0.7416\n",
      "Epoch 4598/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0563 - accuracy: 0.8199 - val_loss: 0.0807 - val_accuracy: 0.7418\n",
      "Epoch 4599/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0563 - accuracy: 0.8196 - val_loss: 0.0815 - val_accuracy: 0.7439\n",
      "Epoch 4600/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0561 - accuracy: 0.8205 - val_loss: 0.0809 - val_accuracy: 0.7412\n",
      "Epoch 4601/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0559 - accuracy: 0.8213 - val_loss: 0.0817 - val_accuracy: 0.7436\n",
      "Epoch 4602/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0560 - accuracy: 0.8214 - val_loss: 0.0810 - val_accuracy: 0.7424\n",
      "Epoch 4603/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0559 - accuracy: 0.8212 - val_loss: 0.0816 - val_accuracy: 0.7442\n",
      "Epoch 4604/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0560 - accuracy: 0.8213 - val_loss: 0.0816 - val_accuracy: 0.7445\n",
      "Epoch 4605/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0560 - accuracy: 0.8209 - val_loss: 0.0804 - val_accuracy: 0.7451\n",
      "Epoch 4606/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0561 - accuracy: 0.8210 - val_loss: 0.0807 - val_accuracy: 0.7414\n",
      "Epoch 4607/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0560 - accuracy: 0.8214 - val_loss: 0.0801 - val_accuracy: 0.7419\n",
      "Epoch 4608/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0559 - accuracy: 0.8213 - val_loss: 0.0802 - val_accuracy: 0.7425\n",
      "Epoch 4609/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0559 - accuracy: 0.8214 - val_loss: 0.0804 - val_accuracy: 0.7426\n",
      "Epoch 4610/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0559 - accuracy: 0.8216 - val_loss: 0.0800 - val_accuracy: 0.7446\n",
      "Epoch 4611/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0559 - accuracy: 0.8213 - val_loss: 0.0810 - val_accuracy: 0.7438\n",
      "Epoch 4612/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0560 - accuracy: 0.8209 - val_loss: 0.0812 - val_accuracy: 0.7431\n",
      "Epoch 4613/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0560 - accuracy: 0.8212 - val_loss: 0.0809 - val_accuracy: 0.7396\n",
      "Epoch 4614/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0560 - accuracy: 0.8215 - val_loss: 0.0805 - val_accuracy: 0.7422\n",
      "Epoch 4615/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0560 - accuracy: 0.8213 - val_loss: 0.0804 - val_accuracy: 0.7430\n",
      "Epoch 4616/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0561 - accuracy: 0.8207 - val_loss: 0.0809 - val_accuracy: 0.7446\n",
      "Epoch 4617/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0560 - accuracy: 0.8204 - val_loss: 0.0820 - val_accuracy: 0.7411\n",
      "Epoch 4618/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0560 - accuracy: 0.8206 - val_loss: 0.0815 - val_accuracy: 0.7423\n",
      "Epoch 4619/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0562 - accuracy: 0.8204 - val_loss: 0.0822 - val_accuracy: 0.7390\n",
      "Epoch 4620/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0563 - accuracy: 0.8202 - val_loss: 0.0810 - val_accuracy: 0.7445\n",
      "Epoch 4621/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0563 - accuracy: 0.8205 - val_loss: 0.0808 - val_accuracy: 0.7425\n",
      "Epoch 4622/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0561 - accuracy: 0.8209 - val_loss: 0.0811 - val_accuracy: 0.7442\n",
      "Epoch 4623/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0560 - accuracy: 0.8210 - val_loss: 0.0838 - val_accuracy: 0.7395\n",
      "Epoch 4624/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0561 - accuracy: 0.8209 - val_loss: 0.0805 - val_accuracy: 0.7413\n",
      "Epoch 4625/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0560 - accuracy: 0.8210 - val_loss: 0.0806 - val_accuracy: 0.7428\n",
      "Epoch 4626/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0562 - accuracy: 0.8206 - val_loss: 0.0807 - val_accuracy: 0.7434\n",
      "Epoch 4627/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0562 - accuracy: 0.8209 - val_loss: 0.0809 - val_accuracy: 0.7428\n",
      "Epoch 4628/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0560 - accuracy: 0.8213 - val_loss: 0.0806 - val_accuracy: 0.7432\n",
      "Epoch 4629/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0561 - accuracy: 0.8209 - val_loss: 0.0808 - val_accuracy: 0.7420\n",
      "Epoch 4630/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0560 - accuracy: 0.8211 - val_loss: 0.0802 - val_accuracy: 0.7454\n",
      "Epoch 4631/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0560 - accuracy: 0.8207 - val_loss: 0.0804 - val_accuracy: 0.7433\n",
      "Epoch 4632/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0558 - accuracy: 0.8214 - val_loss: 0.0809 - val_accuracy: 0.7406\n",
      "Epoch 4633/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0559 - accuracy: 0.8214 - val_loss: 0.0814 - val_accuracy: 0.7425\n",
      "Epoch 4634/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0560 - accuracy: 0.8218 - val_loss: 0.0808 - val_accuracy: 0.7417\n",
      "Epoch 4635/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0561 - accuracy: 0.8214 - val_loss: 0.0815 - val_accuracy: 0.7415\n",
      "Epoch 4636/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0559 - accuracy: 0.8217 - val_loss: 0.0806 - val_accuracy: 0.7451\n",
      "Epoch 4637/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0560 - accuracy: 0.8215 - val_loss: 0.0800 - val_accuracy: 0.7442\n",
      "Epoch 4638/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0560 - accuracy: 0.8212 - val_loss: 0.0807 - val_accuracy: 0.7445\n",
      "Epoch 4639/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0560 - accuracy: 0.8209 - val_loss: 0.0802 - val_accuracy: 0.7443\n",
      "Epoch 4640/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0560 - accuracy: 0.8211 - val_loss: 0.0812 - val_accuracy: 0.7422\n",
      "Epoch 4641/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0560 - accuracy: 0.8212 - val_loss: 0.0800 - val_accuracy: 0.7423\n",
      "Epoch 4642/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0561 - accuracy: 0.8205 - val_loss: 0.0810 - val_accuracy: 0.7436\n",
      "Epoch 4643/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0561 - accuracy: 0.8209 - val_loss: 0.0804 - val_accuracy: 0.7444\n",
      "Epoch 4644/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0562 - accuracy: 0.8210 - val_loss: 0.0802 - val_accuracy: 0.7432\n",
      "Epoch 4645/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0562 - accuracy: 0.8207 - val_loss: 0.0805 - val_accuracy: 0.7412\n",
      "Epoch 4646/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0561 - accuracy: 0.8203 - val_loss: 0.0827 - val_accuracy: 0.7405\n",
      "Epoch 4647/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0562 - accuracy: 0.8201 - val_loss: 0.0812 - val_accuracy: 0.7423\n",
      "Epoch 4648/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0561 - accuracy: 0.8204 - val_loss: 0.0805 - val_accuracy: 0.7413\n",
      "Epoch 4649/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0561 - accuracy: 0.8211 - val_loss: 0.0803 - val_accuracy: 0.7425\n",
      "Epoch 4650/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0561 - accuracy: 0.8217 - val_loss: 0.0809 - val_accuracy: 0.7443\n",
      "Epoch 4651/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0561 - accuracy: 0.8210 - val_loss: 0.0809 - val_accuracy: 0.7419\n",
      "Epoch 4652/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0560 - accuracy: 0.8217 - val_loss: 0.0799 - val_accuracy: 0.7423\n",
      "Epoch 4653/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0558 - accuracy: 0.8218 - val_loss: 0.0809 - val_accuracy: 0.7430\n",
      "Epoch 4654/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0560 - accuracy: 0.8215 - val_loss: 0.0820 - val_accuracy: 0.7431\n",
      "Epoch 4655/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0559 - accuracy: 0.8216 - val_loss: 0.0817 - val_accuracy: 0.7425\n",
      "Epoch 4656/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0560 - accuracy: 0.8217 - val_loss: 0.0806 - val_accuracy: 0.7437\n",
      "Epoch 4657/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0563 - accuracy: 0.8208 - val_loss: 0.0798 - val_accuracy: 0.7421\n",
      "Epoch 4658/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0563 - accuracy: 0.8204 - val_loss: 0.0802 - val_accuracy: 0.7408\n",
      "Epoch 4659/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0563 - accuracy: 0.8205 - val_loss: 0.0810 - val_accuracy: 0.7438\n",
      "Epoch 4660/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0562 - accuracy: 0.8206 - val_loss: 0.0813 - val_accuracy: 0.7421\n",
      "Epoch 4661/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0562 - accuracy: 0.8203 - val_loss: 0.0816 - val_accuracy: 0.7430\n",
      "Epoch 4662/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0560 - accuracy: 0.8211 - val_loss: 0.0811 - val_accuracy: 0.7438\n",
      "Epoch 4663/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0561 - accuracy: 0.8209 - val_loss: 0.0809 - val_accuracy: 0.7437\n",
      "Epoch 4664/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0560 - accuracy: 0.8209 - val_loss: 0.0796 - val_accuracy: 0.7441\n",
      "Epoch 4665/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0563 - accuracy: 0.8205 - val_loss: 0.0814 - val_accuracy: 0.7437\n",
      "Epoch 4666/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0561 - accuracy: 0.8203 - val_loss: 0.0811 - val_accuracy: 0.7438\n",
      "Epoch 4667/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0562 - accuracy: 0.8206 - val_loss: 0.0803 - val_accuracy: 0.7454\n",
      "Epoch 4668/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0561 - accuracy: 0.8210 - val_loss: 0.0812 - val_accuracy: 0.7413\n",
      "Epoch 4669/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0561 - accuracy: 0.8207 - val_loss: 0.0816 - val_accuracy: 0.7408\n",
      "Epoch 4670/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0561 - accuracy: 0.8208 - val_loss: 0.0812 - val_accuracy: 0.7417\n",
      "Epoch 4671/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0561 - accuracy: 0.8211 - val_loss: 0.0810 - val_accuracy: 0.7447\n",
      "Epoch 4672/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0564 - accuracy: 0.8200 - val_loss: 0.0801 - val_accuracy: 0.7400\n",
      "Epoch 4673/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0563 - accuracy: 0.8198 - val_loss: 0.0807 - val_accuracy: 0.7419\n",
      "Epoch 4674/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0561 - accuracy: 0.8208 - val_loss: 0.0822 - val_accuracy: 0.7411\n",
      "Epoch 4675/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0562 - accuracy: 0.8208 - val_loss: 0.0801 - val_accuracy: 0.7423\n",
      "Epoch 4676/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0562 - accuracy: 0.8207 - val_loss: 0.0813 - val_accuracy: 0.7435\n",
      "Epoch 4677/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0562 - accuracy: 0.8206 - val_loss: 0.0814 - val_accuracy: 0.7409\n",
      "Epoch 4678/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0563 - accuracy: 0.8196 - val_loss: 0.0805 - val_accuracy: 0.7425\n",
      "Epoch 4679/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0561 - accuracy: 0.8208 - val_loss: 0.0817 - val_accuracy: 0.7436\n",
      "Epoch 4680/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0563 - accuracy: 0.8198 - val_loss: 0.0811 - val_accuracy: 0.7439\n",
      "Epoch 4681/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0563 - accuracy: 0.8197 - val_loss: 0.0818 - val_accuracy: 0.7419\n",
      "Epoch 4682/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0564 - accuracy: 0.8195 - val_loss: 0.0816 - val_accuracy: 0.7415\n",
      "Epoch 4683/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0565 - accuracy: 0.8192 - val_loss: 0.0818 - val_accuracy: 0.7382\n",
      "Epoch 4684/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0564 - accuracy: 0.8197 - val_loss: 0.0810 - val_accuracy: 0.7415\n",
      "Epoch 4685/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0564 - accuracy: 0.8198 - val_loss: 0.0824 - val_accuracy: 0.7400\n",
      "Epoch 4686/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0564 - accuracy: 0.8200 - val_loss: 0.0807 - val_accuracy: 0.7412\n",
      "Epoch 4687/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0564 - accuracy: 0.8200 - val_loss: 0.0820 - val_accuracy: 0.7435\n",
      "Epoch 4688/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0563 - accuracy: 0.8200 - val_loss: 0.0816 - val_accuracy: 0.7420\n",
      "Epoch 4689/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0563 - accuracy: 0.8201 - val_loss: 0.0812 - val_accuracy: 0.7413\n",
      "Epoch 4690/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0562 - accuracy: 0.8197 - val_loss: 0.0803 - val_accuracy: 0.7420\n",
      "Epoch 4691/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0563 - accuracy: 0.8200 - val_loss: 0.0808 - val_accuracy: 0.7381\n",
      "Epoch 4692/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0564 - accuracy: 0.8192 - val_loss: 0.0807 - val_accuracy: 0.7432\n",
      "Epoch 4693/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0563 - accuracy: 0.8194 - val_loss: 0.0813 - val_accuracy: 0.7411\n",
      "Epoch 4694/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0565 - accuracy: 0.8187 - val_loss: 0.0800 - val_accuracy: 0.7431\n",
      "Epoch 4695/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0565 - accuracy: 0.8188 - val_loss: 0.0815 - val_accuracy: 0.7402\n",
      "Epoch 4696/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0564 - accuracy: 0.8195 - val_loss: 0.0838 - val_accuracy: 0.7385\n",
      "Epoch 4697/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0563 - accuracy: 0.8196 - val_loss: 0.0815 - val_accuracy: 0.7435\n",
      "Epoch 4698/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0565 - accuracy: 0.8189 - val_loss: 0.0819 - val_accuracy: 0.7374\n",
      "Epoch 4699/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0563 - accuracy: 0.8192 - val_loss: 0.0803 - val_accuracy: 0.7435\n",
      "Epoch 4700/5000\n",
      "11786/11786 [==============================] - 8s 714us/step - loss: 0.0564 - accuracy: 0.8192 - val_loss: 0.0803 - val_accuracy: 0.7427\n",
      "Epoch 4701/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0565 - accuracy: 0.8190 - val_loss: 0.0818 - val_accuracy: 0.7427\n",
      "Epoch 4702/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0564 - accuracy: 0.8193 - val_loss: 0.0806 - val_accuracy: 0.7406\n",
      "Epoch 4703/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0563 - accuracy: 0.8195 - val_loss: 0.0802 - val_accuracy: 0.7432\n",
      "Epoch 4704/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0563 - accuracy: 0.8198 - val_loss: 0.0803 - val_accuracy: 0.7437\n",
      "Epoch 4705/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0563 - accuracy: 0.8201 - val_loss: 0.0815 - val_accuracy: 0.7421\n",
      "Epoch 4706/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0563 - accuracy: 0.8199 - val_loss: 0.0811 - val_accuracy: 0.7421\n",
      "Epoch 4707/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0562 - accuracy: 0.8196 - val_loss: 0.0821 - val_accuracy: 0.7415\n",
      "Epoch 4708/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0562 - accuracy: 0.8204 - val_loss: 0.0816 - val_accuracy: 0.7424\n",
      "Epoch 4709/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0562 - accuracy: 0.8204 - val_loss: 0.0814 - val_accuracy: 0.7437\n",
      "Epoch 4710/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0562 - accuracy: 0.8204 - val_loss: 0.0808 - val_accuracy: 0.7420\n",
      "Epoch 4711/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0565 - accuracy: 0.8189 - val_loss: 0.0813 - val_accuracy: 0.7424\n",
      "Epoch 4712/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0564 - accuracy: 0.8189 - val_loss: 0.0809 - val_accuracy: 0.7421\n",
      "Epoch 4713/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0562 - accuracy: 0.8197 - val_loss: 0.0812 - val_accuracy: 0.7432\n",
      "Epoch 4714/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0565 - accuracy: 0.8187 - val_loss: 0.0810 - val_accuracy: 0.7415\n",
      "Epoch 4715/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0565 - accuracy: 0.8182 - val_loss: 0.0823 - val_accuracy: 0.7410\n",
      "Epoch 4716/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0566 - accuracy: 0.8185 - val_loss: 0.0813 - val_accuracy: 0.7420\n",
      "Epoch 4717/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0564 - accuracy: 0.8188 - val_loss: 0.0811 - val_accuracy: 0.7397\n",
      "Epoch 4718/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0564 - accuracy: 0.8194 - val_loss: 0.0806 - val_accuracy: 0.7412\n",
      "Epoch 4719/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0565 - accuracy: 0.8187 - val_loss: 0.0818 - val_accuracy: 0.7415\n",
      "Epoch 4720/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0565 - accuracy: 0.8184 - val_loss: 0.0804 - val_accuracy: 0.7401\n",
      "Epoch 4721/5000\n",
      "11786/11786 [==============================] - 8s 714us/step - loss: 0.0565 - accuracy: 0.8186 - val_loss: 0.0819 - val_accuracy: 0.7421\n",
      "Epoch 4722/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0564 - accuracy: 0.8188 - val_loss: 0.0814 - val_accuracy: 0.7420\n",
      "Epoch 4723/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0564 - accuracy: 0.8189 - val_loss: 0.0811 - val_accuracy: 0.7390\n",
      "Epoch 4724/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0566 - accuracy: 0.8184 - val_loss: 0.0811 - val_accuracy: 0.7410\n",
      "Epoch 4725/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0564 - accuracy: 0.8188 - val_loss: 0.0804 - val_accuracy: 0.7437\n",
      "Epoch 4726/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0564 - accuracy: 0.8190 - val_loss: 0.0801 - val_accuracy: 0.7424\n",
      "Epoch 4727/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0561 - accuracy: 0.8200 - val_loss: 0.0813 - val_accuracy: 0.7426\n",
      "Epoch 4728/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0564 - accuracy: 0.8190 - val_loss: 0.0808 - val_accuracy: 0.7425\n",
      "Epoch 4729/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0562 - accuracy: 0.8199 - val_loss: 0.0807 - val_accuracy: 0.7442\n",
      "Epoch 4730/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0564 - accuracy: 0.8192 - val_loss: 0.0813 - val_accuracy: 0.7396\n",
      "Epoch 4731/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0563 - accuracy: 0.8191 - val_loss: 0.0832 - val_accuracy: 0.7382\n",
      "Epoch 4732/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0565 - accuracy: 0.8188 - val_loss: 0.0811 - val_accuracy: 0.7416\n",
      "Epoch 4733/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0563 - accuracy: 0.8195 - val_loss: 0.0809 - val_accuracy: 0.7421\n",
      "Epoch 4734/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0561 - accuracy: 0.8198 - val_loss: 0.0808 - val_accuracy: 0.7411\n",
      "Epoch 4735/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0565 - accuracy: 0.8187 - val_loss: 0.0815 - val_accuracy: 0.7403\n",
      "Epoch 4736/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0566 - accuracy: 0.8187 - val_loss: 0.0807 - val_accuracy: 0.7433\n",
      "Epoch 4737/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0563 - accuracy: 0.8200 - val_loss: 0.0800 - val_accuracy: 0.7428\n",
      "Epoch 4738/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0565 - accuracy: 0.8194 - val_loss: 0.0813 - val_accuracy: 0.7417\n",
      "Epoch 4739/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0563 - accuracy: 0.8197 - val_loss: 0.0817 - val_accuracy: 0.7413\n",
      "Epoch 4740/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0562 - accuracy: 0.8198 - val_loss: 0.0815 - val_accuracy: 0.7423\n",
      "Epoch 4741/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0564 - accuracy: 0.8192 - val_loss: 0.0804 - val_accuracy: 0.7411\n",
      "Epoch 4742/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0564 - accuracy: 0.8192 - val_loss: 0.0826 - val_accuracy: 0.7401\n",
      "Epoch 4743/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0563 - accuracy: 0.8196 - val_loss: 0.0797 - val_accuracy: 0.7433\n",
      "Epoch 4744/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0564 - accuracy: 0.8190 - val_loss: 0.0820 - val_accuracy: 0.7411\n",
      "Epoch 4745/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0563 - accuracy: 0.8199 - val_loss: 0.0824 - val_accuracy: 0.7411\n",
      "Epoch 4746/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0563 - accuracy: 0.8192 - val_loss: 0.0813 - val_accuracy: 0.7397\n",
      "Epoch 4747/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0564 - accuracy: 0.8190 - val_loss: 0.0818 - val_accuracy: 0.7426\n",
      "Epoch 4748/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0565 - accuracy: 0.8193 - val_loss: 0.0813 - val_accuracy: 0.7395\n",
      "Epoch 4749/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0566 - accuracy: 0.8188 - val_loss: 0.0815 - val_accuracy: 0.7399\n",
      "Epoch 4750/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0565 - accuracy: 0.8185 - val_loss: 0.0812 - val_accuracy: 0.7416\n",
      "Epoch 4751/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0565 - accuracy: 0.8191 - val_loss: 0.0816 - val_accuracy: 0.7427\n",
      "Epoch 4752/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0565 - accuracy: 0.8192 - val_loss: 0.0809 - val_accuracy: 0.7416\n",
      "Epoch 4753/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0565 - accuracy: 0.8182 - val_loss: 0.0817 - val_accuracy: 0.7404\n",
      "Epoch 4754/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0565 - accuracy: 0.8190 - val_loss: 0.0820 - val_accuracy: 0.7414\n",
      "Epoch 4755/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0566 - accuracy: 0.8185 - val_loss: 0.0815 - val_accuracy: 0.7398\n",
      "Epoch 4756/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0566 - accuracy: 0.8185 - val_loss: 0.0808 - val_accuracy: 0.7404\n",
      "Epoch 4757/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0566 - accuracy: 0.8179 - val_loss: 0.0810 - val_accuracy: 0.7402\n",
      "Epoch 4758/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0565 - accuracy: 0.8187 - val_loss: 0.0813 - val_accuracy: 0.7404\n",
      "Epoch 4759/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0564 - accuracy: 0.8181 - val_loss: 0.0806 - val_accuracy: 0.7412\n",
      "Epoch 4760/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0563 - accuracy: 0.8193 - val_loss: 0.0814 - val_accuracy: 0.7405\n",
      "Epoch 4761/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0564 - accuracy: 0.8191 - val_loss: 0.0811 - val_accuracy: 0.7391\n",
      "Epoch 4762/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0565 - accuracy: 0.8187 - val_loss: 0.0813 - val_accuracy: 0.7394\n",
      "Epoch 4763/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0567 - accuracy: 0.8178 - val_loss: 0.0821 - val_accuracy: 0.7380\n",
      "Epoch 4764/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0567 - accuracy: 0.8182 - val_loss: 0.0807 - val_accuracy: 0.7399\n",
      "Epoch 4765/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0566 - accuracy: 0.8189 - val_loss: 0.0810 - val_accuracy: 0.7407\n",
      "Epoch 4766/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0565 - accuracy: 0.8192 - val_loss: 0.0806 - val_accuracy: 0.7407\n",
      "Epoch 4767/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0563 - accuracy: 0.8196 - val_loss: 0.0804 - val_accuracy: 0.7414\n",
      "Epoch 4768/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0563 - accuracy: 0.8191 - val_loss: 0.0816 - val_accuracy: 0.7402\n",
      "Epoch 4769/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0565 - accuracy: 0.8185 - val_loss: 0.0810 - val_accuracy: 0.7425\n",
      "Epoch 4770/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0567 - accuracy: 0.8183 - val_loss: 0.0817 - val_accuracy: 0.7410\n",
      "Epoch 4771/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0567 - accuracy: 0.8174 - val_loss: 0.0820 - val_accuracy: 0.7426\n",
      "Epoch 4772/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0565 - accuracy: 0.8187 - val_loss: 0.0812 - val_accuracy: 0.7419\n",
      "Epoch 4773/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0565 - accuracy: 0.8187 - val_loss: 0.0809 - val_accuracy: 0.7400\n",
      "Epoch 4774/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0566 - accuracy: 0.8187 - val_loss: 0.0803 - val_accuracy: 0.7392\n",
      "Epoch 4775/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0568 - accuracy: 0.8175 - val_loss: 0.0811 - val_accuracy: 0.7387\n",
      "Epoch 4776/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0568 - accuracy: 0.8183 - val_loss: 0.0816 - val_accuracy: 0.7417\n",
      "Epoch 4777/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0568 - accuracy: 0.8177 - val_loss: 0.0819 - val_accuracy: 0.7387\n",
      "Epoch 4778/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0568 - accuracy: 0.8173 - val_loss: 0.0809 - val_accuracy: 0.7410\n",
      "Epoch 4779/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0569 - accuracy: 0.8176 - val_loss: 0.0813 - val_accuracy: 0.7389\n",
      "Epoch 4780/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0567 - accuracy: 0.8175 - val_loss: 0.0806 - val_accuracy: 0.7399\n",
      "Epoch 4781/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0567 - accuracy: 0.8182 - val_loss: 0.0816 - val_accuracy: 0.7392\n",
      "Epoch 4782/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0567 - accuracy: 0.8186 - val_loss: 0.0824 - val_accuracy: 0.7410\n",
      "Epoch 4783/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0566 - accuracy: 0.8194 - val_loss: 0.0808 - val_accuracy: 0.7422\n",
      "Epoch 4784/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0565 - accuracy: 0.8192 - val_loss: 0.0814 - val_accuracy: 0.7413\n",
      "Epoch 4785/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0567 - accuracy: 0.8177 - val_loss: 0.0832 - val_accuracy: 0.7417\n",
      "Epoch 4786/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0567 - accuracy: 0.8180 - val_loss: 0.0807 - val_accuracy: 0.7423\n",
      "Epoch 4787/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0566 - accuracy: 0.8185 - val_loss: 0.0807 - val_accuracy: 0.7432\n",
      "Epoch 4788/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0566 - accuracy: 0.8184 - val_loss: 0.0815 - val_accuracy: 0.7382\n",
      "Epoch 4789/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0568 - accuracy: 0.8181 - val_loss: 0.0814 - val_accuracy: 0.7401\n",
      "Epoch 4790/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0568 - accuracy: 0.8179 - val_loss: 0.0814 - val_accuracy: 0.7385\n",
      "Epoch 4791/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0566 - accuracy: 0.8187 - val_loss: 0.0814 - val_accuracy: 0.7418\n",
      "Epoch 4792/5000\n",
      "11786/11786 [==============================] - 8s 694us/step - loss: 0.0568 - accuracy: 0.8177 - val_loss: 0.0811 - val_accuracy: 0.7412\n",
      "Epoch 4793/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0568 - accuracy: 0.8177 - val_loss: 0.0817 - val_accuracy: 0.7379\n",
      "Epoch 4794/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0567 - accuracy: 0.8183 - val_loss: 0.0809 - val_accuracy: 0.7398\n",
      "Epoch 4795/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0567 - accuracy: 0.8176 - val_loss: 0.0803 - val_accuracy: 0.7417\n",
      "Epoch 4796/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0567 - accuracy: 0.8178 - val_loss: 0.0817 - val_accuracy: 0.7367\n",
      "Epoch 4797/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0567 - accuracy: 0.8182 - val_loss: 0.0808 - val_accuracy: 0.7423\n",
      "Epoch 4798/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0566 - accuracy: 0.8181 - val_loss: 0.0816 - val_accuracy: 0.7396\n",
      "Epoch 4799/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0567 - accuracy: 0.8182 - val_loss: 0.0816 - val_accuracy: 0.7422\n",
      "Epoch 4800/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0567 - accuracy: 0.8173 - val_loss: 0.0808 - val_accuracy: 0.7416\n",
      "Epoch 4801/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0570 - accuracy: 0.8175 - val_loss: 0.0800 - val_accuracy: 0.7430\n",
      "Epoch 4802/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0567 - accuracy: 0.8185 - val_loss: 0.0811 - val_accuracy: 0.7437\n",
      "Epoch 4803/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0569 - accuracy: 0.8175 - val_loss: 0.0827 - val_accuracy: 0.7391\n",
      "Epoch 4804/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0569 - accuracy: 0.8173 - val_loss: 0.0814 - val_accuracy: 0.7418\n",
      "Epoch 4805/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0568 - accuracy: 0.8173 - val_loss: 0.0801 - val_accuracy: 0.7404\n",
      "Epoch 4806/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0568 - accuracy: 0.8177 - val_loss: 0.0812 - val_accuracy: 0.7425\n",
      "Epoch 4807/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0568 - accuracy: 0.8174 - val_loss: 0.0811 - val_accuracy: 0.7414\n",
      "Epoch 4808/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0567 - accuracy: 0.8180 - val_loss: 0.0806 - val_accuracy: 0.7417\n",
      "Epoch 4809/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0568 - accuracy: 0.8178 - val_loss: 0.0820 - val_accuracy: 0.7422\n",
      "Epoch 4810/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0567 - accuracy: 0.8180 - val_loss: 0.0806 - val_accuracy: 0.7439\n",
      "Epoch 4811/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0569 - accuracy: 0.8179 - val_loss: 0.0808 - val_accuracy: 0.7426\n",
      "Epoch 4812/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0566 - accuracy: 0.8184 - val_loss: 0.0818 - val_accuracy: 0.7433\n",
      "Epoch 4813/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0568 - accuracy: 0.8177 - val_loss: 0.0815 - val_accuracy: 0.7357\n",
      "Epoch 4814/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0566 - accuracy: 0.8182 - val_loss: 0.0805 - val_accuracy: 0.7406\n",
      "Epoch 4815/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0567 - accuracy: 0.8181 - val_loss: 0.0820 - val_accuracy: 0.7411\n",
      "Epoch 4816/5000\n",
      "11786/11786 [==============================] - 8s 693us/step - loss: 0.0565 - accuracy: 0.8187 - val_loss: 0.0802 - val_accuracy: 0.7424\n",
      "Epoch 4817/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0567 - accuracy: 0.8181 - val_loss: 0.0804 - val_accuracy: 0.7406\n",
      "Epoch 4818/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0565 - accuracy: 0.8186 - val_loss: 0.0819 - val_accuracy: 0.7415\n",
      "Epoch 4819/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0565 - accuracy: 0.8192 - val_loss: 0.0811 - val_accuracy: 0.7414\n",
      "Epoch 4820/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0566 - accuracy: 0.8187 - val_loss: 0.0799 - val_accuracy: 0.7409\n",
      "Epoch 4821/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0566 - accuracy: 0.8187 - val_loss: 0.0818 - val_accuracy: 0.7395\n",
      "Epoch 4822/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0563 - accuracy: 0.8202 - val_loss: 0.0817 - val_accuracy: 0.7407\n",
      "Epoch 4823/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0565 - accuracy: 0.8190 - val_loss: 0.0806 - val_accuracy: 0.7430\n",
      "Epoch 4824/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0565 - accuracy: 0.8186 - val_loss: 0.0822 - val_accuracy: 0.7407\n",
      "Epoch 4825/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0566 - accuracy: 0.8186 - val_loss: 0.0830 - val_accuracy: 0.7392\n",
      "Epoch 4826/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0565 - accuracy: 0.8190 - val_loss: 0.0811 - val_accuracy: 0.7431\n",
      "Epoch 4827/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0566 - accuracy: 0.8187 - val_loss: 0.0816 - val_accuracy: 0.7404\n",
      "Epoch 4828/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0566 - accuracy: 0.8182 - val_loss: 0.0802 - val_accuracy: 0.7414\n",
      "Epoch 4829/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0565 - accuracy: 0.8186 - val_loss: 0.0810 - val_accuracy: 0.7420\n",
      "Epoch 4830/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0566 - accuracy: 0.8181 - val_loss: 0.0834 - val_accuracy: 0.7405\n",
      "Epoch 4831/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0565 - accuracy: 0.8186 - val_loss: 0.0803 - val_accuracy: 0.7417\n",
      "Epoch 4832/5000\n",
      "11786/11786 [==============================] - 8s 699us/step - loss: 0.0566 - accuracy: 0.8186 - val_loss: 0.0804 - val_accuracy: 0.7423\n",
      "Epoch 4833/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0565 - accuracy: 0.8186 - val_loss: 0.0814 - val_accuracy: 0.7400\n",
      "Epoch 4834/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0567 - accuracy: 0.8183 - val_loss: 0.0816 - val_accuracy: 0.7383\n",
      "Epoch 4835/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0566 - accuracy: 0.8191 - val_loss: 0.0805 - val_accuracy: 0.7421\n",
      "Epoch 4836/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0566 - accuracy: 0.8186 - val_loss: 0.0815 - val_accuracy: 0.7408\n",
      "Epoch 4837/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0564 - accuracy: 0.8189 - val_loss: 0.0808 - val_accuracy: 0.7429\n",
      "Epoch 4838/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0566 - accuracy: 0.8189 - val_loss: 0.0814 - val_accuracy: 0.7401\n",
      "Epoch 4839/5000\n",
      "11786/11786 [==============================] - 8s 695us/step - loss: 0.0566 - accuracy: 0.8187 - val_loss: 0.0798 - val_accuracy: 0.7422\n",
      "Epoch 4840/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0569 - accuracy: 0.8177 - val_loss: 0.0818 - val_accuracy: 0.7390\n",
      "Epoch 4841/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0567 - accuracy: 0.8182 - val_loss: 0.0821 - val_accuracy: 0.7427\n",
      "Epoch 4842/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0566 - accuracy: 0.8188 - val_loss: 0.0812 - val_accuracy: 0.7408\n",
      "Epoch 4843/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0567 - accuracy: 0.8181 - val_loss: 0.0809 - val_accuracy: 0.7414\n",
      "Epoch 4844/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0567 - accuracy: 0.8185 - val_loss: 0.0808 - val_accuracy: 0.7418\n",
      "Epoch 4845/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0567 - accuracy: 0.8187 - val_loss: 0.0817 - val_accuracy: 0.7410\n",
      "Epoch 4846/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0566 - accuracy: 0.8189 - val_loss: 0.0806 - val_accuracy: 0.7399\n",
      "Epoch 4847/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0566 - accuracy: 0.8185 - val_loss: 0.0811 - val_accuracy: 0.7414\n",
      "Epoch 4848/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0568 - accuracy: 0.8186 - val_loss: 0.0804 - val_accuracy: 0.7424\n",
      "Epoch 4849/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0566 - accuracy: 0.8184 - val_loss: 0.0812 - val_accuracy: 0.7379\n",
      "Epoch 4850/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0567 - accuracy: 0.8179 - val_loss: 0.0824 - val_accuracy: 0.7403\n",
      "Epoch 4851/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0570 - accuracy: 0.8174 - val_loss: 0.0818 - val_accuracy: 0.7411\n",
      "Epoch 4852/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0569 - accuracy: 0.8177 - val_loss: 0.0815 - val_accuracy: 0.7396\n",
      "Epoch 4853/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0568 - accuracy: 0.8173 - val_loss: 0.0816 - val_accuracy: 0.7397\n",
      "Epoch 4854/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0569 - accuracy: 0.8172 - val_loss: 0.0822 - val_accuracy: 0.7388\n",
      "Epoch 4855/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0571 - accuracy: 0.8166 - val_loss: 0.0821 - val_accuracy: 0.7382\n",
      "Epoch 4856/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0569 - accuracy: 0.8173 - val_loss: 0.0809 - val_accuracy: 0.7414\n",
      "Epoch 4857/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0569 - accuracy: 0.8172 - val_loss: 0.0826 - val_accuracy: 0.7414\n",
      "Epoch 4858/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0569 - accuracy: 0.8173 - val_loss: 0.0817 - val_accuracy: 0.7413\n",
      "Epoch 4859/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0569 - accuracy: 0.8172 - val_loss: 0.0816 - val_accuracy: 0.7429\n",
      "Epoch 4860/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0569 - accuracy: 0.8176 - val_loss: 0.0808 - val_accuracy: 0.7420\n",
      "Epoch 4861/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0566 - accuracy: 0.8191 - val_loss: 0.0825 - val_accuracy: 0.7400\n",
      "Epoch 4862/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0567 - accuracy: 0.8182 - val_loss: 0.0812 - val_accuracy: 0.7388\n",
      "Epoch 4863/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0567 - accuracy: 0.8182 - val_loss: 0.0806 - val_accuracy: 0.7395\n",
      "Epoch 4864/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0567 - accuracy: 0.8184 - val_loss: 0.0819 - val_accuracy: 0.7397\n",
      "Epoch 4865/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0568 - accuracy: 0.8183 - val_loss: 0.0833 - val_accuracy: 0.7361\n",
      "Epoch 4866/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0569 - accuracy: 0.8174 - val_loss: 0.0809 - val_accuracy: 0.7428\n",
      "Epoch 4867/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0568 - accuracy: 0.8182 - val_loss: 0.0805 - val_accuracy: 0.7411\n",
      "Epoch 4868/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0571 - accuracy: 0.8173 - val_loss: 0.0808 - val_accuracy: 0.7412\n",
      "Epoch 4869/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0570 - accuracy: 0.8167 - val_loss: 0.0817 - val_accuracy: 0.7380\n",
      "Epoch 4870/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0569 - accuracy: 0.8174 - val_loss: 0.0816 - val_accuracy: 0.7390\n",
      "Epoch 4871/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0571 - accuracy: 0.8168 - val_loss: 0.0802 - val_accuracy: 0.7382\n",
      "Epoch 4872/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0569 - accuracy: 0.8180 - val_loss: 0.0815 - val_accuracy: 0.7392\n",
      "Epoch 4873/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0568 - accuracy: 0.8184 - val_loss: 0.0811 - val_accuracy: 0.7432\n",
      "Epoch 4874/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0569 - accuracy: 0.8178 - val_loss: 0.0811 - val_accuracy: 0.7412\n",
      "Epoch 4875/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0569 - accuracy: 0.8176 - val_loss: 0.0806 - val_accuracy: 0.7384\n",
      "Epoch 4876/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0570 - accuracy: 0.8174 - val_loss: 0.0811 - val_accuracy: 0.7398\n",
      "Epoch 4877/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0572 - accuracy: 0.8161 - val_loss: 0.0828 - val_accuracy: 0.7384\n",
      "Epoch 4878/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0569 - accuracy: 0.8168 - val_loss: 0.0829 - val_accuracy: 0.7410\n",
      "Epoch 4879/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0572 - accuracy: 0.8159 - val_loss: 0.0814 - val_accuracy: 0.7387\n",
      "Epoch 4880/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0571 - accuracy: 0.8160 - val_loss: 0.0801 - val_accuracy: 0.7393\n",
      "Epoch 4881/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0570 - accuracy: 0.8168 - val_loss: 0.0813 - val_accuracy: 0.7397\n",
      "Epoch 4882/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0571 - accuracy: 0.8165 - val_loss: 0.0812 - val_accuracy: 0.7399\n",
      "Epoch 4883/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0570 - accuracy: 0.8164 - val_loss: 0.0811 - val_accuracy: 0.7405\n",
      "Epoch 4884/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0570 - accuracy: 0.8172 - val_loss: 0.0811 - val_accuracy: 0.7380\n",
      "Epoch 4885/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0571 - accuracy: 0.8170 - val_loss: 0.0803 - val_accuracy: 0.7407\n",
      "Epoch 4886/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0570 - accuracy: 0.8178 - val_loss: 0.0816 - val_accuracy: 0.7399\n",
      "Epoch 4887/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0570 - accuracy: 0.8167 - val_loss: 0.0815 - val_accuracy: 0.7405\n",
      "Epoch 4888/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0568 - accuracy: 0.8175 - val_loss: 0.0810 - val_accuracy: 0.7423\n",
      "Epoch 4889/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0570 - accuracy: 0.8171 - val_loss: 0.0807 - val_accuracy: 0.7389\n",
      "Epoch 4890/5000\n",
      "11786/11786 [==============================] - 8s 696us/step - loss: 0.0569 - accuracy: 0.8174 - val_loss: 0.0814 - val_accuracy: 0.7416\n",
      "Epoch 4891/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0570 - accuracy: 0.8171 - val_loss: 0.0811 - val_accuracy: 0.7401\n",
      "Epoch 4892/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0569 - accuracy: 0.8176 - val_loss: 0.0812 - val_accuracy: 0.7396\n",
      "Epoch 4893/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0569 - accuracy: 0.8176 - val_loss: 0.0805 - val_accuracy: 0.7402\n",
      "Epoch 4894/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0570 - accuracy: 0.8175 - val_loss: 0.0799 - val_accuracy: 0.7408\n",
      "Epoch 4895/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0568 - accuracy: 0.8181 - val_loss: 0.0808 - val_accuracy: 0.7400\n",
      "Epoch 4896/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0567 - accuracy: 0.8184 - val_loss: 0.0806 - val_accuracy: 0.7408\n",
      "Epoch 4897/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0569 - accuracy: 0.8176 - val_loss: 0.0810 - val_accuracy: 0.7418\n",
      "Epoch 4898/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0570 - accuracy: 0.8174 - val_loss: 0.0808 - val_accuracy: 0.7421\n",
      "Epoch 4899/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0569 - accuracy: 0.8177 - val_loss: 0.0821 - val_accuracy: 0.7408\n",
      "Epoch 4900/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0569 - accuracy: 0.8175 - val_loss: 0.0808 - val_accuracy: 0.7396\n",
      "Epoch 4901/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0567 - accuracy: 0.8180 - val_loss: 0.0818 - val_accuracy: 0.7383\n",
      "Epoch 4902/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0567 - accuracy: 0.8177 - val_loss: 0.0808 - val_accuracy: 0.7404\n",
      "Epoch 4903/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0569 - accuracy: 0.8174 - val_loss: 0.0820 - val_accuracy: 0.7415\n",
      "Epoch 4904/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0569 - accuracy: 0.8171 - val_loss: 0.0817 - val_accuracy: 0.7382\n",
      "Epoch 4905/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0569 - accuracy: 0.8171 - val_loss: 0.0809 - val_accuracy: 0.7418\n",
      "Epoch 4906/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0569 - accuracy: 0.8170 - val_loss: 0.0808 - val_accuracy: 0.7418\n",
      "Epoch 4907/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0567 - accuracy: 0.8179 - val_loss: 0.0810 - val_accuracy: 0.7420\n",
      "Epoch 4908/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0571 - accuracy: 0.8165 - val_loss: 0.0802 - val_accuracy: 0.7422\n",
      "Epoch 4909/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0571 - accuracy: 0.8160 - val_loss: 0.0810 - val_accuracy: 0.7400\n",
      "Epoch 4910/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0572 - accuracy: 0.8162 - val_loss: 0.0807 - val_accuracy: 0.7407\n",
      "Epoch 4911/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0571 - accuracy: 0.8164 - val_loss: 0.0801 - val_accuracy: 0.7413\n",
      "Epoch 4912/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0571 - accuracy: 0.8164 - val_loss: 0.0819 - val_accuracy: 0.7426\n",
      "Epoch 4913/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0572 - accuracy: 0.8167 - val_loss: 0.0826 - val_accuracy: 0.7380\n",
      "Epoch 4914/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0570 - accuracy: 0.8166 - val_loss: 0.0815 - val_accuracy: 0.7402\n",
      "Epoch 4915/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0572 - accuracy: 0.8165 - val_loss: 0.0812 - val_accuracy: 0.7403\n",
      "Epoch 4916/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0570 - accuracy: 0.8168 - val_loss: 0.0807 - val_accuracy: 0.7399\n",
      "Epoch 4917/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0573 - accuracy: 0.8158 - val_loss: 0.0812 - val_accuracy: 0.7404\n",
      "Epoch 4918/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0572 - accuracy: 0.8168 - val_loss: 0.0807 - val_accuracy: 0.7386\n",
      "Epoch 4919/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0573 - accuracy: 0.8158 - val_loss: 0.0812 - val_accuracy: 0.7409\n",
      "Epoch 4920/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0573 - accuracy: 0.8155 - val_loss: 0.0823 - val_accuracy: 0.7403\n",
      "Epoch 4921/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0571 - accuracy: 0.8161 - val_loss: 0.0812 - val_accuracy: 0.7418\n",
      "Epoch 4922/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0572 - accuracy: 0.8158 - val_loss: 0.0821 - val_accuracy: 0.7373\n",
      "Epoch 4923/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0571 - accuracy: 0.8162 - val_loss: 0.0807 - val_accuracy: 0.7400\n",
      "Epoch 4924/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0568 - accuracy: 0.8175 - val_loss: 0.0823 - val_accuracy: 0.7391\n",
      "Epoch 4925/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0569 - accuracy: 0.8175 - val_loss: 0.0818 - val_accuracy: 0.7392\n",
      "Epoch 4926/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0570 - accuracy: 0.8167 - val_loss: 0.0814 - val_accuracy: 0.7408\n",
      "Epoch 4927/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0568 - accuracy: 0.8176 - val_loss: 0.0817 - val_accuracy: 0.7408\n",
      "Epoch 4928/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0572 - accuracy: 0.8163 - val_loss: 0.0806 - val_accuracy: 0.7426\n",
      "Epoch 4929/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0570 - accuracy: 0.8171 - val_loss: 0.0818 - val_accuracy: 0.7382\n",
      "Epoch 4930/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0571 - accuracy: 0.8170 - val_loss: 0.0817 - val_accuracy: 0.7398\n",
      "Epoch 4931/5000\n",
      "11786/11786 [==============================] - 8s 714us/step - loss: 0.0569 - accuracy: 0.8169 - val_loss: 0.0808 - val_accuracy: 0.7424\n",
      "Epoch 4932/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0570 - accuracy: 0.8166 - val_loss: 0.0808 - val_accuracy: 0.7393\n",
      "Epoch 4933/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0569 - accuracy: 0.8171 - val_loss: 0.0810 - val_accuracy: 0.7407\n",
      "Epoch 4934/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0570 - accuracy: 0.8169 - val_loss: 0.0804 - val_accuracy: 0.7398\n",
      "Epoch 4935/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0570 - accuracy: 0.8167 - val_loss: 0.0810 - val_accuracy: 0.7400\n",
      "Epoch 4936/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0569 - accuracy: 0.8166 - val_loss: 0.0824 - val_accuracy: 0.7404\n",
      "Epoch 4937/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0569 - accuracy: 0.8170 - val_loss: 0.0811 - val_accuracy: 0.7385\n",
      "Epoch 4938/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0570 - accuracy: 0.8166 - val_loss: 0.0796 - val_accuracy: 0.7429\n",
      "Epoch 4939/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0568 - accuracy: 0.8172 - val_loss: 0.0807 - val_accuracy: 0.7414\n",
      "Epoch 4940/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0571 - accuracy: 0.8165 - val_loss: 0.0812 - val_accuracy: 0.7407\n",
      "Epoch 4941/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0569 - accuracy: 0.8171 - val_loss: 0.0809 - val_accuracy: 0.7416\n",
      "Epoch 4942/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0567 - accuracy: 0.8173 - val_loss: 0.0803 - val_accuracy: 0.7415\n",
      "Epoch 4943/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0568 - accuracy: 0.8175 - val_loss: 0.0821 - val_accuracy: 0.7405\n",
      "Epoch 4944/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0569 - accuracy: 0.8172 - val_loss: 0.0806 - val_accuracy: 0.7421\n",
      "Epoch 4945/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0568 - accuracy: 0.8168 - val_loss: 0.0818 - val_accuracy: 0.7398\n",
      "Epoch 4946/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0567 - accuracy: 0.8172 - val_loss: 0.0816 - val_accuracy: 0.7404\n",
      "Epoch 4947/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0570 - accuracy: 0.8167 - val_loss: 0.0816 - val_accuracy: 0.7403\n",
      "Epoch 4948/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0569 - accuracy: 0.8168 - val_loss: 0.0809 - val_accuracy: 0.7429\n",
      "Epoch 4949/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0568 - accuracy: 0.8169 - val_loss: 0.0802 - val_accuracy: 0.7408\n",
      "Epoch 4950/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0570 - accuracy: 0.8162 - val_loss: 0.0809 - val_accuracy: 0.7415\n",
      "Epoch 4951/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0571 - accuracy: 0.8157 - val_loss: 0.0811 - val_accuracy: 0.7410\n",
      "Epoch 4952/5000\n",
      "11786/11786 [==============================] - 8s 698us/step - loss: 0.0569 - accuracy: 0.8175 - val_loss: 0.0827 - val_accuracy: 0.7379\n",
      "Epoch 4953/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0570 - accuracy: 0.8170 - val_loss: 0.0823 - val_accuracy: 0.7395\n",
      "Epoch 4954/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0569 - accuracy: 0.8167 - val_loss: 0.0824 - val_accuracy: 0.7387\n",
      "Epoch 4955/5000\n",
      "11786/11786 [==============================] - 8s 692us/step - loss: 0.0571 - accuracy: 0.8164 - val_loss: 0.0811 - val_accuracy: 0.7387\n",
      "Epoch 4956/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0571 - accuracy: 0.8163 - val_loss: 0.0814 - val_accuracy: 0.7398\n",
      "Epoch 4957/5000\n",
      "11786/11786 [==============================] - 8s 702us/step - loss: 0.0568 - accuracy: 0.8178 - val_loss: 0.0806 - val_accuracy: 0.7409\n",
      "Epoch 4958/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0569 - accuracy: 0.8172 - val_loss: 0.0819 - val_accuracy: 0.7424\n",
      "Epoch 4959/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0569 - accuracy: 0.8180 - val_loss: 0.0797 - val_accuracy: 0.7431\n",
      "Epoch 4960/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0568 - accuracy: 0.8182 - val_loss: 0.0799 - val_accuracy: 0.7421\n",
      "Epoch 4961/5000\n",
      "11786/11786 [==============================] - 8s 701us/step - loss: 0.0569 - accuracy: 0.8175 - val_loss: 0.0808 - val_accuracy: 0.7395\n",
      "Epoch 4962/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0569 - accuracy: 0.8170 - val_loss: 0.0800 - val_accuracy: 0.7417\n",
      "Epoch 4963/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0569 - accuracy: 0.8168 - val_loss: 0.0812 - val_accuracy: 0.7407\n",
      "Epoch 4964/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0569 - accuracy: 0.8171 - val_loss: 0.0811 - val_accuracy: 0.7413\n",
      "Epoch 4965/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0570 - accuracy: 0.8169 - val_loss: 0.0809 - val_accuracy: 0.7431\n",
      "Epoch 4966/5000\n",
      "11786/11786 [==============================] - 8s 697us/step - loss: 0.0569 - accuracy: 0.8180 - val_loss: 0.0810 - val_accuracy: 0.7431\n",
      "Epoch 4967/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0571 - accuracy: 0.8169 - val_loss: 0.0814 - val_accuracy: 0.7401\n",
      "Epoch 4968/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0568 - accuracy: 0.8177 - val_loss: 0.0810 - val_accuracy: 0.7391\n",
      "Epoch 4969/5000\n",
      "11786/11786 [==============================] - 8s 710us/step - loss: 0.0570 - accuracy: 0.8172 - val_loss: 0.0817 - val_accuracy: 0.7407\n",
      "Epoch 4970/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0568 - accuracy: 0.8181 - val_loss: 0.0799 - val_accuracy: 0.7390\n",
      "Epoch 4971/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0569 - accuracy: 0.8173 - val_loss: 0.0818 - val_accuracy: 0.7419\n",
      "Epoch 4972/5000\n",
      "11786/11786 [==============================] - 8s 708us/step - loss: 0.0569 - accuracy: 0.8172 - val_loss: 0.0814 - val_accuracy: 0.7406\n",
      "Epoch 4973/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0569 - accuracy: 0.8173 - val_loss: 0.0807 - val_accuracy: 0.7409\n",
      "Epoch 4974/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0570 - accuracy: 0.8170 - val_loss: 0.0804 - val_accuracy: 0.7404\n",
      "Epoch 4975/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0568 - accuracy: 0.8175 - val_loss: 0.0809 - val_accuracy: 0.7425\n",
      "Epoch 4976/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0569 - accuracy: 0.8173 - val_loss: 0.0802 - val_accuracy: 0.7417\n",
      "Epoch 4977/5000\n",
      "11786/11786 [==============================] - 8s 700us/step - loss: 0.0567 - accuracy: 0.8178 - val_loss: 0.0807 - val_accuracy: 0.7400\n",
      "Epoch 4978/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0568 - accuracy: 0.8172 - val_loss: 0.0811 - val_accuracy: 0.7405\n",
      "Epoch 4979/5000\n",
      "11786/11786 [==============================] - 8s 707us/step - loss: 0.0569 - accuracy: 0.8166 - val_loss: 0.0814 - val_accuracy: 0.7411\n",
      "Epoch 4980/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0568 - accuracy: 0.8173 - val_loss: 0.0799 - val_accuracy: 0.7428\n",
      "Epoch 4981/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0569 - accuracy: 0.8177 - val_loss: 0.0802 - val_accuracy: 0.7420\n",
      "Epoch 4982/5000\n",
      "11786/11786 [==============================] - 8s 704us/step - loss: 0.0570 - accuracy: 0.8168 - val_loss: 0.0816 - val_accuracy: 0.7383\n",
      "Epoch 4983/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0568 - accuracy: 0.8176 - val_loss: 0.0814 - val_accuracy: 0.7405\n",
      "Epoch 4984/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0567 - accuracy: 0.8178 - val_loss: 0.0801 - val_accuracy: 0.7420\n",
      "Epoch 4985/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0568 - accuracy: 0.8176 - val_loss: 0.0803 - val_accuracy: 0.7421\n",
      "Epoch 4986/5000\n",
      "11786/11786 [==============================] - 8s 706us/step - loss: 0.0568 - accuracy: 0.8172 - val_loss: 0.0807 - val_accuracy: 0.7400\n",
      "Epoch 4987/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0567 - accuracy: 0.8172 - val_loss: 0.0808 - val_accuracy: 0.7412\n",
      "Epoch 4988/5000\n",
      "11786/11786 [==============================] - 8s 709us/step - loss: 0.0569 - accuracy: 0.8168 - val_loss: 0.0806 - val_accuracy: 0.7425\n",
      "Epoch 4989/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0568 - accuracy: 0.8178 - val_loss: 0.0817 - val_accuracy: 0.7397\n",
      "Epoch 4990/5000\n",
      "11786/11786 [==============================] - 8s 711us/step - loss: 0.0567 - accuracy: 0.8178 - val_loss: 0.0799 - val_accuracy: 0.7425\n",
      "Epoch 4991/5000\n",
      "11786/11786 [==============================] - 8s 712us/step - loss: 0.0567 - accuracy: 0.8179 - val_loss: 0.0804 - val_accuracy: 0.7407\n",
      "Epoch 4992/5000\n",
      "11786/11786 [==============================] - 8s 713us/step - loss: 0.0568 - accuracy: 0.8177 - val_loss: 0.0806 - val_accuracy: 0.7424\n",
      "Epoch 4993/5000\n",
      "11786/11786 [==============================] - 8s 716us/step - loss: 0.0568 - accuracy: 0.8176 - val_loss: 0.0797 - val_accuracy: 0.7421\n",
      "Epoch 4994/5000\n",
      "11786/11786 [==============================] - 8s 718us/step - loss: 0.0568 - accuracy: 0.8179 - val_loss: 0.0801 - val_accuracy: 0.7407\n",
      "Epoch 4995/5000\n",
      "11786/11786 [==============================] - 8s 705us/step - loss: 0.0567 - accuracy: 0.8179 - val_loss: 0.0800 - val_accuracy: 0.7416\n",
      "Epoch 4996/5000\n",
      "11786/11786 [==============================] - 8s 715us/step - loss: 0.0567 - accuracy: 0.8175 - val_loss: 0.0810 - val_accuracy: 0.7424\n",
      "Epoch 4997/5000\n",
      "11786/11786 [==============================] - 8s 720us/step - loss: 0.0567 - accuracy: 0.8178 - val_loss: 0.0803 - val_accuracy: 0.7405\n",
      "Epoch 4998/5000\n",
      "11786/11786 [==============================] - 8s 714us/step - loss: 0.0569 - accuracy: 0.8175 - val_loss: 0.0809 - val_accuracy: 0.7416\n",
      "Epoch 4999/5000\n",
      "11786/11786 [==============================] - 8s 703us/step - loss: 0.0567 - accuracy: 0.8173 - val_loss: 0.0798 - val_accuracy: 0.7416\n",
      "Epoch 5000/5000\n",
      "11786/11786 [==============================] - 8s 714us/step - loss: 0.0566 - accuracy: 0.8178 - val_loss: 0.0803 - val_accuracy: 0.7419\n"
     ]
    }
   ],
   "source": [
    "history = (model.fit(X_train, y_train, epochs=5000, validation_data=(X_val, y_val), callbacks=[model_checkpoint_callback]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICT AND PLOT\n",
    "\n",
    "##### For 1000 epochs, from data saved in `'/media/csuser/DATA/ARTEMIS/yale/NN_acc_report.csv'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICT AND PLOT\n",
    "\n",
    "##### For 5000 epochs, from data saved in history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/csuser/DATA/ARTEMIS/romania\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig('/media/csuser/DATA/ARTEMIS/yale/figs/NN_ACCURACYvsEPOCHS.png', dpi=500)\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig('/media/csuser/DATA/ARTEMIS/yale/figs/NN_LOSSvsEPOCHS.png', dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f9699277670>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model.load_weights('/media/csuser/DATA/ARTEMIS/models/yale_smote')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(117852, 488)\n",
      "3683/3683 [==============================] - 1s 332us/step\n",
      "(117852, 5)\n",
      "(117852, 5)\n",
      "[4 4 0 ... 1 4 1]\n",
      "[4 4 0 ... 1 4 1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CONFUSION MATRIX\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, classification_report, recall_score, ConfusionMatrixDisplay\n",
    "from numpy import argmax\n",
    "\n",
    "print(X_test.shape)\n",
    "y_pred = model.predict(X_test)\n",
    "print(y_test.shape)\n",
    "print(y_pred.shape)\n",
    "y_test = argmax(a=y_test, axis=1)\n",
    "y_pred = argmax(a=y_pred, axis=1)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "ConfusionMatrixDisplay.from_predictions(y_test+1, y_pred+1)\n",
    "plt.savefig('/media/csuser/DATA/ARTEMIS/yale/figs/NN_confusion_yale_smote.png', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 0, ..., 1, 4, 1])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "FP = cm.sum(axis=0) - np.diag(cm)  \n",
    "FN = cm.sum(axis=1) - np.diag(cm)\n",
    "TP = np.diag(cm)\n",
    "TN = cm.sum() - (FP + FN + TP)\n",
    "\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP) \n",
    "# Precision or positive predictive value\n",
    "PPV = TP/(TP+FP)\n",
    "# Negative predictive value\n",
    "NPV = TN/(TN+FN)\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "# False negative rate\n",
    "FNR = FN/(TP+FN)\n",
    "# False discovery rate\n",
    "FDR = FP/(TP+FP)\n",
    "\n",
    "# Overall accuracy\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99933272 0.7408853  0.58834065 0.67671117 0.84916652] [0.99719837 0.94451966 0.91980128 0.9147013  0.93887805] [0.98914345 0.76707523 0.64566855 0.66509768 0.77594715] [0.99982911 0.93663331 0.89995336 0.91871703 0.96149462] [0.00280163 0.05548034 0.08019872 0.0852987  0.06112195] [0.01085655 0.23292477 0.35433145 0.33490232 0.22405285] [0.99763262 0.90423582 0.85385059 0.86705359 0.92097716]\n"
     ]
    }
   ],
   "source": [
    "print(TPR, TNR, PPV, NPV, FPR, FDR, ACC)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
