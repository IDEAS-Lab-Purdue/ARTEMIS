{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processing\n",
    "import string\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/csuser/DATA/ARTEMIS/yale\n"
     ]
    }
   ],
   "source": [
    "# read RData\n",
    "#res = pyreadr.read_r('5v_cleandf.RData')\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = res[\"df\"]\n",
    "df = pd.read_csv('/media/csuser/DATA/ARTEMIS/yale/yale_triage.csv')\n",
    "# df.dropna()\n",
    "# df.to_csv('yale_triage.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(560486, 973)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = df.dropna()\n",
    "# with all the 972 columns, if you run dropna directly, there actually ends up being 0 \n",
    "# remaining rows\n",
    "\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208\n",
      "208\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "269549"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = df.keys()\n",
    "#new_keys = ['triage_vital_temp', 'triage_vital_rr', 'triage_vital_hr', 'triage_vital_sbp', 'triage_vital_dbp', 'triage_vital_o2', 'esi', 'age']\n",
    "new_keys = ['triage_vital_temp', 'triage_vital_rr', 'triage_vital_hr', 'triage_vital_sbp', 'triage_vital_dbp', 'triage_vital_o2', 'age']\n",
    "# reach = False\n",
    "\n",
    "# for i in range(len(keys)):\n",
    "#     if(keys[i]!='2ndarymalig' and reach==False):\n",
    "#         # print(keys[i])\n",
    "#         continue\n",
    "#     reach = True\n",
    "#     if(keys[i]!='whtblooddx'):\n",
    "#         new_keys.append(keys[i])\n",
    "#     else:\n",
    "#         new_keys.append(keys[i])\n",
    "#         break\n",
    "\n",
    "reach = False\n",
    "for i in range(len(keys)):\n",
    "    if(keys[i]!='cc_abdominalcramping' and reach==False):\n",
    "        continue\n",
    "    reach = True\n",
    "    if(keys[i]!='cc_wristpain'):\n",
    "        new_keys.append(keys[i])\n",
    "    else:\n",
    "        new_keys.append(keys[i])\n",
    "        break\n",
    "\n",
    "new_keys.append('esi')\n",
    "print(len(list(set(new_keys))))\n",
    "print(len(new_keys))\n",
    "#df = df[['triage_vital_temp', 'triage_vital_rr', 'triage_vital_hr', 'triage_vital_sbp', 'triage_vital_dbp', 'triage_vital_o2', 'esi', 'age', 'gender', 'arrivalmode', 'previousdispo']]\n",
    "df = df[new_keys]\n",
    "df = df.dropna()\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df.head()\n",
    "len(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df[\"triage_vital_temp\"] >= 51.8) & (df[\"triage_vital_temp\"] <= 108.14) & (df[\"triage_vital_hr\"] > 0) & (df[\"triage_vital_hr\"] < 140) & (df[\"triage_vital_o2\"] > 0) & (df[\"triage_vital_o2\"] < 100)]\n",
    "df = df.drop(df.loc[df['triage_vital_sbp'] > 400].index) # impossible\n",
    "df = df.drop(df.loc[df['triage_vital_dbp'] > 400].index) # impossible\n",
    "df = df.drop(df.loc[df['triage_vital_rr'] > 200].index) # impossible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csuser/mambaforge/envs/tim/lib/python3.8/site-packages/pandas/plotting/_matplotlib/core.py:1070: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored\n",
      "  scatter = ax.scatter(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109106    2.0\n",
      "141020    1.0\n",
      "Name: esi, dtype: float64\n",
      "(268469, 208)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.plot.scatter(x=\"triage_vital_temp\", y=\"esi\")\n",
    "print(df.esi[df.loc[df[\"triage_vital_temp\"] == max(df.triage_vital_temp)].index])\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>triage_vital_temp</th>\n",
       "      <th>triage_vital_rr</th>\n",
       "      <th>triage_vital_hr</th>\n",
       "      <th>triage_vital_sbp</th>\n",
       "      <th>triage_vital_dbp</th>\n",
       "      <th>triage_vital_o2</th>\n",
       "      <th>age</th>\n",
       "      <th>cc_abdominalcramping</th>\n",
       "      <th>cc_abdominaldistention</th>\n",
       "      <th>cc_abdominalpain</th>\n",
       "      <th>...</th>\n",
       "      <th>cc_vaginalpain</th>\n",
       "      <th>cc_weakness</th>\n",
       "      <th>cc_wheezing</th>\n",
       "      <th>cc_withdrawal-alcohol</th>\n",
       "      <th>cc_woundcheck</th>\n",
       "      <th>cc_woundinfection</th>\n",
       "      <th>cc_woundre-evaluation</th>\n",
       "      <th>cc_wristinjury</th>\n",
       "      <th>cc_wristpain</th>\n",
       "      <th>esi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97.8</td>\n",
       "      <td>16.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98.4</td>\n",
       "      <td>18.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98.5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97.8</td>\n",
       "      <td>17.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269544</th>\n",
       "      <td>98.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269545</th>\n",
       "      <td>98.1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269546</th>\n",
       "      <td>97.5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269547</th>\n",
       "      <td>97.5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269548</th>\n",
       "      <td>98.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>268469 rows Ã— 208 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        triage_vital_temp  triage_vital_rr  triage_vital_hr  triage_vital_sbp  \\\n",
       "0                    97.0             18.0             63.0             146.0   \n",
       "1                    97.8             16.0             78.0             134.0   \n",
       "2                    98.4             18.0            101.0             133.0   \n",
       "3                    98.5             18.0             76.0             143.0   \n",
       "4                    97.8             17.0             88.0             155.0   \n",
       "...                   ...              ...              ...               ...   \n",
       "269544               98.0             16.0             71.0             117.0   \n",
       "269545               98.1             16.0             89.0             114.0   \n",
       "269546               97.5             18.0             89.0             125.0   \n",
       "269547               97.5             18.0             89.0             135.0   \n",
       "269548               98.0             16.0             77.0             118.0   \n",
       "\n",
       "        triage_vital_dbp  triage_vital_o2   age  cc_abdominalcramping  \\\n",
       "0                   85.0             97.0  40.0                   0.0   \n",
       "1                   78.0             97.0  66.0                   0.0   \n",
       "2                   72.0             97.0  84.0                   0.0   \n",
       "3                   87.0             98.0  86.0                   0.0   \n",
       "4                   75.0             98.0  87.0                   0.0   \n",
       "...                  ...              ...   ...                   ...   \n",
       "269544              74.0             95.0  49.0                   0.0   \n",
       "269545              75.0             94.0  49.0                   0.0   \n",
       "269546              82.0             94.0  50.0                   0.0   \n",
       "269547              92.0             98.0  50.0                   0.0   \n",
       "269548              73.0             94.0  50.0                   0.0   \n",
       "\n",
       "        cc_abdominaldistention  cc_abdominalpain  ...  cc_vaginalpain  \\\n",
       "0                          0.0               0.0  ...             0.0   \n",
       "1                          0.0               0.0  ...             0.0   \n",
       "2                          0.0               0.0  ...             0.0   \n",
       "3                          0.0               0.0  ...             0.0   \n",
       "4                          0.0               0.0  ...             0.0   \n",
       "...                        ...               ...  ...             ...   \n",
       "269544                     0.0               0.0  ...             0.0   \n",
       "269545                     0.0               0.0  ...             0.0   \n",
       "269546                     0.0               0.0  ...             0.0   \n",
       "269547                     0.0               0.0  ...             0.0   \n",
       "269548                     0.0               0.0  ...             0.0   \n",
       "\n",
       "        cc_weakness  cc_wheezing  cc_withdrawal-alcohol  cc_woundcheck  \\\n",
       "0               0.0          0.0                    0.0            0.0   \n",
       "1               0.0          0.0                    0.0            0.0   \n",
       "2               0.0          0.0                    0.0            0.0   \n",
       "3               0.0          0.0                    0.0            0.0   \n",
       "4               0.0          0.0                    0.0            0.0   \n",
       "...             ...          ...                    ...            ...   \n",
       "269544          0.0          0.0                    0.0            0.0   \n",
       "269545          0.0          0.0                    0.0            0.0   \n",
       "269546          0.0          0.0                    0.0            0.0   \n",
       "269547          0.0          0.0                    0.0            0.0   \n",
       "269548          0.0          0.0                    0.0            0.0   \n",
       "\n",
       "        cc_woundinfection  cc_woundre-evaluation  cc_wristinjury  \\\n",
       "0                     0.0                    0.0             0.0   \n",
       "1                     0.0                    0.0             0.0   \n",
       "2                     0.0                    0.0             0.0   \n",
       "3                     0.0                    0.0             0.0   \n",
       "4                     0.0                    0.0             0.0   \n",
       "...                   ...                    ...             ...   \n",
       "269544                0.0                    0.0             0.0   \n",
       "269545                0.0                    0.0             0.0   \n",
       "269546                0.0                    0.0             0.0   \n",
       "269547                0.0                    0.0             0.0   \n",
       "269548                0.0                    0.0             0.0   \n",
       "\n",
       "        cc_wristpain  esi  \n",
       "0                0.0  4.0  \n",
       "1                0.0  2.0  \n",
       "2                0.0  3.0  \n",
       "3                0.0  3.0  \n",
       "4                0.0  4.0  \n",
       "...              ...  ...  \n",
       "269544           0.0  3.0  \n",
       "269545           0.0  3.0  \n",
       "269546           0.0  3.0  \n",
       "269547           0.0  3.0  \n",
       "269548           0.0  3.0  \n",
       "\n",
       "[268469 rows x 208 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0    117852\n",
       "4.0     71472\n",
       "2.0     67048\n",
       "5.0     11835\n",
       "1.0       262\n",
       "Name: esi, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"esi\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the data\n",
    "numerical_cols = ['triage_vital_temp', 'triage_vital_hr', 'triage_vital_o2', 'triage_vital_sbp', 'triage_vital_dbp', 'triage_vital_rr', 'age']\n",
    "for col in numerical_cols:\n",
    "   df[col] = (df[col] - df[col].min()) / (df[col].max() - df[col].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversample and plot imbalanced dataset with SMOTE\n",
    "# Oversample with SMOTE and random undersample for imbalanced dataset\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from matplotlib import pyplot\n",
    "from numpy import where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>triage_vital_temp</th>\n",
       "      <th>triage_vital_rr</th>\n",
       "      <th>triage_vital_hr</th>\n",
       "      <th>triage_vital_sbp</th>\n",
       "      <th>triage_vital_dbp</th>\n",
       "      <th>triage_vital_o2</th>\n",
       "      <th>age</th>\n",
       "      <th>cc_abdominalcramping</th>\n",
       "      <th>cc_abdominaldistention</th>\n",
       "      <th>cc_abdominalpain</th>\n",
       "      <th>...</th>\n",
       "      <th>cc_vaginalpain</th>\n",
       "      <th>cc_weakness</th>\n",
       "      <th>cc_wheezing</th>\n",
       "      <th>cc_withdrawal-alcohol</th>\n",
       "      <th>cc_woundcheck</th>\n",
       "      <th>cc_woundinfection</th>\n",
       "      <th>cc_woundre-evaluation</th>\n",
       "      <th>cc_wristinjury</th>\n",
       "      <th>cc_wristpain</th>\n",
       "      <th>esi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.43750</td>\n",
       "      <td>0.163934</td>\n",
       "      <td>0.302752</td>\n",
       "      <td>0.363985</td>\n",
       "      <td>0.365854</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.247191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.48750</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>0.440367</td>\n",
       "      <td>0.318008</td>\n",
       "      <td>0.323171</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.539326</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.52500</td>\n",
       "      <td>0.163934</td>\n",
       "      <td>0.651376</td>\n",
       "      <td>0.314176</td>\n",
       "      <td>0.286585</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.741573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.53125</td>\n",
       "      <td>0.163934</td>\n",
       "      <td>0.422018</td>\n",
       "      <td>0.352490</td>\n",
       "      <td>0.378049</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.48750</td>\n",
       "      <td>0.147541</td>\n",
       "      <td>0.532110</td>\n",
       "      <td>0.398467</td>\n",
       "      <td>0.304878</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269544</th>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>0.376147</td>\n",
       "      <td>0.252874</td>\n",
       "      <td>0.298780</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.348315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269545</th>\n",
       "      <td>0.50625</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>0.541284</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.304878</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.348315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269546</th>\n",
       "      <td>0.46875</td>\n",
       "      <td>0.163934</td>\n",
       "      <td>0.541284</td>\n",
       "      <td>0.283525</td>\n",
       "      <td>0.347561</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.359551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269547</th>\n",
       "      <td>0.46875</td>\n",
       "      <td>0.163934</td>\n",
       "      <td>0.541284</td>\n",
       "      <td>0.321839</td>\n",
       "      <td>0.408537</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.359551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269548</th>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>0.431193</td>\n",
       "      <td>0.256705</td>\n",
       "      <td>0.292683</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.359551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>268469 rows Ã— 208 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        triage_vital_temp  triage_vital_rr  triage_vital_hr  triage_vital_sbp  \\\n",
       "0                 0.43750         0.163934         0.302752          0.363985   \n",
       "1                 0.48750         0.131148         0.440367          0.318008   \n",
       "2                 0.52500         0.163934         0.651376          0.314176   \n",
       "3                 0.53125         0.163934         0.422018          0.352490   \n",
       "4                 0.48750         0.147541         0.532110          0.398467   \n",
       "...                   ...              ...              ...               ...   \n",
       "269544            0.50000         0.131148         0.376147          0.252874   \n",
       "269545            0.50625         0.131148         0.541284          0.241379   \n",
       "269546            0.46875         0.163934         0.541284          0.283525   \n",
       "269547            0.46875         0.163934         0.541284          0.321839   \n",
       "269548            0.50000         0.131148         0.431193          0.256705   \n",
       "\n",
       "        triage_vital_dbp  triage_vital_o2       age  cc_abdominalcramping  \\\n",
       "0               0.365854         0.948718  0.247191                   0.0   \n",
       "1               0.323171         0.948718  0.539326                   0.0   \n",
       "2               0.286585         0.948718  0.741573                   0.0   \n",
       "3               0.378049         0.974359  0.764045                   0.0   \n",
       "4               0.304878         0.974359  0.775281                   0.0   \n",
       "...                  ...              ...       ...                   ...   \n",
       "269544          0.298780         0.897436  0.348315                   0.0   \n",
       "269545          0.304878         0.871795  0.348315                   0.0   \n",
       "269546          0.347561         0.871795  0.359551                   0.0   \n",
       "269547          0.408537         0.974359  0.359551                   0.0   \n",
       "269548          0.292683         0.871795  0.359551                   0.0   \n",
       "\n",
       "        cc_abdominaldistention  cc_abdominalpain  ...  cc_vaginalpain  \\\n",
       "0                          0.0               0.0  ...             0.0   \n",
       "1                          0.0               0.0  ...             0.0   \n",
       "2                          0.0               0.0  ...             0.0   \n",
       "3                          0.0               0.0  ...             0.0   \n",
       "4                          0.0               0.0  ...             0.0   \n",
       "...                        ...               ...  ...             ...   \n",
       "269544                     0.0               0.0  ...             0.0   \n",
       "269545                     0.0               0.0  ...             0.0   \n",
       "269546                     0.0               0.0  ...             0.0   \n",
       "269547                     0.0               0.0  ...             0.0   \n",
       "269548                     0.0               0.0  ...             0.0   \n",
       "\n",
       "        cc_weakness  cc_wheezing  cc_withdrawal-alcohol  cc_woundcheck  \\\n",
       "0               0.0          0.0                    0.0            0.0   \n",
       "1               0.0          0.0                    0.0            0.0   \n",
       "2               0.0          0.0                    0.0            0.0   \n",
       "3               0.0          0.0                    0.0            0.0   \n",
       "4               0.0          0.0                    0.0            0.0   \n",
       "...             ...          ...                    ...            ...   \n",
       "269544          0.0          0.0                    0.0            0.0   \n",
       "269545          0.0          0.0                    0.0            0.0   \n",
       "269546          0.0          0.0                    0.0            0.0   \n",
       "269547          0.0          0.0                    0.0            0.0   \n",
       "269548          0.0          0.0                    0.0            0.0   \n",
       "\n",
       "        cc_woundinfection  cc_woundre-evaluation  cc_wristinjury  \\\n",
       "0                     0.0                    0.0             0.0   \n",
       "1                     0.0                    0.0             0.0   \n",
       "2                     0.0                    0.0             0.0   \n",
       "3                     0.0                    0.0             0.0   \n",
       "4                     0.0                    0.0             0.0   \n",
       "...                   ...                    ...             ...   \n",
       "269544                0.0                    0.0             0.0   \n",
       "269545                0.0                    0.0             0.0   \n",
       "269546                0.0                    0.0             0.0   \n",
       "269547                0.0                    0.0             0.0   \n",
       "269548                0.0                    0.0             0.0   \n",
       "\n",
       "        cc_wristpain  esi  \n",
       "0                0.0  4.0  \n",
       "1                0.0  2.0  \n",
       "2                0.0  3.0  \n",
       "3                0.0  3.0  \n",
       "4                0.0  4.0  \n",
       "...              ...  ...  \n",
       "269544           0.0  3.0  \n",
       "269545           0.0  3.0  \n",
       "269546           0.0  3.0  \n",
       "269547           0.0  3.0  \n",
       "269548           0.0  3.0  \n",
       "\n",
       "[268469 rows x 208 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({3.0: 117852, 4.0: 71472, 2.0: 67048, 5.0: 11835, 1.0: 262})\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['esi'], axis=1).to_numpy()\n",
    "y = df['esi'].to_numpy()\n",
    "counter = Counter(y)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>triage_vital_temp</th>\n",
       "      <th>triage_vital_rr</th>\n",
       "      <th>triage_vital_hr</th>\n",
       "      <th>triage_vital_sbp</th>\n",
       "      <th>triage_vital_dbp</th>\n",
       "      <th>triage_vital_o2</th>\n",
       "      <th>age</th>\n",
       "      <th>cc_abdominalcramping</th>\n",
       "      <th>cc_abdominaldistention</th>\n",
       "      <th>cc_abdominalpain</th>\n",
       "      <th>...</th>\n",
       "      <th>cc_vaginalpain</th>\n",
       "      <th>cc_weakness</th>\n",
       "      <th>cc_wheezing</th>\n",
       "      <th>cc_withdrawal-alcohol</th>\n",
       "      <th>cc_woundcheck</th>\n",
       "      <th>cc_woundinfection</th>\n",
       "      <th>cc_woundre-evaluation</th>\n",
       "      <th>cc_wristinjury</th>\n",
       "      <th>cc_wristpain</th>\n",
       "      <th>esi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.43750</td>\n",
       "      <td>0.163934</td>\n",
       "      <td>0.302752</td>\n",
       "      <td>0.363985</td>\n",
       "      <td>0.365854</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.247191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.48750</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>0.440367</td>\n",
       "      <td>0.318008</td>\n",
       "      <td>0.323171</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.539326</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.52500</td>\n",
       "      <td>0.163934</td>\n",
       "      <td>0.651376</td>\n",
       "      <td>0.314176</td>\n",
       "      <td>0.286585</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.741573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.53125</td>\n",
       "      <td>0.163934</td>\n",
       "      <td>0.422018</td>\n",
       "      <td>0.352490</td>\n",
       "      <td>0.378049</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.48750</td>\n",
       "      <td>0.147541</td>\n",
       "      <td>0.532110</td>\n",
       "      <td>0.398467</td>\n",
       "      <td>0.304878</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269544</th>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>0.376147</td>\n",
       "      <td>0.252874</td>\n",
       "      <td>0.298780</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.348315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269545</th>\n",
       "      <td>0.50625</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>0.541284</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.304878</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.348315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269546</th>\n",
       "      <td>0.46875</td>\n",
       "      <td>0.163934</td>\n",
       "      <td>0.541284</td>\n",
       "      <td>0.283525</td>\n",
       "      <td>0.347561</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.359551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269547</th>\n",
       "      <td>0.46875</td>\n",
       "      <td>0.163934</td>\n",
       "      <td>0.541284</td>\n",
       "      <td>0.321839</td>\n",
       "      <td>0.408537</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.359551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269548</th>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>0.431193</td>\n",
       "      <td>0.256705</td>\n",
       "      <td>0.292683</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.359551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>268469 rows Ã— 208 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        triage_vital_temp  triage_vital_rr  triage_vital_hr  triage_vital_sbp  \\\n",
       "0                 0.43750         0.163934         0.302752          0.363985   \n",
       "1                 0.48750         0.131148         0.440367          0.318008   \n",
       "2                 0.52500         0.163934         0.651376          0.314176   \n",
       "3                 0.53125         0.163934         0.422018          0.352490   \n",
       "4                 0.48750         0.147541         0.532110          0.398467   \n",
       "...                   ...              ...              ...               ...   \n",
       "269544            0.50000         0.131148         0.376147          0.252874   \n",
       "269545            0.50625         0.131148         0.541284          0.241379   \n",
       "269546            0.46875         0.163934         0.541284          0.283525   \n",
       "269547            0.46875         0.163934         0.541284          0.321839   \n",
       "269548            0.50000         0.131148         0.431193          0.256705   \n",
       "\n",
       "        triage_vital_dbp  triage_vital_o2       age  cc_abdominalcramping  \\\n",
       "0               0.365854         0.948718  0.247191                   0.0   \n",
       "1               0.323171         0.948718  0.539326                   0.0   \n",
       "2               0.286585         0.948718  0.741573                   0.0   \n",
       "3               0.378049         0.974359  0.764045                   0.0   \n",
       "4               0.304878         0.974359  0.775281                   0.0   \n",
       "...                  ...              ...       ...                   ...   \n",
       "269544          0.298780         0.897436  0.348315                   0.0   \n",
       "269545          0.304878         0.871795  0.348315                   0.0   \n",
       "269546          0.347561         0.871795  0.359551                   0.0   \n",
       "269547          0.408537         0.974359  0.359551                   0.0   \n",
       "269548          0.292683         0.871795  0.359551                   0.0   \n",
       "\n",
       "        cc_abdominaldistention  cc_abdominalpain  ...  cc_vaginalpain  \\\n",
       "0                          0.0               0.0  ...             0.0   \n",
       "1                          0.0               0.0  ...             0.0   \n",
       "2                          0.0               0.0  ...             0.0   \n",
       "3                          0.0               0.0  ...             0.0   \n",
       "4                          0.0               0.0  ...             0.0   \n",
       "...                        ...               ...  ...             ...   \n",
       "269544                     0.0               0.0  ...             0.0   \n",
       "269545                     0.0               0.0  ...             0.0   \n",
       "269546                     0.0               0.0  ...             0.0   \n",
       "269547                     0.0               0.0  ...             0.0   \n",
       "269548                     0.0               0.0  ...             0.0   \n",
       "\n",
       "        cc_weakness  cc_wheezing  cc_withdrawal-alcohol  cc_woundcheck  \\\n",
       "0               0.0          0.0                    0.0            0.0   \n",
       "1               0.0          0.0                    0.0            0.0   \n",
       "2               0.0          0.0                    0.0            0.0   \n",
       "3               0.0          0.0                    0.0            0.0   \n",
       "4               0.0          0.0                    0.0            0.0   \n",
       "...             ...          ...                    ...            ...   \n",
       "269544          0.0          0.0                    0.0            0.0   \n",
       "269545          0.0          0.0                    0.0            0.0   \n",
       "269546          0.0          0.0                    0.0            0.0   \n",
       "269547          0.0          0.0                    0.0            0.0   \n",
       "269548          0.0          0.0                    0.0            0.0   \n",
       "\n",
       "        cc_woundinfection  cc_woundre-evaluation  cc_wristinjury  \\\n",
       "0                     0.0                    0.0             0.0   \n",
       "1                     0.0                    0.0             0.0   \n",
       "2                     0.0                    0.0             0.0   \n",
       "3                     0.0                    0.0             0.0   \n",
       "4                     0.0                    0.0             0.0   \n",
       "...                   ...                    ...             ...   \n",
       "269544                0.0                    0.0             0.0   \n",
       "269545                0.0                    0.0             0.0   \n",
       "269546                0.0                    0.0             0.0   \n",
       "269547                0.0                    0.0             0.0   \n",
       "269548                0.0                    0.0             0.0   \n",
       "\n",
       "        cc_wristpain  esi  \n",
       "0                0.0  4.0  \n",
       "1                0.0  2.0  \n",
       "2                0.0  3.0  \n",
       "3                0.0  3.0  \n",
       "4                0.0  4.0  \n",
       "...              ...  ...  \n",
       "269544           0.0  3.0  \n",
       "269545           0.0  3.0  \n",
       "269546           0.0  3.0  \n",
       "269547           0.0  3.0  \n",
       "269548           0.0  3.0  \n",
       "\n",
       "[268469 rows x 208 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for label, _ in counter.items():\n",
    "    row_ix = where(y == label)[0]\n",
    "    plt.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "over = SMOTE(sampling_strategy={1: 117852, 2: 117852, 3: 117852, 4: 117852, 5: 117852})\n",
    "# under = RandomUnderSampler(sampling_strategy={1: 117852, 2: 117852, 3: 117852, 4: 117852, 5: 117852})\n",
    "steps = [('o', over),]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "X, y = pipeline.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({4.0: 117852, 2.0: 117852, 3.0: 117852, 5.0: 117852, 1.0: 117852})\n"
     ]
    }
   ],
   "source": [
    "counter = Counter(y)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for label, _ in counter.items():\n",
    "    row_ix = where(y == label)[0]\n",
    "    plt.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>triage_vital_temp</th>\n",
       "      <th>triage_vital_rr</th>\n",
       "      <th>triage_vital_hr</th>\n",
       "      <th>triage_vital_sbp</th>\n",
       "      <th>triage_vital_dbp</th>\n",
       "      <th>triage_vital_o2</th>\n",
       "      <th>age</th>\n",
       "      <th>cc_abdominalcramping</th>\n",
       "      <th>cc_abdominaldistention</th>\n",
       "      <th>cc_abdominalpain</th>\n",
       "      <th>...</th>\n",
       "      <th>cc_vaginalpain</th>\n",
       "      <th>cc_weakness</th>\n",
       "      <th>cc_wheezing</th>\n",
       "      <th>cc_withdrawal-alcohol</th>\n",
       "      <th>cc_woundcheck</th>\n",
       "      <th>cc_woundinfection</th>\n",
       "      <th>cc_woundre-evaluation</th>\n",
       "      <th>cc_wristinjury</th>\n",
       "      <th>cc_wristpain</th>\n",
       "      <th>esi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.43750</td>\n",
       "      <td>0.163934</td>\n",
       "      <td>0.302752</td>\n",
       "      <td>0.363985</td>\n",
       "      <td>0.365854</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.247191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.48750</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>0.440367</td>\n",
       "      <td>0.318008</td>\n",
       "      <td>0.323171</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.539326</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.52500</td>\n",
       "      <td>0.163934</td>\n",
       "      <td>0.651376</td>\n",
       "      <td>0.314176</td>\n",
       "      <td>0.286585</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.741573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.53125</td>\n",
       "      <td>0.163934</td>\n",
       "      <td>0.422018</td>\n",
       "      <td>0.352490</td>\n",
       "      <td>0.378049</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.48750</td>\n",
       "      <td>0.147541</td>\n",
       "      <td>0.532110</td>\n",
       "      <td>0.398467</td>\n",
       "      <td>0.304878</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269544</th>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>0.376147</td>\n",
       "      <td>0.252874</td>\n",
       "      <td>0.298780</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.348315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269545</th>\n",
       "      <td>0.50625</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>0.541284</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.304878</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.348315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269546</th>\n",
       "      <td>0.46875</td>\n",
       "      <td>0.163934</td>\n",
       "      <td>0.541284</td>\n",
       "      <td>0.283525</td>\n",
       "      <td>0.347561</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.359551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269547</th>\n",
       "      <td>0.46875</td>\n",
       "      <td>0.163934</td>\n",
       "      <td>0.541284</td>\n",
       "      <td>0.321839</td>\n",
       "      <td>0.408537</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.359551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269548</th>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>0.431193</td>\n",
       "      <td>0.256705</td>\n",
       "      <td>0.292683</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.359551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>268469 rows Ã— 208 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        triage_vital_temp  triage_vital_rr  triage_vital_hr  triage_vital_sbp  \\\n",
       "0                 0.43750         0.163934         0.302752          0.363985   \n",
       "1                 0.48750         0.131148         0.440367          0.318008   \n",
       "2                 0.52500         0.163934         0.651376          0.314176   \n",
       "3                 0.53125         0.163934         0.422018          0.352490   \n",
       "4                 0.48750         0.147541         0.532110          0.398467   \n",
       "...                   ...              ...              ...               ...   \n",
       "269544            0.50000         0.131148         0.376147          0.252874   \n",
       "269545            0.50625         0.131148         0.541284          0.241379   \n",
       "269546            0.46875         0.163934         0.541284          0.283525   \n",
       "269547            0.46875         0.163934         0.541284          0.321839   \n",
       "269548            0.50000         0.131148         0.431193          0.256705   \n",
       "\n",
       "        triage_vital_dbp  triage_vital_o2       age  cc_abdominalcramping  \\\n",
       "0               0.365854         0.948718  0.247191                   0.0   \n",
       "1               0.323171         0.948718  0.539326                   0.0   \n",
       "2               0.286585         0.948718  0.741573                   0.0   \n",
       "3               0.378049         0.974359  0.764045                   0.0   \n",
       "4               0.304878         0.974359  0.775281                   0.0   \n",
       "...                  ...              ...       ...                   ...   \n",
       "269544          0.298780         0.897436  0.348315                   0.0   \n",
       "269545          0.304878         0.871795  0.348315                   0.0   \n",
       "269546          0.347561         0.871795  0.359551                   0.0   \n",
       "269547          0.408537         0.974359  0.359551                   0.0   \n",
       "269548          0.292683         0.871795  0.359551                   0.0   \n",
       "\n",
       "        cc_abdominaldistention  cc_abdominalpain  ...  cc_vaginalpain  \\\n",
       "0                          0.0               0.0  ...             0.0   \n",
       "1                          0.0               0.0  ...             0.0   \n",
       "2                          0.0               0.0  ...             0.0   \n",
       "3                          0.0               0.0  ...             0.0   \n",
       "4                          0.0               0.0  ...             0.0   \n",
       "...                        ...               ...  ...             ...   \n",
       "269544                     0.0               0.0  ...             0.0   \n",
       "269545                     0.0               0.0  ...             0.0   \n",
       "269546                     0.0               0.0  ...             0.0   \n",
       "269547                     0.0               0.0  ...             0.0   \n",
       "269548                     0.0               0.0  ...             0.0   \n",
       "\n",
       "        cc_weakness  cc_wheezing  cc_withdrawal-alcohol  cc_woundcheck  \\\n",
       "0               0.0          0.0                    0.0            0.0   \n",
       "1               0.0          0.0                    0.0            0.0   \n",
       "2               0.0          0.0                    0.0            0.0   \n",
       "3               0.0          0.0                    0.0            0.0   \n",
       "4               0.0          0.0                    0.0            0.0   \n",
       "...             ...          ...                    ...            ...   \n",
       "269544          0.0          0.0                    0.0            0.0   \n",
       "269545          0.0          0.0                    0.0            0.0   \n",
       "269546          0.0          0.0                    0.0            0.0   \n",
       "269547          0.0          0.0                    0.0            0.0   \n",
       "269548          0.0          0.0                    0.0            0.0   \n",
       "\n",
       "        cc_woundinfection  cc_woundre-evaluation  cc_wristinjury  \\\n",
       "0                     0.0                    0.0             0.0   \n",
       "1                     0.0                    0.0             0.0   \n",
       "2                     0.0                    0.0             0.0   \n",
       "3                     0.0                    0.0             0.0   \n",
       "4                     0.0                    0.0             0.0   \n",
       "...                   ...                    ...             ...   \n",
       "269544                0.0                    0.0             0.0   \n",
       "269545                0.0                    0.0             0.0   \n",
       "269546                0.0                    0.0             0.0   \n",
       "269547                0.0                    0.0             0.0   \n",
       "269548                0.0                    0.0             0.0   \n",
       "\n",
       "        cc_wristpain  esi  \n",
       "0                0.0  4.0  \n",
       "1                0.0  2.0  \n",
       "2                0.0  3.0  \n",
       "3                0.0  3.0  \n",
       "4                0.0  4.0  \n",
       "...              ...  ...  \n",
       "269544           0.0  3.0  \n",
       "269545           0.0  3.0  \n",
       "269546           0.0  3.0  \n",
       "269547           0.0  3.0  \n",
       "269548           0.0  3.0  \n",
       "\n",
       "[268469 rows x 208 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Concatenate X and y numpy arrays\n",
    "Xy = np.concatenate((X, y.reshape(-1, 1)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/csuser/DATA/ARTEMIS/yale\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 589260 entries, 0 to 589259\n",
      "Columns: 208 entries, triage_vital_temp to esi\n",
      "dtypes: float64(208)\n",
      "memory usage: 935.1 MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a pandas DataFrame from the concatenated array\n",
    "#new_keys.remove('esi')\n",
    "#new_keys.append('esi')\n",
    "df = pd.DataFrame(data=Xy, columns=new_keys)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/media/csuser/DATA/ARTEMIS/yale/yale_triage_smote.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # clean up the first column since its unnamed and has indices\n",
    "# import pandas as pd\n",
    "\n",
    "# # Read the CSV file\n",
    "# df = pd.read_csv('/media/csuser/DATA/ARTEMIS/yale/yale_triage_smote.csv')\n",
    "\n",
    "# # Remove the first column and all data under it\n",
    "# df = df.iloc[:, 1:]\n",
    "\n",
    "# # Write the modified DataFrame back to the CSV file\n",
    "# df.to_csv('/media/csuser/DATA/ARTEMIS/yale/yale_triage_smote.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(589260, 208)\n",
      "[[0.4375     0.16393442 0.3027523  ... 0.         0.         0.        ]\n",
      " [0.4875     0.13114753 0.44036698 ... 0.         0.         0.        ]\n",
      " [0.525      0.16393442 0.6513761  ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.5299843  0.19008158 0.45964456 ... 0.         0.         0.        ]\n",
      " [0.512652   0.16413374 0.6882965  ... 0.         0.         0.        ]\n",
      " [0.49592218 0.10739045 0.30115804 ... 0.         0.         0.        ]]\n",
      "(589260, 207)\n",
      "[array([1, 2, 3, 4, 5])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(589260, 5)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/media/csuser/DATA/ARTEMIS/yale/yale_triage_smote.csv')\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "print(df.shape)\n",
    "x = df.drop(['esi'], axis=1)\n",
    "y = df['esi']\n",
    "\n",
    "x = x.to_numpy().astype(np.float32)\n",
    "y = y.to_numpy().reshape(-1,1).astype(np.int_)\n",
    "\n",
    "print(np.asarray(x))\n",
    "\n",
    "# x = tf.constant(np.asarray(x), dtype=tf.float64)\n",
    "# y = tf.constant(np.asarray(y).reshape(-1, 1), dtype=tf.float64)\n",
    "\n",
    "print(x.shape)\n",
    "\n",
    "# convert to one hot vector\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(handle_unknown='ignore', sparse=False).fit(y)\n",
    "print(ohe.categories_)\n",
    "\n",
    "y = ohe.transform(y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>triage_vital_temp</th>\n",
       "      <th>triage_vital_rr</th>\n",
       "      <th>triage_vital_hr</th>\n",
       "      <th>triage_vital_sbp</th>\n",
       "      <th>triage_vital_dbp</th>\n",
       "      <th>triage_vital_o2</th>\n",
       "      <th>age</th>\n",
       "      <th>cc_abdominalcramping</th>\n",
       "      <th>cc_abdominaldistention</th>\n",
       "      <th>cc_abdominalpain</th>\n",
       "      <th>...</th>\n",
       "      <th>cc_vaginalpain</th>\n",
       "      <th>cc_weakness</th>\n",
       "      <th>cc_wheezing</th>\n",
       "      <th>cc_withdrawal-alcohol</th>\n",
       "      <th>cc_woundcheck</th>\n",
       "      <th>cc_woundinfection</th>\n",
       "      <th>cc_woundre-evaluation</th>\n",
       "      <th>cc_wristinjury</th>\n",
       "      <th>cc_wristpain</th>\n",
       "      <th>esi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.43750</td>\n",
       "      <td>0.163934</td>\n",
       "      <td>0.302752</td>\n",
       "      <td>0.363985</td>\n",
       "      <td>0.365854</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.247191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.48750</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>0.440367</td>\n",
       "      <td>0.318008</td>\n",
       "      <td>0.323171</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.539326</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.52500</td>\n",
       "      <td>0.163934</td>\n",
       "      <td>0.651376</td>\n",
       "      <td>0.314176</td>\n",
       "      <td>0.286585</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.741573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.53125</td>\n",
       "      <td>0.163934</td>\n",
       "      <td>0.422018</td>\n",
       "      <td>0.352490</td>\n",
       "      <td>0.378049</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.48750</td>\n",
       "      <td>0.147541</td>\n",
       "      <td>0.532110</td>\n",
       "      <td>0.398467</td>\n",
       "      <td>0.304878</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 208 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   triage_vital_temp  triage_vital_rr  triage_vital_hr  triage_vital_sbp  \\\n",
       "0            0.43750         0.163934         0.302752          0.363985   \n",
       "1            0.48750         0.131148         0.440367          0.318008   \n",
       "2            0.52500         0.163934         0.651376          0.314176   \n",
       "3            0.53125         0.163934         0.422018          0.352490   \n",
       "4            0.48750         0.147541         0.532110          0.398467   \n",
       "\n",
       "   triage_vital_dbp  triage_vital_o2       age  cc_abdominalcramping  \\\n",
       "0          0.365854         0.948718  0.247191                   0.0   \n",
       "1          0.323171         0.948718  0.539326                   0.0   \n",
       "2          0.286585         0.948718  0.741573                   0.0   \n",
       "3          0.378049         0.974359  0.764045                   0.0   \n",
       "4          0.304878         0.974359  0.775281                   0.0   \n",
       "\n",
       "   cc_abdominaldistention  cc_abdominalpain  ...  cc_vaginalpain  cc_weakness  \\\n",
       "0                     0.0               0.0  ...             0.0          0.0   \n",
       "1                     0.0               0.0  ...             0.0          0.0   \n",
       "2                     0.0               0.0  ...             0.0          0.0   \n",
       "3                     0.0               0.0  ...             0.0          0.0   \n",
       "4                     0.0               0.0  ...             0.0          0.0   \n",
       "\n",
       "   cc_wheezing  cc_withdrawal-alcohol  cc_woundcheck  cc_woundinfection  \\\n",
       "0          0.0                    0.0            0.0                0.0   \n",
       "1          0.0                    0.0            0.0                0.0   \n",
       "2          0.0                    0.0            0.0                0.0   \n",
       "3          0.0                    0.0            0.0                0.0   \n",
       "4          0.0                    0.0            0.0                0.0   \n",
       "\n",
       "   cc_woundre-evaluation  cc_wristinjury  cc_wristpain  esi  \n",
       "0                    0.0             0.0           0.0  4.0  \n",
       "1                    0.0             0.0           0.0  2.0  \n",
       "2                    0.0             0.0           0.0  3.0  \n",
       "3                    0.0             0.0           0.0  3.0  \n",
       "4                    0.0             0.0           0.0  4.0  \n",
       "\n",
       "[5 rows x 208 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # yale model\n",
    "def make_model(input_shape, num_classes):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    dense1 = layers.Dense(units=50, activation='ReLU', use_bias=True,)(inputs)\n",
    "    dense2 = layers.Dense(units=50, activation='ReLU', use_bias=True,)(dense1)\n",
    "    dense3 = layers.Dense(units=50, activation='ReLU', use_bias=True,)(dense2)\n",
    "    dense4 = layers.Dense(units=50, activation='ReLU', use_bias=True,)(dense3)\n",
    "    output = layers.Dense(units=num_classes, activation='softmax')(dense4)\n",
    "    return keras.Model(inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=1)\n",
    "X_train, X_val, y_train, y_val =  train_test_split(X_train, y_train, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 207)]             0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 50)                10400     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 5)                 255       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,305\n",
      "Trainable params: 18,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = make_model(input_shape=(207), num_classes=y[0].shape[0])\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adamax(learning_rate=0.01, weight_decay=1e-6),\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "# make the save callback\n",
    "best_model_path = '/media/csuser/DATA/ARTEMIS/models/yale_smote'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=best_model_path,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "# load the saved model by:\n",
    "# model.load_weights(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0902 - accuracy: 0.6612 - val_loss: 0.0861 - val_accuracy: 0.6735\n",
      "Epoch 2/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0835 - accuracy: 0.6900 - val_loss: 0.0826 - val_accuracy: 0.6901\n",
      "Epoch 3/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0811 - accuracy: 0.6997 - val_loss: 0.0819 - val_accuracy: 0.6963\n",
      "Epoch 4/5000\n",
      "11786/11786 [==============================] - 7s 619us/step - loss: 0.0797 - accuracy: 0.7050 - val_loss: 0.0796 - val_accuracy: 0.7058\n",
      "Epoch 5/5000\n",
      "11786/11786 [==============================] - 7s 621us/step - loss: 0.0786 - accuracy: 0.7092 - val_loss: 0.0796 - val_accuracy: 0.7055\n",
      "Epoch 6/5000\n",
      "11786/11786 [==============================] - 7s 614us/step - loss: 0.0779 - accuracy: 0.7117 - val_loss: 0.0784 - val_accuracy: 0.7105\n",
      "Epoch 7/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0773 - accuracy: 0.7142 - val_loss: 0.0780 - val_accuracy: 0.7108\n",
      "Epoch 8/5000\n",
      "11786/11786 [==============================] - 7s 617us/step - loss: 0.0768 - accuracy: 0.7166 - val_loss: 0.0783 - val_accuracy: 0.7094\n",
      "Epoch 9/5000\n",
      "11786/11786 [==============================] - 7s 618us/step - loss: 0.0764 - accuracy: 0.7176 - val_loss: 0.0767 - val_accuracy: 0.7147\n",
      "Epoch 10/5000\n",
      "11786/11786 [==============================] - 7s 617us/step - loss: 0.0759 - accuracy: 0.7200 - val_loss: 0.0774 - val_accuracy: 0.7141\n",
      "Epoch 11/5000\n",
      "11786/11786 [==============================] - 7s 620us/step - loss: 0.0756 - accuracy: 0.7208 - val_loss: 0.0766 - val_accuracy: 0.7167\n",
      "Epoch 12/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0753 - accuracy: 0.7219 - val_loss: 0.0764 - val_accuracy: 0.7180\n",
      "Epoch 13/5000\n",
      "11786/11786 [==============================] - 7s 619us/step - loss: 0.0750 - accuracy: 0.7235 - val_loss: 0.0770 - val_accuracy: 0.7144\n",
      "Epoch 14/5000\n",
      "11786/11786 [==============================] - 7s 618us/step - loss: 0.0747 - accuracy: 0.7244 - val_loss: 0.0762 - val_accuracy: 0.7190\n",
      "Epoch 15/5000\n",
      "11786/11786 [==============================] - 7s 618us/step - loss: 0.0745 - accuracy: 0.7250 - val_loss: 0.0763 - val_accuracy: 0.7189\n",
      "Epoch 16/5000\n",
      "11786/11786 [==============================] - 7s 623us/step - loss: 0.0742 - accuracy: 0.7265 - val_loss: 0.0752 - val_accuracy: 0.7224\n",
      "Epoch 17/5000\n",
      "11786/11786 [==============================] - 7s 620us/step - loss: 0.0740 - accuracy: 0.7271 - val_loss: 0.0757 - val_accuracy: 0.7207\n",
      "Epoch 18/5000\n",
      "11786/11786 [==============================] - 7s 617us/step - loss: 0.0738 - accuracy: 0.7284 - val_loss: 0.0751 - val_accuracy: 0.7229\n",
      "Epoch 19/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0737 - accuracy: 0.7291 - val_loss: 0.0754 - val_accuracy: 0.7219\n",
      "Epoch 20/5000\n",
      "11786/11786 [==============================] - 7s 615us/step - loss: 0.0735 - accuracy: 0.7290 - val_loss: 0.0754 - val_accuracy: 0.7216\n",
      "Epoch 21/5000\n",
      "11786/11786 [==============================] - 7s 622us/step - loss: 0.0733 - accuracy: 0.7303 - val_loss: 0.0759 - val_accuracy: 0.7195\n",
      "Epoch 22/5000\n",
      "11786/11786 [==============================] - 7s 610us/step - loss: 0.0731 - accuracy: 0.7310 - val_loss: 0.0750 - val_accuracy: 0.7226\n",
      "Epoch 23/5000\n",
      "11786/11786 [==============================] - 7s 618us/step - loss: 0.0729 - accuracy: 0.7314 - val_loss: 0.0747 - val_accuracy: 0.7251\n",
      "Epoch 24/5000\n",
      "11786/11786 [==============================] - 7s 618us/step - loss: 0.0728 - accuracy: 0.7324 - val_loss: 0.0755 - val_accuracy: 0.7207\n",
      "Epoch 25/5000\n",
      "11786/11786 [==============================] - 7s 616us/step - loss: 0.0727 - accuracy: 0.7329 - val_loss: 0.0754 - val_accuracy: 0.7193\n",
      "Epoch 26/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0726 - accuracy: 0.7334 - val_loss: 0.0749 - val_accuracy: 0.7240\n",
      "Epoch 27/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0724 - accuracy: 0.7339 - val_loss: 0.0757 - val_accuracy: 0.7223\n",
      "Epoch 28/5000\n",
      "11786/11786 [==============================] - 7s 619us/step - loss: 0.0722 - accuracy: 0.7345 - val_loss: 0.0752 - val_accuracy: 0.7232\n",
      "Epoch 29/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0722 - accuracy: 0.7344 - val_loss: 0.0755 - val_accuracy: 0.7235\n",
      "Epoch 30/5000\n",
      "11786/11786 [==============================] - 7s 621us/step - loss: 0.0721 - accuracy: 0.7350 - val_loss: 0.0749 - val_accuracy: 0.7233\n",
      "Epoch 31/5000\n",
      "11786/11786 [==============================] - 7s 614us/step - loss: 0.0720 - accuracy: 0.7362 - val_loss: 0.0746 - val_accuracy: 0.7262\n",
      "Epoch 32/5000\n",
      "11786/11786 [==============================] - 7s 610us/step - loss: 0.0718 - accuracy: 0.7367 - val_loss: 0.0741 - val_accuracy: 0.7271\n",
      "Epoch 33/5000\n",
      "11786/11786 [==============================] - 7s 618us/step - loss: 0.0718 - accuracy: 0.7367 - val_loss: 0.0755 - val_accuracy: 0.7224\n",
      "Epoch 34/5000\n",
      "11786/11786 [==============================] - 7s 615us/step - loss: 0.0716 - accuracy: 0.7376 - val_loss: 0.0741 - val_accuracy: 0.7267\n",
      "Epoch 35/5000\n",
      "11786/11786 [==============================] - 7s 615us/step - loss: 0.0715 - accuracy: 0.7374 - val_loss: 0.0745 - val_accuracy: 0.7250\n",
      "Epoch 36/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0714 - accuracy: 0.7377 - val_loss: 0.0741 - val_accuracy: 0.7284\n",
      "Epoch 37/5000\n",
      "11786/11786 [==============================] - 7s 615us/step - loss: 0.0713 - accuracy: 0.7381 - val_loss: 0.0747 - val_accuracy: 0.7246\n",
      "Epoch 38/5000\n",
      "11786/11786 [==============================] - 7s 617us/step - loss: 0.0713 - accuracy: 0.7392 - val_loss: 0.0744 - val_accuracy: 0.7268\n",
      "Epoch 39/5000\n",
      "11786/11786 [==============================] - 7s 620us/step - loss: 0.0712 - accuracy: 0.7393 - val_loss: 0.0736 - val_accuracy: 0.7300\n",
      "Epoch 40/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0710 - accuracy: 0.7394 - val_loss: 0.0739 - val_accuracy: 0.7286\n",
      "Epoch 41/5000\n",
      "11786/11786 [==============================] - 7s 618us/step - loss: 0.0710 - accuracy: 0.7399 - val_loss: 0.0736 - val_accuracy: 0.7296\n",
      "Epoch 42/5000\n",
      "11786/11786 [==============================] - 7s 608us/step - loss: 0.0710 - accuracy: 0.7402 - val_loss: 0.0738 - val_accuracy: 0.7283\n",
      "Epoch 43/5000\n",
      "11786/11786 [==============================] - 7s 615us/step - loss: 0.0709 - accuracy: 0.7409 - val_loss: 0.0747 - val_accuracy: 0.7275\n",
      "Epoch 44/5000\n",
      "11786/11786 [==============================] - 7s 613us/step - loss: 0.0707 - accuracy: 0.7410 - val_loss: 0.0745 - val_accuracy: 0.7282\n",
      "Epoch 45/5000\n",
      "11786/11786 [==============================] - 7s 608us/step - loss: 0.0707 - accuracy: 0.7414 - val_loss: 0.0737 - val_accuracy: 0.7295\n",
      "Epoch 46/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0706 - accuracy: 0.7417 - val_loss: 0.0739 - val_accuracy: 0.7299\n",
      "Epoch 47/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0705 - accuracy: 0.7422 - val_loss: 0.0739 - val_accuracy: 0.7303\n",
      "Epoch 48/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0705 - accuracy: 0.7426 - val_loss: 0.0731 - val_accuracy: 0.7308\n",
      "Epoch 49/5000\n",
      "11786/11786 [==============================] - 7s 617us/step - loss: 0.0703 - accuracy: 0.7435 - val_loss: 0.0748 - val_accuracy: 0.7269\n",
      "Epoch 50/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0704 - accuracy: 0.7427 - val_loss: 0.0747 - val_accuracy: 0.7262\n",
      "Epoch 51/5000\n",
      "11786/11786 [==============================] - 7s 619us/step - loss: 0.0703 - accuracy: 0.7429 - val_loss: 0.0737 - val_accuracy: 0.7302\n",
      "Epoch 52/5000\n",
      "11786/11786 [==============================] - 7s 615us/step - loss: 0.0703 - accuracy: 0.7436 - val_loss: 0.0744 - val_accuracy: 0.7283\n",
      "Epoch 53/5000\n",
      "11786/11786 [==============================] - 7s 617us/step - loss: 0.0701 - accuracy: 0.7439 - val_loss: 0.0737 - val_accuracy: 0.7301\n",
      "Epoch 54/5000\n",
      "11786/11786 [==============================] - 7s 620us/step - loss: 0.0701 - accuracy: 0.7436 - val_loss: 0.0735 - val_accuracy: 0.7322\n",
      "Epoch 55/5000\n",
      "11786/11786 [==============================] - 7s 620us/step - loss: 0.0700 - accuracy: 0.7443 - val_loss: 0.0745 - val_accuracy: 0.7282\n",
      "Epoch 56/5000\n",
      "11786/11786 [==============================] - 7s 613us/step - loss: 0.0699 - accuracy: 0.7445 - val_loss: 0.0733 - val_accuracy: 0.7321\n",
      "Epoch 57/5000\n",
      "11786/11786 [==============================] - 7s 618us/step - loss: 0.0699 - accuracy: 0.7447 - val_loss: 0.0745 - val_accuracy: 0.7272\n",
      "Epoch 58/5000\n",
      "11786/11786 [==============================] - 7s 621us/step - loss: 0.0699 - accuracy: 0.7448 - val_loss: 0.0746 - val_accuracy: 0.7265\n",
      "Epoch 59/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0698 - accuracy: 0.7455 - val_loss: 0.0735 - val_accuracy: 0.7301\n",
      "Epoch 60/5000\n",
      "11786/11786 [==============================] - 7s 618us/step - loss: 0.0697 - accuracy: 0.7458 - val_loss: 0.0744 - val_accuracy: 0.7283\n",
      "Epoch 61/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0697 - accuracy: 0.7459 - val_loss: 0.0740 - val_accuracy: 0.7285\n",
      "Epoch 62/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0697 - accuracy: 0.7457 - val_loss: 0.0738 - val_accuracy: 0.7301\n",
      "Epoch 63/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0696 - accuracy: 0.7461 - val_loss: 0.0736 - val_accuracy: 0.7311\n",
      "Epoch 64/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0696 - accuracy: 0.7462 - val_loss: 0.0735 - val_accuracy: 0.7305\n",
      "Epoch 65/5000\n",
      "11786/11786 [==============================] - 7s 623us/step - loss: 0.0696 - accuracy: 0.7462 - val_loss: 0.0730 - val_accuracy: 0.7347\n",
      "Epoch 66/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0696 - accuracy: 0.7472 - val_loss: 0.0737 - val_accuracy: 0.7295\n",
      "Epoch 67/5000\n",
      "11786/11786 [==============================] - 7s 617us/step - loss: 0.0695 - accuracy: 0.7468 - val_loss: 0.0735 - val_accuracy: 0.7300\n",
      "Epoch 68/5000\n",
      "11786/11786 [==============================] - 7s 616us/step - loss: 0.0694 - accuracy: 0.7472 - val_loss: 0.0745 - val_accuracy: 0.7280\n",
      "Epoch 69/5000\n",
      "11786/11786 [==============================] - 7s 616us/step - loss: 0.0693 - accuracy: 0.7479 - val_loss: 0.0741 - val_accuracy: 0.7276\n",
      "Epoch 70/5000\n",
      "11786/11786 [==============================] - 7s 617us/step - loss: 0.0693 - accuracy: 0.7473 - val_loss: 0.0736 - val_accuracy: 0.7300\n",
      "Epoch 71/5000\n",
      "11786/11786 [==============================] - 7s 617us/step - loss: 0.0692 - accuracy: 0.7478 - val_loss: 0.0734 - val_accuracy: 0.7322\n",
      "Epoch 72/5000\n",
      "11786/11786 [==============================] - 7s 604us/step - loss: 0.0692 - accuracy: 0.7481 - val_loss: 0.0730 - val_accuracy: 0.7342\n",
      "Epoch 73/5000\n",
      "11786/11786 [==============================] - 7s 606us/step - loss: 0.0691 - accuracy: 0.7484 - val_loss: 0.0737 - val_accuracy: 0.7317\n",
      "Epoch 74/5000\n",
      "11786/11786 [==============================] - 7s 597us/step - loss: 0.0691 - accuracy: 0.7486 - val_loss: 0.0739 - val_accuracy: 0.7311\n",
      "Epoch 75/5000\n",
      "11786/11786 [==============================] - 7s 602us/step - loss: 0.0691 - accuracy: 0.7488 - val_loss: 0.0733 - val_accuracy: 0.7321\n",
      "Epoch 76/5000\n",
      "11786/11786 [==============================] - 7s 602us/step - loss: 0.0691 - accuracy: 0.7491 - val_loss: 0.0735 - val_accuracy: 0.7332\n",
      "Epoch 77/5000\n",
      "11786/11786 [==============================] - 7s 603us/step - loss: 0.0690 - accuracy: 0.7494 - val_loss: 0.0737 - val_accuracy: 0.7342\n",
      "Epoch 78/5000\n",
      "11786/11786 [==============================] - 7s 608us/step - loss: 0.0690 - accuracy: 0.7493 - val_loss: 0.0735 - val_accuracy: 0.7312\n",
      "Epoch 79/5000\n",
      "11786/11786 [==============================] - 7s 603us/step - loss: 0.0689 - accuracy: 0.7494 - val_loss: 0.0734 - val_accuracy: 0.7334\n",
      "Epoch 80/5000\n",
      "11786/11786 [==============================] - 7s 602us/step - loss: 0.0689 - accuracy: 0.7498 - val_loss: 0.0740 - val_accuracy: 0.7306\n",
      "Epoch 81/5000\n",
      "11786/11786 [==============================] - 7s 602us/step - loss: 0.0689 - accuracy: 0.7500 - val_loss: 0.0742 - val_accuracy: 0.7307\n",
      "Epoch 82/5000\n",
      "11786/11786 [==============================] - 7s 608us/step - loss: 0.0688 - accuracy: 0.7500 - val_loss: 0.0732 - val_accuracy: 0.7330\n",
      "Epoch 83/5000\n",
      "11786/11786 [==============================] - 7s 605us/step - loss: 0.0689 - accuracy: 0.7496 - val_loss: 0.0740 - val_accuracy: 0.7306\n",
      "Epoch 84/5000\n",
      "11786/11786 [==============================] - 7s 604us/step - loss: 0.0687 - accuracy: 0.7507 - val_loss: 0.0740 - val_accuracy: 0.7290\n",
      "Epoch 85/5000\n",
      "11786/11786 [==============================] - 7s 598us/step - loss: 0.0687 - accuracy: 0.7505 - val_loss: 0.0735 - val_accuracy: 0.7333\n",
      "Epoch 86/5000\n",
      "11786/11786 [==============================] - 7s 605us/step - loss: 0.0688 - accuracy: 0.7494 - val_loss: 0.0748 - val_accuracy: 0.7282\n",
      "Epoch 87/5000\n",
      "11786/11786 [==============================] - 7s 600us/step - loss: 0.0687 - accuracy: 0.7507 - val_loss: 0.0739 - val_accuracy: 0.7305\n",
      "Epoch 88/5000\n",
      "11786/11786 [==============================] - 7s 601us/step - loss: 0.0686 - accuracy: 0.7511 - val_loss: 0.0730 - val_accuracy: 0.7338\n",
      "Epoch 89/5000\n",
      "11786/11786 [==============================] - 7s 602us/step - loss: 0.0685 - accuracy: 0.7513 - val_loss: 0.0736 - val_accuracy: 0.7327\n",
      "Epoch 90/5000\n",
      "11786/11786 [==============================] - 7s 605us/step - loss: 0.0686 - accuracy: 0.7514 - val_loss: 0.0735 - val_accuracy: 0.7325\n",
      "Epoch 91/5000\n",
      "11786/11786 [==============================] - 7s 596us/step - loss: 0.0685 - accuracy: 0.7517 - val_loss: 0.0733 - val_accuracy: 0.7337\n",
      "Epoch 92/5000\n",
      "11786/11786 [==============================] - 7s 605us/step - loss: 0.0685 - accuracy: 0.7518 - val_loss: 0.0732 - val_accuracy: 0.7339\n",
      "Epoch 93/5000\n",
      "11786/11786 [==============================] - 7s 603us/step - loss: 0.0684 - accuracy: 0.7522 - val_loss: 0.0737 - val_accuracy: 0.7312\n",
      "Epoch 94/5000\n",
      "11786/11786 [==============================] - 7s 602us/step - loss: 0.0684 - accuracy: 0.7522 - val_loss: 0.0738 - val_accuracy: 0.7329\n",
      "Epoch 95/5000\n",
      "11786/11786 [==============================] - 7s 596us/step - loss: 0.0684 - accuracy: 0.7517 - val_loss: 0.0732 - val_accuracy: 0.7345\n",
      "Epoch 96/5000\n",
      "11786/11786 [==============================] - 7s 615us/step - loss: 0.0684 - accuracy: 0.7522 - val_loss: 0.0742 - val_accuracy: 0.7293\n",
      "Epoch 97/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0683 - accuracy: 0.7528 - val_loss: 0.0737 - val_accuracy: 0.7312\n",
      "Epoch 98/5000\n",
      "11786/11786 [==============================] - 7s 615us/step - loss: 0.0684 - accuracy: 0.7522 - val_loss: 0.0733 - val_accuracy: 0.7347\n",
      "Epoch 99/5000\n",
      "11786/11786 [==============================] - 7s 621us/step - loss: 0.0683 - accuracy: 0.7529 - val_loss: 0.0734 - val_accuracy: 0.7334\n",
      "Epoch 100/5000\n",
      "11786/11786 [==============================] - 7s 616us/step - loss: 0.0682 - accuracy: 0.7528 - val_loss: 0.0730 - val_accuracy: 0.7343\n",
      "Epoch 101/5000\n",
      "11786/11786 [==============================] - 7s 610us/step - loss: 0.0682 - accuracy: 0.7535 - val_loss: 0.0751 - val_accuracy: 0.7270\n",
      "Epoch 102/5000\n",
      "11786/11786 [==============================] - 7s 616us/step - loss: 0.0681 - accuracy: 0.7531 - val_loss: 0.0732 - val_accuracy: 0.7339\n",
      "Epoch 103/5000\n",
      "11786/11786 [==============================] - 7s 608us/step - loss: 0.0682 - accuracy: 0.7533 - val_loss: 0.0736 - val_accuracy: 0.7328\n",
      "Epoch 104/5000\n",
      "11786/11786 [==============================] - 7s 601us/step - loss: 0.0681 - accuracy: 0.7535 - val_loss: 0.0736 - val_accuracy: 0.7323\n",
      "Epoch 105/5000\n",
      "11786/11786 [==============================] - 7s 601us/step - loss: 0.0682 - accuracy: 0.7531 - val_loss: 0.0731 - val_accuracy: 0.7343\n",
      "Epoch 106/5000\n",
      "11786/11786 [==============================] - 7s 599us/step - loss: 0.0680 - accuracy: 0.7536 - val_loss: 0.0734 - val_accuracy: 0.7328\n",
      "Epoch 107/5000\n",
      "11786/11786 [==============================] - 7s 601us/step - loss: 0.0680 - accuracy: 0.7539 - val_loss: 0.0731 - val_accuracy: 0.7365\n",
      "Epoch 108/5000\n",
      "11786/11786 [==============================] - 7s 600us/step - loss: 0.0679 - accuracy: 0.7543 - val_loss: 0.0736 - val_accuracy: 0.7331\n",
      "Epoch 109/5000\n",
      "11786/11786 [==============================] - 7s 607us/step - loss: 0.0680 - accuracy: 0.7541 - val_loss: 0.0743 - val_accuracy: 0.7308\n",
      "Epoch 110/5000\n",
      "11786/11786 [==============================] - 7s 606us/step - loss: 0.0680 - accuracy: 0.7543 - val_loss: 0.0738 - val_accuracy: 0.7338\n",
      "Epoch 111/5000\n",
      "11786/11786 [==============================] - 7s 609us/step - loss: 0.0680 - accuracy: 0.7539 - val_loss: 0.0733 - val_accuracy: 0.7345\n",
      "Epoch 112/5000\n",
      "11786/11786 [==============================] - 7s 608us/step - loss: 0.0678 - accuracy: 0.7552 - val_loss: 0.0737 - val_accuracy: 0.7335\n",
      "Epoch 113/5000\n",
      "11786/11786 [==============================] - 7s 604us/step - loss: 0.0679 - accuracy: 0.7543 - val_loss: 0.0735 - val_accuracy: 0.7344\n",
      "Epoch 114/5000\n",
      "11786/11786 [==============================] - 7s 600us/step - loss: 0.0678 - accuracy: 0.7547 - val_loss: 0.0736 - val_accuracy: 0.7347\n",
      "Epoch 115/5000\n",
      "11786/11786 [==============================] - 7s 599us/step - loss: 0.0678 - accuracy: 0.7547 - val_loss: 0.0740 - val_accuracy: 0.7315\n",
      "Epoch 116/5000\n",
      "11786/11786 [==============================] - 7s 598us/step - loss: 0.0678 - accuracy: 0.7550 - val_loss: 0.0734 - val_accuracy: 0.7337\n",
      "Epoch 117/5000\n",
      "11786/11786 [==============================] - 7s 600us/step - loss: 0.0678 - accuracy: 0.7546 - val_loss: 0.0731 - val_accuracy: 0.7362\n",
      "Epoch 118/5000\n",
      "11786/11786 [==============================] - 7s 605us/step - loss: 0.0678 - accuracy: 0.7549 - val_loss: 0.0734 - val_accuracy: 0.7338\n",
      "Epoch 119/5000\n",
      "11786/11786 [==============================] - 7s 597us/step - loss: 0.0678 - accuracy: 0.7546 - val_loss: 0.0741 - val_accuracy: 0.7314\n",
      "Epoch 120/5000\n",
      "11786/11786 [==============================] - 7s 600us/step - loss: 0.0678 - accuracy: 0.7550 - val_loss: 0.0737 - val_accuracy: 0.7324\n",
      "Epoch 121/5000\n",
      "11786/11786 [==============================] - 7s 597us/step - loss: 0.0677 - accuracy: 0.7548 - val_loss: 0.0732 - val_accuracy: 0.7358\n",
      "Epoch 122/5000\n",
      "11786/11786 [==============================] - 7s 600us/step - loss: 0.0677 - accuracy: 0.7560 - val_loss: 0.0731 - val_accuracy: 0.7352\n",
      "Epoch 123/5000\n",
      "11786/11786 [==============================] - 7s 604us/step - loss: 0.0677 - accuracy: 0.7554 - val_loss: 0.0737 - val_accuracy: 0.7352\n",
      "Epoch 124/5000\n",
      "11786/11786 [==============================] - 7s 601us/step - loss: 0.0676 - accuracy: 0.7553 - val_loss: 0.0731 - val_accuracy: 0.7349\n",
      "Epoch 125/5000\n",
      "11786/11786 [==============================] - 7s 603us/step - loss: 0.0677 - accuracy: 0.7552 - val_loss: 0.0735 - val_accuracy: 0.7327\n",
      "Epoch 126/5000\n",
      "11786/11786 [==============================] - 7s 597us/step - loss: 0.0676 - accuracy: 0.7553 - val_loss: 0.0732 - val_accuracy: 0.7358\n",
      "Epoch 127/5000\n",
      "11786/11786 [==============================] - 7s 601us/step - loss: 0.0675 - accuracy: 0.7563 - val_loss: 0.0731 - val_accuracy: 0.7359\n",
      "Epoch 128/5000\n",
      "11786/11786 [==============================] - 7s 600us/step - loss: 0.0675 - accuracy: 0.7565 - val_loss: 0.0734 - val_accuracy: 0.7339\n",
      "Epoch 129/5000\n",
      "11786/11786 [==============================] - 7s 596us/step - loss: 0.0675 - accuracy: 0.7567 - val_loss: 0.0733 - val_accuracy: 0.7357\n",
      "Epoch 130/5000\n",
      "11786/11786 [==============================] - 7s 599us/step - loss: 0.0675 - accuracy: 0.7564 - val_loss: 0.0739 - val_accuracy: 0.7326\n",
      "Epoch 131/5000\n",
      "11786/11786 [==============================] - 7s 606us/step - loss: 0.0675 - accuracy: 0.7560 - val_loss: 0.0737 - val_accuracy: 0.7317\n",
      "Epoch 132/5000\n",
      "11786/11786 [==============================] - 7s 600us/step - loss: 0.0675 - accuracy: 0.7565 - val_loss: 0.0734 - val_accuracy: 0.7343\n",
      "Epoch 133/5000\n",
      "11786/11786 [==============================] - 7s 599us/step - loss: 0.0675 - accuracy: 0.7559 - val_loss: 0.0734 - val_accuracy: 0.7348\n",
      "Epoch 134/5000\n",
      "11786/11786 [==============================] - 7s 600us/step - loss: 0.0674 - accuracy: 0.7567 - val_loss: 0.0736 - val_accuracy: 0.7344\n",
      "Epoch 135/5000\n",
      "11786/11786 [==============================] - 7s 605us/step - loss: 0.0675 - accuracy: 0.7567 - val_loss: 0.0733 - val_accuracy: 0.7338\n",
      "Epoch 136/5000\n",
      "11786/11786 [==============================] - 7s 603us/step - loss: 0.0675 - accuracy: 0.7562 - val_loss: 0.0731 - val_accuracy: 0.7350\n",
      "Epoch 137/5000\n",
      "11786/11786 [==============================] - 7s 601us/step - loss: 0.0674 - accuracy: 0.7565 - val_loss: 0.0737 - val_accuracy: 0.7324\n",
      "Epoch 138/5000\n",
      "11786/11786 [==============================] - 7s 603us/step - loss: 0.0673 - accuracy: 0.7572 - val_loss: 0.0731 - val_accuracy: 0.7373\n",
      "Epoch 139/5000\n",
      "11786/11786 [==============================] - 7s 594us/step - loss: 0.0673 - accuracy: 0.7566 - val_loss: 0.0736 - val_accuracy: 0.7341\n",
      "Epoch 140/5000\n",
      "11786/11786 [==============================] - 7s 597us/step - loss: 0.0673 - accuracy: 0.7571 - val_loss: 0.0733 - val_accuracy: 0.7346\n",
      "Epoch 141/5000\n",
      "11786/11786 [==============================] - 7s 601us/step - loss: 0.0673 - accuracy: 0.7581 - val_loss: 0.0730 - val_accuracy: 0.7350\n",
      "Epoch 142/5000\n",
      "11786/11786 [==============================] - 7s 601us/step - loss: 0.0674 - accuracy: 0.7571 - val_loss: 0.0732 - val_accuracy: 0.7352\n",
      "Epoch 143/5000\n",
      "11786/11786 [==============================] - 7s 597us/step - loss: 0.0673 - accuracy: 0.7570 - val_loss: 0.0739 - val_accuracy: 0.7329\n",
      "Epoch 144/5000\n",
      "11786/11786 [==============================] - 7s 605us/step - loss: 0.0673 - accuracy: 0.7574 - val_loss: 0.0738 - val_accuracy: 0.7324\n",
      "Epoch 145/5000\n",
      "11786/11786 [==============================] - 7s 592us/step - loss: 0.0674 - accuracy: 0.7570 - val_loss: 0.0736 - val_accuracy: 0.7341\n",
      "Epoch 146/5000\n",
      "11786/11786 [==============================] - 7s 606us/step - loss: 0.0672 - accuracy: 0.7581 - val_loss: 0.0733 - val_accuracy: 0.7353\n",
      "Epoch 147/5000\n",
      "11786/11786 [==============================] - 7s 604us/step - loss: 0.0672 - accuracy: 0.7576 - val_loss: 0.0734 - val_accuracy: 0.7347\n",
      "Epoch 148/5000\n",
      "11786/11786 [==============================] - 7s 598us/step - loss: 0.0672 - accuracy: 0.7578 - val_loss: 0.0727 - val_accuracy: 0.7362\n",
      "Epoch 149/5000\n",
      "11786/11786 [==============================] - 7s 604us/step - loss: 0.0673 - accuracy: 0.7580 - val_loss: 0.0735 - val_accuracy: 0.7348\n",
      "Epoch 150/5000\n",
      "11786/11786 [==============================] - 7s 600us/step - loss: 0.0672 - accuracy: 0.7577 - val_loss: 0.0732 - val_accuracy: 0.7369\n",
      "Epoch 151/5000\n",
      "11786/11786 [==============================] - 7s 607us/step - loss: 0.0672 - accuracy: 0.7573 - val_loss: 0.0730 - val_accuracy: 0.7355\n",
      "Epoch 152/5000\n",
      "11786/11786 [==============================] - 7s 609us/step - loss: 0.0671 - accuracy: 0.7589 - val_loss: 0.0731 - val_accuracy: 0.7351\n",
      "Epoch 153/5000\n",
      "11786/11786 [==============================] - 7s 598us/step - loss: 0.0672 - accuracy: 0.7575 - val_loss: 0.0731 - val_accuracy: 0.7340\n",
      "Epoch 154/5000\n",
      "11786/11786 [==============================] - 7s 606us/step - loss: 0.0672 - accuracy: 0.7577 - val_loss: 0.0734 - val_accuracy: 0.7340\n",
      "Epoch 155/5000\n",
      "11786/11786 [==============================] - 7s 603us/step - loss: 0.0672 - accuracy: 0.7579 - val_loss: 0.0739 - val_accuracy: 0.7328\n",
      "Epoch 156/5000\n",
      "11786/11786 [==============================] - 7s 605us/step - loss: 0.0671 - accuracy: 0.7583 - val_loss: 0.0733 - val_accuracy: 0.7358\n",
      "Epoch 157/5000\n",
      "11786/11786 [==============================] - 7s 593us/step - loss: 0.0671 - accuracy: 0.7580 - val_loss: 0.0731 - val_accuracy: 0.7344\n",
      "Epoch 158/5000\n",
      "11786/11786 [==============================] - 7s 597us/step - loss: 0.0671 - accuracy: 0.7582 - val_loss: 0.0730 - val_accuracy: 0.7377\n",
      "Epoch 159/5000\n",
      "11786/11786 [==============================] - 7s 599us/step - loss: 0.0671 - accuracy: 0.7583 - val_loss: 0.0739 - val_accuracy: 0.7350\n",
      "Epoch 160/5000\n",
      "11786/11786 [==============================] - 7s 605us/step - loss: 0.0670 - accuracy: 0.7584 - val_loss: 0.0733 - val_accuracy: 0.7352\n",
      "Epoch 161/5000\n",
      "11786/11786 [==============================] - 7s 609us/step - loss: 0.0670 - accuracy: 0.7584 - val_loss: 0.0733 - val_accuracy: 0.7368\n",
      "Epoch 162/5000\n",
      "11786/11786 [==============================] - 7s 603us/step - loss: 0.0670 - accuracy: 0.7585 - val_loss: 0.0734 - val_accuracy: 0.7368\n",
      "Epoch 163/5000\n",
      "11786/11786 [==============================] - 7s 601us/step - loss: 0.0670 - accuracy: 0.7585 - val_loss: 0.0737 - val_accuracy: 0.7347\n",
      "Epoch 164/5000\n",
      "11786/11786 [==============================] - 7s 605us/step - loss: 0.0670 - accuracy: 0.7593 - val_loss: 0.0740 - val_accuracy: 0.7358\n",
      "Epoch 165/5000\n",
      "11786/11786 [==============================] - 7s 609us/step - loss: 0.0670 - accuracy: 0.7589 - val_loss: 0.0741 - val_accuracy: 0.7327\n",
      "Epoch 166/5000\n",
      "11786/11786 [==============================] - 7s 605us/step - loss: 0.0671 - accuracy: 0.7589 - val_loss: 0.0732 - val_accuracy: 0.7365\n",
      "Epoch 167/5000\n",
      "11786/11786 [==============================] - 7s 604us/step - loss: 0.0669 - accuracy: 0.7588 - val_loss: 0.0735 - val_accuracy: 0.7336\n",
      "Epoch 168/5000\n",
      "11786/11786 [==============================] - 7s 603us/step - loss: 0.0669 - accuracy: 0.7592 - val_loss: 0.0737 - val_accuracy: 0.7345\n",
      "Epoch 169/5000\n",
      "11786/11786 [==============================] - 7s 601us/step - loss: 0.0669 - accuracy: 0.7592 - val_loss: 0.0740 - val_accuracy: 0.7344\n",
      "Epoch 170/5000\n",
      "11786/11786 [==============================] - 7s 597us/step - loss: 0.0670 - accuracy: 0.7588 - val_loss: 0.0735 - val_accuracy: 0.7351\n",
      "Epoch 171/5000\n",
      "11786/11786 [==============================] - 7s 594us/step - loss: 0.0669 - accuracy: 0.7588 - val_loss: 0.0739 - val_accuracy: 0.7346\n",
      "Epoch 172/5000\n",
      "11786/11786 [==============================] - 7s 607us/step - loss: 0.0668 - accuracy: 0.7594 - val_loss: 0.0731 - val_accuracy: 0.7356\n",
      "Epoch 173/5000\n",
      "11786/11786 [==============================] - 7s 608us/step - loss: 0.0669 - accuracy: 0.7593 - val_loss: 0.0732 - val_accuracy: 0.7359\n",
      "Epoch 174/5000\n",
      "11786/11786 [==============================] - 7s 600us/step - loss: 0.0668 - accuracy: 0.7596 - val_loss: 0.0739 - val_accuracy: 0.7326\n",
      "Epoch 175/5000\n",
      "11786/11786 [==============================] - 7s 608us/step - loss: 0.0669 - accuracy: 0.7595 - val_loss: 0.0731 - val_accuracy: 0.7343\n",
      "Epoch 176/5000\n",
      "11786/11786 [==============================] - 7s 606us/step - loss: 0.0668 - accuracy: 0.7597 - val_loss: 0.0737 - val_accuracy: 0.7342\n",
      "Epoch 177/5000\n",
      "11786/11786 [==============================] - 7s 601us/step - loss: 0.0668 - accuracy: 0.7594 - val_loss: 0.0738 - val_accuracy: 0.7338\n",
      "Epoch 178/5000\n",
      "11786/11786 [==============================] - 7s 600us/step - loss: 0.0667 - accuracy: 0.7600 - val_loss: 0.0732 - val_accuracy: 0.7342\n",
      "Epoch 179/5000\n",
      "11786/11786 [==============================] - 7s 611us/step - loss: 0.0668 - accuracy: 0.7598 - val_loss: 0.0726 - val_accuracy: 0.7392\n",
      "Epoch 180/5000\n",
      "11786/11786 [==============================] - 7s 612us/step - loss: 0.0668 - accuracy: 0.7596 - val_loss: 0.0732 - val_accuracy: 0.7367\n",
      "Epoch 181/5000\n",
      "11786/11786 [==============================] - 7s 603us/step - loss: 0.0667 - accuracy: 0.7610 - val_loss: 0.0730 - val_accuracy: 0.7365\n",
      "Epoch 182/5000\n",
      "11786/11786 [==============================] - 7s 600us/step - loss: 0.0668 - accuracy: 0.7599 - val_loss: 0.0735 - val_accuracy: 0.7342\n",
      "Epoch 183/5000\n",
      "11786/11786 [==============================] - 7s 606us/step - loss: 0.0667 - accuracy: 0.7600 - val_loss: 0.0738 - val_accuracy: 0.7344\n",
      "Epoch 184/5000\n",
      "11786/11786 [==============================] - 7s 599us/step - loss: 0.0667 - accuracy: 0.7605 - val_loss: 0.0740 - val_accuracy: 0.7325\n",
      "Epoch 185/5000\n",
      "11786/11786 [==============================] - 7s 602us/step - loss: 0.0666 - accuracy: 0.7611 - val_loss: 0.0734 - val_accuracy: 0.7358\n",
      "Epoch 186/5000\n",
      "11786/11786 [==============================] - 7s 602us/step - loss: 0.0666 - accuracy: 0.7604 - val_loss: 0.0734 - val_accuracy: 0.7375\n",
      "Epoch 187/5000\n",
      "11786/11786 [==============================] - 7s 597us/step - loss: 0.0668 - accuracy: 0.7599 - val_loss: 0.0734 - val_accuracy: 0.7355\n",
      "Epoch 188/5000\n",
      "11786/11786 [==============================] - 7s 602us/step - loss: 0.0666 - accuracy: 0.7606 - val_loss: 0.0744 - val_accuracy: 0.7320\n",
      "Epoch 189/5000\n",
      "11786/11786 [==============================] - 7s 603us/step - loss: 0.0667 - accuracy: 0.7598 - val_loss: 0.0738 - val_accuracy: 0.7367\n",
      "Epoch 190/5000\n",
      "11786/11786 [==============================] - 7s 602us/step - loss: 0.0667 - accuracy: 0.7605 - val_loss: 0.0731 - val_accuracy: 0.7351\n",
      "Epoch 191/5000\n",
      "11786/11786 [==============================] - 7s 604us/step - loss: 0.0667 - accuracy: 0.7599 - val_loss: 0.0733 - val_accuracy: 0.7353\n",
      "Epoch 192/5000\n",
      "11786/11786 [==============================] - 7s 595us/step - loss: 0.0667 - accuracy: 0.7598 - val_loss: 0.0735 - val_accuracy: 0.7341\n",
      "Epoch 193/5000\n",
      "11786/11786 [==============================] - 7s 595us/step - loss: 0.0666 - accuracy: 0.7605 - val_loss: 0.0732 - val_accuracy: 0.7368\n",
      "Epoch 194/5000\n",
      "11786/11786 [==============================] - 7s 603us/step - loss: 0.0665 - accuracy: 0.7608 - val_loss: 0.0736 - val_accuracy: 0.7354\n",
      "Epoch 195/5000\n",
      "11786/11786 [==============================] - 7s 596us/step - loss: 0.0665 - accuracy: 0.7606 - val_loss: 0.0736 - val_accuracy: 0.7353\n",
      "Epoch 196/5000\n",
      "11786/11786 [==============================] - 7s 596us/step - loss: 0.0665 - accuracy: 0.7611 - val_loss: 0.0740 - val_accuracy: 0.7325\n",
      "Epoch 197/5000\n",
      "11786/11786 [==============================] - 7s 601us/step - loss: 0.0666 - accuracy: 0.7612 - val_loss: 0.0728 - val_accuracy: 0.7374\n",
      "Epoch 198/5000\n",
      "11786/11786 [==============================] - 7s 599us/step - loss: 0.0665 - accuracy: 0.7612 - val_loss: 0.0734 - val_accuracy: 0.7352\n",
      "Epoch 199/5000\n",
      "11786/11786 [==============================] - 7s 600us/step - loss: 0.0664 - accuracy: 0.7612 - val_loss: 0.0732 - val_accuracy: 0.7358\n",
      "Epoch 200/5000\n",
      "11786/11786 [==============================] - 7s 601us/step - loss: 0.0666 - accuracy: 0.7607 - val_loss: 0.0729 - val_accuracy: 0.7358\n",
      "Epoch 201/5000\n",
      "11786/11786 [==============================] - 7s 604us/step - loss: 0.0665 - accuracy: 0.7614 - val_loss: 0.0731 - val_accuracy: 0.7363\n",
      "Epoch 202/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0664 - accuracy: 0.7614 - val_loss: 0.0730 - val_accuracy: 0.7381\n",
      "Epoch 203/5000\n",
      "11786/11786 [==============================] - 7s 617us/step - loss: 0.0665 - accuracy: 0.7610 - val_loss: 0.0730 - val_accuracy: 0.7367\n",
      "Epoch 204/5000\n",
      "11786/11786 [==============================] - 7s 608us/step - loss: 0.0665 - accuracy: 0.7609 - val_loss: 0.0732 - val_accuracy: 0.7347\n",
      "Epoch 205/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0664 - accuracy: 0.7615 - val_loss: 0.0728 - val_accuracy: 0.7369\n",
      "Epoch 206/5000\n",
      "11786/11786 [==============================] - 7s 621us/step - loss: 0.0664 - accuracy: 0.7617 - val_loss: 0.0732 - val_accuracy: 0.7355\n",
      "Epoch 207/5000\n",
      "11786/11786 [==============================] - 7s 604us/step - loss: 0.0664 - accuracy: 0.7612 - val_loss: 0.0727 - val_accuracy: 0.7377\n",
      "Epoch 208/5000\n",
      "11786/11786 [==============================] - 7s 608us/step - loss: 0.0664 - accuracy: 0.7615 - val_loss: 0.0733 - val_accuracy: 0.7366\n",
      "Epoch 209/5000\n",
      "11786/11786 [==============================] - 7s 617us/step - loss: 0.0664 - accuracy: 0.7613 - val_loss: 0.0732 - val_accuracy: 0.7358\n",
      "Epoch 210/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0664 - accuracy: 0.7617 - val_loss: 0.0737 - val_accuracy: 0.7346\n",
      "Epoch 211/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0663 - accuracy: 0.7616 - val_loss: 0.0734 - val_accuracy: 0.7362\n",
      "Epoch 212/5000\n",
      "11786/11786 [==============================] - 7s 618us/step - loss: 0.0663 - accuracy: 0.7619 - val_loss: 0.0730 - val_accuracy: 0.7368\n",
      "Epoch 213/5000\n",
      "11786/11786 [==============================] - 7s 621us/step - loss: 0.0664 - accuracy: 0.7616 - val_loss: 0.0734 - val_accuracy: 0.7338\n",
      "Epoch 214/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0665 - accuracy: 0.7610 - val_loss: 0.0731 - val_accuracy: 0.7387\n",
      "Epoch 215/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0665 - accuracy: 0.7611 - val_loss: 0.0732 - val_accuracy: 0.7358\n",
      "Epoch 216/5000\n",
      "11786/11786 [==============================] - 7s 618us/step - loss: 0.0664 - accuracy: 0.7618 - val_loss: 0.0732 - val_accuracy: 0.7373\n",
      "Epoch 217/5000\n",
      "11786/11786 [==============================] - 7s 608us/step - loss: 0.0664 - accuracy: 0.7616 - val_loss: 0.0736 - val_accuracy: 0.7341\n",
      "Epoch 218/5000\n",
      "11786/11786 [==============================] - 7s 603us/step - loss: 0.0663 - accuracy: 0.7616 - val_loss: 0.0734 - val_accuracy: 0.7358\n",
      "Epoch 219/5000\n",
      "11786/11786 [==============================] - 7s 614us/step - loss: 0.0663 - accuracy: 0.7618 - val_loss: 0.0730 - val_accuracy: 0.7362\n",
      "Epoch 220/5000\n",
      "11786/11786 [==============================] - 7s 616us/step - loss: 0.0664 - accuracy: 0.7616 - val_loss: 0.0736 - val_accuracy: 0.7363\n",
      "Epoch 221/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0663 - accuracy: 0.7618 - val_loss: 0.0733 - val_accuracy: 0.7361\n",
      "Epoch 222/5000\n",
      "11786/11786 [==============================] - 7s 621us/step - loss: 0.0663 - accuracy: 0.7622 - val_loss: 0.0731 - val_accuracy: 0.7385\n",
      "Epoch 223/5000\n",
      "11786/11786 [==============================] - 7s 609us/step - loss: 0.0663 - accuracy: 0.7618 - val_loss: 0.0743 - val_accuracy: 0.7304\n",
      "Epoch 224/5000\n",
      "11786/11786 [==============================] - 7s 603us/step - loss: 0.0663 - accuracy: 0.7620 - val_loss: 0.0734 - val_accuracy: 0.7364\n",
      "Epoch 225/5000\n",
      "11786/11786 [==============================] - 7s 601us/step - loss: 0.0663 - accuracy: 0.7618 - val_loss: 0.0733 - val_accuracy: 0.7357\n",
      "Epoch 226/5000\n",
      "11786/11786 [==============================] - 7s 612us/step - loss: 0.0662 - accuracy: 0.7622 - val_loss: 0.0733 - val_accuracy: 0.7349\n",
      "Epoch 227/5000\n",
      "11786/11786 [==============================] - 7s 622us/step - loss: 0.0662 - accuracy: 0.7623 - val_loss: 0.0743 - val_accuracy: 0.7324\n",
      "Epoch 228/5000\n",
      "11786/11786 [==============================] - 7s 620us/step - loss: 0.0663 - accuracy: 0.7623 - val_loss: 0.0744 - val_accuracy: 0.7307\n",
      "Epoch 229/5000\n",
      "11786/11786 [==============================] - 7s 622us/step - loss: 0.0662 - accuracy: 0.7624 - val_loss: 0.0731 - val_accuracy: 0.7368\n",
      "Epoch 230/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0662 - accuracy: 0.7625 - val_loss: 0.0736 - val_accuracy: 0.7352\n",
      "Epoch 231/5000\n",
      "11786/11786 [==============================] - 7s 615us/step - loss: 0.0661 - accuracy: 0.7627 - val_loss: 0.0729 - val_accuracy: 0.7381\n",
      "Epoch 232/5000\n",
      "11786/11786 [==============================] - 7s 619us/step - loss: 0.0661 - accuracy: 0.7629 - val_loss: 0.0736 - val_accuracy: 0.7360\n",
      "Epoch 233/5000\n",
      "11786/11786 [==============================] - 7s 617us/step - loss: 0.0663 - accuracy: 0.7621 - val_loss: 0.0732 - val_accuracy: 0.7378\n",
      "Epoch 234/5000\n",
      "11786/11786 [==============================] - 7s 617us/step - loss: 0.0662 - accuracy: 0.7623 - val_loss: 0.0731 - val_accuracy: 0.7385\n",
      "Epoch 235/5000\n",
      "11786/11786 [==============================] - 7s 619us/step - loss: 0.0662 - accuracy: 0.7623 - val_loss: 0.0734 - val_accuracy: 0.7375\n",
      "Epoch 236/5000\n",
      "11786/11786 [==============================] - 7s 620us/step - loss: 0.0663 - accuracy: 0.7625 - val_loss: 0.0740 - val_accuracy: 0.7361\n",
      "Epoch 237/5000\n",
      "11786/11786 [==============================] - 7s 619us/step - loss: 0.0661 - accuracy: 0.7629 - val_loss: 0.0737 - val_accuracy: 0.7363\n",
      "Epoch 238/5000\n",
      "11786/11786 [==============================] - 7s 612us/step - loss: 0.0661 - accuracy: 0.7630 - val_loss: 0.0731 - val_accuracy: 0.7376\n",
      "Epoch 239/5000\n",
      "11786/11786 [==============================] - 7s 614us/step - loss: 0.0662 - accuracy: 0.7624 - val_loss: 0.0733 - val_accuracy: 0.7370\n",
      "Epoch 240/5000\n",
      "11786/11786 [==============================] - 7s 614us/step - loss: 0.0662 - accuracy: 0.7622 - val_loss: 0.0728 - val_accuracy: 0.7389\n",
      "Epoch 241/5000\n",
      "11786/11786 [==============================] - 7s 621us/step - loss: 0.0661 - accuracy: 0.7628 - val_loss: 0.0733 - val_accuracy: 0.7379\n",
      "Epoch 242/5000\n",
      "11786/11786 [==============================] - 7s 614us/step - loss: 0.0661 - accuracy: 0.7627 - val_loss: 0.0733 - val_accuracy: 0.7377\n",
      "Epoch 243/5000\n",
      "11786/11786 [==============================] - 7s 611us/step - loss: 0.0661 - accuracy: 0.7629 - val_loss: 0.0739 - val_accuracy: 0.7362\n",
      "Epoch 244/5000\n",
      "11786/11786 [==============================] - 7s 620us/step - loss: 0.0661 - accuracy: 0.7626 - val_loss: 0.0728 - val_accuracy: 0.7381\n",
      "Epoch 245/5000\n",
      "11786/11786 [==============================] - 7s 611us/step - loss: 0.0661 - accuracy: 0.7625 - val_loss: 0.0735 - val_accuracy: 0.7361\n",
      "Epoch 246/5000\n",
      "11786/11786 [==============================] - 7s 614us/step - loss: 0.0662 - accuracy: 0.7623 - val_loss: 0.0733 - val_accuracy: 0.7361\n",
      "Epoch 247/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0662 - accuracy: 0.7629 - val_loss: 0.0731 - val_accuracy: 0.7364\n",
      "Epoch 248/5000\n",
      "11786/11786 [==============================] - 7s 620us/step - loss: 0.0661 - accuracy: 0.7632 - val_loss: 0.0747 - val_accuracy: 0.7308\n",
      "Epoch 249/5000\n",
      "11786/11786 [==============================] - 7s 614us/step - loss: 0.0661 - accuracy: 0.7630 - val_loss: 0.0734 - val_accuracy: 0.7361\n",
      "Epoch 250/5000\n",
      "11786/11786 [==============================] - 7s 609us/step - loss: 0.0660 - accuracy: 0.7629 - val_loss: 0.0740 - val_accuracy: 0.7346\n",
      "Epoch 251/5000\n",
      "11786/11786 [==============================] - 7s 616us/step - loss: 0.0662 - accuracy: 0.7628 - val_loss: 0.0738 - val_accuracy: 0.7348\n",
      "Epoch 252/5000\n",
      "11786/11786 [==============================] - 7s 623us/step - loss: 0.0660 - accuracy: 0.7631 - val_loss: 0.0740 - val_accuracy: 0.7344\n",
      "Epoch 253/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0661 - accuracy: 0.7633 - val_loss: 0.0731 - val_accuracy: 0.7377\n",
      "Epoch 254/5000\n",
      "11786/11786 [==============================] - 7s 599us/step - loss: 0.0660 - accuracy: 0.7630 - val_loss: 0.0737 - val_accuracy: 0.7343\n",
      "Epoch 255/5000\n",
      "11786/11786 [==============================] - 7s 606us/step - loss: 0.0661 - accuracy: 0.7629 - val_loss: 0.0727 - val_accuracy: 0.7385\n",
      "Epoch 256/5000\n",
      "11786/11786 [==============================] - 7s 598us/step - loss: 0.0661 - accuracy: 0.7635 - val_loss: 0.0731 - val_accuracy: 0.7360\n",
      "Epoch 257/5000\n",
      "11786/11786 [==============================] - 7s 612us/step - loss: 0.0661 - accuracy: 0.7629 - val_loss: 0.0735 - val_accuracy: 0.7375\n",
      "Epoch 258/5000\n",
      "11786/11786 [==============================] - 7s 619us/step - loss: 0.0660 - accuracy: 0.7634 - val_loss: 0.0736 - val_accuracy: 0.7376\n",
      "Epoch 259/5000\n",
      "11786/11786 [==============================] - 7s 612us/step - loss: 0.0661 - accuracy: 0.7631 - val_loss: 0.0734 - val_accuracy: 0.7359\n",
      "Epoch 260/5000\n",
      "11786/11786 [==============================] - 7s 617us/step - loss: 0.0660 - accuracy: 0.7634 - val_loss: 0.0730 - val_accuracy: 0.7381\n",
      "Epoch 261/5000\n",
      "11786/11786 [==============================] - 7s 604us/step - loss: 0.0660 - accuracy: 0.7631 - val_loss: 0.0729 - val_accuracy: 0.7379\n",
      "Epoch 262/5000\n",
      "11786/11786 [==============================] - 7s 622us/step - loss: 0.0660 - accuracy: 0.7629 - val_loss: 0.0737 - val_accuracy: 0.7357\n",
      "Epoch 263/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0660 - accuracy: 0.7632 - val_loss: 0.0732 - val_accuracy: 0.7370\n",
      "Epoch 264/5000\n",
      "11786/11786 [==============================] - 7s 614us/step - loss: 0.0660 - accuracy: 0.7634 - val_loss: 0.0737 - val_accuracy: 0.7354\n",
      "Epoch 265/5000\n",
      "11786/11786 [==============================] - 7s 609us/step - loss: 0.0661 - accuracy: 0.7635 - val_loss: 0.0733 - val_accuracy: 0.7373\n",
      "Epoch 266/5000\n",
      "11786/11786 [==============================] - 7s 616us/step - loss: 0.0660 - accuracy: 0.7629 - val_loss: 0.0735 - val_accuracy: 0.7357\n",
      "Epoch 267/5000\n",
      "11786/11786 [==============================] - 7s 606us/step - loss: 0.0659 - accuracy: 0.7638 - val_loss: 0.0736 - val_accuracy: 0.7350\n",
      "Epoch 268/5000\n",
      "11786/11786 [==============================] - 7s 611us/step - loss: 0.0660 - accuracy: 0.7630 - val_loss: 0.0732 - val_accuracy: 0.7370\n",
      "Epoch 269/5000\n",
      "11786/11786 [==============================] - 7s 604us/step - loss: 0.0659 - accuracy: 0.7637 - val_loss: 0.0732 - val_accuracy: 0.7375\n",
      "Epoch 270/5000\n",
      "11786/11786 [==============================] - 7s 606us/step - loss: 0.0660 - accuracy: 0.7634 - val_loss: 0.0735 - val_accuracy: 0.7384\n",
      "Epoch 271/5000\n",
      "11786/11786 [==============================] - 7s 609us/step - loss: 0.0659 - accuracy: 0.7642 - val_loss: 0.0731 - val_accuracy: 0.7383\n",
      "Epoch 272/5000\n",
      "11786/11786 [==============================] - 7s 606us/step - loss: 0.0660 - accuracy: 0.7636 - val_loss: 0.0733 - val_accuracy: 0.7360\n",
      "Epoch 273/5000\n",
      "11786/11786 [==============================] - 7s 603us/step - loss: 0.0660 - accuracy: 0.7633 - val_loss: 0.0734 - val_accuracy: 0.7380\n",
      "Epoch 274/5000\n",
      "11786/11786 [==============================] - 7s 608us/step - loss: 0.0660 - accuracy: 0.7634 - val_loss: 0.0724 - val_accuracy: 0.7393\n",
      "Epoch 275/5000\n",
      "11786/11786 [==============================] - 7s 608us/step - loss: 0.0659 - accuracy: 0.7639 - val_loss: 0.0733 - val_accuracy: 0.7381\n",
      "Epoch 276/5000\n",
      "11786/11786 [==============================] - 7s 605us/step - loss: 0.0659 - accuracy: 0.7639 - val_loss: 0.0728 - val_accuracy: 0.7388\n",
      "Epoch 277/5000\n",
      "11786/11786 [==============================] - 7s 601us/step - loss: 0.0659 - accuracy: 0.7638 - val_loss: 0.0730 - val_accuracy: 0.7393\n",
      "Epoch 278/5000\n",
      "11786/11786 [==============================] - 7s 604us/step - loss: 0.0659 - accuracy: 0.7635 - val_loss: 0.0731 - val_accuracy: 0.7371\n",
      "Epoch 279/5000\n",
      "11786/11786 [==============================] - 7s 606us/step - loss: 0.0659 - accuracy: 0.7638 - val_loss: 0.0730 - val_accuracy: 0.7362\n",
      "Epoch 280/5000\n",
      "11786/11786 [==============================] - 7s 602us/step - loss: 0.0659 - accuracy: 0.7641 - val_loss: 0.0728 - val_accuracy: 0.7374\n",
      "Epoch 281/5000\n",
      "11786/11786 [==============================] - 7s 605us/step - loss: 0.0659 - accuracy: 0.7641 - val_loss: 0.0733 - val_accuracy: 0.7368\n",
      "Epoch 282/5000\n",
      "11786/11786 [==============================] - 7s 605us/step - loss: 0.0659 - accuracy: 0.7641 - val_loss: 0.0730 - val_accuracy: 0.7372\n",
      "Epoch 283/5000\n",
      "11786/11786 [==============================] - 7s 617us/step - loss: 0.0659 - accuracy: 0.7643 - val_loss: 0.0742 - val_accuracy: 0.7333\n",
      "Epoch 284/5000\n",
      "11786/11786 [==============================] - 7s 611us/step - loss: 0.0658 - accuracy: 0.7637 - val_loss: 0.0733 - val_accuracy: 0.7365\n",
      "Epoch 285/5000\n",
      "11786/11786 [==============================] - 7s 609us/step - loss: 0.0658 - accuracy: 0.7641 - val_loss: 0.0739 - val_accuracy: 0.7351\n",
      "Epoch 286/5000\n",
      "11786/11786 [==============================] - 7s 611us/step - loss: 0.0659 - accuracy: 0.7637 - val_loss: 0.0732 - val_accuracy: 0.7358\n",
      "Epoch 287/5000\n",
      "11786/11786 [==============================] - 7s 608us/step - loss: 0.0658 - accuracy: 0.7646 - val_loss: 0.0728 - val_accuracy: 0.7384\n",
      "Epoch 288/5000\n",
      "11786/11786 [==============================] - 7s 616us/step - loss: 0.0659 - accuracy: 0.7642 - val_loss: 0.0729 - val_accuracy: 0.7376\n",
      "Epoch 289/5000\n",
      "11786/11786 [==============================] - 7s 612us/step - loss: 0.0659 - accuracy: 0.7641 - val_loss: 0.0738 - val_accuracy: 0.7370\n",
      "Epoch 290/5000\n",
      "11786/11786 [==============================] - 7s 613us/step - loss: 0.0658 - accuracy: 0.7640 - val_loss: 0.0735 - val_accuracy: 0.7367\n",
      "Epoch 291/5000\n",
      "11786/11786 [==============================] - 7s 615us/step - loss: 0.0658 - accuracy: 0.7644 - val_loss: 0.0726 - val_accuracy: 0.7387\n",
      "Epoch 292/5000\n",
      "11786/11786 [==============================] - 7s 606us/step - loss: 0.0658 - accuracy: 0.7638 - val_loss: 0.0729 - val_accuracy: 0.7387\n",
      "Epoch 293/5000\n",
      "11786/11786 [==============================] - 7s 604us/step - loss: 0.0658 - accuracy: 0.7647 - val_loss: 0.0734 - val_accuracy: 0.7353\n",
      "Epoch 294/5000\n",
      "11786/11786 [==============================] - 7s 614us/step - loss: 0.0657 - accuracy: 0.7647 - val_loss: 0.0731 - val_accuracy: 0.7373\n",
      "Epoch 295/5000\n",
      "11786/11786 [==============================] - 7s 600us/step - loss: 0.0658 - accuracy: 0.7642 - val_loss: 0.0732 - val_accuracy: 0.7370\n",
      "Epoch 296/5000\n",
      "11786/11786 [==============================] - 7s 607us/step - loss: 0.0659 - accuracy: 0.7642 - val_loss: 0.0733 - val_accuracy: 0.7376\n",
      "Epoch 297/5000\n",
      "11786/11786 [==============================] - 7s 610us/step - loss: 0.0660 - accuracy: 0.7635 - val_loss: 0.0729 - val_accuracy: 0.7391\n",
      "Epoch 298/5000\n",
      "11786/11786 [==============================] - 7s 609us/step - loss: 0.0657 - accuracy: 0.7641 - val_loss: 0.0734 - val_accuracy: 0.7360\n",
      "Epoch 299/5000\n",
      "11786/11786 [==============================] - 7s 616us/step - loss: 0.0658 - accuracy: 0.7647 - val_loss: 0.0732 - val_accuracy: 0.7371\n",
      "Epoch 300/5000\n",
      "11786/11786 [==============================] - 7s 623us/step - loss: 0.0658 - accuracy: 0.7646 - val_loss: 0.0739 - val_accuracy: 0.7351\n",
      "Epoch 301/5000\n",
      "11786/11786 [==============================] - 7s 622us/step - loss: 0.0658 - accuracy: 0.7648 - val_loss: 0.0736 - val_accuracy: 0.7358\n",
      "Epoch 302/5000\n",
      "11786/11786 [==============================] - 7s 616us/step - loss: 0.0657 - accuracy: 0.7648 - val_loss: 0.0737 - val_accuracy: 0.7353\n",
      "Epoch 303/5000\n",
      "11786/11786 [==============================] - 7s 615us/step - loss: 0.0658 - accuracy: 0.7643 - val_loss: 0.0733 - val_accuracy: 0.7359\n",
      "Epoch 304/5000\n",
      "11786/11786 [==============================] - 7s 618us/step - loss: 0.0657 - accuracy: 0.7647 - val_loss: 0.0734 - val_accuracy: 0.7386\n",
      "Epoch 305/5000\n",
      "11786/11786 [==============================] - 7s 619us/step - loss: 0.0657 - accuracy: 0.7648 - val_loss: 0.0731 - val_accuracy: 0.7365\n",
      "Epoch 306/5000\n",
      "11786/11786 [==============================] - 7s 619us/step - loss: 0.0657 - accuracy: 0.7649 - val_loss: 0.0736 - val_accuracy: 0.7384\n",
      "Epoch 307/5000\n",
      "11786/11786 [==============================] - 7s 623us/step - loss: 0.0657 - accuracy: 0.7654 - val_loss: 0.0730 - val_accuracy: 0.7384\n",
      "Epoch 308/5000\n",
      "11786/11786 [==============================] - 7s 613us/step - loss: 0.0658 - accuracy: 0.7648 - val_loss: 0.0738 - val_accuracy: 0.7358\n",
      "Epoch 309/5000\n",
      "11786/11786 [==============================] - 7s 605us/step - loss: 0.0657 - accuracy: 0.7648 - val_loss: 0.0739 - val_accuracy: 0.7354\n",
      "Epoch 310/5000\n",
      "11786/11786 [==============================] - 7s 616us/step - loss: 0.0657 - accuracy: 0.7644 - val_loss: 0.0731 - val_accuracy: 0.7381\n",
      "Epoch 311/5000\n",
      "11786/11786 [==============================] - 7s 611us/step - loss: 0.0658 - accuracy: 0.7644 - val_loss: 0.0730 - val_accuracy: 0.7372\n",
      "Epoch 312/5000\n",
      "11786/11786 [==============================] - 7s 615us/step - loss: 0.0657 - accuracy: 0.7650 - val_loss: 0.0731 - val_accuracy: 0.7390\n",
      "Epoch 313/5000\n",
      "11786/11786 [==============================] - 7s 621us/step - loss: 0.0657 - accuracy: 0.7646 - val_loss: 0.0733 - val_accuracy: 0.7361\n",
      "Epoch 314/5000\n",
      "11786/11786 [==============================] - 7s 617us/step - loss: 0.0657 - accuracy: 0.7652 - val_loss: 0.0729 - val_accuracy: 0.7393\n",
      "Epoch 315/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0657 - accuracy: 0.7651 - val_loss: 0.0729 - val_accuracy: 0.7378\n",
      "Epoch 316/5000\n",
      "11786/11786 [==============================] - 7s 615us/step - loss: 0.0657 - accuracy: 0.7649 - val_loss: 0.0735 - val_accuracy: 0.7358\n",
      "Epoch 317/5000\n",
      "11786/11786 [==============================] - 7s 603us/step - loss: 0.0657 - accuracy: 0.7649 - val_loss: 0.0730 - val_accuracy: 0.7373\n",
      "Epoch 318/5000\n",
      "11786/11786 [==============================] - 7s 614us/step - loss: 0.0657 - accuracy: 0.7646 - val_loss: 0.0736 - val_accuracy: 0.7369\n",
      "Epoch 319/5000\n",
      "11786/11786 [==============================] - 7s 602us/step - loss: 0.0656 - accuracy: 0.7653 - val_loss: 0.0744 - val_accuracy: 0.7357\n",
      "Epoch 320/5000\n",
      "11786/11786 [==============================] - 7s 602us/step - loss: 0.0656 - accuracy: 0.7651 - val_loss: 0.0734 - val_accuracy: 0.7366\n",
      "Epoch 321/5000\n",
      "11786/11786 [==============================] - 7s 598us/step - loss: 0.0658 - accuracy: 0.7651 - val_loss: 0.0738 - val_accuracy: 0.7361\n",
      "Epoch 322/5000\n",
      "11786/11786 [==============================] - 7s 599us/step - loss: 0.0657 - accuracy: 0.7650 - val_loss: 0.0740 - val_accuracy: 0.7348\n",
      "Epoch 323/5000\n",
      "11786/11786 [==============================] - 7s 600us/step - loss: 0.0657 - accuracy: 0.7648 - val_loss: 0.0730 - val_accuracy: 0.7381\n",
      "Epoch 324/5000\n",
      "11786/11786 [==============================] - 7s 612us/step - loss: 0.0657 - accuracy: 0.7647 - val_loss: 0.0734 - val_accuracy: 0.7376\n",
      "Epoch 325/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0656 - accuracy: 0.7652 - val_loss: 0.0733 - val_accuracy: 0.7376\n",
      "Epoch 326/5000\n",
      "11786/11786 [==============================] - 7s 617us/step - loss: 0.0657 - accuracy: 0.7653 - val_loss: 0.0738 - val_accuracy: 0.7346\n",
      "Epoch 327/5000\n",
      "11786/11786 [==============================] - 7s 619us/step - loss: 0.0657 - accuracy: 0.7645 - val_loss: 0.0732 - val_accuracy: 0.7371\n",
      "Epoch 328/5000\n",
      "11786/11786 [==============================] - 7s 613us/step - loss: 0.0656 - accuracy: 0.7649 - val_loss: 0.0730 - val_accuracy: 0.7381\n",
      "Epoch 329/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0657 - accuracy: 0.7647 - val_loss: 0.0751 - val_accuracy: 0.7347\n",
      "Epoch 330/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0657 - accuracy: 0.7653 - val_loss: 0.0732 - val_accuracy: 0.7371\n",
      "Epoch 331/5000\n",
      "11786/11786 [==============================] - 7s 616us/step - loss: 0.0656 - accuracy: 0.7656 - val_loss: 0.0730 - val_accuracy: 0.7392\n",
      "Epoch 332/5000\n",
      "11786/11786 [==============================] - 7s 622us/step - loss: 0.0657 - accuracy: 0.7656 - val_loss: 0.0735 - val_accuracy: 0.7369\n",
      "Epoch 333/5000\n",
      "11786/11786 [==============================] - 7s 617us/step - loss: 0.0657 - accuracy: 0.7650 - val_loss: 0.0742 - val_accuracy: 0.7341\n",
      "Epoch 334/5000\n",
      "11786/11786 [==============================] - 7s 623us/step - loss: 0.0657 - accuracy: 0.7650 - val_loss: 0.0729 - val_accuracy: 0.7374\n",
      "Epoch 335/5000\n",
      "11786/11786 [==============================] - 7s 621us/step - loss: 0.0657 - accuracy: 0.7648 - val_loss: 0.0733 - val_accuracy: 0.7370\n",
      "Epoch 336/5000\n",
      "11786/11786 [==============================] - 7s 622us/step - loss: 0.0657 - accuracy: 0.7646 - val_loss: 0.0728 - val_accuracy: 0.7387\n",
      "Epoch 337/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0656 - accuracy: 0.7655 - val_loss: 0.0733 - val_accuracy: 0.7380\n",
      "Epoch 338/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0656 - accuracy: 0.7653 - val_loss: 0.0734 - val_accuracy: 0.7382\n",
      "Epoch 339/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0655 - accuracy: 0.7653 - val_loss: 0.0733 - val_accuracy: 0.7365\n",
      "Epoch 340/5000\n",
      "11786/11786 [==============================] - 7s 609us/step - loss: 0.0656 - accuracy: 0.7653 - val_loss: 0.0730 - val_accuracy: 0.7385\n",
      "Epoch 341/5000\n",
      "11786/11786 [==============================] - 7s 608us/step - loss: 0.0656 - accuracy: 0.7654 - val_loss: 0.0729 - val_accuracy: 0.7390\n",
      "Epoch 342/5000\n",
      "11786/11786 [==============================] - 7s 605us/step - loss: 0.0656 - accuracy: 0.7657 - val_loss: 0.0737 - val_accuracy: 0.7361\n",
      "Epoch 343/5000\n",
      "11786/11786 [==============================] - 7s 601us/step - loss: 0.0657 - accuracy: 0.7654 - val_loss: 0.0731 - val_accuracy: 0.7376\n",
      "Epoch 344/5000\n",
      "11786/11786 [==============================] - 7s 600us/step - loss: 0.0655 - accuracy: 0.7659 - val_loss: 0.0730 - val_accuracy: 0.7383\n",
      "Epoch 345/5000\n",
      "11786/11786 [==============================] - 7s 597us/step - loss: 0.0655 - accuracy: 0.7657 - val_loss: 0.0729 - val_accuracy: 0.7381\n",
      "Epoch 346/5000\n",
      "11786/11786 [==============================] - 7s 600us/step - loss: 0.0656 - accuracy: 0.7657 - val_loss: 0.0734 - val_accuracy: 0.7371\n",
      "Epoch 347/5000\n",
      "11786/11786 [==============================] - 7s 607us/step - loss: 0.0655 - accuracy: 0.7654 - val_loss: 0.0741 - val_accuracy: 0.7357\n",
      "Epoch 348/5000\n",
      "11786/11786 [==============================] - 7s 603us/step - loss: 0.0656 - accuracy: 0.7656 - val_loss: 0.0728 - val_accuracy: 0.7379\n",
      "Epoch 349/5000\n",
      "11786/11786 [==============================] - 7s 601us/step - loss: 0.0655 - accuracy: 0.7659 - val_loss: 0.0731 - val_accuracy: 0.7377\n",
      "Epoch 350/5000\n",
      "11786/11786 [==============================] - 7s 598us/step - loss: 0.0655 - accuracy: 0.7657 - val_loss: 0.0736 - val_accuracy: 0.7374\n",
      "Epoch 351/5000\n",
      "11786/11786 [==============================] - 7s 603us/step - loss: 0.0656 - accuracy: 0.7654 - val_loss: 0.0732 - val_accuracy: 0.7378\n",
      "Epoch 352/5000\n",
      "11786/11786 [==============================] - 7s 601us/step - loss: 0.0655 - accuracy: 0.7656 - val_loss: 0.0733 - val_accuracy: 0.7368\n",
      "Epoch 353/5000\n",
      "11786/11786 [==============================] - 7s 602us/step - loss: 0.0655 - accuracy: 0.7660 - val_loss: 0.0735 - val_accuracy: 0.7379\n",
      "Epoch 354/5000\n",
      "11786/11786 [==============================] - 7s 594us/step - loss: 0.0655 - accuracy: 0.7662 - val_loss: 0.0732 - val_accuracy: 0.7379\n",
      "Epoch 355/5000\n",
      "11786/11786 [==============================] - 7s 603us/step - loss: 0.0655 - accuracy: 0.7662 - val_loss: 0.0731 - val_accuracy: 0.7372\n",
      "Epoch 356/5000\n",
      "11786/11786 [==============================] - 7s 599us/step - loss: 0.0655 - accuracy: 0.7659 - val_loss: 0.0733 - val_accuracy: 0.7380\n",
      "Epoch 357/5000\n",
      "11786/11786 [==============================] - 7s 601us/step - loss: 0.0655 - accuracy: 0.7658 - val_loss: 0.0731 - val_accuracy: 0.7379\n",
      "Epoch 358/5000\n",
      "11786/11786 [==============================] - 7s 601us/step - loss: 0.0656 - accuracy: 0.7654 - val_loss: 0.0730 - val_accuracy: 0.7395\n",
      "Epoch 359/5000\n",
      "11786/11786 [==============================] - 7s 612us/step - loss: 0.0655 - accuracy: 0.7662 - val_loss: 0.0738 - val_accuracy: 0.7358\n",
      "Epoch 360/5000\n",
      "11786/11786 [==============================] - 7s 604us/step - loss: 0.0656 - accuracy: 0.7652 - val_loss: 0.0733 - val_accuracy: 0.7363\n",
      "Epoch 361/5000\n",
      "11786/11786 [==============================] - 7s 603us/step - loss: 0.0654 - accuracy: 0.7664 - val_loss: 0.0734 - val_accuracy: 0.7375\n",
      "Epoch 362/5000\n",
      "11786/11786 [==============================] - 7s 609us/step - loss: 0.0655 - accuracy: 0.7666 - val_loss: 0.0736 - val_accuracy: 0.7379\n",
      "Epoch 363/5000\n",
      "11786/11786 [==============================] - 7s 594us/step - loss: 0.0655 - accuracy: 0.7667 - val_loss: 0.0732 - val_accuracy: 0.7391\n",
      "Epoch 364/5000\n",
      "11786/11786 [==============================] - 7s 603us/step - loss: 0.0654 - accuracy: 0.7663 - val_loss: 0.0734 - val_accuracy: 0.7362\n",
      "Epoch 365/5000\n",
      "11786/11786 [==============================] - 7s 600us/step - loss: 0.0654 - accuracy: 0.7663 - val_loss: 0.0744 - val_accuracy: 0.7320\n",
      "Epoch 366/5000\n",
      "11786/11786 [==============================] - 7s 599us/step - loss: 0.0655 - accuracy: 0.7659 - val_loss: 0.0738 - val_accuracy: 0.7349\n",
      "Epoch 367/5000\n",
      "11786/11786 [==============================] - 7s 601us/step - loss: 0.0655 - accuracy: 0.7660 - val_loss: 0.0732 - val_accuracy: 0.7378\n",
      "Epoch 368/5000\n",
      "11786/11786 [==============================] - 7s 602us/step - loss: 0.0655 - accuracy: 0.7657 - val_loss: 0.0734 - val_accuracy: 0.7376\n",
      "Epoch 369/5000\n",
      "11786/11786 [==============================] - 7s 601us/step - loss: 0.0654 - accuracy: 0.7667 - val_loss: 0.0735 - val_accuracy: 0.7382\n",
      "Epoch 370/5000\n",
      "11786/11786 [==============================] - 7s 604us/step - loss: 0.0654 - accuracy: 0.7666 - val_loss: 0.0737 - val_accuracy: 0.7382\n",
      "Epoch 371/5000\n",
      "11786/11786 [==============================] - 7s 600us/step - loss: 0.0655 - accuracy: 0.7660 - val_loss: 0.0730 - val_accuracy: 0.7384\n",
      "Epoch 372/5000\n",
      "11786/11786 [==============================] - 7s 610us/step - loss: 0.0654 - accuracy: 0.7663 - val_loss: 0.0735 - val_accuracy: 0.7374\n",
      "Epoch 373/5000\n",
      "11786/11786 [==============================] - 7s 599us/step - loss: 0.0654 - accuracy: 0.7663 - val_loss: 0.0736 - val_accuracy: 0.7364\n",
      "Epoch 374/5000\n",
      "11786/11786 [==============================] - 7s 606us/step - loss: 0.0656 - accuracy: 0.7659 - val_loss: 0.0733 - val_accuracy: 0.7395\n",
      "Epoch 375/5000\n",
      "11786/11786 [==============================] - 7s 607us/step - loss: 0.0655 - accuracy: 0.7657 - val_loss: 0.0733 - val_accuracy: 0.7374\n",
      "Epoch 376/5000\n",
      "11786/11786 [==============================] - 7s 615us/step - loss: 0.0655 - accuracy: 0.7657 - val_loss: 0.0733 - val_accuracy: 0.7391\n",
      "Epoch 377/5000\n",
      "11786/11786 [==============================] - 7s 615us/step - loss: 0.0654 - accuracy: 0.7665 - val_loss: 0.0734 - val_accuracy: 0.7379\n",
      "Epoch 378/5000\n",
      "11786/11786 [==============================] - 7s 614us/step - loss: 0.0654 - accuracy: 0.7664 - val_loss: 0.0738 - val_accuracy: 0.7357\n",
      "Epoch 379/5000\n",
      "11786/11786 [==============================] - 7s 612us/step - loss: 0.0653 - accuracy: 0.7664 - val_loss: 0.0732 - val_accuracy: 0.7384\n",
      "Epoch 380/5000\n",
      "11786/11786 [==============================] - 7s 608us/step - loss: 0.0654 - accuracy: 0.7665 - val_loss: 0.0731 - val_accuracy: 0.7397\n",
      "Epoch 381/5000\n",
      "11786/11786 [==============================] - 7s 616us/step - loss: 0.0653 - accuracy: 0.7671 - val_loss: 0.0733 - val_accuracy: 0.7370\n",
      "Epoch 382/5000\n",
      "11786/11786 [==============================] - 7s 619us/step - loss: 0.0654 - accuracy: 0.7664 - val_loss: 0.0729 - val_accuracy: 0.7405\n",
      "Epoch 383/5000\n",
      "11786/11786 [==============================] - 7s 618us/step - loss: 0.0653 - accuracy: 0.7667 - val_loss: 0.0742 - val_accuracy: 0.7354\n",
      "Epoch 384/5000\n",
      "11786/11786 [==============================] - 7s 621us/step - loss: 0.0655 - accuracy: 0.7662 - val_loss: 0.0738 - val_accuracy: 0.7366\n",
      "Epoch 385/5000\n",
      "11786/11786 [==============================] - 7s 620us/step - loss: 0.0654 - accuracy: 0.7663 - val_loss: 0.0739 - val_accuracy: 0.7375\n",
      "Epoch 386/5000\n",
      "11786/11786 [==============================] - 7s 617us/step - loss: 0.0653 - accuracy: 0.7670 - val_loss: 0.0732 - val_accuracy: 0.7392\n",
      "Epoch 387/5000\n",
      "11786/11786 [==============================] - 7s 616us/step - loss: 0.0654 - accuracy: 0.7669 - val_loss: 0.0730 - val_accuracy: 0.7381\n",
      "Epoch 388/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0654 - accuracy: 0.7665 - val_loss: 0.0734 - val_accuracy: 0.7369\n",
      "Epoch 389/5000\n",
      "11786/11786 [==============================] - 7s 622us/step - loss: 0.0654 - accuracy: 0.7662 - val_loss: 0.0751 - val_accuracy: 0.7316\n",
      "Epoch 390/5000\n",
      "11786/11786 [==============================] - 7s 621us/step - loss: 0.0653 - accuracy: 0.7659 - val_loss: 0.0732 - val_accuracy: 0.7378\n",
      "Epoch 391/5000\n",
      "11786/11786 [==============================] - 7s 615us/step - loss: 0.0653 - accuracy: 0.7672 - val_loss: 0.0733 - val_accuracy: 0.7378\n",
      "Epoch 392/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0653 - accuracy: 0.7673 - val_loss: 0.0732 - val_accuracy: 0.7381\n",
      "Epoch 393/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0653 - accuracy: 0.7664 - val_loss: 0.0731 - val_accuracy: 0.7388\n",
      "Epoch 394/5000\n",
      "11786/11786 [==============================] - 7s 621us/step - loss: 0.0653 - accuracy: 0.7668 - val_loss: 0.0737 - val_accuracy: 0.7379\n",
      "Epoch 395/5000\n",
      "11786/11786 [==============================] - 7s 621us/step - loss: 0.0654 - accuracy: 0.7668 - val_loss: 0.0735 - val_accuracy: 0.7379\n",
      "Epoch 396/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0652 - accuracy: 0.7672 - val_loss: 0.0735 - val_accuracy: 0.7379\n",
      "Epoch 397/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0653 - accuracy: 0.7668 - val_loss: 0.0738 - val_accuracy: 0.7381\n",
      "Epoch 398/5000\n",
      "11786/11786 [==============================] - 7s 618us/step - loss: 0.0653 - accuracy: 0.7669 - val_loss: 0.0732 - val_accuracy: 0.7377\n",
      "Epoch 399/5000\n",
      "11786/11786 [==============================] - 7s 615us/step - loss: 0.0653 - accuracy: 0.7666 - val_loss: 0.0731 - val_accuracy: 0.7395\n",
      "Epoch 400/5000\n",
      "11786/11786 [==============================] - 7s 620us/step - loss: 0.0653 - accuracy: 0.7669 - val_loss: 0.0735 - val_accuracy: 0.7369\n",
      "Epoch 401/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0653 - accuracy: 0.7675 - val_loss: 0.0732 - val_accuracy: 0.7381\n",
      "Epoch 402/5000\n",
      "11786/11786 [==============================] - 7s 615us/step - loss: 0.0653 - accuracy: 0.7666 - val_loss: 0.0737 - val_accuracy: 0.7385\n",
      "Epoch 403/5000\n",
      "11786/11786 [==============================] - 7s 614us/step - loss: 0.0653 - accuracy: 0.7667 - val_loss: 0.0734 - val_accuracy: 0.7377\n",
      "Epoch 404/5000\n",
      "11786/11786 [==============================] - 7s 614us/step - loss: 0.0653 - accuracy: 0.7667 - val_loss: 0.0732 - val_accuracy: 0.7371\n",
      "Epoch 405/5000\n",
      "11786/11786 [==============================] - 7s 622us/step - loss: 0.0653 - accuracy: 0.7668 - val_loss: 0.0735 - val_accuracy: 0.7385\n",
      "Epoch 406/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0653 - accuracy: 0.7668 - val_loss: 0.0736 - val_accuracy: 0.7367\n",
      "Epoch 407/5000\n",
      "11786/11786 [==============================] - 7s 614us/step - loss: 0.0654 - accuracy: 0.7667 - val_loss: 0.0731 - val_accuracy: 0.7380\n",
      "Epoch 408/5000\n",
      "11786/11786 [==============================] - 7s 619us/step - loss: 0.0653 - accuracy: 0.7669 - val_loss: 0.0736 - val_accuracy: 0.7372\n",
      "Epoch 409/5000\n",
      "11786/11786 [==============================] - 7s 619us/step - loss: 0.0653 - accuracy: 0.7671 - val_loss: 0.0734 - val_accuracy: 0.7370\n",
      "Epoch 410/5000\n",
      "11786/11786 [==============================] - 7s 609us/step - loss: 0.0654 - accuracy: 0.7670 - val_loss: 0.0731 - val_accuracy: 0.7384\n",
      "Epoch 411/5000\n",
      "11786/11786 [==============================] - 7s 617us/step - loss: 0.0653 - accuracy: 0.7676 - val_loss: 0.0727 - val_accuracy: 0.7397\n",
      "Epoch 412/5000\n",
      "11786/11786 [==============================] - 7s 617us/step - loss: 0.0652 - accuracy: 0.7670 - val_loss: 0.0732 - val_accuracy: 0.7387\n",
      "Epoch 413/5000\n",
      "11786/11786 [==============================] - 7s 615us/step - loss: 0.0652 - accuracy: 0.7672 - val_loss: 0.0732 - val_accuracy: 0.7390\n",
      "Epoch 414/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0654 - accuracy: 0.7667 - val_loss: 0.0733 - val_accuracy: 0.7394\n",
      "Epoch 415/5000\n",
      "11786/11786 [==============================] - 7s 620us/step - loss: 0.0652 - accuracy: 0.7674 - val_loss: 0.0740 - val_accuracy: 0.7365\n",
      "Epoch 416/5000\n",
      "11786/11786 [==============================] - 7s 620us/step - loss: 0.0652 - accuracy: 0.7677 - val_loss: 0.0733 - val_accuracy: 0.7386\n",
      "Epoch 417/5000\n",
      "11786/11786 [==============================] - 7s 615us/step - loss: 0.0653 - accuracy: 0.7671 - val_loss: 0.0734 - val_accuracy: 0.7377\n",
      "Epoch 418/5000\n",
      "11786/11786 [==============================] - 7s 615us/step - loss: 0.0652 - accuracy: 0.7673 - val_loss: 0.0735 - val_accuracy: 0.7379\n",
      "Epoch 419/5000\n",
      "11786/11786 [==============================] - 7s 622us/step - loss: 0.0653 - accuracy: 0.7672 - val_loss: 0.0737 - val_accuracy: 0.7369\n",
      "Epoch 420/5000\n",
      "11786/11786 [==============================] - 7s 619us/step - loss: 0.0653 - accuracy: 0.7672 - val_loss: 0.0734 - val_accuracy: 0.7384\n",
      "Epoch 421/5000\n",
      "11786/11786 [==============================] - 7s 621us/step - loss: 0.0653 - accuracy: 0.7668 - val_loss: 0.0736 - val_accuracy: 0.7386\n",
      "Epoch 422/5000\n",
      "11786/11786 [==============================] - 7s 609us/step - loss: 0.0652 - accuracy: 0.7673 - val_loss: 0.0735 - val_accuracy: 0.7393\n",
      "Epoch 423/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0652 - accuracy: 0.7673 - val_loss: 0.0751 - val_accuracy: 0.7332\n",
      "Epoch 424/5000\n",
      "11786/11786 [==============================] - 7s 620us/step - loss: 0.0652 - accuracy: 0.7668 - val_loss: 0.0744 - val_accuracy: 0.7349\n",
      "Epoch 425/5000\n",
      "11786/11786 [==============================] - 7s 612us/step - loss: 0.0652 - accuracy: 0.7667 - val_loss: 0.0732 - val_accuracy: 0.7380\n",
      "Epoch 426/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0653 - accuracy: 0.7669 - val_loss: 0.0735 - val_accuracy: 0.7369\n",
      "Epoch 427/5000\n",
      "11786/11786 [==============================] - 7s 619us/step - loss: 0.0652 - accuracy: 0.7675 - val_loss: 0.0736 - val_accuracy: 0.7358\n",
      "Epoch 428/5000\n",
      "11786/11786 [==============================] - 7s 620us/step - loss: 0.0652 - accuracy: 0.7665 - val_loss: 0.0733 - val_accuracy: 0.7396\n",
      "Epoch 429/5000\n",
      "11786/11786 [==============================] - 7s 619us/step - loss: 0.0652 - accuracy: 0.7672 - val_loss: 0.0736 - val_accuracy: 0.7353\n",
      "Epoch 430/5000\n",
      "11786/11786 [==============================] - 7s 616us/step - loss: 0.0652 - accuracy: 0.7671 - val_loss: 0.0732 - val_accuracy: 0.7391\n",
      "Epoch 431/5000\n",
      "11786/11786 [==============================] - 7s 622us/step - loss: 0.0652 - accuracy: 0.7677 - val_loss: 0.0733 - val_accuracy: 0.7385\n",
      "Epoch 432/5000\n",
      "11786/11786 [==============================] - 7s 620us/step - loss: 0.0651 - accuracy: 0.7675 - val_loss: 0.0732 - val_accuracy: 0.7384\n",
      "Epoch 433/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0653 - accuracy: 0.7674 - val_loss: 0.0731 - val_accuracy: 0.7392\n",
      "Epoch 434/5000\n",
      "11786/11786 [==============================] - 7s 617us/step - loss: 0.0652 - accuracy: 0.7670 - val_loss: 0.0733 - val_accuracy: 0.7385\n",
      "Epoch 435/5000\n",
      "11786/11786 [==============================] - 7s 613us/step - loss: 0.0653 - accuracy: 0.7670 - val_loss: 0.0733 - val_accuracy: 0.7378\n",
      "Epoch 436/5000\n",
      "11786/11786 [==============================] - 7s 612us/step - loss: 0.0652 - accuracy: 0.7674 - val_loss: 0.0733 - val_accuracy: 0.7393\n",
      "Epoch 437/5000\n",
      "11786/11786 [==============================] - 7s 612us/step - loss: 0.0653 - accuracy: 0.7669 - val_loss: 0.0732 - val_accuracy: 0.7386\n",
      "Epoch 438/5000\n",
      "11786/11786 [==============================] - 7s 617us/step - loss: 0.0653 - accuracy: 0.7671 - val_loss: 0.0739 - val_accuracy: 0.7384\n",
      "Epoch 439/5000\n",
      "11786/11786 [==============================] - 7s 617us/step - loss: 0.0652 - accuracy: 0.7673 - val_loss: 0.0734 - val_accuracy: 0.7376\n",
      "Epoch 440/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0652 - accuracy: 0.7670 - val_loss: 0.0733 - val_accuracy: 0.7384\n",
      "Epoch 441/5000\n",
      "11786/11786 [==============================] - 7s 619us/step - loss: 0.0652 - accuracy: 0.7675 - val_loss: 0.0744 - val_accuracy: 0.7337\n",
      "Epoch 442/5000\n",
      "11786/11786 [==============================] - 7s 609us/step - loss: 0.0651 - accuracy: 0.7677 - val_loss: 0.0737 - val_accuracy: 0.7376\n",
      "Epoch 443/5000\n",
      "11786/11786 [==============================] - 7s 618us/step - loss: 0.0651 - accuracy: 0.7673 - val_loss: 0.0727 - val_accuracy: 0.7398\n",
      "Epoch 444/5000\n",
      "11786/11786 [==============================] - 7s 619us/step - loss: 0.0651 - accuracy: 0.7679 - val_loss: 0.0739 - val_accuracy: 0.7362\n",
      "Epoch 445/5000\n",
      "11786/11786 [==============================] - 7s 613us/step - loss: 0.0652 - accuracy: 0.7671 - val_loss: 0.0731 - val_accuracy: 0.7363\n",
      "Epoch 446/5000\n",
      "11786/11786 [==============================] - 7s 611us/step - loss: 0.0652 - accuracy: 0.7673 - val_loss: 0.0736 - val_accuracy: 0.7378\n",
      "Epoch 447/5000\n",
      "11786/11786 [==============================] - 7s 613us/step - loss: 0.0651 - accuracy: 0.7679 - val_loss: 0.0734 - val_accuracy: 0.7396\n",
      "Epoch 448/5000\n",
      "11786/11786 [==============================] - 7s 621us/step - loss: 0.0652 - accuracy: 0.7672 - val_loss: 0.0744 - val_accuracy: 0.7346\n",
      "Epoch 449/5000\n",
      "11786/11786 [==============================] - 7s 615us/step - loss: 0.0651 - accuracy: 0.7677 - val_loss: 0.0732 - val_accuracy: 0.7386\n",
      "Epoch 450/5000\n",
      "11786/11786 [==============================] - 7s 620us/step - loss: 0.0651 - accuracy: 0.7676 - val_loss: 0.0738 - val_accuracy: 0.7353\n",
      "Epoch 451/5000\n",
      "11786/11786 [==============================] - 7s 610us/step - loss: 0.0652 - accuracy: 0.7675 - val_loss: 0.0731 - val_accuracy: 0.7399\n",
      "Epoch 452/5000\n",
      "11786/11786 [==============================] - 7s 620us/step - loss: 0.0652 - accuracy: 0.7677 - val_loss: 0.0731 - val_accuracy: 0.7383\n",
      "Epoch 453/5000\n",
      "11786/11786 [==============================] - 7s 621us/step - loss: 0.0651 - accuracy: 0.7677 - val_loss: 0.0739 - val_accuracy: 0.7387\n",
      "Epoch 454/5000\n",
      "11786/11786 [==============================] - 7s 619us/step - loss: 0.0651 - accuracy: 0.7676 - val_loss: 0.0736 - val_accuracy: 0.7367\n",
      "Epoch 455/5000\n",
      "11786/11786 [==============================] - 7s 609us/step - loss: 0.0652 - accuracy: 0.7676 - val_loss: 0.0736 - val_accuracy: 0.7389\n",
      "Epoch 456/5000\n",
      "11786/11786 [==============================] - 7s 611us/step - loss: 0.0650 - accuracy: 0.7683 - val_loss: 0.0734 - val_accuracy: 0.7386\n",
      "Epoch 457/5000\n",
      "11786/11786 [==============================] - 7s 603us/step - loss: 0.0651 - accuracy: 0.7676 - val_loss: 0.0735 - val_accuracy: 0.7372\n",
      "Epoch 458/5000\n",
      "11786/11786 [==============================] - 7s 620us/step - loss: 0.0651 - accuracy: 0.7681 - val_loss: 0.0734 - val_accuracy: 0.7387\n",
      "Epoch 459/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0653 - accuracy: 0.7673 - val_loss: 0.0735 - val_accuracy: 0.7368\n",
      "Epoch 460/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0651 - accuracy: 0.7679 - val_loss: 0.0742 - val_accuracy: 0.7336\n",
      "Epoch 461/5000\n",
      "11786/11786 [==============================] - 7s 622us/step - loss: 0.0651 - accuracy: 0.7684 - val_loss: 0.0736 - val_accuracy: 0.7376\n",
      "Epoch 462/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0651 - accuracy: 0.7679 - val_loss: 0.0742 - val_accuracy: 0.7362\n",
      "Epoch 463/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0652 - accuracy: 0.7677 - val_loss: 0.0741 - val_accuracy: 0.7358\n",
      "Epoch 464/5000\n",
      "11786/11786 [==============================] - 7s 618us/step - loss: 0.0650 - accuracy: 0.7681 - val_loss: 0.0730 - val_accuracy: 0.7394\n",
      "Epoch 465/5000\n",
      "11786/11786 [==============================] - 7s 617us/step - loss: 0.0651 - accuracy: 0.7681 - val_loss: 0.0740 - val_accuracy: 0.7344\n",
      "Epoch 466/5000\n",
      "11786/11786 [==============================] - 7s 620us/step - loss: 0.0652 - accuracy: 0.7676 - val_loss: 0.0740 - val_accuracy: 0.7371\n",
      "Epoch 467/5000\n",
      "11786/11786 [==============================] - 7s 611us/step - loss: 0.0651 - accuracy: 0.7685 - val_loss: 0.0738 - val_accuracy: 0.7375\n",
      "Epoch 468/5000\n",
      "11786/11786 [==============================] - 7s 606us/step - loss: 0.0651 - accuracy: 0.7676 - val_loss: 0.0737 - val_accuracy: 0.7381\n",
      "Epoch 469/5000\n",
      "11786/11786 [==============================] - 7s 611us/step - loss: 0.0651 - accuracy: 0.7681 - val_loss: 0.0729 - val_accuracy: 0.7392\n",
      "Epoch 470/5000\n",
      "11786/11786 [==============================] - 7s 615us/step - loss: 0.0652 - accuracy: 0.7676 - val_loss: 0.0734 - val_accuracy: 0.7387\n",
      "Epoch 471/5000\n",
      "11786/11786 [==============================] - 7s 605us/step - loss: 0.0651 - accuracy: 0.7681 - val_loss: 0.0738 - val_accuracy: 0.7393\n",
      "Epoch 472/5000\n",
      "11786/11786 [==============================] - 7s 608us/step - loss: 0.0652 - accuracy: 0.7676 - val_loss: 0.0731 - val_accuracy: 0.7387\n",
      "Epoch 473/5000\n",
      "11786/11786 [==============================] - 7s 613us/step - loss: 0.0652 - accuracy: 0.7678 - val_loss: 0.0733 - val_accuracy: 0.7407\n",
      "Epoch 474/5000\n",
      "11786/11786 [==============================] - 7s 609us/step - loss: 0.0650 - accuracy: 0.7685 - val_loss: 0.0732 - val_accuracy: 0.7406\n",
      "Epoch 475/5000\n",
      "11786/11786 [==============================] - 7s 607us/step - loss: 0.0652 - accuracy: 0.7676 - val_loss: 0.0731 - val_accuracy: 0.7390\n",
      "Epoch 476/5000\n",
      "11786/11786 [==============================] - 7s 609us/step - loss: 0.0651 - accuracy: 0.7683 - val_loss: 0.0732 - val_accuracy: 0.7381\n",
      "Epoch 477/5000\n",
      "11786/11786 [==============================] - 7s 612us/step - loss: 0.0650 - accuracy: 0.7687 - val_loss: 0.0743 - val_accuracy: 0.7354\n",
      "Epoch 478/5000\n",
      "11786/11786 [==============================] - 7s 604us/step - loss: 0.0652 - accuracy: 0.7676 - val_loss: 0.0732 - val_accuracy: 0.7392\n",
      "Epoch 479/5000\n",
      "11786/11786 [==============================] - 7s 608us/step - loss: 0.0651 - accuracy: 0.7677 - val_loss: 0.0731 - val_accuracy: 0.7384\n",
      "Epoch 480/5000\n",
      "11786/11786 [==============================] - 7s 605us/step - loss: 0.0650 - accuracy: 0.7680 - val_loss: 0.0736 - val_accuracy: 0.7372\n",
      "Epoch 481/5000\n",
      "11786/11786 [==============================] - 7s 602us/step - loss: 0.0651 - accuracy: 0.7679 - val_loss: 0.0734 - val_accuracy: 0.7387\n",
      "Epoch 482/5000\n",
      "11786/11786 [==============================] - 7s 605us/step - loss: 0.0651 - accuracy: 0.7674 - val_loss: 0.0733 - val_accuracy: 0.7386\n",
      "Epoch 483/5000\n",
      "11786/11786 [==============================] - 7s 609us/step - loss: 0.0651 - accuracy: 0.7682 - val_loss: 0.0738 - val_accuracy: 0.7373\n",
      "Epoch 484/5000\n",
      "11786/11786 [==============================] - 7s 616us/step - loss: 0.0651 - accuracy: 0.7681 - val_loss: 0.0736 - val_accuracy: 0.7377\n",
      "Epoch 485/5000\n",
      "11786/11786 [==============================] - 7s 608us/step - loss: 0.0651 - accuracy: 0.7683 - val_loss: 0.0731 - val_accuracy: 0.7386\n",
      "Epoch 486/5000\n",
      "11786/11786 [==============================] - 7s 615us/step - loss: 0.0651 - accuracy: 0.7681 - val_loss: 0.0742 - val_accuracy: 0.7361\n",
      "Epoch 487/5000\n",
      "11786/11786 [==============================] - 7s 623us/step - loss: 0.0651 - accuracy: 0.7679 - val_loss: 0.0736 - val_accuracy: 0.7364\n",
      "Epoch 488/5000\n",
      "11786/11786 [==============================] - 7s 602us/step - loss: 0.0651 - accuracy: 0.7676 - val_loss: 0.0743 - val_accuracy: 0.7331\n",
      "Epoch 489/5000\n",
      "11786/11786 [==============================] - 7s 609us/step - loss: 0.0651 - accuracy: 0.7679 - val_loss: 0.0737 - val_accuracy: 0.7384\n",
      "Epoch 490/5000\n",
      "11786/11786 [==============================] - 7s 610us/step - loss: 0.0652 - accuracy: 0.7674 - val_loss: 0.0744 - val_accuracy: 0.7352\n",
      "Epoch 491/5000\n",
      "11786/11786 [==============================] - 7s 613us/step - loss: 0.0651 - accuracy: 0.7685 - val_loss: 0.0735 - val_accuracy: 0.7392\n",
      "Epoch 492/5000\n",
      "11786/11786 [==============================] - 7s 600us/step - loss: 0.0652 - accuracy: 0.7678 - val_loss: 0.0740 - val_accuracy: 0.7367\n",
      "Epoch 493/5000\n",
      "11786/11786 [==============================] - 7s 600us/step - loss: 0.0650 - accuracy: 0.7686 - val_loss: 0.0733 - val_accuracy: 0.7403\n",
      "Epoch 494/5000\n",
      "11786/11786 [==============================] - 7s 616us/step - loss: 0.0651 - accuracy: 0.7678 - val_loss: 0.0738 - val_accuracy: 0.7374\n",
      "Epoch 495/5000\n",
      "11786/11786 [==============================] - 7s 611us/step - loss: 0.0650 - accuracy: 0.7684 - val_loss: 0.0735 - val_accuracy: 0.7369\n",
      "Epoch 496/5000\n",
      "11786/11786 [==============================] - 7s 614us/step - loss: 0.0650 - accuracy: 0.7678 - val_loss: 0.0735 - val_accuracy: 0.7378\n",
      "Epoch 497/5000\n",
      "11786/11786 [==============================] - 7s 615us/step - loss: 0.0651 - accuracy: 0.7682 - val_loss: 0.0733 - val_accuracy: 0.7381\n",
      "Epoch 498/5000\n",
      "11786/11786 [==============================] - 7s 606us/step - loss: 0.0650 - accuracy: 0.7680 - val_loss: 0.0749 - val_accuracy: 0.7320\n",
      "Epoch 499/5000\n",
      "11786/11786 [==============================] - 7s 607us/step - loss: 0.0650 - accuracy: 0.7678 - val_loss: 0.0735 - val_accuracy: 0.7394\n",
      "Epoch 500/5000\n",
      "11786/11786 [==============================] - 7s 610us/step - loss: 0.0650 - accuracy: 0.7683 - val_loss: 0.0737 - val_accuracy: 0.7382\n",
      "Epoch 501/5000\n",
      "11786/11786 [==============================] - 7s 622us/step - loss: 0.0651 - accuracy: 0.7682 - val_loss: 0.0732 - val_accuracy: 0.7405\n",
      "Epoch 502/5000\n",
      "11786/11786 [==============================] - 7s 615us/step - loss: 0.0651 - accuracy: 0.7680 - val_loss: 0.0732 - val_accuracy: 0.7395\n",
      "Epoch 503/5000\n",
      "11786/11786 [==============================] - 7s 619us/step - loss: 0.0651 - accuracy: 0.7680 - val_loss: 0.0744 - val_accuracy: 0.7362\n",
      "Epoch 504/5000\n",
      "11786/11786 [==============================] - 7s 615us/step - loss: 0.0651 - accuracy: 0.7679 - val_loss: 0.0735 - val_accuracy: 0.7388\n",
      "Epoch 505/5000\n",
      "11786/11786 [==============================] - 7s 614us/step - loss: 0.0651 - accuracy: 0.7682 - val_loss: 0.0735 - val_accuracy: 0.7386\n",
      "Epoch 506/5000\n",
      "11786/11786 [==============================] - 7s 612us/step - loss: 0.0651 - accuracy: 0.7684 - val_loss: 0.0738 - val_accuracy: 0.7382\n",
      "Epoch 507/5000\n",
      "11786/11786 [==============================] - 7s 618us/step - loss: 0.0650 - accuracy: 0.7683 - val_loss: 0.0736 - val_accuracy: 0.7381\n",
      "Epoch 508/5000\n",
      "11786/11786 [==============================] - 7s 609us/step - loss: 0.0650 - accuracy: 0.7684 - val_loss: 0.0735 - val_accuracy: 0.7386\n",
      "Epoch 509/5000\n",
      "11786/11786 [==============================] - 7s 613us/step - loss: 0.0651 - accuracy: 0.7687 - val_loss: 0.0739 - val_accuracy: 0.7352\n",
      "Epoch 510/5000\n",
      "11786/11786 [==============================] - 7s 621us/step - loss: 0.0652 - accuracy: 0.7679 - val_loss: 0.0738 - val_accuracy: 0.7370\n",
      "Epoch 511/5000\n",
      "11786/11786 [==============================] - 7s 609us/step - loss: 0.0651 - accuracy: 0.7679 - val_loss: 0.0742 - val_accuracy: 0.7359\n",
      "Epoch 512/5000\n",
      "11786/11786 [==============================] - 7s 619us/step - loss: 0.0651 - accuracy: 0.7681 - val_loss: 0.0733 - val_accuracy: 0.7382\n",
      "Epoch 513/5000\n",
      "11786/11786 [==============================] - 7s 608us/step - loss: 0.0651 - accuracy: 0.7681 - val_loss: 0.0739 - val_accuracy: 0.7371\n",
      "Epoch 514/5000\n",
      "11786/11786 [==============================] - 7s 609us/step - loss: 0.0651 - accuracy: 0.7681 - val_loss: 0.0731 - val_accuracy: 0.7389\n",
      "Epoch 515/5000\n",
      "11786/11786 [==============================] - 7s 610us/step - loss: 0.0651 - accuracy: 0.7679 - val_loss: 0.0739 - val_accuracy: 0.7365\n",
      "Epoch 516/5000\n",
      "11786/11786 [==============================] - 7s 598us/step - loss: 0.0652 - accuracy: 0.7678 - val_loss: 0.0734 - val_accuracy: 0.7372\n",
      "Epoch 517/5000\n",
      "11786/11786 [==============================] - 7s 605us/step - loss: 0.0651 - accuracy: 0.7680 - val_loss: 0.0732 - val_accuracy: 0.7392\n",
      "Epoch 518/5000\n",
      "11786/11786 [==============================] - 7s 609us/step - loss: 0.0651 - accuracy: 0.7681 - val_loss: 0.0739 - val_accuracy: 0.7377\n",
      "Epoch 519/5000\n",
      "11786/11786 [==============================] - 7s 619us/step - loss: 0.0651 - accuracy: 0.7683 - val_loss: 0.0727 - val_accuracy: 0.7408\n",
      "Epoch 520/5000\n",
      "11786/11786 [==============================] - 7s 611us/step - loss: 0.0650 - accuracy: 0.7685 - val_loss: 0.0743 - val_accuracy: 0.7353\n",
      "Epoch 521/5000\n",
      "11786/11786 [==============================] - 7s 604us/step - loss: 0.0650 - accuracy: 0.7684 - val_loss: 0.0734 - val_accuracy: 0.7372\n",
      "Epoch 522/5000\n",
      "11786/11786 [==============================] - 7s 606us/step - loss: 0.0650 - accuracy: 0.7684 - val_loss: 0.0736 - val_accuracy: 0.7377\n",
      "Epoch 523/5000\n",
      "11786/11786 [==============================] - 7s 616us/step - loss: 0.0651 - accuracy: 0.7682 - val_loss: 0.0735 - val_accuracy: 0.7383\n",
      "Epoch 524/5000\n",
      "11786/11786 [==============================] - 7s 607us/step - loss: 0.0651 - accuracy: 0.7684 - val_loss: 0.0739 - val_accuracy: 0.7364\n",
      "Epoch 525/5000\n",
      "11786/11786 [==============================] - 7s 613us/step - loss: 0.0651 - accuracy: 0.7683 - val_loss: 0.0739 - val_accuracy: 0.7348\n",
      "Epoch 526/5000\n",
      "11786/11786 [==============================] - 7s 615us/step - loss: 0.0650 - accuracy: 0.7683 - val_loss: 0.0739 - val_accuracy: 0.7361\n",
      "Epoch 527/5000\n",
      "11786/11786 [==============================] - 7s 620us/step - loss: 0.0650 - accuracy: 0.7684 - val_loss: 0.0732 - val_accuracy: 0.7383\n",
      "Epoch 528/5000\n",
      "11786/11786 [==============================] - 7s 608us/step - loss: 0.0651 - accuracy: 0.7677 - val_loss: 0.0731 - val_accuracy: 0.7394\n",
      "Epoch 529/5000\n",
      "11786/11786 [==============================] - 7s 622us/step - loss: 0.0650 - accuracy: 0.7688 - val_loss: 0.0739 - val_accuracy: 0.7353\n",
      "Epoch 530/5000\n",
      "11786/11786 [==============================] - 7s 615us/step - loss: 0.0649 - accuracy: 0.7691 - val_loss: 0.0742 - val_accuracy: 0.7352\n",
      "Epoch 531/5000\n",
      "11786/11786 [==============================] - 7s 617us/step - loss: 0.0650 - accuracy: 0.7683 - val_loss: 0.0734 - val_accuracy: 0.7393\n",
      "Epoch 532/5000\n",
      "11786/11786 [==============================] - 7s 615us/step - loss: 0.0649 - accuracy: 0.7683 - val_loss: 0.0741 - val_accuracy: 0.7375\n",
      "Epoch 533/5000\n",
      "11786/11786 [==============================] - 7s 605us/step - loss: 0.0649 - accuracy: 0.7689 - val_loss: 0.0736 - val_accuracy: 0.7373\n",
      "Epoch 534/5000\n",
      "11786/11786 [==============================] - 7s 614us/step - loss: 0.0649 - accuracy: 0.7688 - val_loss: 0.0732 - val_accuracy: 0.7399\n",
      "Epoch 535/5000\n",
      "11786/11786 [==============================] - 7s 622us/step - loss: 0.0650 - accuracy: 0.7685 - val_loss: 0.0731 - val_accuracy: 0.7388\n",
      "Epoch 536/5000\n",
      "11786/11786 [==============================] - 7s 620us/step - loss: 0.0650 - accuracy: 0.7685 - val_loss: 0.0744 - val_accuracy: 0.7339\n",
      "Epoch 537/5000\n",
      "11786/11786 [==============================] - 7s 615us/step - loss: 0.0649 - accuracy: 0.7691 - val_loss: 0.0732 - val_accuracy: 0.7380\n",
      "Epoch 538/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0650 - accuracy: 0.7684 - val_loss: 0.0750 - val_accuracy: 0.7295\n",
      "Epoch 539/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0651 - accuracy: 0.7681 - val_loss: 0.0740 - val_accuracy: 0.7358\n",
      "Epoch 540/5000\n",
      "11786/11786 [==============================] - 7s 617us/step - loss: 0.0651 - accuracy: 0.7683 - val_loss: 0.0734 - val_accuracy: 0.7383\n",
      "Epoch 541/5000\n",
      "11786/11786 [==============================] - 7s 615us/step - loss: 0.0650 - accuracy: 0.7689 - val_loss: 0.0735 - val_accuracy: 0.7388\n",
      "Epoch 542/5000\n",
      "11786/11786 [==============================] - 7s 620us/step - loss: 0.0650 - accuracy: 0.7680 - val_loss: 0.0744 - val_accuracy: 0.7367\n",
      "Epoch 543/5000\n",
      "11786/11786 [==============================] - 7s 619us/step - loss: 0.0650 - accuracy: 0.7683 - val_loss: 0.0738 - val_accuracy: 0.7356\n",
      "Epoch 544/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0650 - accuracy: 0.7684 - val_loss: 0.0733 - val_accuracy: 0.7388\n",
      "Epoch 545/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0650 - accuracy: 0.7682 - val_loss: 0.0741 - val_accuracy: 0.7368\n",
      "Epoch 546/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0649 - accuracy: 0.7684 - val_loss: 0.0736 - val_accuracy: 0.7387\n",
      "Epoch 547/5000\n",
      "11786/11786 [==============================] - 7s 618us/step - loss: 0.0649 - accuracy: 0.7684 - val_loss: 0.0737 - val_accuracy: 0.7394\n",
      "Epoch 548/5000\n",
      "11786/11786 [==============================] - 7s 617us/step - loss: 0.0649 - accuracy: 0.7685 - val_loss: 0.0735 - val_accuracy: 0.7392\n",
      "Epoch 549/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0649 - accuracy: 0.7691 - val_loss: 0.0735 - val_accuracy: 0.7394\n",
      "Epoch 550/5000\n",
      "11786/11786 [==============================] - 7s 618us/step - loss: 0.0650 - accuracy: 0.7688 - val_loss: 0.0740 - val_accuracy: 0.7373\n",
      "Epoch 551/5000\n",
      "11786/11786 [==============================] - 7s 617us/step - loss: 0.0650 - accuracy: 0.7686 - val_loss: 0.0742 - val_accuracy: 0.7365\n",
      "Epoch 552/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0649 - accuracy: 0.7690 - val_loss: 0.0734 - val_accuracy: 0.7379\n",
      "Epoch 553/5000\n",
      "11786/11786 [==============================] - 7s 623us/step - loss: 0.0649 - accuracy: 0.7687 - val_loss: 0.0733 - val_accuracy: 0.7386\n",
      "Epoch 554/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0650 - accuracy: 0.7686 - val_loss: 0.0733 - val_accuracy: 0.7393\n",
      "Epoch 555/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0649 - accuracy: 0.7687 - val_loss: 0.0738 - val_accuracy: 0.7373\n",
      "Epoch 556/5000\n",
      "11786/11786 [==============================] - 7s 622us/step - loss: 0.0650 - accuracy: 0.7685 - val_loss: 0.0735 - val_accuracy: 0.7382\n",
      "Epoch 557/5000\n",
      "11786/11786 [==============================] - 7s 618us/step - loss: 0.0649 - accuracy: 0.7686 - val_loss: 0.0733 - val_accuracy: 0.7385\n",
      "Epoch 558/5000\n",
      "11786/11786 [==============================] - 7s 621us/step - loss: 0.0650 - accuracy: 0.7684 - val_loss: 0.0741 - val_accuracy: 0.7366\n",
      "Epoch 559/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0649 - accuracy: 0.7685 - val_loss: 0.0740 - val_accuracy: 0.7384\n",
      "Epoch 560/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0650 - accuracy: 0.7690 - val_loss: 0.0734 - val_accuracy: 0.7399\n",
      "Epoch 561/5000\n",
      "11786/11786 [==============================] - 7s 620us/step - loss: 0.0649 - accuracy: 0.7689 - val_loss: 0.0733 - val_accuracy: 0.7403\n",
      "Epoch 562/5000\n",
      "11786/11786 [==============================] - 7s 617us/step - loss: 0.0650 - accuracy: 0.7685 - val_loss: 0.0732 - val_accuracy: 0.7387\n",
      "Epoch 563/5000\n",
      "11786/11786 [==============================] - 7s 620us/step - loss: 0.0650 - accuracy: 0.7685 - val_loss: 0.0735 - val_accuracy: 0.7380\n",
      "Epoch 564/5000\n",
      "11786/11786 [==============================] - 7s 616us/step - loss: 0.0649 - accuracy: 0.7690 - val_loss: 0.0734 - val_accuracy: 0.7385\n",
      "Epoch 565/5000\n",
      "11786/11786 [==============================] - 7s 616us/step - loss: 0.0649 - accuracy: 0.7684 - val_loss: 0.0746 - val_accuracy: 0.7348\n",
      "Epoch 566/5000\n",
      "11786/11786 [==============================] - 7s 617us/step - loss: 0.0649 - accuracy: 0.7687 - val_loss: 0.0736 - val_accuracy: 0.7371\n",
      "Epoch 567/5000\n",
      "11786/11786 [==============================] - 7s 616us/step - loss: 0.0649 - accuracy: 0.7693 - val_loss: 0.0735 - val_accuracy: 0.7364\n",
      "Epoch 568/5000\n",
      "11786/11786 [==============================] - 7s 617us/step - loss: 0.0649 - accuracy: 0.7687 - val_loss: 0.0737 - val_accuracy: 0.7371\n",
      "Epoch 569/5000\n",
      "11786/11786 [==============================] - 7s 613us/step - loss: 0.0649 - accuracy: 0.7684 - val_loss: 0.0736 - val_accuracy: 0.7358\n",
      "Epoch 570/5000\n",
      "11786/11786 [==============================] - 7s 617us/step - loss: 0.0649 - accuracy: 0.7691 - val_loss: 0.0736 - val_accuracy: 0.7380\n",
      "Epoch 571/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0649 - accuracy: 0.7687 - val_loss: 0.0732 - val_accuracy: 0.7396\n",
      "Epoch 572/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0649 - accuracy: 0.7687 - val_loss: 0.0732 - val_accuracy: 0.7379\n",
      "Epoch 573/5000\n",
      "11786/11786 [==============================] - 7s 621us/step - loss: 0.0650 - accuracy: 0.7682 - val_loss: 0.0737 - val_accuracy: 0.7386\n",
      "Epoch 574/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0650 - accuracy: 0.7688 - val_loss: 0.0734 - val_accuracy: 0.7391\n",
      "Epoch 575/5000\n",
      "11786/11786 [==============================] - 7s 619us/step - loss: 0.0648 - accuracy: 0.7688 - val_loss: 0.0745 - val_accuracy: 0.7360\n",
      "Epoch 576/5000\n",
      "11786/11786 [==============================] - 7s 614us/step - loss: 0.0649 - accuracy: 0.7687 - val_loss: 0.0735 - val_accuracy: 0.7379\n",
      "Epoch 577/5000\n",
      "11786/11786 [==============================] - 7s 621us/step - loss: 0.0648 - accuracy: 0.7693 - val_loss: 0.0733 - val_accuracy: 0.7376\n",
      "Epoch 578/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0648 - accuracy: 0.7691 - val_loss: 0.0733 - val_accuracy: 0.7392\n",
      "Epoch 579/5000\n",
      "11786/11786 [==============================] - 7s 612us/step - loss: 0.0648 - accuracy: 0.7698 - val_loss: 0.0733 - val_accuracy: 0.7395\n",
      "Epoch 580/5000\n",
      "11786/11786 [==============================] - 7s 615us/step - loss: 0.0649 - accuracy: 0.7687 - val_loss: 0.0735 - val_accuracy: 0.7390\n",
      "Epoch 581/5000\n",
      "11786/11786 [==============================] - 7s 622us/step - loss: 0.0649 - accuracy: 0.7691 - val_loss: 0.0733 - val_accuracy: 0.7379\n",
      "Epoch 582/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0648 - accuracy: 0.7686 - val_loss: 0.0735 - val_accuracy: 0.7390\n",
      "Epoch 583/5000\n",
      "11786/11786 [==============================] - 7s 610us/step - loss: 0.0649 - accuracy: 0.7686 - val_loss: 0.0738 - val_accuracy: 0.7382\n",
      "Epoch 584/5000\n",
      "11786/11786 [==============================] - 7s 617us/step - loss: 0.0649 - accuracy: 0.7690 - val_loss: 0.0734 - val_accuracy: 0.7386\n",
      "Epoch 585/5000\n",
      "11786/11786 [==============================] - 7s 621us/step - loss: 0.0648 - accuracy: 0.7693 - val_loss: 0.0739 - val_accuracy: 0.7375\n",
      "Epoch 586/5000\n",
      "11786/11786 [==============================] - 7s 617us/step - loss: 0.0648 - accuracy: 0.7694 - val_loss: 0.0739 - val_accuracy: 0.7365\n",
      "Epoch 587/5000\n",
      "11786/11786 [==============================] - 7s 619us/step - loss: 0.0649 - accuracy: 0.7692 - val_loss: 0.0741 - val_accuracy: 0.7346\n",
      "Epoch 588/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0648 - accuracy: 0.7688 - val_loss: 0.0736 - val_accuracy: 0.7390\n",
      "Epoch 589/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0648 - accuracy: 0.7695 - val_loss: 0.0734 - val_accuracy: 0.7387\n",
      "Epoch 590/5000\n",
      "11786/11786 [==============================] - 7s 622us/step - loss: 0.0649 - accuracy: 0.7691 - val_loss: 0.0732 - val_accuracy: 0.7384\n",
      "Epoch 591/5000\n",
      "11786/11786 [==============================] - 7s 617us/step - loss: 0.0648 - accuracy: 0.7692 - val_loss: 0.0739 - val_accuracy: 0.7388\n",
      "Epoch 592/5000\n",
      "11786/11786 [==============================] - 7s 616us/step - loss: 0.0649 - accuracy: 0.7690 - val_loss: 0.0731 - val_accuracy: 0.7403\n",
      "Epoch 593/5000\n",
      "11786/11786 [==============================] - 7s 623us/step - loss: 0.0648 - accuracy: 0.7691 - val_loss: 0.0737 - val_accuracy: 0.7378\n",
      "Epoch 594/5000\n",
      "11786/11786 [==============================] - 7s 614us/step - loss: 0.0648 - accuracy: 0.7693 - val_loss: 0.0735 - val_accuracy: 0.7402\n",
      "Epoch 595/5000\n",
      "11786/11786 [==============================] - 7s 617us/step - loss: 0.0649 - accuracy: 0.7692 - val_loss: 0.0734 - val_accuracy: 0.7391\n",
      "Epoch 596/5000\n",
      "11786/11786 [==============================] - 7s 615us/step - loss: 0.0648 - accuracy: 0.7689 - val_loss: 0.0734 - val_accuracy: 0.7399\n",
      "Epoch 597/5000\n",
      "11786/11786 [==============================] - 7s 616us/step - loss: 0.0648 - accuracy: 0.7692 - val_loss: 0.0742 - val_accuracy: 0.7366\n",
      "Epoch 598/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0647 - accuracy: 0.7697 - val_loss: 0.0737 - val_accuracy: 0.7386\n",
      "Epoch 599/5000\n",
      "11786/11786 [==============================] - 7s 613us/step - loss: 0.0649 - accuracy: 0.7695 - val_loss: 0.0732 - val_accuracy: 0.7375\n",
      "Epoch 600/5000\n",
      "11786/11786 [==============================] - 7s 617us/step - loss: 0.0649 - accuracy: 0.7690 - val_loss: 0.0734 - val_accuracy: 0.7380\n",
      "Epoch 601/5000\n",
      "11786/11786 [==============================] - 7s 615us/step - loss: 0.0647 - accuracy: 0.7696 - val_loss: 0.0733 - val_accuracy: 0.7385\n",
      "Epoch 602/5000\n",
      "11786/11786 [==============================] - 7s 614us/step - loss: 0.0648 - accuracy: 0.7698 - val_loss: 0.0733 - val_accuracy: 0.7399\n",
      "Epoch 603/5000\n",
      "11786/11786 [==============================] - 7s 616us/step - loss: 0.0648 - accuracy: 0.7698 - val_loss: 0.0731 - val_accuracy: 0.7398\n",
      "Epoch 604/5000\n",
      "11786/11786 [==============================] - 7s 619us/step - loss: 0.0648 - accuracy: 0.7697 - val_loss: 0.0735 - val_accuracy: 0.7383\n",
      "Epoch 605/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0648 - accuracy: 0.7697 - val_loss: 0.0738 - val_accuracy: 0.7390\n",
      "Epoch 606/5000\n",
      "11786/11786 [==============================] - 7s 623us/step - loss: 0.0648 - accuracy: 0.7696 - val_loss: 0.0739 - val_accuracy: 0.7392\n",
      "Epoch 607/5000\n",
      "11786/11786 [==============================] - 7s 614us/step - loss: 0.0648 - accuracy: 0.7693 - val_loss: 0.0739 - val_accuracy: 0.7376\n",
      "Epoch 608/5000\n",
      "11786/11786 [==============================] - 7s 614us/step - loss: 0.0649 - accuracy: 0.7694 - val_loss: 0.0739 - val_accuracy: 0.7379\n",
      "Epoch 609/5000\n",
      "11786/11786 [==============================] - 7s 621us/step - loss: 0.0648 - accuracy: 0.7693 - val_loss: 0.0738 - val_accuracy: 0.7390\n",
      "Epoch 610/5000\n",
      "11786/11786 [==============================] - 7s 610us/step - loss: 0.0649 - accuracy: 0.7694 - val_loss: 0.0737 - val_accuracy: 0.7368\n",
      "Epoch 611/5000\n",
      "11786/11786 [==============================] - 7s 619us/step - loss: 0.0648 - accuracy: 0.7690 - val_loss: 0.0736 - val_accuracy: 0.7387\n",
      "Epoch 612/5000\n",
      "11786/11786 [==============================] - 7s 620us/step - loss: 0.0648 - accuracy: 0.7694 - val_loss: 0.0736 - val_accuracy: 0.7388\n",
      "Epoch 613/5000\n",
      "11786/11786 [==============================] - 7s 616us/step - loss: 0.0648 - accuracy: 0.7694 - val_loss: 0.0735 - val_accuracy: 0.7393\n",
      "Epoch 614/5000\n",
      "11786/11786 [==============================] - 7s 609us/step - loss: 0.0648 - accuracy: 0.7694 - val_loss: 0.0731 - val_accuracy: 0.7397\n",
      "Epoch 615/5000\n",
      "11786/11786 [==============================] - 7s 619us/step - loss: 0.0648 - accuracy: 0.7693 - val_loss: 0.0739 - val_accuracy: 0.7369\n",
      "Epoch 616/5000\n",
      "11786/11786 [==============================] - 7s 618us/step - loss: 0.0649 - accuracy: 0.7696 - val_loss: 0.0734 - val_accuracy: 0.7391\n",
      "Epoch 617/5000\n",
      "11786/11786 [==============================] - 7s 621us/step - loss: 0.0649 - accuracy: 0.7691 - val_loss: 0.0736 - val_accuracy: 0.7391\n",
      "Epoch 618/5000\n",
      "11786/11786 [==============================] - 7s 619us/step - loss: 0.0648 - accuracy: 0.7695 - val_loss: 0.0734 - val_accuracy: 0.7391\n",
      "Epoch 619/5000\n",
      "11786/11786 [==============================] - 7s 610us/step - loss: 0.0648 - accuracy: 0.7697 - val_loss: 0.0735 - val_accuracy: 0.7380\n",
      "Epoch 620/5000\n",
      "11786/11786 [==============================] - 7s 610us/step - loss: 0.0648 - accuracy: 0.7696 - val_loss: 0.0733 - val_accuracy: 0.7400\n",
      "Epoch 621/5000\n",
      "11786/11786 [==============================] - 7s 616us/step - loss: 0.0649 - accuracy: 0.7692 - val_loss: 0.0741 - val_accuracy: 0.7377\n",
      "Epoch 622/5000\n",
      "11786/11786 [==============================] - 7s 615us/step - loss: 0.0648 - accuracy: 0.7699 - val_loss: 0.0734 - val_accuracy: 0.7382\n",
      "Epoch 623/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0648 - accuracy: 0.7694 - val_loss: 0.0734 - val_accuracy: 0.7402\n",
      "Epoch 624/5000\n",
      "11786/11786 [==============================] - 7s 619us/step - loss: 0.0647 - accuracy: 0.7697 - val_loss: 0.0738 - val_accuracy: 0.7365\n",
      "Epoch 625/5000\n",
      "11786/11786 [==============================] - 7s 616us/step - loss: 0.0647 - accuracy: 0.7694 - val_loss: 0.0735 - val_accuracy: 0.7394\n",
      "Epoch 626/5000\n",
      "11786/11786 [==============================] - 7s 622us/step - loss: 0.0647 - accuracy: 0.7701 - val_loss: 0.0735 - val_accuracy: 0.7381\n",
      "Epoch 627/5000\n",
      "11786/11786 [==============================] - 7s 620us/step - loss: 0.0648 - accuracy: 0.7693 - val_loss: 0.0741 - val_accuracy: 0.7379\n",
      "Epoch 628/5000\n",
      "11786/11786 [==============================] - 7s 613us/step - loss: 0.0648 - accuracy: 0.7693 - val_loss: 0.0739 - val_accuracy: 0.7376\n",
      "Epoch 629/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0649 - accuracy: 0.7691 - val_loss: 0.0735 - val_accuracy: 0.7398\n",
      "Epoch 630/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0648 - accuracy: 0.7694 - val_loss: 0.0737 - val_accuracy: 0.7384\n",
      "Epoch 631/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0648 - accuracy: 0.7692 - val_loss: 0.0732 - val_accuracy: 0.7415\n",
      "Epoch 632/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0647 - accuracy: 0.7699 - val_loss: 0.0739 - val_accuracy: 0.7376\n",
      "Epoch 633/5000\n",
      "11786/11786 [==============================] - 7s 619us/step - loss: 0.0648 - accuracy: 0.7692 - val_loss: 0.0732 - val_accuracy: 0.7385\n",
      "Epoch 634/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0648 - accuracy: 0.7695 - val_loss: 0.0731 - val_accuracy: 0.7394\n",
      "Epoch 635/5000\n",
      "11786/11786 [==============================] - 7s 620us/step - loss: 0.0648 - accuracy: 0.7699 - val_loss: 0.0733 - val_accuracy: 0.7396\n",
      "Epoch 636/5000\n",
      "11786/11786 [==============================] - 7s 620us/step - loss: 0.0647 - accuracy: 0.7700 - val_loss: 0.0734 - val_accuracy: 0.7391\n",
      "Epoch 637/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0646 - accuracy: 0.7704 - val_loss: 0.0739 - val_accuracy: 0.7385\n",
      "Epoch 638/5000\n",
      "11786/11786 [==============================] - 7s 618us/step - loss: 0.0647 - accuracy: 0.7695 - val_loss: 0.0737 - val_accuracy: 0.7375\n",
      "Epoch 639/5000\n",
      "11786/11786 [==============================] - 7s 611us/step - loss: 0.0648 - accuracy: 0.7697 - val_loss: 0.0738 - val_accuracy: 0.7405\n",
      "Epoch 640/5000\n",
      "11786/11786 [==============================] - 7s 623us/step - loss: 0.0649 - accuracy: 0.7692 - val_loss: 0.0741 - val_accuracy: 0.7342\n",
      "Epoch 641/5000\n",
      "11786/11786 [==============================] - 7s 618us/step - loss: 0.0647 - accuracy: 0.7694 - val_loss: 0.0738 - val_accuracy: 0.7383\n",
      "Epoch 642/5000\n",
      "11786/11786 [==============================] - 7s 617us/step - loss: 0.0647 - accuracy: 0.7700 - val_loss: 0.0737 - val_accuracy: 0.7377\n",
      "Epoch 643/5000\n",
      "11786/11786 [==============================] - 7s 621us/step - loss: 0.0647 - accuracy: 0.7701 - val_loss: 0.0733 - val_accuracy: 0.7397\n",
      "Epoch 644/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0649 - accuracy: 0.7693 - val_loss: 0.0735 - val_accuracy: 0.7395\n",
      "Epoch 645/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0648 - accuracy: 0.7699 - val_loss: 0.0732 - val_accuracy: 0.7394\n",
      "Epoch 646/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0648 - accuracy: 0.7695 - val_loss: 0.0733 - val_accuracy: 0.7382\n",
      "Epoch 647/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0648 - accuracy: 0.7689 - val_loss: 0.0743 - val_accuracy: 0.7369\n",
      "Epoch 648/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0647 - accuracy: 0.7702 - val_loss: 0.0737 - val_accuracy: 0.7391\n",
      "Epoch 649/5000\n",
      "11786/11786 [==============================] - 7s 619us/step - loss: 0.0648 - accuracy: 0.7692 - val_loss: 0.0735 - val_accuracy: 0.7393\n",
      "Epoch 650/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0647 - accuracy: 0.7696 - val_loss: 0.0734 - val_accuracy: 0.7389\n",
      "Epoch 651/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0648 - accuracy: 0.7693 - val_loss: 0.0734 - val_accuracy: 0.7395\n",
      "Epoch 652/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0649 - accuracy: 0.7695 - val_loss: 0.0736 - val_accuracy: 0.7388\n",
      "Epoch 653/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0647 - accuracy: 0.7698 - val_loss: 0.0736 - val_accuracy: 0.7382\n",
      "Epoch 654/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0648 - accuracy: 0.7696 - val_loss: 0.0738 - val_accuracy: 0.7381\n",
      "Epoch 655/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0647 - accuracy: 0.7699 - val_loss: 0.0732 - val_accuracy: 0.7395\n",
      "Epoch 656/5000\n",
      "11786/11786 [==============================] - 7s 622us/step - loss: 0.0648 - accuracy: 0.7695 - val_loss: 0.0732 - val_accuracy: 0.7395\n",
      "Epoch 657/5000\n",
      "11786/11786 [==============================] - 7s 616us/step - loss: 0.0648 - accuracy: 0.7698 - val_loss: 0.0731 - val_accuracy: 0.7400\n",
      "Epoch 658/5000\n",
      "11786/11786 [==============================] - 7s 620us/step - loss: 0.0648 - accuracy: 0.7695 - val_loss: 0.0734 - val_accuracy: 0.7378\n",
      "Epoch 659/5000\n",
      "11786/11786 [==============================] - 7s 618us/step - loss: 0.0649 - accuracy: 0.7695 - val_loss: 0.0728 - val_accuracy: 0.7408\n",
      "Epoch 660/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0648 - accuracy: 0.7695 - val_loss: 0.0743 - val_accuracy: 0.7354\n",
      "Epoch 661/5000\n",
      "11786/11786 [==============================] - 7s 621us/step - loss: 0.0647 - accuracy: 0.7694 - val_loss: 0.0738 - val_accuracy: 0.7374\n",
      "Epoch 662/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0648 - accuracy: 0.7696 - val_loss: 0.0742 - val_accuracy: 0.7348\n",
      "Epoch 663/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0647 - accuracy: 0.7698 - val_loss: 0.0733 - val_accuracy: 0.7417\n",
      "Epoch 664/5000\n",
      "11786/11786 [==============================] - 7s 619us/step - loss: 0.0646 - accuracy: 0.7703 - val_loss: 0.0733 - val_accuracy: 0.7394\n",
      "Epoch 665/5000\n",
      "11786/11786 [==============================] - 7s 620us/step - loss: 0.0648 - accuracy: 0.7698 - val_loss: 0.0742 - val_accuracy: 0.7364\n",
      "Epoch 666/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0648 - accuracy: 0.7694 - val_loss: 0.0734 - val_accuracy: 0.7388\n",
      "Epoch 667/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0647 - accuracy: 0.7700 - val_loss: 0.0732 - val_accuracy: 0.7392\n",
      "Epoch 668/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0648 - accuracy: 0.7699 - val_loss: 0.0739 - val_accuracy: 0.7385\n",
      "Epoch 669/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0647 - accuracy: 0.7694 - val_loss: 0.0742 - val_accuracy: 0.7364\n",
      "Epoch 670/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0648 - accuracy: 0.7700 - val_loss: 0.0735 - val_accuracy: 0.7393\n",
      "Epoch 671/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0648 - accuracy: 0.7696 - val_loss: 0.0735 - val_accuracy: 0.7367\n",
      "Epoch 672/5000\n",
      "11786/11786 [==============================] - 7s 620us/step - loss: 0.0648 - accuracy: 0.7694 - val_loss: 0.0735 - val_accuracy: 0.7388\n",
      "Epoch 673/5000\n",
      "11786/11786 [==============================] - 7s 621us/step - loss: 0.0648 - accuracy: 0.7698 - val_loss: 0.0728 - val_accuracy: 0.7404\n",
      "Epoch 674/5000\n",
      "11786/11786 [==============================] - 7s 618us/step - loss: 0.0648 - accuracy: 0.7695 - val_loss: 0.0737 - val_accuracy: 0.7391\n",
      "Epoch 675/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0647 - accuracy: 0.7697 - val_loss: 0.0731 - val_accuracy: 0.7397\n",
      "Epoch 676/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0647 - accuracy: 0.7695 - val_loss: 0.0736 - val_accuracy: 0.7392\n",
      "Epoch 677/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0648 - accuracy: 0.7696 - val_loss: 0.0738 - val_accuracy: 0.7368\n",
      "Epoch 678/5000\n",
      "11786/11786 [==============================] - 7s 619us/step - loss: 0.0648 - accuracy: 0.7697 - val_loss: 0.0741 - val_accuracy: 0.7357\n",
      "Epoch 679/5000\n",
      "11786/11786 [==============================] - 7s 618us/step - loss: 0.0647 - accuracy: 0.7702 - val_loss: 0.0735 - val_accuracy: 0.7394\n",
      "Epoch 680/5000\n",
      "11786/11786 [==============================] - 7s 623us/step - loss: 0.0647 - accuracy: 0.7700 - val_loss: 0.0737 - val_accuracy: 0.7395\n",
      "Epoch 681/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0647 - accuracy: 0.7699 - val_loss: 0.0736 - val_accuracy: 0.7401\n",
      "Epoch 682/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0647 - accuracy: 0.7696 - val_loss: 0.0740 - val_accuracy: 0.7368\n",
      "Epoch 683/5000\n",
      "11786/11786 [==============================] - 7s 619us/step - loss: 0.0647 - accuracy: 0.7696 - val_loss: 0.0733 - val_accuracy: 0.7387\n",
      "Epoch 684/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0647 - accuracy: 0.7702 - val_loss: 0.0728 - val_accuracy: 0.7406\n",
      "Epoch 685/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0647 - accuracy: 0.7701 - val_loss: 0.0738 - val_accuracy: 0.7385\n",
      "Epoch 686/5000\n",
      "11786/11786 [==============================] - 7s 621us/step - loss: 0.0646 - accuracy: 0.7700 - val_loss: 0.0734 - val_accuracy: 0.7371\n",
      "Epoch 687/5000\n",
      "11786/11786 [==============================] - 7s 617us/step - loss: 0.0646 - accuracy: 0.7711 - val_loss: 0.0738 - val_accuracy: 0.7385\n",
      "Epoch 688/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0647 - accuracy: 0.7698 - val_loss: 0.0741 - val_accuracy: 0.7348\n",
      "Epoch 689/5000\n",
      "11786/11786 [==============================] - 7s 620us/step - loss: 0.0647 - accuracy: 0.7697 - val_loss: 0.0736 - val_accuracy: 0.7385\n",
      "Epoch 690/5000\n",
      "11786/11786 [==============================] - 7s 611us/step - loss: 0.0646 - accuracy: 0.7705 - val_loss: 0.0730 - val_accuracy: 0.7402\n",
      "Epoch 691/5000\n",
      "11786/11786 [==============================] - 7s 623us/step - loss: 0.0647 - accuracy: 0.7704 - val_loss: 0.0740 - val_accuracy: 0.7373\n",
      "Epoch 692/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0646 - accuracy: 0.7705 - val_loss: 0.0732 - val_accuracy: 0.7402\n",
      "Epoch 693/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0647 - accuracy: 0.7703 - val_loss: 0.0733 - val_accuracy: 0.7389\n",
      "Epoch 694/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0648 - accuracy: 0.7694 - val_loss: 0.0733 - val_accuracy: 0.7412\n",
      "Epoch 695/5000\n",
      "11786/11786 [==============================] - 7s 616us/step - loss: 0.0647 - accuracy: 0.7698 - val_loss: 0.0735 - val_accuracy: 0.7397\n",
      "Epoch 696/5000\n",
      "11786/11786 [==============================] - 7s 609us/step - loss: 0.0647 - accuracy: 0.7701 - val_loss: 0.0737 - val_accuracy: 0.7397\n",
      "Epoch 697/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0646 - accuracy: 0.7706 - val_loss: 0.0732 - val_accuracy: 0.7397\n",
      "Epoch 698/5000\n",
      "11786/11786 [==============================] - 7s 617us/step - loss: 0.0646 - accuracy: 0.7702 - val_loss: 0.0734 - val_accuracy: 0.7385\n",
      "Epoch 699/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0647 - accuracy: 0.7699 - val_loss: 0.0738 - val_accuracy: 0.7386\n",
      "Epoch 700/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0648 - accuracy: 0.7701 - val_loss: 0.0737 - val_accuracy: 0.7372\n",
      "Epoch 701/5000\n",
      "11786/11786 [==============================] - 7s 620us/step - loss: 0.0648 - accuracy: 0.7697 - val_loss: 0.0731 - val_accuracy: 0.7410\n",
      "Epoch 702/5000\n",
      "11786/11786 [==============================] - 7s 619us/step - loss: 0.0647 - accuracy: 0.7697 - val_loss: 0.0744 - val_accuracy: 0.7368\n",
      "Epoch 703/5000\n",
      "11786/11786 [==============================] - 7s 619us/step - loss: 0.0647 - accuracy: 0.7694 - val_loss: 0.0735 - val_accuracy: 0.7381\n",
      "Epoch 704/5000\n",
      "11786/11786 [==============================] - 7s 623us/step - loss: 0.0648 - accuracy: 0.7697 - val_loss: 0.0734 - val_accuracy: 0.7394\n",
      "Epoch 705/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0647 - accuracy: 0.7701 - val_loss: 0.0737 - val_accuracy: 0.7387\n",
      "Epoch 706/5000\n",
      "11786/11786 [==============================] - 7s 618us/step - loss: 0.0646 - accuracy: 0.7704 - val_loss: 0.0738 - val_accuracy: 0.7392\n",
      "Epoch 707/5000\n",
      "11786/11786 [==============================] - 7s 621us/step - loss: 0.0647 - accuracy: 0.7699 - val_loss: 0.0737 - val_accuracy: 0.7384\n",
      "Epoch 708/5000\n",
      "11786/11786 [==============================] - 7s 622us/step - loss: 0.0648 - accuracy: 0.7698 - val_loss: 0.0737 - val_accuracy: 0.7383\n",
      "Epoch 709/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0647 - accuracy: 0.7698 - val_loss: 0.0741 - val_accuracy: 0.7381\n",
      "Epoch 710/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0647 - accuracy: 0.7701 - val_loss: 0.0741 - val_accuracy: 0.7393\n",
      "Epoch 711/5000\n",
      "11786/11786 [==============================] - 7s 623us/step - loss: 0.0646 - accuracy: 0.7703 - val_loss: 0.0741 - val_accuracy: 0.7382\n",
      "Epoch 712/5000\n",
      "11786/11786 [==============================] - 7s 623us/step - loss: 0.0647 - accuracy: 0.7698 - val_loss: 0.0740 - val_accuracy: 0.7378\n",
      "Epoch 713/5000\n",
      "11786/11786 [==============================] - 7s 619us/step - loss: 0.0647 - accuracy: 0.7701 - val_loss: 0.0738 - val_accuracy: 0.7388\n",
      "Epoch 714/5000\n",
      "11786/11786 [==============================] - 7s 622us/step - loss: 0.0646 - accuracy: 0.7706 - val_loss: 0.0735 - val_accuracy: 0.7397\n",
      "Epoch 715/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0648 - accuracy: 0.7699 - val_loss: 0.0734 - val_accuracy: 0.7394\n",
      "Epoch 716/5000\n",
      "11786/11786 [==============================] - 7s 618us/step - loss: 0.0647 - accuracy: 0.7701 - val_loss: 0.0733 - val_accuracy: 0.7406\n",
      "Epoch 717/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0646 - accuracy: 0.7708 - val_loss: 0.0734 - val_accuracy: 0.7406\n",
      "Epoch 718/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0646 - accuracy: 0.7706 - val_loss: 0.0737 - val_accuracy: 0.7375\n",
      "Epoch 719/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0648 - accuracy: 0.7701 - val_loss: 0.0733 - val_accuracy: 0.7390\n",
      "Epoch 720/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0647 - accuracy: 0.7702 - val_loss: 0.0732 - val_accuracy: 0.7397\n",
      "Epoch 721/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0647 - accuracy: 0.7703 - val_loss: 0.0743 - val_accuracy: 0.7348\n",
      "Epoch 722/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0647 - accuracy: 0.7703 - val_loss: 0.0740 - val_accuracy: 0.7372\n",
      "Epoch 723/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0646 - accuracy: 0.7708 - val_loss: 0.0740 - val_accuracy: 0.7379\n",
      "Epoch 724/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0648 - accuracy: 0.7702 - val_loss: 0.0730 - val_accuracy: 0.7399\n",
      "Epoch 725/5000\n",
      "11786/11786 [==============================] - 7s 618us/step - loss: 0.0647 - accuracy: 0.7701 - val_loss: 0.0734 - val_accuracy: 0.7383\n",
      "Epoch 726/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0647 - accuracy: 0.7704 - val_loss: 0.0734 - val_accuracy: 0.7382\n",
      "Epoch 727/5000\n",
      "11786/11786 [==============================] - 7s 623us/step - loss: 0.0646 - accuracy: 0.7700 - val_loss: 0.0742 - val_accuracy: 0.7372\n",
      "Epoch 728/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0647 - accuracy: 0.7704 - val_loss: 0.0733 - val_accuracy: 0.7403\n",
      "Epoch 729/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0647 - accuracy: 0.7702 - val_loss: 0.0733 - val_accuracy: 0.7409\n",
      "Epoch 730/5000\n",
      "11786/11786 [==============================] - 7s 618us/step - loss: 0.0647 - accuracy: 0.7707 - val_loss: 0.0749 - val_accuracy: 0.7350\n",
      "Epoch 731/5000\n",
      "11786/11786 [==============================] - 7s 621us/step - loss: 0.0646 - accuracy: 0.7704 - val_loss: 0.0731 - val_accuracy: 0.7393\n",
      "Epoch 732/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0647 - accuracy: 0.7701 - val_loss: 0.0739 - val_accuracy: 0.7373\n",
      "Epoch 733/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0647 - accuracy: 0.7699 - val_loss: 0.0735 - val_accuracy: 0.7389\n",
      "Epoch 734/5000\n",
      "11786/11786 [==============================] - 7s 622us/step - loss: 0.0646 - accuracy: 0.7703 - val_loss: 0.0736 - val_accuracy: 0.7374\n",
      "Epoch 735/5000\n",
      "11786/11786 [==============================] - 7s 620us/step - loss: 0.0647 - accuracy: 0.7702 - val_loss: 0.0736 - val_accuracy: 0.7375\n",
      "Epoch 736/5000\n",
      "11786/11786 [==============================] - 7s 620us/step - loss: 0.0647 - accuracy: 0.7702 - val_loss: 0.0734 - val_accuracy: 0.7393\n",
      "Epoch 737/5000\n",
      "11786/11786 [==============================] - 7s 621us/step - loss: 0.0646 - accuracy: 0.7705 - val_loss: 0.0740 - val_accuracy: 0.7379\n",
      "Epoch 738/5000\n",
      "11786/11786 [==============================] - 7s 622us/step - loss: 0.0647 - accuracy: 0.7704 - val_loss: 0.0739 - val_accuracy: 0.7374\n",
      "Epoch 739/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0646 - accuracy: 0.7704 - val_loss: 0.0738 - val_accuracy: 0.7384\n",
      "Epoch 740/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0647 - accuracy: 0.7698 - val_loss: 0.0741 - val_accuracy: 0.7384\n",
      "Epoch 741/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0646 - accuracy: 0.7707 - val_loss: 0.0734 - val_accuracy: 0.7393\n",
      "Epoch 742/5000\n",
      "11786/11786 [==============================] - 7s 619us/step - loss: 0.0647 - accuracy: 0.7705 - val_loss: 0.0743 - val_accuracy: 0.7377\n",
      "Epoch 743/5000\n",
      "11786/11786 [==============================] - 7s 622us/step - loss: 0.0646 - accuracy: 0.7708 - val_loss: 0.0734 - val_accuracy: 0.7404\n",
      "Epoch 744/5000\n",
      "11786/11786 [==============================] - 7s 623us/step - loss: 0.0646 - accuracy: 0.7705 - val_loss: 0.0735 - val_accuracy: 0.7382\n",
      "Epoch 745/5000\n",
      "11786/11786 [==============================] - 7s 617us/step - loss: 0.0647 - accuracy: 0.7705 - val_loss: 0.0739 - val_accuracy: 0.7382\n",
      "Epoch 746/5000\n",
      "11786/11786 [==============================] - 7s 622us/step - loss: 0.0647 - accuracy: 0.7704 - val_loss: 0.0737 - val_accuracy: 0.7391\n",
      "Epoch 747/5000\n",
      "11786/11786 [==============================] - 7s 617us/step - loss: 0.0647 - accuracy: 0.7704 - val_loss: 0.0734 - val_accuracy: 0.7394\n",
      "Epoch 748/5000\n",
      "11786/11786 [==============================] - 7s 622us/step - loss: 0.0646 - accuracy: 0.7710 - val_loss: 0.0739 - val_accuracy: 0.7390\n",
      "Epoch 749/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0646 - accuracy: 0.7710 - val_loss: 0.0735 - val_accuracy: 0.7387\n",
      "Epoch 750/5000\n",
      "11786/11786 [==============================] - 7s 620us/step - loss: 0.0646 - accuracy: 0.7705 - val_loss: 0.0736 - val_accuracy: 0.7400\n",
      "Epoch 751/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0647 - accuracy: 0.7702 - val_loss: 0.0736 - val_accuracy: 0.7407\n",
      "Epoch 752/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0646 - accuracy: 0.7712 - val_loss: 0.0735 - val_accuracy: 0.7408\n",
      "Epoch 753/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0646 - accuracy: 0.7707 - val_loss: 0.0734 - val_accuracy: 0.7390\n",
      "Epoch 754/5000\n",
      "11786/11786 [==============================] - 7s 618us/step - loss: 0.0647 - accuracy: 0.7700 - val_loss: 0.0733 - val_accuracy: 0.7395\n",
      "Epoch 755/5000\n",
      "11786/11786 [==============================] - 7s 623us/step - loss: 0.0646 - accuracy: 0.7709 - val_loss: 0.0740 - val_accuracy: 0.7372\n",
      "Epoch 756/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0645 - accuracy: 0.7704 - val_loss: 0.0742 - val_accuracy: 0.7365\n",
      "Epoch 757/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0646 - accuracy: 0.7704 - val_loss: 0.0738 - val_accuracy: 0.7369\n",
      "Epoch 758/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0647 - accuracy: 0.7702 - val_loss: 0.0733 - val_accuracy: 0.7410\n",
      "Epoch 759/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0646 - accuracy: 0.7709 - val_loss: 0.0730 - val_accuracy: 0.7391\n",
      "Epoch 760/5000\n",
      "11786/11786 [==============================] - 7s 619us/step - loss: 0.0646 - accuracy: 0.7702 - val_loss: 0.0739 - val_accuracy: 0.7363\n",
      "Epoch 761/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0646 - accuracy: 0.7703 - val_loss: 0.0738 - val_accuracy: 0.7387\n",
      "Epoch 762/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0647 - accuracy: 0.7703 - val_loss: 0.0737 - val_accuracy: 0.7374\n",
      "Epoch 763/5000\n",
      "11786/11786 [==============================] - 7s 621us/step - loss: 0.0647 - accuracy: 0.7699 - val_loss: 0.0732 - val_accuracy: 0.7401\n",
      "Epoch 764/5000\n",
      "11786/11786 [==============================] - 7s 621us/step - loss: 0.0647 - accuracy: 0.7707 - val_loss: 0.0740 - val_accuracy: 0.7373\n",
      "Epoch 765/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0647 - accuracy: 0.7707 - val_loss: 0.0735 - val_accuracy: 0.7405\n",
      "Epoch 766/5000\n",
      "11786/11786 [==============================] - 7s 617us/step - loss: 0.0646 - accuracy: 0.7703 - val_loss: 0.0734 - val_accuracy: 0.7374\n",
      "Epoch 767/5000\n",
      "11786/11786 [==============================] - 7s 619us/step - loss: 0.0646 - accuracy: 0.7708 - val_loss: 0.0733 - val_accuracy: 0.7387\n",
      "Epoch 768/5000\n",
      "11786/11786 [==============================] - 7s 611us/step - loss: 0.0646 - accuracy: 0.7709 - val_loss: 0.0732 - val_accuracy: 0.7394\n",
      "Epoch 769/5000\n",
      "11786/11786 [==============================] - 7s 622us/step - loss: 0.0646 - accuracy: 0.7713 - val_loss: 0.0740 - val_accuracy: 0.7368\n",
      "Epoch 770/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0647 - accuracy: 0.7705 - val_loss: 0.0731 - val_accuracy: 0.7409\n",
      "Epoch 771/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0646 - accuracy: 0.7708 - val_loss: 0.0733 - val_accuracy: 0.7405\n",
      "Epoch 772/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0645 - accuracy: 0.7708 - val_loss: 0.0732 - val_accuracy: 0.7406\n",
      "Epoch 773/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0647 - accuracy: 0.7703 - val_loss: 0.0744 - val_accuracy: 0.7386\n",
      "Epoch 774/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0646 - accuracy: 0.7711 - val_loss: 0.0735 - val_accuracy: 0.7396\n",
      "Epoch 775/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0647 - accuracy: 0.7705 - val_loss: 0.0729 - val_accuracy: 0.7408\n",
      "Epoch 776/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0646 - accuracy: 0.7707 - val_loss: 0.0738 - val_accuracy: 0.7388\n",
      "Epoch 777/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0647 - accuracy: 0.7707 - val_loss: 0.0732 - val_accuracy: 0.7401\n",
      "Epoch 778/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0646 - accuracy: 0.7709 - val_loss: 0.0738 - val_accuracy: 0.7377\n",
      "Epoch 779/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0647 - accuracy: 0.7705 - val_loss: 0.0741 - val_accuracy: 0.7366\n",
      "Epoch 780/5000\n",
      "11786/11786 [==============================] - 7s 623us/step - loss: 0.0647 - accuracy: 0.7706 - val_loss: 0.0741 - val_accuracy: 0.7374\n",
      "Epoch 781/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0647 - accuracy: 0.7702 - val_loss: 0.0736 - val_accuracy: 0.7401\n",
      "Epoch 782/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0645 - accuracy: 0.7710 - val_loss: 0.0738 - val_accuracy: 0.7389\n",
      "Epoch 783/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0646 - accuracy: 0.7706 - val_loss: 0.0742 - val_accuracy: 0.7373\n",
      "Epoch 784/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0646 - accuracy: 0.7706 - val_loss: 0.0733 - val_accuracy: 0.7389\n",
      "Epoch 785/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0646 - accuracy: 0.7709 - val_loss: 0.0729 - val_accuracy: 0.7402\n",
      "Epoch 786/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0647 - accuracy: 0.7702 - val_loss: 0.0734 - val_accuracy: 0.7400\n",
      "Epoch 787/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0646 - accuracy: 0.7702 - val_loss: 0.0735 - val_accuracy: 0.7387\n",
      "Epoch 788/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0646 - accuracy: 0.7711 - val_loss: 0.0742 - val_accuracy: 0.7377\n",
      "Epoch 789/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0646 - accuracy: 0.7705 - val_loss: 0.0732 - val_accuracy: 0.7404\n",
      "Epoch 790/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0646 - accuracy: 0.7708 - val_loss: 0.0738 - val_accuracy: 0.7393\n",
      "Epoch 791/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0646 - accuracy: 0.7698 - val_loss: 0.0743 - val_accuracy: 0.7356\n",
      "Epoch 792/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0646 - accuracy: 0.7707 - val_loss: 0.0741 - val_accuracy: 0.7383\n",
      "Epoch 793/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0646 - accuracy: 0.7707 - val_loss: 0.0741 - val_accuracy: 0.7401\n",
      "Epoch 794/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0646 - accuracy: 0.7709 - val_loss: 0.0739 - val_accuracy: 0.7396\n",
      "Epoch 795/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0646 - accuracy: 0.7708 - val_loss: 0.0732 - val_accuracy: 0.7414\n",
      "Epoch 796/5000\n",
      "11786/11786 [==============================] - 7s 620us/step - loss: 0.0646 - accuracy: 0.7708 - val_loss: 0.0734 - val_accuracy: 0.7401\n",
      "Epoch 797/5000\n",
      "11786/11786 [==============================] - 7s 623us/step - loss: 0.0646 - accuracy: 0.7707 - val_loss: 0.0731 - val_accuracy: 0.7412\n",
      "Epoch 798/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0646 - accuracy: 0.7706 - val_loss: 0.0739 - val_accuracy: 0.7379\n",
      "Epoch 799/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0646 - accuracy: 0.7710 - val_loss: 0.0738 - val_accuracy: 0.7389\n",
      "Epoch 800/5000\n",
      "11786/11786 [==============================] - 7s 622us/step - loss: 0.0647 - accuracy: 0.7708 - val_loss: 0.0731 - val_accuracy: 0.7400\n",
      "Epoch 801/5000\n",
      "11786/11786 [==============================] - 7s 622us/step - loss: 0.0646 - accuracy: 0.7706 - val_loss: 0.0738 - val_accuracy: 0.7386\n",
      "Epoch 802/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0647 - accuracy: 0.7707 - val_loss: 0.0735 - val_accuracy: 0.7413\n",
      "Epoch 803/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0646 - accuracy: 0.7711 - val_loss: 0.0734 - val_accuracy: 0.7390\n",
      "Epoch 804/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0646 - accuracy: 0.7713 - val_loss: 0.0733 - val_accuracy: 0.7407\n",
      "Epoch 805/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0646 - accuracy: 0.7711 - val_loss: 0.0740 - val_accuracy: 0.7376\n",
      "Epoch 806/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0646 - accuracy: 0.7706 - val_loss: 0.0735 - val_accuracy: 0.7396\n",
      "Epoch 807/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0646 - accuracy: 0.7713 - val_loss: 0.0737 - val_accuracy: 0.7377\n",
      "Epoch 808/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0645 - accuracy: 0.7714 - val_loss: 0.0736 - val_accuracy: 0.7410\n",
      "Epoch 809/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0646 - accuracy: 0.7712 - val_loss: 0.0743 - val_accuracy: 0.7368\n",
      "Epoch 810/5000\n",
      "11786/11786 [==============================] - 7s 622us/step - loss: 0.0645 - accuracy: 0.7711 - val_loss: 0.0740 - val_accuracy: 0.7363\n",
      "Epoch 811/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0646 - accuracy: 0.7710 - val_loss: 0.0735 - val_accuracy: 0.7392\n",
      "Epoch 812/5000\n",
      "11786/11786 [==============================] - 7s 621us/step - loss: 0.0646 - accuracy: 0.7712 - val_loss: 0.0738 - val_accuracy: 0.7404\n",
      "Epoch 813/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0647 - accuracy: 0.7706 - val_loss: 0.0739 - val_accuracy: 0.7379\n",
      "Epoch 814/5000\n",
      "11786/11786 [==============================] - 7s 622us/step - loss: 0.0647 - accuracy: 0.7706 - val_loss: 0.0738 - val_accuracy: 0.7383\n",
      "Epoch 815/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0646 - accuracy: 0.7706 - val_loss: 0.0739 - val_accuracy: 0.7388\n",
      "Epoch 816/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0645 - accuracy: 0.7714 - val_loss: 0.0729 - val_accuracy: 0.7418\n",
      "Epoch 817/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0646 - accuracy: 0.7707 - val_loss: 0.0736 - val_accuracy: 0.7396\n",
      "Epoch 818/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0645 - accuracy: 0.7717 - val_loss: 0.0742 - val_accuracy: 0.7359\n",
      "Epoch 819/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0646 - accuracy: 0.7706 - val_loss: 0.0741 - val_accuracy: 0.7385\n",
      "Epoch 820/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0645 - accuracy: 0.7713 - val_loss: 0.0740 - val_accuracy: 0.7382\n",
      "Epoch 821/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0646 - accuracy: 0.7708 - val_loss: 0.0740 - val_accuracy: 0.7388\n",
      "Epoch 822/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0646 - accuracy: 0.7706 - val_loss: 0.0735 - val_accuracy: 0.7391\n",
      "Epoch 823/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0647 - accuracy: 0.7711 - val_loss: 0.0740 - val_accuracy: 0.7387\n",
      "Epoch 824/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0646 - accuracy: 0.7712 - val_loss: 0.0736 - val_accuracy: 0.7393\n",
      "Epoch 825/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0646 - accuracy: 0.7710 - val_loss: 0.0737 - val_accuracy: 0.7380\n",
      "Epoch 826/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0647 - accuracy: 0.7707 - val_loss: 0.0740 - val_accuracy: 0.7389\n",
      "Epoch 827/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0645 - accuracy: 0.7710 - val_loss: 0.0736 - val_accuracy: 0.7384\n",
      "Epoch 828/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0646 - accuracy: 0.7709 - val_loss: 0.0734 - val_accuracy: 0.7411\n",
      "Epoch 829/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0645 - accuracy: 0.7712 - val_loss: 0.0740 - val_accuracy: 0.7381\n",
      "Epoch 830/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0646 - accuracy: 0.7706 - val_loss: 0.0736 - val_accuracy: 0.7400\n",
      "Epoch 831/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0646 - accuracy: 0.7711 - val_loss: 0.0740 - val_accuracy: 0.7385\n",
      "Epoch 832/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0645 - accuracy: 0.7712 - val_loss: 0.0734 - val_accuracy: 0.7403\n",
      "Epoch 833/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0646 - accuracy: 0.7707 - val_loss: 0.0739 - val_accuracy: 0.7399\n",
      "Epoch 834/5000\n",
      "11786/11786 [==============================] - 7s 622us/step - loss: 0.0645 - accuracy: 0.7712 - val_loss: 0.0737 - val_accuracy: 0.7385\n",
      "Epoch 835/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0646 - accuracy: 0.7710 - val_loss: 0.0740 - val_accuracy: 0.7374\n",
      "Epoch 836/5000\n",
      "11786/11786 [==============================] - 7s 622us/step - loss: 0.0646 - accuracy: 0.7707 - val_loss: 0.0738 - val_accuracy: 0.7399\n",
      "Epoch 837/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0646 - accuracy: 0.7710 - val_loss: 0.0736 - val_accuracy: 0.7394\n",
      "Epoch 838/5000\n",
      "11786/11786 [==============================] - 7s 621us/step - loss: 0.0645 - accuracy: 0.7713 - val_loss: 0.0740 - val_accuracy: 0.7401\n",
      "Epoch 839/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0646 - accuracy: 0.7707 - val_loss: 0.0736 - val_accuracy: 0.7395\n",
      "Epoch 840/5000\n",
      "11786/11786 [==============================] - 7s 623us/step - loss: 0.0646 - accuracy: 0.7709 - val_loss: 0.0742 - val_accuracy: 0.7371\n",
      "Epoch 841/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0646 - accuracy: 0.7707 - val_loss: 0.0735 - val_accuracy: 0.7392\n",
      "Epoch 842/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0646 - accuracy: 0.7706 - val_loss: 0.0736 - val_accuracy: 0.7421\n",
      "Epoch 843/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0647 - accuracy: 0.7704 - val_loss: 0.0741 - val_accuracy: 0.7393\n",
      "Epoch 844/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0647 - accuracy: 0.7705 - val_loss: 0.0735 - val_accuracy: 0.7384\n",
      "Epoch 845/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0646 - accuracy: 0.7706 - val_loss: 0.0741 - val_accuracy: 0.7380\n",
      "Epoch 846/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0645 - accuracy: 0.7713 - val_loss: 0.0738 - val_accuracy: 0.7377\n",
      "Epoch 847/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0646 - accuracy: 0.7714 - val_loss: 0.0735 - val_accuracy: 0.7389\n",
      "Epoch 848/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0645 - accuracy: 0.7710 - val_loss: 0.0738 - val_accuracy: 0.7401\n",
      "Epoch 849/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0646 - accuracy: 0.7709 - val_loss: 0.0737 - val_accuracy: 0.7398\n",
      "Epoch 850/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0646 - accuracy: 0.7709 - val_loss: 0.0732 - val_accuracy: 0.7411\n",
      "Epoch 851/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0646 - accuracy: 0.7708 - val_loss: 0.0733 - val_accuracy: 0.7400\n",
      "Epoch 852/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0646 - accuracy: 0.7710 - val_loss: 0.0737 - val_accuracy: 0.7399\n",
      "Epoch 853/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0646 - accuracy: 0.7709 - val_loss: 0.0738 - val_accuracy: 0.7399\n",
      "Epoch 854/5000\n",
      "11786/11786 [==============================] - 7s 620us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0734 - val_accuracy: 0.7396\n",
      "Epoch 855/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0646 - accuracy: 0.7710 - val_loss: 0.0739 - val_accuracy: 0.7374\n",
      "Epoch 856/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0645 - accuracy: 0.7708 - val_loss: 0.0736 - val_accuracy: 0.7390\n",
      "Epoch 857/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0645 - accuracy: 0.7711 - val_loss: 0.0734 - val_accuracy: 0.7405\n",
      "Epoch 858/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0646 - accuracy: 0.7710 - val_loss: 0.0732 - val_accuracy: 0.7418\n",
      "Epoch 859/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0646 - accuracy: 0.7709 - val_loss: 0.0737 - val_accuracy: 0.7394\n",
      "Epoch 860/5000\n",
      "11786/11786 [==============================] - 7s 623us/step - loss: 0.0645 - accuracy: 0.7711 - val_loss: 0.0740 - val_accuracy: 0.7395\n",
      "Epoch 861/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0645 - accuracy: 0.7708 - val_loss: 0.0744 - val_accuracy: 0.7353\n",
      "Epoch 862/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0646 - accuracy: 0.7709 - val_loss: 0.0743 - val_accuracy: 0.7394\n",
      "Epoch 863/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0645 - accuracy: 0.7711 - val_loss: 0.0737 - val_accuracy: 0.7398\n",
      "Epoch 864/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0645 - accuracy: 0.7706 - val_loss: 0.0735 - val_accuracy: 0.7388\n",
      "Epoch 865/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0646 - accuracy: 0.7711 - val_loss: 0.0736 - val_accuracy: 0.7389\n",
      "Epoch 866/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0646 - accuracy: 0.7708 - val_loss: 0.0739 - val_accuracy: 0.7399\n",
      "Epoch 867/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0646 - accuracy: 0.7709 - val_loss: 0.0742 - val_accuracy: 0.7371\n",
      "Epoch 868/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0645 - accuracy: 0.7711 - val_loss: 0.0742 - val_accuracy: 0.7380\n",
      "Epoch 869/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0647 - accuracy: 0.7707 - val_loss: 0.0729 - val_accuracy: 0.7411\n",
      "Epoch 870/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0645 - accuracy: 0.7709 - val_loss: 0.0736 - val_accuracy: 0.7408\n",
      "Epoch 871/5000\n",
      "11786/11786 [==============================] - 7s 623us/step - loss: 0.0646 - accuracy: 0.7707 - val_loss: 0.0743 - val_accuracy: 0.7374\n",
      "Epoch 872/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0646 - accuracy: 0.7711 - val_loss: 0.0733 - val_accuracy: 0.7405\n",
      "Epoch 873/5000\n",
      "11786/11786 [==============================] - 7s 623us/step - loss: 0.0646 - accuracy: 0.7709 - val_loss: 0.0730 - val_accuracy: 0.7416\n",
      "Epoch 874/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0646 - accuracy: 0.7708 - val_loss: 0.0740 - val_accuracy: 0.7380\n",
      "Epoch 875/5000\n",
      "11786/11786 [==============================] - 7s 622us/step - loss: 0.0645 - accuracy: 0.7706 - val_loss: 0.0740 - val_accuracy: 0.7391\n",
      "Epoch 876/5000\n",
      "11786/11786 [==============================] - 7s 618us/step - loss: 0.0645 - accuracy: 0.7714 - val_loss: 0.0734 - val_accuracy: 0.7393\n",
      "Epoch 877/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0646 - accuracy: 0.7711 - val_loss: 0.0738 - val_accuracy: 0.7388\n",
      "Epoch 878/5000\n",
      "11786/11786 [==============================] - 7s 619us/step - loss: 0.0646 - accuracy: 0.7707 - val_loss: 0.0735 - val_accuracy: 0.7391\n",
      "Epoch 879/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0646 - accuracy: 0.7712 - val_loss: 0.0737 - val_accuracy: 0.7401\n",
      "Epoch 880/5000\n",
      "11786/11786 [==============================] - 7s 623us/step - loss: 0.0646 - accuracy: 0.7712 - val_loss: 0.0741 - val_accuracy: 0.7378\n",
      "Epoch 881/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0646 - accuracy: 0.7711 - val_loss: 0.0736 - val_accuracy: 0.7388\n",
      "Epoch 882/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0646 - accuracy: 0.7709 - val_loss: 0.0741 - val_accuracy: 0.7406\n",
      "Epoch 883/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0646 - accuracy: 0.7709 - val_loss: 0.0737 - val_accuracy: 0.7397\n",
      "Epoch 884/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0645 - accuracy: 0.7712 - val_loss: 0.0739 - val_accuracy: 0.7382\n",
      "Epoch 885/5000\n",
      "11786/11786 [==============================] - 7s 622us/step - loss: 0.0645 - accuracy: 0.7714 - val_loss: 0.0737 - val_accuracy: 0.7390\n",
      "Epoch 886/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0645 - accuracy: 0.7711 - val_loss: 0.0743 - val_accuracy: 0.7379\n",
      "Epoch 887/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0647 - accuracy: 0.7707 - val_loss: 0.0733 - val_accuracy: 0.7395\n",
      "Epoch 888/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0646 - accuracy: 0.7707 - val_loss: 0.0739 - val_accuracy: 0.7391\n",
      "Epoch 889/5000\n",
      "11786/11786 [==============================] - 7s 623us/step - loss: 0.0646 - accuracy: 0.7710 - val_loss: 0.0738 - val_accuracy: 0.7373\n",
      "Epoch 890/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0647 - accuracy: 0.7700 - val_loss: 0.0735 - val_accuracy: 0.7400\n",
      "Epoch 891/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0645 - accuracy: 0.7711 - val_loss: 0.0735 - val_accuracy: 0.7399\n",
      "Epoch 892/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0646 - accuracy: 0.7709 - val_loss: 0.0732 - val_accuracy: 0.7412\n",
      "Epoch 893/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0646 - accuracy: 0.7707 - val_loss: 0.0738 - val_accuracy: 0.7396\n",
      "Epoch 894/5000\n",
      "11786/11786 [==============================] - 7s 623us/step - loss: 0.0645 - accuracy: 0.7709 - val_loss: 0.0734 - val_accuracy: 0.7397\n",
      "Epoch 895/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0646 - accuracy: 0.7709 - val_loss: 0.0749 - val_accuracy: 0.7337\n",
      "Epoch 896/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0646 - accuracy: 0.7711 - val_loss: 0.0736 - val_accuracy: 0.7395\n",
      "Epoch 897/5000\n",
      "11786/11786 [==============================] - 7s 617us/step - loss: 0.0646 - accuracy: 0.7710 - val_loss: 0.0739 - val_accuracy: 0.7405\n",
      "Epoch 898/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0737 - val_accuracy: 0.7396\n",
      "Epoch 899/5000\n",
      "11786/11786 [==============================] - 7s 620us/step - loss: 0.0645 - accuracy: 0.7709 - val_loss: 0.0745 - val_accuracy: 0.7386\n",
      "Epoch 900/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0645 - accuracy: 0.7713 - val_loss: 0.0736 - val_accuracy: 0.7403\n",
      "Epoch 901/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0646 - accuracy: 0.7712 - val_loss: 0.0736 - val_accuracy: 0.7393\n",
      "Epoch 902/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0645 - accuracy: 0.7710 - val_loss: 0.0735 - val_accuracy: 0.7395\n",
      "Epoch 903/5000\n",
      "11786/11786 [==============================] - 7s 623us/step - loss: 0.0646 - accuracy: 0.7710 - val_loss: 0.0732 - val_accuracy: 0.7412\n",
      "Epoch 904/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0645 - accuracy: 0.7717 - val_loss: 0.0738 - val_accuracy: 0.7397\n",
      "Epoch 905/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0645 - accuracy: 0.7713 - val_loss: 0.0739 - val_accuracy: 0.7389\n",
      "Epoch 906/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0645 - accuracy: 0.7714 - val_loss: 0.0735 - val_accuracy: 0.7386\n",
      "Epoch 907/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0645 - accuracy: 0.7711 - val_loss: 0.0736 - val_accuracy: 0.7392\n",
      "Epoch 908/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0646 - accuracy: 0.7711 - val_loss: 0.0737 - val_accuracy: 0.7416\n",
      "Epoch 909/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0646 - accuracy: 0.7708 - val_loss: 0.0741 - val_accuracy: 0.7376\n",
      "Epoch 910/5000\n",
      "11786/11786 [==============================] - 7s 623us/step - loss: 0.0647 - accuracy: 0.7713 - val_loss: 0.0738 - val_accuracy: 0.7403\n",
      "Epoch 911/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0646 - accuracy: 0.7706 - val_loss: 0.0733 - val_accuracy: 0.7397\n",
      "Epoch 912/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0647 - accuracy: 0.7706 - val_loss: 0.0734 - val_accuracy: 0.7402\n",
      "Epoch 913/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0646 - accuracy: 0.7712 - val_loss: 0.0734 - val_accuracy: 0.7394\n",
      "Epoch 914/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0646 - accuracy: 0.7710 - val_loss: 0.0748 - val_accuracy: 0.7371\n",
      "Epoch 915/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0646 - accuracy: 0.7710 - val_loss: 0.0747 - val_accuracy: 0.7358\n",
      "Epoch 916/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0646 - accuracy: 0.7709 - val_loss: 0.0738 - val_accuracy: 0.7381\n",
      "Epoch 917/5000\n",
      "11786/11786 [==============================] - 7s 622us/step - loss: 0.0646 - accuracy: 0.7712 - val_loss: 0.0743 - val_accuracy: 0.7386\n",
      "Epoch 918/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0646 - accuracy: 0.7708 - val_loss: 0.0739 - val_accuracy: 0.7391\n",
      "Epoch 919/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0646 - accuracy: 0.7708 - val_loss: 0.0732 - val_accuracy: 0.7406\n",
      "Epoch 920/5000\n",
      "11786/11786 [==============================] - 7s 618us/step - loss: 0.0645 - accuracy: 0.7713 - val_loss: 0.0740 - val_accuracy: 0.7387\n",
      "Epoch 921/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0739 - val_accuracy: 0.7370\n",
      "Epoch 922/5000\n",
      "11786/11786 [==============================] - 7s 622us/step - loss: 0.0646 - accuracy: 0.7708 - val_loss: 0.0739 - val_accuracy: 0.7391\n",
      "Epoch 923/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0645 - accuracy: 0.7713 - val_loss: 0.0735 - val_accuracy: 0.7392\n",
      "Epoch 924/5000\n",
      "11786/11786 [==============================] - 7s 619us/step - loss: 0.0645 - accuracy: 0.7714 - val_loss: 0.0743 - val_accuracy: 0.7375\n",
      "Epoch 925/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0646 - accuracy: 0.7706 - val_loss: 0.0737 - val_accuracy: 0.7384\n",
      "Epoch 926/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0647 - accuracy: 0.7712 - val_loss: 0.0736 - val_accuracy: 0.7380\n",
      "Epoch 927/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0646 - accuracy: 0.7710 - val_loss: 0.0735 - val_accuracy: 0.7405\n",
      "Epoch 928/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0645 - accuracy: 0.7717 - val_loss: 0.0734 - val_accuracy: 0.7395\n",
      "Epoch 929/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0646 - accuracy: 0.7712 - val_loss: 0.0743 - val_accuracy: 0.7371\n",
      "Epoch 930/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0744 - val_accuracy: 0.7382\n",
      "Epoch 931/5000\n",
      "11786/11786 [==============================] - 7s 622us/step - loss: 0.0646 - accuracy: 0.7711 - val_loss: 0.0736 - val_accuracy: 0.7397\n",
      "Epoch 932/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0646 - accuracy: 0.7709 - val_loss: 0.0738 - val_accuracy: 0.7394\n",
      "Epoch 933/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0646 - accuracy: 0.7711 - val_loss: 0.0741 - val_accuracy: 0.7389\n",
      "Epoch 934/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0646 - accuracy: 0.7709 - val_loss: 0.0737 - val_accuracy: 0.7391\n",
      "Epoch 935/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0646 - accuracy: 0.7711 - val_loss: 0.0736 - val_accuracy: 0.7399\n",
      "Epoch 936/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0645 - accuracy: 0.7713 - val_loss: 0.0740 - val_accuracy: 0.7393\n",
      "Epoch 937/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0644 - accuracy: 0.7720 - val_loss: 0.0743 - val_accuracy: 0.7369\n",
      "Epoch 938/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0646 - accuracy: 0.7712 - val_loss: 0.0744 - val_accuracy: 0.7396\n",
      "Epoch 939/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0646 - accuracy: 0.7709 - val_loss: 0.0735 - val_accuracy: 0.7397\n",
      "Epoch 940/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0646 - accuracy: 0.7709 - val_loss: 0.0738 - val_accuracy: 0.7382\n",
      "Epoch 941/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0646 - accuracy: 0.7712 - val_loss: 0.0734 - val_accuracy: 0.7416\n",
      "Epoch 942/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0646 - accuracy: 0.7709 - val_loss: 0.0739 - val_accuracy: 0.7365\n",
      "Epoch 943/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0646 - accuracy: 0.7714 - val_loss: 0.0746 - val_accuracy: 0.7359\n",
      "Epoch 944/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0645 - accuracy: 0.7711 - val_loss: 0.0738 - val_accuracy: 0.7382\n",
      "Epoch 945/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0646 - accuracy: 0.7711 - val_loss: 0.0734 - val_accuracy: 0.7406\n",
      "Epoch 946/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0646 - accuracy: 0.7716 - val_loss: 0.0734 - val_accuracy: 0.7405\n",
      "Epoch 947/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0645 - accuracy: 0.7713 - val_loss: 0.0738 - val_accuracy: 0.7408\n",
      "Epoch 948/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0646 - accuracy: 0.7709 - val_loss: 0.0738 - val_accuracy: 0.7398\n",
      "Epoch 949/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0737 - val_accuracy: 0.7399\n",
      "Epoch 950/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0646 - accuracy: 0.7709 - val_loss: 0.0735 - val_accuracy: 0.7403\n",
      "Epoch 951/5000\n",
      "11786/11786 [==============================] - 7s 623us/step - loss: 0.0646 - accuracy: 0.7714 - val_loss: 0.0739 - val_accuracy: 0.7373\n",
      "Epoch 952/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0646 - accuracy: 0.7708 - val_loss: 0.0744 - val_accuracy: 0.7381\n",
      "Epoch 953/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0645 - accuracy: 0.7713 - val_loss: 0.0736 - val_accuracy: 0.7403\n",
      "Epoch 954/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0646 - accuracy: 0.7715 - val_loss: 0.0737 - val_accuracy: 0.7381\n",
      "Epoch 955/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0737 - val_accuracy: 0.7407\n",
      "Epoch 956/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0646 - accuracy: 0.7711 - val_loss: 0.0737 - val_accuracy: 0.7410\n",
      "Epoch 957/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0737 - val_accuracy: 0.7395\n",
      "Epoch 958/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0646 - accuracy: 0.7712 - val_loss: 0.0736 - val_accuracy: 0.7392\n",
      "Epoch 959/5000\n",
      "11786/11786 [==============================] - 7s 620us/step - loss: 0.0646 - accuracy: 0.7705 - val_loss: 0.0742 - val_accuracy: 0.7396\n",
      "Epoch 960/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0644 - accuracy: 0.7719 - val_loss: 0.0746 - val_accuracy: 0.7388\n",
      "Epoch 961/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0646 - accuracy: 0.7710 - val_loss: 0.0738 - val_accuracy: 0.7391\n",
      "Epoch 962/5000\n",
      "11786/11786 [==============================] - 7s 622us/step - loss: 0.0645 - accuracy: 0.7712 - val_loss: 0.0743 - val_accuracy: 0.7372\n",
      "Epoch 963/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0743 - val_accuracy: 0.7353\n",
      "Epoch 964/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0645 - accuracy: 0.7714 - val_loss: 0.0736 - val_accuracy: 0.7393\n",
      "Epoch 965/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0646 - accuracy: 0.7712 - val_loss: 0.0736 - val_accuracy: 0.7398\n",
      "Epoch 966/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0646 - accuracy: 0.7712 - val_loss: 0.0736 - val_accuracy: 0.7391\n",
      "Epoch 967/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0646 - accuracy: 0.7717 - val_loss: 0.0743 - val_accuracy: 0.7383\n",
      "Epoch 968/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0645 - accuracy: 0.7711 - val_loss: 0.0739 - val_accuracy: 0.7400\n",
      "Epoch 969/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0738 - val_accuracy: 0.7385\n",
      "Epoch 970/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0646 - accuracy: 0.7710 - val_loss: 0.0740 - val_accuracy: 0.7385\n",
      "Epoch 971/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0737 - val_accuracy: 0.7399\n",
      "Epoch 972/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0646 - accuracy: 0.7714 - val_loss: 0.0736 - val_accuracy: 0.7411\n",
      "Epoch 973/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0646 - accuracy: 0.7715 - val_loss: 0.0746 - val_accuracy: 0.7362\n",
      "Epoch 974/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0646 - accuracy: 0.7709 - val_loss: 0.0742 - val_accuracy: 0.7390\n",
      "Epoch 975/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0646 - accuracy: 0.7712 - val_loss: 0.0737 - val_accuracy: 0.7392\n",
      "Epoch 976/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0737 - val_accuracy: 0.7397\n",
      "Epoch 977/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0646 - accuracy: 0.7709 - val_loss: 0.0741 - val_accuracy: 0.7388\n",
      "Epoch 978/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0647 - accuracy: 0.7708 - val_loss: 0.0736 - val_accuracy: 0.7384\n",
      "Epoch 979/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0646 - accuracy: 0.7712 - val_loss: 0.0735 - val_accuracy: 0.7399\n",
      "Epoch 980/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0646 - accuracy: 0.7708 - val_loss: 0.0742 - val_accuracy: 0.7395\n",
      "Epoch 981/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0646 - accuracy: 0.7706 - val_loss: 0.0738 - val_accuracy: 0.7394\n",
      "Epoch 982/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0646 - accuracy: 0.7715 - val_loss: 0.0738 - val_accuracy: 0.7377\n",
      "Epoch 983/5000\n",
      "11786/11786 [==============================] - 7s 623us/step - loss: 0.0645 - accuracy: 0.7713 - val_loss: 0.0738 - val_accuracy: 0.7402\n",
      "Epoch 984/5000\n",
      "11786/11786 [==============================] - 7s 621us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0738 - val_accuracy: 0.7400\n",
      "Epoch 985/5000\n",
      "11786/11786 [==============================] - 7s 618us/step - loss: 0.0644 - accuracy: 0.7714 - val_loss: 0.0737 - val_accuracy: 0.7396\n",
      "Epoch 986/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0646 - accuracy: 0.7715 - val_loss: 0.0738 - val_accuracy: 0.7386\n",
      "Epoch 987/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0646 - accuracy: 0.7713 - val_loss: 0.0739 - val_accuracy: 0.7392\n",
      "Epoch 988/5000\n",
      "11786/11786 [==============================] - 7s 621us/step - loss: 0.0646 - accuracy: 0.7711 - val_loss: 0.0742 - val_accuracy: 0.7377\n",
      "Epoch 989/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0645 - accuracy: 0.7714 - val_loss: 0.0736 - val_accuracy: 0.7403\n",
      "Epoch 990/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0646 - accuracy: 0.7712 - val_loss: 0.0740 - val_accuracy: 0.7382\n",
      "Epoch 991/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0647 - accuracy: 0.7709 - val_loss: 0.0738 - val_accuracy: 0.7400\n",
      "Epoch 992/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0645 - accuracy: 0.7713 - val_loss: 0.0739 - val_accuracy: 0.7384\n",
      "Epoch 993/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0646 - accuracy: 0.7714 - val_loss: 0.0739 - val_accuracy: 0.7369\n",
      "Epoch 994/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0646 - accuracy: 0.7708 - val_loss: 0.0734 - val_accuracy: 0.7397\n",
      "Epoch 995/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0646 - accuracy: 0.7707 - val_loss: 0.0743 - val_accuracy: 0.7372\n",
      "Epoch 996/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0646 - accuracy: 0.7711 - val_loss: 0.0732 - val_accuracy: 0.7409\n",
      "Epoch 997/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0646 - accuracy: 0.7709 - val_loss: 0.0736 - val_accuracy: 0.7394\n",
      "Epoch 998/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0646 - accuracy: 0.7712 - val_loss: 0.0732 - val_accuracy: 0.7400\n",
      "Epoch 999/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0645 - accuracy: 0.7710 - val_loss: 0.0734 - val_accuracy: 0.7393\n",
      "Epoch 1000/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0743 - val_accuracy: 0.7394\n",
      "Epoch 1001/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0645 - accuracy: 0.7710 - val_loss: 0.0732 - val_accuracy: 0.7402\n",
      "Epoch 1002/5000\n",
      "11786/11786 [==============================] - 7s 622us/step - loss: 0.0646 - accuracy: 0.7705 - val_loss: 0.0733 - val_accuracy: 0.7402\n",
      "Epoch 1003/5000\n",
      "11786/11786 [==============================] - 7s 622us/step - loss: 0.0646 - accuracy: 0.7709 - val_loss: 0.0735 - val_accuracy: 0.7380\n",
      "Epoch 1004/5000\n",
      "11786/11786 [==============================] - 7s 620us/step - loss: 0.0646 - accuracy: 0.7706 - val_loss: 0.0737 - val_accuracy: 0.7398\n",
      "Epoch 1005/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0646 - accuracy: 0.7707 - val_loss: 0.0735 - val_accuracy: 0.7394\n",
      "Epoch 1006/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0646 - accuracy: 0.7703 - val_loss: 0.0734 - val_accuracy: 0.7394\n",
      "Epoch 1007/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0645 - accuracy: 0.7712 - val_loss: 0.0737 - val_accuracy: 0.7387\n",
      "Epoch 1008/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0737 - val_accuracy: 0.7390\n",
      "Epoch 1009/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0645 - accuracy: 0.7718 - val_loss: 0.0735 - val_accuracy: 0.7385\n",
      "Epoch 1010/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0646 - accuracy: 0.7714 - val_loss: 0.0747 - val_accuracy: 0.7358\n",
      "Epoch 1011/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0646 - accuracy: 0.7711 - val_loss: 0.0746 - val_accuracy: 0.7365\n",
      "Epoch 1012/5000\n",
      "11786/11786 [==============================] - 7s 622us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0736 - val_accuracy: 0.7395\n",
      "Epoch 1013/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0646 - accuracy: 0.7715 - val_loss: 0.0738 - val_accuracy: 0.7406\n",
      "Epoch 1014/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0646 - accuracy: 0.7709 - val_loss: 0.0737 - val_accuracy: 0.7371\n",
      "Epoch 1015/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0646 - accuracy: 0.7710 - val_loss: 0.0746 - val_accuracy: 0.7385\n",
      "Epoch 1016/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0647 - accuracy: 0.7710 - val_loss: 0.0734 - val_accuracy: 0.7400\n",
      "Epoch 1017/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0645 - accuracy: 0.7710 - val_loss: 0.0733 - val_accuracy: 0.7400\n",
      "Epoch 1018/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0647 - accuracy: 0.7710 - val_loss: 0.0740 - val_accuracy: 0.7379\n",
      "Epoch 1019/5000\n",
      "11786/11786 [==============================] - 7s 621us/step - loss: 0.0646 - accuracy: 0.7713 - val_loss: 0.0737 - val_accuracy: 0.7390\n",
      "Epoch 1020/5000\n",
      "11786/11786 [==============================] - 7s 623us/step - loss: 0.0646 - accuracy: 0.7711 - val_loss: 0.0736 - val_accuracy: 0.7392\n",
      "Epoch 1021/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0737 - val_accuracy: 0.7397\n",
      "Epoch 1022/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0646 - accuracy: 0.7708 - val_loss: 0.0737 - val_accuracy: 0.7390\n",
      "Epoch 1023/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0646 - accuracy: 0.7707 - val_loss: 0.0741 - val_accuracy: 0.7374\n",
      "Epoch 1024/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0646 - accuracy: 0.7711 - val_loss: 0.0736 - val_accuracy: 0.7400\n",
      "Epoch 1025/5000\n",
      "11786/11786 [==============================] - 8s 644us/step - loss: 0.0646 - accuracy: 0.7716 - val_loss: 0.0734 - val_accuracy: 0.7393\n",
      "Epoch 1026/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0646 - accuracy: 0.7710 - val_loss: 0.0739 - val_accuracy: 0.7373\n",
      "Epoch 1027/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0646 - accuracy: 0.7709 - val_loss: 0.0735 - val_accuracy: 0.7398\n",
      "Epoch 1028/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0646 - accuracy: 0.7712 - val_loss: 0.0739 - val_accuracy: 0.7384\n",
      "Epoch 1029/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0644 - accuracy: 0.7720 - val_loss: 0.0735 - val_accuracy: 0.7399\n",
      "Epoch 1030/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0645 - accuracy: 0.7713 - val_loss: 0.0738 - val_accuracy: 0.7394\n",
      "Epoch 1031/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0646 - accuracy: 0.7710 - val_loss: 0.0737 - val_accuracy: 0.7390\n",
      "Epoch 1032/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0646 - accuracy: 0.7709 - val_loss: 0.0737 - val_accuracy: 0.7389\n",
      "Epoch 1033/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0646 - accuracy: 0.7709 - val_loss: 0.0738 - val_accuracy: 0.7383\n",
      "Epoch 1034/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0646 - accuracy: 0.7710 - val_loss: 0.0738 - val_accuracy: 0.7391\n",
      "Epoch 1035/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0646 - accuracy: 0.7713 - val_loss: 0.0737 - val_accuracy: 0.7384\n",
      "Epoch 1036/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0645 - accuracy: 0.7708 - val_loss: 0.0739 - val_accuracy: 0.7381\n",
      "Epoch 1037/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0646 - accuracy: 0.7706 - val_loss: 0.0743 - val_accuracy: 0.7390\n",
      "Epoch 1038/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0646 - accuracy: 0.7709 - val_loss: 0.0740 - val_accuracy: 0.7389\n",
      "Epoch 1039/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0736 - val_accuracy: 0.7388\n",
      "Epoch 1040/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0646 - accuracy: 0.7713 - val_loss: 0.0736 - val_accuracy: 0.7390\n",
      "Epoch 1041/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0646 - accuracy: 0.7706 - val_loss: 0.0740 - val_accuracy: 0.7383\n",
      "Epoch 1042/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0646 - accuracy: 0.7709 - val_loss: 0.0736 - val_accuracy: 0.7394\n",
      "Epoch 1043/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0645 - accuracy: 0.7713 - val_loss: 0.0735 - val_accuracy: 0.7403\n",
      "Epoch 1044/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0739 - val_accuracy: 0.7387\n",
      "Epoch 1045/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0645 - accuracy: 0.7712 - val_loss: 0.0736 - val_accuracy: 0.7403\n",
      "Epoch 1046/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0645 - accuracy: 0.7713 - val_loss: 0.0732 - val_accuracy: 0.7412\n",
      "Epoch 1047/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0645 - accuracy: 0.7712 - val_loss: 0.0740 - val_accuracy: 0.7380\n",
      "Epoch 1048/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0646 - accuracy: 0.7706 - val_loss: 0.0738 - val_accuracy: 0.7378\n",
      "Epoch 1049/5000\n",
      "11786/11786 [==============================] - 7s 622us/step - loss: 0.0645 - accuracy: 0.7714 - val_loss: 0.0743 - val_accuracy: 0.7365\n",
      "Epoch 1050/5000\n",
      "11786/11786 [==============================] - 7s 623us/step - loss: 0.0646 - accuracy: 0.7717 - val_loss: 0.0739 - val_accuracy: 0.7380\n",
      "Epoch 1051/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0645 - accuracy: 0.7713 - val_loss: 0.0742 - val_accuracy: 0.7386\n",
      "Epoch 1052/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0736 - val_accuracy: 0.7386\n",
      "Epoch 1053/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0646 - accuracy: 0.7709 - val_loss: 0.0740 - val_accuracy: 0.7373\n",
      "Epoch 1054/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0645 - accuracy: 0.7711 - val_loss: 0.0742 - val_accuracy: 0.7376\n",
      "Epoch 1055/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0745 - val_accuracy: 0.7382\n",
      "Epoch 1056/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0646 - accuracy: 0.7716 - val_loss: 0.0742 - val_accuracy: 0.7383\n",
      "Epoch 1057/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0646 - accuracy: 0.7712 - val_loss: 0.0742 - val_accuracy: 0.7383\n",
      "Epoch 1058/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0646 - accuracy: 0.7703 - val_loss: 0.0737 - val_accuracy: 0.7384\n",
      "Epoch 1059/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0646 - accuracy: 0.7714 - val_loss: 0.0739 - val_accuracy: 0.7399\n",
      "Epoch 1060/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0646 - accuracy: 0.7711 - val_loss: 0.0738 - val_accuracy: 0.7405\n",
      "Epoch 1061/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0646 - accuracy: 0.7708 - val_loss: 0.0741 - val_accuracy: 0.7377\n",
      "Epoch 1062/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0646 - accuracy: 0.7709 - val_loss: 0.0741 - val_accuracy: 0.7397\n",
      "Epoch 1063/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0645 - accuracy: 0.7714 - val_loss: 0.0742 - val_accuracy: 0.7357\n",
      "Epoch 1064/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0646 - accuracy: 0.7708 - val_loss: 0.0738 - val_accuracy: 0.7388\n",
      "Epoch 1065/5000\n",
      "11786/11786 [==============================] - 7s 619us/step - loss: 0.0646 - accuracy: 0.7715 - val_loss: 0.0735 - val_accuracy: 0.7402\n",
      "Epoch 1066/5000\n",
      "11786/11786 [==============================] - 7s 619us/step - loss: 0.0645 - accuracy: 0.7717 - val_loss: 0.0742 - val_accuracy: 0.7362\n",
      "Epoch 1067/5000\n",
      "11786/11786 [==============================] - 7s 621us/step - loss: 0.0646 - accuracy: 0.7718 - val_loss: 0.0746 - val_accuracy: 0.7374\n",
      "Epoch 1068/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0646 - accuracy: 0.7714 - val_loss: 0.0737 - val_accuracy: 0.7396\n",
      "Epoch 1069/5000\n",
      "11786/11786 [==============================] - 7s 623us/step - loss: 0.0646 - accuracy: 0.7710 - val_loss: 0.0734 - val_accuracy: 0.7400\n",
      "Epoch 1070/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0742 - val_accuracy: 0.7378\n",
      "Epoch 1071/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0646 - accuracy: 0.7710 - val_loss: 0.0736 - val_accuracy: 0.7390\n",
      "Epoch 1072/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0735 - val_accuracy: 0.7387\n",
      "Epoch 1073/5000\n",
      "11786/11786 [==============================] - 7s 623us/step - loss: 0.0645 - accuracy: 0.7714 - val_loss: 0.0739 - val_accuracy: 0.7391\n",
      "Epoch 1074/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0646 - accuracy: 0.7711 - val_loss: 0.0742 - val_accuracy: 0.7393\n",
      "Epoch 1075/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0741 - val_accuracy: 0.7391\n",
      "Epoch 1076/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0735 - val_accuracy: 0.7400\n",
      "Epoch 1077/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0645 - accuracy: 0.7712 - val_loss: 0.0737 - val_accuracy: 0.7379\n",
      "Epoch 1078/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0645 - accuracy: 0.7712 - val_loss: 0.0737 - val_accuracy: 0.7406\n",
      "Epoch 1079/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0644 - accuracy: 0.7720 - val_loss: 0.0740 - val_accuracy: 0.7370\n",
      "Epoch 1080/5000\n",
      "11786/11786 [==============================] - 7s 621us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0735 - val_accuracy: 0.7402\n",
      "Epoch 1081/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0645 - accuracy: 0.7722 - val_loss: 0.0736 - val_accuracy: 0.7388\n",
      "Epoch 1082/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0646 - accuracy: 0.7711 - val_loss: 0.0739 - val_accuracy: 0.7393\n",
      "Epoch 1083/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0644 - accuracy: 0.7720 - val_loss: 0.0747 - val_accuracy: 0.7347\n",
      "Epoch 1084/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0644 - accuracy: 0.7721 - val_loss: 0.0740 - val_accuracy: 0.7382\n",
      "Epoch 1085/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0645 - accuracy: 0.7717 - val_loss: 0.0738 - val_accuracy: 0.7392\n",
      "Epoch 1086/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0737 - val_accuracy: 0.7380\n",
      "Epoch 1087/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0645 - accuracy: 0.7714 - val_loss: 0.0741 - val_accuracy: 0.7387\n",
      "Epoch 1088/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0742 - val_accuracy: 0.7373\n",
      "Epoch 1089/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0740 - val_accuracy: 0.7377\n",
      "Epoch 1090/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0645 - accuracy: 0.7723 - val_loss: 0.0739 - val_accuracy: 0.7384\n",
      "Epoch 1091/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0645 - accuracy: 0.7710 - val_loss: 0.0736 - val_accuracy: 0.7388\n",
      "Epoch 1092/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0644 - accuracy: 0.7717 - val_loss: 0.0741 - val_accuracy: 0.7395\n",
      "Epoch 1093/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0645 - accuracy: 0.7718 - val_loss: 0.0740 - val_accuracy: 0.7382\n",
      "Epoch 1094/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0737 - val_accuracy: 0.7383\n",
      "Epoch 1095/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0645 - accuracy: 0.7718 - val_loss: 0.0741 - val_accuracy: 0.7377\n",
      "Epoch 1096/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0739 - val_accuracy: 0.7360\n",
      "Epoch 1097/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0645 - accuracy: 0.7713 - val_loss: 0.0744 - val_accuracy: 0.7362\n",
      "Epoch 1098/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0646 - accuracy: 0.7711 - val_loss: 0.0736 - val_accuracy: 0.7383\n",
      "Epoch 1099/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0644 - accuracy: 0.7721 - val_loss: 0.0742 - val_accuracy: 0.7389\n",
      "Epoch 1100/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0644 - accuracy: 0.7717 - val_loss: 0.0744 - val_accuracy: 0.7372\n",
      "Epoch 1101/5000\n",
      "11786/11786 [==============================] - 7s 618us/step - loss: 0.0645 - accuracy: 0.7712 - val_loss: 0.0737 - val_accuracy: 0.7384\n",
      "Epoch 1102/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0740 - val_accuracy: 0.7373\n",
      "Epoch 1103/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0645 - accuracy: 0.7714 - val_loss: 0.0742 - val_accuracy: 0.7407\n",
      "Epoch 1104/5000\n",
      "11786/11786 [==============================] - 7s 623us/step - loss: 0.0646 - accuracy: 0.7715 - val_loss: 0.0741 - val_accuracy: 0.7401\n",
      "Epoch 1105/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0646 - accuracy: 0.7712 - val_loss: 0.0738 - val_accuracy: 0.7379\n",
      "Epoch 1106/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0737 - val_accuracy: 0.7392\n",
      "Epoch 1107/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0645 - accuracy: 0.7717 - val_loss: 0.0739 - val_accuracy: 0.7389\n",
      "Epoch 1108/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0742 - val_accuracy: 0.7380\n",
      "Epoch 1109/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0645 - accuracy: 0.7717 - val_loss: 0.0743 - val_accuracy: 0.7377\n",
      "Epoch 1110/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0646 - accuracy: 0.7710 - val_loss: 0.0741 - val_accuracy: 0.7394\n",
      "Epoch 1111/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0645 - accuracy: 0.7717 - val_loss: 0.0741 - val_accuracy: 0.7383\n",
      "Epoch 1112/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0646 - accuracy: 0.7715 - val_loss: 0.0733 - val_accuracy: 0.7410\n",
      "Epoch 1113/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0645 - accuracy: 0.7714 - val_loss: 0.0737 - val_accuracy: 0.7382\n",
      "Epoch 1114/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0645 - accuracy: 0.7714 - val_loss: 0.0742 - val_accuracy: 0.7393\n",
      "Epoch 1115/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0646 - accuracy: 0.7712 - val_loss: 0.0740 - val_accuracy: 0.7387\n",
      "Epoch 1116/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0645 - accuracy: 0.7717 - val_loss: 0.0738 - val_accuracy: 0.7399\n",
      "Epoch 1117/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0645 - accuracy: 0.7712 - val_loss: 0.0740 - val_accuracy: 0.7380\n",
      "Epoch 1118/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0645 - accuracy: 0.7714 - val_loss: 0.0738 - val_accuracy: 0.7393\n",
      "Epoch 1119/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0645 - accuracy: 0.7713 - val_loss: 0.0742 - val_accuracy: 0.7381\n",
      "Epoch 1120/5000\n",
      "11786/11786 [==============================] - 7s 623us/step - loss: 0.0645 - accuracy: 0.7712 - val_loss: 0.0737 - val_accuracy: 0.7388\n",
      "Epoch 1121/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0645 - accuracy: 0.7717 - val_loss: 0.0743 - val_accuracy: 0.7370\n",
      "Epoch 1122/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0645 - accuracy: 0.7714 - val_loss: 0.0746 - val_accuracy: 0.7378\n",
      "Epoch 1123/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0646 - accuracy: 0.7712 - val_loss: 0.0742 - val_accuracy: 0.7365\n",
      "Epoch 1124/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0645 - accuracy: 0.7713 - val_loss: 0.0738 - val_accuracy: 0.7400\n",
      "Epoch 1125/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0645 - accuracy: 0.7709 - val_loss: 0.0743 - val_accuracy: 0.7381\n",
      "Epoch 1126/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0645 - accuracy: 0.7720 - val_loss: 0.0737 - val_accuracy: 0.7399\n",
      "Epoch 1127/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0739 - val_accuracy: 0.7396\n",
      "Epoch 1128/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0645 - accuracy: 0.7714 - val_loss: 0.0739 - val_accuracy: 0.7387\n",
      "Epoch 1129/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0645 - accuracy: 0.7711 - val_loss: 0.0745 - val_accuracy: 0.7381\n",
      "Epoch 1130/5000\n",
      "11786/11786 [==============================] - 7s 620us/step - loss: 0.0646 - accuracy: 0.7714 - val_loss: 0.0736 - val_accuracy: 0.7388\n",
      "Epoch 1131/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0741 - val_accuracy: 0.7401\n",
      "Epoch 1132/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0738 - val_accuracy: 0.7379\n",
      "Epoch 1133/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0645 - accuracy: 0.7711 - val_loss: 0.0740 - val_accuracy: 0.7392\n",
      "Epoch 1134/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0736 - val_accuracy: 0.7393\n",
      "Epoch 1135/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0646 - accuracy: 0.7712 - val_loss: 0.0736 - val_accuracy: 0.7403\n",
      "Epoch 1136/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0646 - accuracy: 0.7708 - val_loss: 0.0736 - val_accuracy: 0.7386\n",
      "Epoch 1137/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0737 - val_accuracy: 0.7387\n",
      "Epoch 1138/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0645 - accuracy: 0.7714 - val_loss: 0.0743 - val_accuracy: 0.7364\n",
      "Epoch 1139/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0645 - accuracy: 0.7717 - val_loss: 0.0740 - val_accuracy: 0.7365\n",
      "Epoch 1140/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0645 - accuracy: 0.7710 - val_loss: 0.0736 - val_accuracy: 0.7390\n",
      "Epoch 1141/5000\n",
      "11786/11786 [==============================] - 7s 621us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0735 - val_accuracy: 0.7393\n",
      "Epoch 1142/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0645 - accuracy: 0.7717 - val_loss: 0.0738 - val_accuracy: 0.7387\n",
      "Epoch 1143/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0645 - accuracy: 0.7718 - val_loss: 0.0735 - val_accuracy: 0.7405\n",
      "Epoch 1144/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0739 - val_accuracy: 0.7368\n",
      "Epoch 1145/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0644 - accuracy: 0.7714 - val_loss: 0.0739 - val_accuracy: 0.7393\n",
      "Epoch 1146/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0645 - accuracy: 0.7714 - val_loss: 0.0735 - val_accuracy: 0.7407\n",
      "Epoch 1147/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0739 - val_accuracy: 0.7380\n",
      "Epoch 1148/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0644 - accuracy: 0.7717 - val_loss: 0.0739 - val_accuracy: 0.7391\n",
      "Epoch 1149/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0645 - accuracy: 0.7723 - val_loss: 0.0745 - val_accuracy: 0.7364\n",
      "Epoch 1150/5000\n",
      "11786/11786 [==============================] - 7s 623us/step - loss: 0.0645 - accuracy: 0.7712 - val_loss: 0.0738 - val_accuracy: 0.7384\n",
      "Epoch 1151/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0645 - accuracy: 0.7718 - val_loss: 0.0742 - val_accuracy: 0.7376\n",
      "Epoch 1152/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0645 - accuracy: 0.7712 - val_loss: 0.0739 - val_accuracy: 0.7383\n",
      "Epoch 1153/5000\n",
      "11786/11786 [==============================] - 7s 622us/step - loss: 0.0645 - accuracy: 0.7708 - val_loss: 0.0739 - val_accuracy: 0.7382\n",
      "Epoch 1154/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0645 - accuracy: 0.7713 - val_loss: 0.0741 - val_accuracy: 0.7387\n",
      "Epoch 1155/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0647 - accuracy: 0.7703 - val_loss: 0.0743 - val_accuracy: 0.7388\n",
      "Epoch 1156/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0735 - val_accuracy: 0.7408\n",
      "Epoch 1157/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0645 - accuracy: 0.7717 - val_loss: 0.0748 - val_accuracy: 0.7369\n",
      "Epoch 1158/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0742 - val_accuracy: 0.7377\n",
      "Epoch 1159/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0645 - accuracy: 0.7709 - val_loss: 0.0744 - val_accuracy: 0.7381\n",
      "Epoch 1160/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0644 - accuracy: 0.7719 - val_loss: 0.0738 - val_accuracy: 0.7391\n",
      "Epoch 1161/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0645 - accuracy: 0.7717 - val_loss: 0.0740 - val_accuracy: 0.7393\n",
      "Epoch 1162/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0644 - accuracy: 0.7717 - val_loss: 0.0736 - val_accuracy: 0.7392\n",
      "Epoch 1163/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0740 - val_accuracy: 0.7392\n",
      "Epoch 1164/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0646 - accuracy: 0.7711 - val_loss: 0.0746 - val_accuracy: 0.7391\n",
      "Epoch 1165/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0737 - val_accuracy: 0.7406\n",
      "Epoch 1166/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0751 - val_accuracy: 0.7365\n",
      "Epoch 1167/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0644 - accuracy: 0.7720 - val_loss: 0.0740 - val_accuracy: 0.7371\n",
      "Epoch 1168/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0739 - val_accuracy: 0.7379\n",
      "Epoch 1169/5000\n",
      "11786/11786 [==============================] - 7s 622us/step - loss: 0.0645 - accuracy: 0.7710 - val_loss: 0.0740 - val_accuracy: 0.7393\n",
      "Epoch 1170/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0644 - accuracy: 0.7718 - val_loss: 0.0735 - val_accuracy: 0.7396\n",
      "Epoch 1171/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0644 - accuracy: 0.7719 - val_loss: 0.0732 - val_accuracy: 0.7379\n",
      "Epoch 1172/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0644 - accuracy: 0.7717 - val_loss: 0.0734 - val_accuracy: 0.7402\n",
      "Epoch 1173/5000\n",
      "11786/11786 [==============================] - 7s 619us/step - loss: 0.0645 - accuracy: 0.7713 - val_loss: 0.0743 - val_accuracy: 0.7369\n",
      "Epoch 1174/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0645 - accuracy: 0.7718 - val_loss: 0.0736 - val_accuracy: 0.7386\n",
      "Epoch 1175/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0645 - accuracy: 0.7713 - val_loss: 0.0739 - val_accuracy: 0.7401\n",
      "Epoch 1176/5000\n",
      "11786/11786 [==============================] - 7s 623us/step - loss: 0.0645 - accuracy: 0.7713 - val_loss: 0.0742 - val_accuracy: 0.7392\n",
      "Epoch 1177/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0646 - accuracy: 0.7716 - val_loss: 0.0749 - val_accuracy: 0.7357\n",
      "Epoch 1178/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0743 - val_accuracy: 0.7389\n",
      "Epoch 1179/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0646 - accuracy: 0.7713 - val_loss: 0.0743 - val_accuracy: 0.7384\n",
      "Epoch 1180/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0646 - accuracy: 0.7717 - val_loss: 0.0744 - val_accuracy: 0.7368\n",
      "Epoch 1181/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0644 - accuracy: 0.7716 - val_loss: 0.0738 - val_accuracy: 0.7395\n",
      "Epoch 1182/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0646 - accuracy: 0.7714 - val_loss: 0.0743 - val_accuracy: 0.7380\n",
      "Epoch 1183/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0644 - accuracy: 0.7722 - val_loss: 0.0734 - val_accuracy: 0.7398\n",
      "Epoch 1184/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0738 - val_accuracy: 0.7395\n",
      "Epoch 1185/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0645 - accuracy: 0.7721 - val_loss: 0.0747 - val_accuracy: 0.7350\n",
      "Epoch 1186/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0645 - accuracy: 0.7717 - val_loss: 0.0743 - val_accuracy: 0.7365\n",
      "Epoch 1187/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0646 - accuracy: 0.7714 - val_loss: 0.0750 - val_accuracy: 0.7354\n",
      "Epoch 1188/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0645 - accuracy: 0.7713 - val_loss: 0.0735 - val_accuracy: 0.7386\n",
      "Epoch 1189/5000\n",
      "11786/11786 [==============================] - 8s 636us/step - loss: 0.0645 - accuracy: 0.7720 - val_loss: 0.0744 - val_accuracy: 0.7385\n",
      "Epoch 1190/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0644 - accuracy: 0.7715 - val_loss: 0.0744 - val_accuracy: 0.7395\n",
      "Epoch 1191/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0736 - val_accuracy: 0.7388\n",
      "Epoch 1192/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0644 - accuracy: 0.7717 - val_loss: 0.0749 - val_accuracy: 0.7355\n",
      "Epoch 1193/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0645 - accuracy: 0.7721 - val_loss: 0.0736 - val_accuracy: 0.7383\n",
      "Epoch 1194/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0646 - accuracy: 0.7718 - val_loss: 0.0738 - val_accuracy: 0.7400\n",
      "Epoch 1195/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0644 - accuracy: 0.7718 - val_loss: 0.0739 - val_accuracy: 0.7389\n",
      "Epoch 1196/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0645 - accuracy: 0.7712 - val_loss: 0.0739 - val_accuracy: 0.7384\n",
      "Epoch 1197/5000\n",
      "11786/11786 [==============================] - 7s 623us/step - loss: 0.0645 - accuracy: 0.7712 - val_loss: 0.0738 - val_accuracy: 0.7386\n",
      "Epoch 1198/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0644 - accuracy: 0.7715 - val_loss: 0.0735 - val_accuracy: 0.7414\n",
      "Epoch 1199/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0644 - accuracy: 0.7718 - val_loss: 0.0742 - val_accuracy: 0.7379\n",
      "Epoch 1200/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0645 - accuracy: 0.7717 - val_loss: 0.0743 - val_accuracy: 0.7393\n",
      "Epoch 1201/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0741 - val_accuracy: 0.7400\n",
      "Epoch 1202/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0644 - accuracy: 0.7722 - val_loss: 0.0740 - val_accuracy: 0.7377\n",
      "Epoch 1203/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0737 - val_accuracy: 0.7394\n",
      "Epoch 1204/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0645 - accuracy: 0.7713 - val_loss: 0.0738 - val_accuracy: 0.7384\n",
      "Epoch 1205/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0644 - accuracy: 0.7717 - val_loss: 0.0737 - val_accuracy: 0.7403\n",
      "Epoch 1206/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0644 - accuracy: 0.7719 - val_loss: 0.0739 - val_accuracy: 0.7391\n",
      "Epoch 1207/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0735 - val_accuracy: 0.7404\n",
      "Epoch 1208/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0645 - accuracy: 0.7718 - val_loss: 0.0742 - val_accuracy: 0.7391\n",
      "Epoch 1209/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0736 - val_accuracy: 0.7378\n",
      "Epoch 1210/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0645 - accuracy: 0.7710 - val_loss: 0.0741 - val_accuracy: 0.7378\n",
      "Epoch 1211/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0645 - accuracy: 0.7720 - val_loss: 0.0744 - val_accuracy: 0.7362\n",
      "Epoch 1212/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0645 - accuracy: 0.7717 - val_loss: 0.0745 - val_accuracy: 0.7374\n",
      "Epoch 1213/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0644 - accuracy: 0.7723 - val_loss: 0.0748 - val_accuracy: 0.7363\n",
      "Epoch 1214/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0743 - val_accuracy: 0.7382\n",
      "Epoch 1215/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0646 - accuracy: 0.7715 - val_loss: 0.0740 - val_accuracy: 0.7397\n",
      "Epoch 1216/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0644 - accuracy: 0.7719 - val_loss: 0.0745 - val_accuracy: 0.7360\n",
      "Epoch 1217/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0736 - val_accuracy: 0.7397\n",
      "Epoch 1218/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0645 - accuracy: 0.7720 - val_loss: 0.0739 - val_accuracy: 0.7387\n",
      "Epoch 1219/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0645 - accuracy: 0.7718 - val_loss: 0.0747 - val_accuracy: 0.7377\n",
      "Epoch 1220/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0735 - val_accuracy: 0.7406\n",
      "Epoch 1221/5000\n",
      "11786/11786 [==============================] - 7s 622us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0736 - val_accuracy: 0.7410\n",
      "Epoch 1222/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0748 - val_accuracy: 0.7358\n",
      "Epoch 1223/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0645 - accuracy: 0.7717 - val_loss: 0.0744 - val_accuracy: 0.7384\n",
      "Epoch 1224/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0645 - accuracy: 0.7718 - val_loss: 0.0740 - val_accuracy: 0.7401\n",
      "Epoch 1225/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0645 - accuracy: 0.7717 - val_loss: 0.0743 - val_accuracy: 0.7382\n",
      "Epoch 1226/5000\n",
      "11786/11786 [==============================] - 7s 620us/step - loss: 0.0646 - accuracy: 0.7715 - val_loss: 0.0740 - val_accuracy: 0.7391\n",
      "Epoch 1227/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0644 - accuracy: 0.7718 - val_loss: 0.0744 - val_accuracy: 0.7373\n",
      "Epoch 1228/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0738 - val_accuracy: 0.7388\n",
      "Epoch 1229/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0747 - val_accuracy: 0.7365\n",
      "Epoch 1230/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0645 - accuracy: 0.7717 - val_loss: 0.0744 - val_accuracy: 0.7383\n",
      "Epoch 1231/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0645 - accuracy: 0.7714 - val_loss: 0.0746 - val_accuracy: 0.7342\n",
      "Epoch 1232/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0644 - accuracy: 0.7714 - val_loss: 0.0746 - val_accuracy: 0.7373\n",
      "Epoch 1233/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0645 - accuracy: 0.7714 - val_loss: 0.0737 - val_accuracy: 0.7387\n",
      "Epoch 1234/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0644 - accuracy: 0.7719 - val_loss: 0.0740 - val_accuracy: 0.7397\n",
      "Epoch 1235/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0645 - accuracy: 0.7711 - val_loss: 0.0743 - val_accuracy: 0.7378\n",
      "Epoch 1236/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0739 - val_accuracy: 0.7388\n",
      "Epoch 1237/5000\n",
      "11786/11786 [==============================] - 7s 623us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0738 - val_accuracy: 0.7373\n",
      "Epoch 1238/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0646 - accuracy: 0.7710 - val_loss: 0.0738 - val_accuracy: 0.7384\n",
      "Epoch 1239/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0738 - val_accuracy: 0.7387\n",
      "Epoch 1240/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0738 - val_accuracy: 0.7391\n",
      "Epoch 1241/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0646 - accuracy: 0.7710 - val_loss: 0.0740 - val_accuracy: 0.7392\n",
      "Epoch 1242/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0643 - accuracy: 0.7724 - val_loss: 0.0740 - val_accuracy: 0.7388\n",
      "Epoch 1243/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0644 - accuracy: 0.7719 - val_loss: 0.0739 - val_accuracy: 0.7375\n",
      "Epoch 1244/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0739 - val_accuracy: 0.7390\n",
      "Epoch 1245/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0644 - accuracy: 0.7722 - val_loss: 0.0745 - val_accuracy: 0.7397\n",
      "Epoch 1246/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0644 - accuracy: 0.7724 - val_loss: 0.0741 - val_accuracy: 0.7367\n",
      "Epoch 1247/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0644 - accuracy: 0.7724 - val_loss: 0.0747 - val_accuracy: 0.7367\n",
      "Epoch 1248/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0644 - accuracy: 0.7722 - val_loss: 0.0746 - val_accuracy: 0.7386\n",
      "Epoch 1249/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0644 - accuracy: 0.7718 - val_loss: 0.0741 - val_accuracy: 0.7364\n",
      "Epoch 1250/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0742 - val_accuracy: 0.7369\n",
      "Epoch 1251/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0737 - val_accuracy: 0.7401\n",
      "Epoch 1252/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0644 - accuracy: 0.7720 - val_loss: 0.0735 - val_accuracy: 0.7404\n",
      "Epoch 1253/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0645 - accuracy: 0.7714 - val_loss: 0.0738 - val_accuracy: 0.7395\n",
      "Epoch 1254/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0644 - accuracy: 0.7718 - val_loss: 0.0737 - val_accuracy: 0.7393\n",
      "Epoch 1255/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0644 - accuracy: 0.7718 - val_loss: 0.0738 - val_accuracy: 0.7388\n",
      "Epoch 1256/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0746 - val_accuracy: 0.7368\n",
      "Epoch 1257/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0646 - accuracy: 0.7715 - val_loss: 0.0741 - val_accuracy: 0.7392\n",
      "Epoch 1258/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0645 - accuracy: 0.7717 - val_loss: 0.0742 - val_accuracy: 0.7379\n",
      "Epoch 1259/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0644 - accuracy: 0.7717 - val_loss: 0.0739 - val_accuracy: 0.7386\n",
      "Epoch 1260/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0645 - accuracy: 0.7712 - val_loss: 0.0746 - val_accuracy: 0.7368\n",
      "Epoch 1261/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0740 - val_accuracy: 0.7395\n",
      "Epoch 1262/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0645 - accuracy: 0.7717 - val_loss: 0.0736 - val_accuracy: 0.7387\n",
      "Epoch 1263/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0645 - accuracy: 0.7714 - val_loss: 0.0738 - val_accuracy: 0.7387\n",
      "Epoch 1264/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0644 - accuracy: 0.7714 - val_loss: 0.0741 - val_accuracy: 0.7388\n",
      "Epoch 1265/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0646 - accuracy: 0.7713 - val_loss: 0.0751 - val_accuracy: 0.7378\n",
      "Epoch 1266/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0742 - val_accuracy: 0.7372\n",
      "Epoch 1267/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0645 - accuracy: 0.7718 - val_loss: 0.0741 - val_accuracy: 0.7393\n",
      "Epoch 1268/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0644 - accuracy: 0.7716 - val_loss: 0.0743 - val_accuracy: 0.7373\n",
      "Epoch 1269/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0645 - accuracy: 0.7717 - val_loss: 0.0742 - val_accuracy: 0.7379\n",
      "Epoch 1270/5000\n",
      "11786/11786 [==============================] - 7s 621us/step - loss: 0.0644 - accuracy: 0.7729 - val_loss: 0.0747 - val_accuracy: 0.7386\n",
      "Epoch 1271/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0645 - accuracy: 0.7717 - val_loss: 0.0742 - val_accuracy: 0.7383\n",
      "Epoch 1272/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0745 - val_accuracy: 0.7376\n",
      "Epoch 1273/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0644 - accuracy: 0.7717 - val_loss: 0.0744 - val_accuracy: 0.7388\n",
      "Epoch 1274/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0644 - accuracy: 0.7721 - val_loss: 0.0738 - val_accuracy: 0.7395\n",
      "Epoch 1275/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0644 - accuracy: 0.7716 - val_loss: 0.0741 - val_accuracy: 0.7376\n",
      "Epoch 1276/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0644 - accuracy: 0.7715 - val_loss: 0.0737 - val_accuracy: 0.7390\n",
      "Epoch 1277/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0644 - accuracy: 0.7716 - val_loss: 0.0743 - val_accuracy: 0.7379\n",
      "Epoch 1278/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0644 - accuracy: 0.7718 - val_loss: 0.0741 - val_accuracy: 0.7394\n",
      "Epoch 1279/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0644 - accuracy: 0.7713 - val_loss: 0.0741 - val_accuracy: 0.7399\n",
      "Epoch 1280/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0741 - val_accuracy: 0.7386\n",
      "Epoch 1281/5000\n",
      "11786/11786 [==============================] - 8s 636us/step - loss: 0.0644 - accuracy: 0.7723 - val_loss: 0.0738 - val_accuracy: 0.7397\n",
      "Epoch 1282/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0645 - accuracy: 0.7717 - val_loss: 0.0737 - val_accuracy: 0.7382\n",
      "Epoch 1283/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0644 - accuracy: 0.7718 - val_loss: 0.0738 - val_accuracy: 0.7369\n",
      "Epoch 1284/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0645 - accuracy: 0.7718 - val_loss: 0.0741 - val_accuracy: 0.7377\n",
      "Epoch 1285/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0644 - accuracy: 0.7719 - val_loss: 0.0745 - val_accuracy: 0.7385\n",
      "Epoch 1286/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0644 - accuracy: 0.7718 - val_loss: 0.0744 - val_accuracy: 0.7376\n",
      "Epoch 1287/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0643 - accuracy: 0.7721 - val_loss: 0.0743 - val_accuracy: 0.7410\n",
      "Epoch 1288/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0645 - accuracy: 0.7720 - val_loss: 0.0742 - val_accuracy: 0.7369\n",
      "Epoch 1289/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0645 - accuracy: 0.7720 - val_loss: 0.0743 - val_accuracy: 0.7396\n",
      "Epoch 1290/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0644 - accuracy: 0.7720 - val_loss: 0.0738 - val_accuracy: 0.7399\n",
      "Epoch 1291/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0645 - accuracy: 0.7714 - val_loss: 0.0743 - val_accuracy: 0.7389\n",
      "Epoch 1292/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0643 - accuracy: 0.7724 - val_loss: 0.0739 - val_accuracy: 0.7397\n",
      "Epoch 1293/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0644 - accuracy: 0.7718 - val_loss: 0.0740 - val_accuracy: 0.7395\n",
      "Epoch 1294/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0644 - accuracy: 0.7721 - val_loss: 0.0734 - val_accuracy: 0.7384\n",
      "Epoch 1295/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0742 - val_accuracy: 0.7392\n",
      "Epoch 1296/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0644 - accuracy: 0.7715 - val_loss: 0.0738 - val_accuracy: 0.7398\n",
      "Epoch 1297/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0745 - val_accuracy: 0.7371\n",
      "Epoch 1298/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0644 - accuracy: 0.7721 - val_loss: 0.0742 - val_accuracy: 0.7386\n",
      "Epoch 1299/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0645 - accuracy: 0.7717 - val_loss: 0.0740 - val_accuracy: 0.7395\n",
      "Epoch 1300/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0644 - accuracy: 0.7717 - val_loss: 0.0743 - val_accuracy: 0.7379\n",
      "Epoch 1301/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0644 - accuracy: 0.7715 - val_loss: 0.0736 - val_accuracy: 0.7397\n",
      "Epoch 1302/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0644 - accuracy: 0.7725 - val_loss: 0.0740 - val_accuracy: 0.7397\n",
      "Epoch 1303/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0645 - accuracy: 0.7720 - val_loss: 0.0740 - val_accuracy: 0.7388\n",
      "Epoch 1304/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0645 - accuracy: 0.7714 - val_loss: 0.0745 - val_accuracy: 0.7397\n",
      "Epoch 1305/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0738 - val_accuracy: 0.7390\n",
      "Epoch 1306/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0644 - accuracy: 0.7718 - val_loss: 0.0738 - val_accuracy: 0.7396\n",
      "Epoch 1307/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0644 - accuracy: 0.7723 - val_loss: 0.0739 - val_accuracy: 0.7398\n",
      "Epoch 1308/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0644 - accuracy: 0.7717 - val_loss: 0.0743 - val_accuracy: 0.7387\n",
      "Epoch 1309/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0644 - accuracy: 0.7717 - val_loss: 0.0745 - val_accuracy: 0.7380\n",
      "Epoch 1310/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0644 - accuracy: 0.7720 - val_loss: 0.0744 - val_accuracy: 0.7376\n",
      "Epoch 1311/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0645 - accuracy: 0.7717 - val_loss: 0.0746 - val_accuracy: 0.7369\n",
      "Epoch 1312/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0643 - accuracy: 0.7720 - val_loss: 0.0739 - val_accuracy: 0.7392\n",
      "Epoch 1313/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0644 - accuracy: 0.7722 - val_loss: 0.0743 - val_accuracy: 0.7397\n",
      "Epoch 1314/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0645 - accuracy: 0.7720 - val_loss: 0.0749 - val_accuracy: 0.7328\n",
      "Epoch 1315/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0645 - accuracy: 0.7717 - val_loss: 0.0747 - val_accuracy: 0.7362\n",
      "Epoch 1316/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0738 - val_accuracy: 0.7378\n",
      "Epoch 1317/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0645 - accuracy: 0.7721 - val_loss: 0.0744 - val_accuracy: 0.7365\n",
      "Epoch 1318/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0644 - accuracy: 0.7721 - val_loss: 0.0743 - val_accuracy: 0.7373\n",
      "Epoch 1319/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0746 - val_accuracy: 0.7372\n",
      "Epoch 1320/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0644 - accuracy: 0.7722 - val_loss: 0.0744 - val_accuracy: 0.7372\n",
      "Epoch 1321/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0644 - accuracy: 0.7720 - val_loss: 0.0739 - val_accuracy: 0.7382\n",
      "Epoch 1322/5000\n",
      "11786/11786 [==============================] - 8s 636us/step - loss: 0.0645 - accuracy: 0.7717 - val_loss: 0.0746 - val_accuracy: 0.7361\n",
      "Epoch 1323/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0739 - val_accuracy: 0.7374\n",
      "Epoch 1324/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0742 - val_accuracy: 0.7384\n",
      "Epoch 1325/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0644 - accuracy: 0.7718 - val_loss: 0.0742 - val_accuracy: 0.7374\n",
      "Epoch 1326/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0740 - val_accuracy: 0.7393\n",
      "Epoch 1327/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0645 - accuracy: 0.7717 - val_loss: 0.0743 - val_accuracy: 0.7391\n",
      "Epoch 1328/5000\n",
      "11786/11786 [==============================] - 7s 623us/step - loss: 0.0646 - accuracy: 0.7716 - val_loss: 0.0742 - val_accuracy: 0.7389\n",
      "Epoch 1329/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0743 - val_accuracy: 0.7364\n",
      "Epoch 1330/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0646 - accuracy: 0.7711 - val_loss: 0.0746 - val_accuracy: 0.7384\n",
      "Epoch 1331/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0644 - accuracy: 0.7720 - val_loss: 0.0741 - val_accuracy: 0.7369\n",
      "Epoch 1332/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0645 - accuracy: 0.7717 - val_loss: 0.0743 - val_accuracy: 0.7383\n",
      "Epoch 1333/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0644 - accuracy: 0.7719 - val_loss: 0.0746 - val_accuracy: 0.7372\n",
      "Epoch 1334/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0644 - accuracy: 0.7717 - val_loss: 0.0741 - val_accuracy: 0.7375\n",
      "Epoch 1335/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0646 - accuracy: 0.7717 - val_loss: 0.0745 - val_accuracy: 0.7356\n",
      "Epoch 1336/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0644 - accuracy: 0.7720 - val_loss: 0.0740 - val_accuracy: 0.7395\n",
      "Epoch 1337/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0644 - accuracy: 0.7719 - val_loss: 0.0741 - val_accuracy: 0.7367\n",
      "Epoch 1338/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0645 - accuracy: 0.7717 - val_loss: 0.0745 - val_accuracy: 0.7372\n",
      "Epoch 1339/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0645 - accuracy: 0.7718 - val_loss: 0.0742 - val_accuracy: 0.7380\n",
      "Epoch 1340/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0645 - accuracy: 0.7713 - val_loss: 0.0739 - val_accuracy: 0.7381\n",
      "Epoch 1341/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0645 - accuracy: 0.7714 - val_loss: 0.0748 - val_accuracy: 0.7371\n",
      "Epoch 1342/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0740 - val_accuracy: 0.7373\n",
      "Epoch 1343/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0645 - accuracy: 0.7717 - val_loss: 0.0742 - val_accuracy: 0.7366\n",
      "Epoch 1344/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0644 - accuracy: 0.7723 - val_loss: 0.0740 - val_accuracy: 0.7373\n",
      "Epoch 1345/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0644 - accuracy: 0.7721 - val_loss: 0.0745 - val_accuracy: 0.7366\n",
      "Epoch 1346/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0644 - accuracy: 0.7719 - val_loss: 0.0738 - val_accuracy: 0.7392\n",
      "Epoch 1347/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0644 - accuracy: 0.7716 - val_loss: 0.0737 - val_accuracy: 0.7383\n",
      "Epoch 1348/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0741 - val_accuracy: 0.7399\n",
      "Epoch 1349/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0646 - accuracy: 0.7712 - val_loss: 0.0736 - val_accuracy: 0.7382\n",
      "Epoch 1350/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0646 - accuracy: 0.7715 - val_loss: 0.0740 - val_accuracy: 0.7372\n",
      "Epoch 1351/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0746 - val_accuracy: 0.7373\n",
      "Epoch 1352/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0645 - accuracy: 0.7722 - val_loss: 0.0741 - val_accuracy: 0.7412\n",
      "Epoch 1353/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0646 - accuracy: 0.7715 - val_loss: 0.0742 - val_accuracy: 0.7397\n",
      "Epoch 1354/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0644 - accuracy: 0.7718 - val_loss: 0.0741 - val_accuracy: 0.7371\n",
      "Epoch 1355/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0645 - accuracy: 0.7714 - val_loss: 0.0756 - val_accuracy: 0.7360\n",
      "Epoch 1356/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0741 - val_accuracy: 0.7358\n",
      "Epoch 1357/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0646 - accuracy: 0.7714 - val_loss: 0.0742 - val_accuracy: 0.7399\n",
      "Epoch 1358/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0645 - accuracy: 0.7721 - val_loss: 0.0742 - val_accuracy: 0.7399\n",
      "Epoch 1359/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0645 - accuracy: 0.7718 - val_loss: 0.0738 - val_accuracy: 0.7385\n",
      "Epoch 1360/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0645 - accuracy: 0.7711 - val_loss: 0.0735 - val_accuracy: 0.7402\n",
      "Epoch 1361/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0744 - val_accuracy: 0.7376\n",
      "Epoch 1362/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0741 - val_accuracy: 0.7380\n",
      "Epoch 1363/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0743 - val_accuracy: 0.7371\n",
      "Epoch 1364/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0748 - val_accuracy: 0.7392\n",
      "Epoch 1365/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0645 - accuracy: 0.7713 - val_loss: 0.0752 - val_accuracy: 0.7352\n",
      "Epoch 1366/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0740 - val_accuracy: 0.7390\n",
      "Epoch 1367/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0747 - val_accuracy: 0.7380\n",
      "Epoch 1368/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0738 - val_accuracy: 0.7395\n",
      "Epoch 1369/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0645 - accuracy: 0.7713 - val_loss: 0.0742 - val_accuracy: 0.7364\n",
      "Epoch 1370/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0646 - accuracy: 0.7713 - val_loss: 0.0741 - val_accuracy: 0.7385\n",
      "Epoch 1371/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0644 - accuracy: 0.7721 - val_loss: 0.0737 - val_accuracy: 0.7387\n",
      "Epoch 1372/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0644 - accuracy: 0.7720 - val_loss: 0.0738 - val_accuracy: 0.7376\n",
      "Epoch 1373/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0644 - accuracy: 0.7718 - val_loss: 0.0740 - val_accuracy: 0.7391\n",
      "Epoch 1374/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0644 - accuracy: 0.7725 - val_loss: 0.0734 - val_accuracy: 0.7394\n",
      "Epoch 1375/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0742 - val_accuracy: 0.7376\n",
      "Epoch 1376/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0645 - accuracy: 0.7718 - val_loss: 0.0738 - val_accuracy: 0.7392\n",
      "Epoch 1377/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0645 - accuracy: 0.7721 - val_loss: 0.0745 - val_accuracy: 0.7379\n",
      "Epoch 1378/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0645 - accuracy: 0.7718 - val_loss: 0.0750 - val_accuracy: 0.7361\n",
      "Epoch 1379/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0644 - accuracy: 0.7722 - val_loss: 0.0737 - val_accuracy: 0.7397\n",
      "Epoch 1380/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0743 - val_accuracy: 0.7390\n",
      "Epoch 1381/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0645 - accuracy: 0.7720 - val_loss: 0.0741 - val_accuracy: 0.7381\n",
      "Epoch 1382/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0738 - val_accuracy: 0.7396\n",
      "Epoch 1383/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0645 - accuracy: 0.7723 - val_loss: 0.0741 - val_accuracy: 0.7385\n",
      "Epoch 1384/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0644 - accuracy: 0.7720 - val_loss: 0.0739 - val_accuracy: 0.7405\n",
      "Epoch 1385/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0644 - accuracy: 0.7717 - val_loss: 0.0744 - val_accuracy: 0.7360\n",
      "Epoch 1386/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0646 - accuracy: 0.7718 - val_loss: 0.0740 - val_accuracy: 0.7388\n",
      "Epoch 1387/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0645 - accuracy: 0.7714 - val_loss: 0.0738 - val_accuracy: 0.7400\n",
      "Epoch 1388/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0743 - val_accuracy: 0.7403\n",
      "Epoch 1389/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0645 - accuracy: 0.7720 - val_loss: 0.0739 - val_accuracy: 0.7400\n",
      "Epoch 1390/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0644 - accuracy: 0.7719 - val_loss: 0.0743 - val_accuracy: 0.7394\n",
      "Epoch 1391/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0740 - val_accuracy: 0.7381\n",
      "Epoch 1392/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0742 - val_accuracy: 0.7377\n",
      "Epoch 1393/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0645 - accuracy: 0.7718 - val_loss: 0.0741 - val_accuracy: 0.7397\n",
      "Epoch 1394/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0645 - accuracy: 0.7718 - val_loss: 0.0736 - val_accuracy: 0.7391\n",
      "Epoch 1395/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0644 - accuracy: 0.7720 - val_loss: 0.0741 - val_accuracy: 0.7384\n",
      "Epoch 1396/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0644 - accuracy: 0.7719 - val_loss: 0.0747 - val_accuracy: 0.7366\n",
      "Epoch 1397/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0645 - accuracy: 0.7720 - val_loss: 0.0738 - val_accuracy: 0.7393\n",
      "Epoch 1398/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0644 - accuracy: 0.7721 - val_loss: 0.0742 - val_accuracy: 0.7378\n",
      "Epoch 1399/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0644 - accuracy: 0.7721 - val_loss: 0.0745 - val_accuracy: 0.7409\n",
      "Epoch 1400/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0644 - accuracy: 0.7720 - val_loss: 0.0744 - val_accuracy: 0.7387\n",
      "Epoch 1401/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0644 - accuracy: 0.7718 - val_loss: 0.0743 - val_accuracy: 0.7372\n",
      "Epoch 1402/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0646 - accuracy: 0.7717 - val_loss: 0.0745 - val_accuracy: 0.7374\n",
      "Epoch 1403/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0645 - accuracy: 0.7722 - val_loss: 0.0737 - val_accuracy: 0.7401\n",
      "Epoch 1404/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0645 - accuracy: 0.7718 - val_loss: 0.0743 - val_accuracy: 0.7401\n",
      "Epoch 1405/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0746 - val_accuracy: 0.7377\n",
      "Epoch 1406/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0644 - accuracy: 0.7720 - val_loss: 0.0740 - val_accuracy: 0.7388\n",
      "Epoch 1407/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0644 - accuracy: 0.7721 - val_loss: 0.0738 - val_accuracy: 0.7393\n",
      "Epoch 1408/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0777 - val_accuracy: 0.7228\n",
      "Epoch 1409/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0645 - accuracy: 0.7714 - val_loss: 0.0739 - val_accuracy: 0.7393\n",
      "Epoch 1410/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0644 - accuracy: 0.7717 - val_loss: 0.0743 - val_accuracy: 0.7378\n",
      "Epoch 1411/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0647 - accuracy: 0.7708 - val_loss: 0.0741 - val_accuracy: 0.7393\n",
      "Epoch 1412/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0645 - accuracy: 0.7714 - val_loss: 0.0736 - val_accuracy: 0.7398\n",
      "Epoch 1413/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0644 - accuracy: 0.7721 - val_loss: 0.0737 - val_accuracy: 0.7394\n",
      "Epoch 1414/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0646 - accuracy: 0.7709 - val_loss: 0.0744 - val_accuracy: 0.7386\n",
      "Epoch 1415/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0735 - val_accuracy: 0.7390\n",
      "Epoch 1416/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0645 - accuracy: 0.7718 - val_loss: 0.0745 - val_accuracy: 0.7385\n",
      "Epoch 1417/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0644 - accuracy: 0.7722 - val_loss: 0.0743 - val_accuracy: 0.7370\n",
      "Epoch 1418/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0645 - accuracy: 0.7717 - val_loss: 0.0742 - val_accuracy: 0.7391\n",
      "Epoch 1419/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0645 - accuracy: 0.7713 - val_loss: 0.0747 - val_accuracy: 0.7356\n",
      "Epoch 1420/5000\n",
      "11786/11786 [==============================] - 8s 636us/step - loss: 0.0644 - accuracy: 0.7721 - val_loss: 0.0743 - val_accuracy: 0.7369\n",
      "Epoch 1421/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0644 - accuracy: 0.7716 - val_loss: 0.0743 - val_accuracy: 0.7378\n",
      "Epoch 1422/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0739 - val_accuracy: 0.7392\n",
      "Epoch 1423/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0646 - accuracy: 0.7714 - val_loss: 0.0745 - val_accuracy: 0.7374\n",
      "Epoch 1424/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0645 - accuracy: 0.7718 - val_loss: 0.0738 - val_accuracy: 0.7410\n",
      "Epoch 1425/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0741 - val_accuracy: 0.7380\n",
      "Epoch 1426/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0741 - val_accuracy: 0.7388\n",
      "Epoch 1427/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0743 - val_accuracy: 0.7388\n",
      "Epoch 1428/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0645 - accuracy: 0.7720 - val_loss: 0.0747 - val_accuracy: 0.7383\n",
      "Epoch 1429/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0646 - accuracy: 0.7717 - val_loss: 0.0745 - val_accuracy: 0.7402\n",
      "Epoch 1430/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0741 - val_accuracy: 0.7387\n",
      "Epoch 1431/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0644 - accuracy: 0.7719 - val_loss: 0.0741 - val_accuracy: 0.7389\n",
      "Epoch 1432/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0738 - val_accuracy: 0.7399\n",
      "Epoch 1433/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0645 - accuracy: 0.7711 - val_loss: 0.0746 - val_accuracy: 0.7358\n",
      "Epoch 1434/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0644 - accuracy: 0.7718 - val_loss: 0.0748 - val_accuracy: 0.7349\n",
      "Epoch 1435/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0644 - accuracy: 0.7722 - val_loss: 0.0743 - val_accuracy: 0.7401\n",
      "Epoch 1436/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0645 - accuracy: 0.7714 - val_loss: 0.0738 - val_accuracy: 0.7390\n",
      "Epoch 1437/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0737 - val_accuracy: 0.7395\n",
      "Epoch 1438/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0746 - val_accuracy: 0.7361\n",
      "Epoch 1439/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0646 - accuracy: 0.7716 - val_loss: 0.0744 - val_accuracy: 0.7388\n",
      "Epoch 1440/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0644 - accuracy: 0.7722 - val_loss: 0.0738 - val_accuracy: 0.7390\n",
      "Epoch 1441/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0644 - accuracy: 0.7718 - val_loss: 0.0741 - val_accuracy: 0.7394\n",
      "Epoch 1442/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0748 - val_accuracy: 0.7366\n",
      "Epoch 1443/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0752 - val_accuracy: 0.7349\n",
      "Epoch 1444/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0749 - val_accuracy: 0.7358\n",
      "Epoch 1445/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0644 - accuracy: 0.7717 - val_loss: 0.0746 - val_accuracy: 0.7367\n",
      "Epoch 1446/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0645 - accuracy: 0.7717 - val_loss: 0.0736 - val_accuracy: 0.7395\n",
      "Epoch 1447/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0742 - val_accuracy: 0.7374\n",
      "Epoch 1448/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0739 - val_accuracy: 0.7387\n",
      "Epoch 1449/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0737 - val_accuracy: 0.7411\n",
      "Epoch 1450/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0644 - accuracy: 0.7722 - val_loss: 0.0744 - val_accuracy: 0.7388\n",
      "Epoch 1451/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0645 - accuracy: 0.7722 - val_loss: 0.0739 - val_accuracy: 0.7394\n",
      "Epoch 1452/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0738 - val_accuracy: 0.7388\n",
      "Epoch 1453/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0737 - val_accuracy: 0.7381\n",
      "Epoch 1454/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0736 - val_accuracy: 0.7401\n",
      "Epoch 1455/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0741 - val_accuracy: 0.7373\n",
      "Epoch 1456/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0644 - accuracy: 0.7722 - val_loss: 0.0744 - val_accuracy: 0.7371\n",
      "Epoch 1457/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0645 - accuracy: 0.7718 - val_loss: 0.0740 - val_accuracy: 0.7397\n",
      "Epoch 1458/5000\n",
      "11786/11786 [==============================] - 7s 623us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0742 - val_accuracy: 0.7394\n",
      "Epoch 1459/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0646 - accuracy: 0.7712 - val_loss: 0.0743 - val_accuracy: 0.7388\n",
      "Epoch 1460/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0743 - val_accuracy: 0.7374\n",
      "Epoch 1461/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0644 - accuracy: 0.7719 - val_loss: 0.0740 - val_accuracy: 0.7389\n",
      "Epoch 1462/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0645 - accuracy: 0.7717 - val_loss: 0.0739 - val_accuracy: 0.7394\n",
      "Epoch 1463/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0646 - accuracy: 0.7718 - val_loss: 0.0751 - val_accuracy: 0.7369\n",
      "Epoch 1464/5000\n",
      "11786/11786 [==============================] - 7s 623us/step - loss: 0.0646 - accuracy: 0.7717 - val_loss: 0.0741 - val_accuracy: 0.7373\n",
      "Epoch 1465/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0744 - val_accuracy: 0.7376\n",
      "Epoch 1466/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0644 - accuracy: 0.7723 - val_loss: 0.0741 - val_accuracy: 0.7394\n",
      "Epoch 1467/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0645 - accuracy: 0.7717 - val_loss: 0.0739 - val_accuracy: 0.7381\n",
      "Epoch 1468/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0644 - accuracy: 0.7724 - val_loss: 0.0746 - val_accuracy: 0.7365\n",
      "Epoch 1469/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0735 - val_accuracy: 0.7401\n",
      "Epoch 1470/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0645 - accuracy: 0.7721 - val_loss: 0.0743 - val_accuracy: 0.7378\n",
      "Epoch 1471/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0645 - accuracy: 0.7713 - val_loss: 0.0746 - val_accuracy: 0.7381\n",
      "Epoch 1472/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0644 - accuracy: 0.7723 - val_loss: 0.0747 - val_accuracy: 0.7372\n",
      "Epoch 1473/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0644 - accuracy: 0.7718 - val_loss: 0.0741 - val_accuracy: 0.7383\n",
      "Epoch 1474/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0644 - accuracy: 0.7722 - val_loss: 0.0743 - val_accuracy: 0.7362\n",
      "Epoch 1475/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0646 - accuracy: 0.7723 - val_loss: 0.0746 - val_accuracy: 0.7375\n",
      "Epoch 1476/5000\n",
      "11786/11786 [==============================] - 8s 636us/step - loss: 0.0645 - accuracy: 0.7723 - val_loss: 0.0744 - val_accuracy: 0.7383\n",
      "Epoch 1477/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0645 - accuracy: 0.7717 - val_loss: 0.0749 - val_accuracy: 0.7361\n",
      "Epoch 1478/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0644 - accuracy: 0.7721 - val_loss: 0.0743 - val_accuracy: 0.7371\n",
      "Epoch 1479/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0746 - val_accuracy: 0.7372\n",
      "Epoch 1480/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0645 - accuracy: 0.7718 - val_loss: 0.0740 - val_accuracy: 0.7377\n",
      "Epoch 1481/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0645 - accuracy: 0.7720 - val_loss: 0.0742 - val_accuracy: 0.7383\n",
      "Epoch 1482/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0645 - accuracy: 0.7718 - val_loss: 0.0741 - val_accuracy: 0.7400\n",
      "Epoch 1483/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0645 - accuracy: 0.7717 - val_loss: 0.0740 - val_accuracy: 0.7387\n",
      "Epoch 1484/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0645 - accuracy: 0.7720 - val_loss: 0.0742 - val_accuracy: 0.7380\n",
      "Epoch 1485/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0743 - val_accuracy: 0.7376\n",
      "Epoch 1486/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0745 - val_accuracy: 0.7391\n",
      "Epoch 1487/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0645 - accuracy: 0.7720 - val_loss: 0.0743 - val_accuracy: 0.7386\n",
      "Epoch 1488/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0743 - val_accuracy: 0.7404\n",
      "Epoch 1489/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0645 - accuracy: 0.7717 - val_loss: 0.0744 - val_accuracy: 0.7390\n",
      "Epoch 1490/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0645 - accuracy: 0.7717 - val_loss: 0.0738 - val_accuracy: 0.7398\n",
      "Epoch 1491/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0645 - accuracy: 0.7717 - val_loss: 0.0755 - val_accuracy: 0.7353\n",
      "Epoch 1492/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0645 - accuracy: 0.7720 - val_loss: 0.0740 - val_accuracy: 0.7380\n",
      "Epoch 1493/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0646 - accuracy: 0.7715 - val_loss: 0.0743 - val_accuracy: 0.7388\n",
      "Epoch 1494/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0646 - accuracy: 0.7718 - val_loss: 0.0744 - val_accuracy: 0.7386\n",
      "Epoch 1495/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0645 - accuracy: 0.7720 - val_loss: 0.0741 - val_accuracy: 0.7383\n",
      "Epoch 1496/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0645 - accuracy: 0.7718 - val_loss: 0.0743 - val_accuracy: 0.7405\n",
      "Epoch 1497/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0645 - accuracy: 0.7717 - val_loss: 0.0744 - val_accuracy: 0.7371\n",
      "Epoch 1498/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0745 - val_accuracy: 0.7386\n",
      "Epoch 1499/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0647 - accuracy: 0.7712 - val_loss: 0.0740 - val_accuracy: 0.7387\n",
      "Epoch 1500/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0646 - accuracy: 0.7716 - val_loss: 0.0736 - val_accuracy: 0.7406\n",
      "Epoch 1501/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0644 - accuracy: 0.7722 - val_loss: 0.0739 - val_accuracy: 0.7405\n",
      "Epoch 1502/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0742 - val_accuracy: 0.7386\n",
      "Epoch 1503/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0646 - accuracy: 0.7716 - val_loss: 0.0738 - val_accuracy: 0.7374\n",
      "Epoch 1504/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0644 - accuracy: 0.7720 - val_loss: 0.0745 - val_accuracy: 0.7390\n",
      "Epoch 1505/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0745 - val_accuracy: 0.7372\n",
      "Epoch 1506/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0646 - accuracy: 0.7715 - val_loss: 0.0739 - val_accuracy: 0.7395\n",
      "Epoch 1507/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0645 - accuracy: 0.7722 - val_loss: 0.0741 - val_accuracy: 0.7399\n",
      "Epoch 1508/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0644 - accuracy: 0.7721 - val_loss: 0.0744 - val_accuracy: 0.7367\n",
      "Epoch 1509/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0646 - accuracy: 0.7717 - val_loss: 0.0745 - val_accuracy: 0.7351\n",
      "Epoch 1510/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0646 - accuracy: 0.7716 - val_loss: 0.0743 - val_accuracy: 0.7369\n",
      "Epoch 1511/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0645 - accuracy: 0.7715 - val_loss: 0.0742 - val_accuracy: 0.7372\n",
      "Epoch 1512/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0645 - accuracy: 0.7718 - val_loss: 0.0750 - val_accuracy: 0.7363\n",
      "Epoch 1513/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0646 - accuracy: 0.7714 - val_loss: 0.0742 - val_accuracy: 0.7380\n",
      "Epoch 1514/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0645 - accuracy: 0.7722 - val_loss: 0.0742 - val_accuracy: 0.7393\n",
      "Epoch 1515/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0644 - accuracy: 0.7723 - val_loss: 0.0746 - val_accuracy: 0.7374\n",
      "Epoch 1516/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0646 - accuracy: 0.7709 - val_loss: 0.0747 - val_accuracy: 0.7380\n",
      "Epoch 1517/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0743 - val_accuracy: 0.7393\n",
      "Epoch 1518/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0644 - accuracy: 0.7721 - val_loss: 0.0735 - val_accuracy: 0.7400\n",
      "Epoch 1519/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0741 - val_accuracy: 0.7390\n",
      "Epoch 1520/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0645 - accuracy: 0.7720 - val_loss: 0.0739 - val_accuracy: 0.7396\n",
      "Epoch 1521/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0645 - accuracy: 0.7723 - val_loss: 0.0745 - val_accuracy: 0.7370\n",
      "Epoch 1522/5000\n",
      "11786/11786 [==============================] - 8s 644us/step - loss: 0.0645 - accuracy: 0.7717 - val_loss: 0.0743 - val_accuracy: 0.7409\n",
      "Epoch 1523/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0646 - accuracy: 0.7717 - val_loss: 0.0740 - val_accuracy: 0.7393\n",
      "Epoch 1524/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0647 - accuracy: 0.7714 - val_loss: 0.0749 - val_accuracy: 0.7384\n",
      "Epoch 1525/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0645 - accuracy: 0.7714 - val_loss: 0.0742 - val_accuracy: 0.7379\n",
      "Epoch 1526/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0645 - accuracy: 0.7720 - val_loss: 0.0747 - val_accuracy: 0.7368\n",
      "Epoch 1527/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0645 - accuracy: 0.7718 - val_loss: 0.0745 - val_accuracy: 0.7389\n",
      "Epoch 1528/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0646 - accuracy: 0.7717 - val_loss: 0.0742 - val_accuracy: 0.7382\n",
      "Epoch 1529/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0645 - accuracy: 0.7721 - val_loss: 0.0749 - val_accuracy: 0.7365\n",
      "Epoch 1530/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0646 - accuracy: 0.7715 - val_loss: 0.0742 - val_accuracy: 0.7388\n",
      "Epoch 1531/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0749 - val_accuracy: 0.7336\n",
      "Epoch 1532/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0646 - accuracy: 0.7713 - val_loss: 0.0749 - val_accuracy: 0.7374\n",
      "Epoch 1533/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0645 - accuracy: 0.7727 - val_loss: 0.0745 - val_accuracy: 0.7390\n",
      "Epoch 1534/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0645 - accuracy: 0.7721 - val_loss: 0.0744 - val_accuracy: 0.7373\n",
      "Epoch 1535/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0645 - accuracy: 0.7723 - val_loss: 0.0740 - val_accuracy: 0.7402\n",
      "Epoch 1536/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0645 - accuracy: 0.7717 - val_loss: 0.0742 - val_accuracy: 0.7376\n",
      "Epoch 1537/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0645 - accuracy: 0.7720 - val_loss: 0.0744 - val_accuracy: 0.7380\n",
      "Epoch 1538/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0645 - accuracy: 0.7722 - val_loss: 0.0741 - val_accuracy: 0.7373\n",
      "Epoch 1539/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0646 - accuracy: 0.7714 - val_loss: 0.0739 - val_accuracy: 0.7383\n",
      "Epoch 1540/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0645 - accuracy: 0.7718 - val_loss: 0.0740 - val_accuracy: 0.7387\n",
      "Epoch 1541/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0646 - accuracy: 0.7716 - val_loss: 0.0746 - val_accuracy: 0.7378\n",
      "Epoch 1542/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0646 - accuracy: 0.7720 - val_loss: 0.0747 - val_accuracy: 0.7380\n",
      "Epoch 1543/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0646 - accuracy: 0.7715 - val_loss: 0.0746 - val_accuracy: 0.7376\n",
      "Epoch 1544/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0646 - accuracy: 0.7711 - val_loss: 0.0744 - val_accuracy: 0.7400\n",
      "Epoch 1545/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0646 - accuracy: 0.7713 - val_loss: 0.0737 - val_accuracy: 0.7404\n",
      "Epoch 1546/5000\n",
      "11786/11786 [==============================] - 8s 644us/step - loss: 0.0645 - accuracy: 0.7718 - val_loss: 0.0746 - val_accuracy: 0.7370\n",
      "Epoch 1547/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0646 - accuracy: 0.7717 - val_loss: 0.0738 - val_accuracy: 0.7404\n",
      "Epoch 1548/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0737 - val_accuracy: 0.7387\n",
      "Epoch 1549/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0645 - accuracy: 0.7718 - val_loss: 0.0743 - val_accuracy: 0.7391\n",
      "Epoch 1550/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0644 - accuracy: 0.7720 - val_loss: 0.0749 - val_accuracy: 0.7372\n",
      "Epoch 1551/5000\n",
      "11786/11786 [==============================] - 7s 623us/step - loss: 0.0644 - accuracy: 0.7726 - val_loss: 0.0748 - val_accuracy: 0.7375\n",
      "Epoch 1552/5000\n",
      "11786/11786 [==============================] - 8s 643us/step - loss: 0.0646 - accuracy: 0.7717 - val_loss: 0.0749 - val_accuracy: 0.7378\n",
      "Epoch 1553/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0645 - accuracy: 0.7723 - val_loss: 0.0749 - val_accuracy: 0.7364\n",
      "Epoch 1554/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0646 - accuracy: 0.7715 - val_loss: 0.0742 - val_accuracy: 0.7371\n",
      "Epoch 1555/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0645 - accuracy: 0.7723 - val_loss: 0.0746 - val_accuracy: 0.7380\n",
      "Epoch 1556/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0645 - accuracy: 0.7720 - val_loss: 0.0741 - val_accuracy: 0.7390\n",
      "Epoch 1557/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0646 - accuracy: 0.7717 - val_loss: 0.0747 - val_accuracy: 0.7359\n",
      "Epoch 1558/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0646 - accuracy: 0.7722 - val_loss: 0.0744 - val_accuracy: 0.7406\n",
      "Epoch 1559/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0645 - accuracy: 0.7718 - val_loss: 0.0744 - val_accuracy: 0.7383\n",
      "Epoch 1560/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0743 - val_accuracy: 0.7399\n",
      "Epoch 1561/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0746 - val_accuracy: 0.7374\n",
      "Epoch 1562/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0747 - val_accuracy: 0.7366\n",
      "Epoch 1563/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0644 - accuracy: 0.7722 - val_loss: 0.0742 - val_accuracy: 0.7389\n",
      "Epoch 1564/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0645 - accuracy: 0.7720 - val_loss: 0.0745 - val_accuracy: 0.7367\n",
      "Epoch 1565/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0644 - accuracy: 0.7721 - val_loss: 0.0739 - val_accuracy: 0.7394\n",
      "Epoch 1566/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0747 - val_accuracy: 0.7391\n",
      "Epoch 1567/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0644 - accuracy: 0.7723 - val_loss: 0.0745 - val_accuracy: 0.7395\n",
      "Epoch 1568/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0744 - val_accuracy: 0.7381\n",
      "Epoch 1569/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0752 - val_accuracy: 0.7387\n",
      "Epoch 1570/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0645 - accuracy: 0.7720 - val_loss: 0.0740 - val_accuracy: 0.7379\n",
      "Epoch 1571/5000\n",
      "11786/11786 [==============================] - 7s 624us/step - loss: 0.0645 - accuracy: 0.7721 - val_loss: 0.0745 - val_accuracy: 0.7372\n",
      "Epoch 1572/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0646 - accuracy: 0.7719 - val_loss: 0.0742 - val_accuracy: 0.7393\n",
      "Epoch 1573/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0744 - val_accuracy: 0.7374\n",
      "Epoch 1574/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0644 - accuracy: 0.7725 - val_loss: 0.0743 - val_accuracy: 0.7385\n",
      "Epoch 1575/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0646 - accuracy: 0.7715 - val_loss: 0.0741 - val_accuracy: 0.7394\n",
      "Epoch 1576/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0645 - accuracy: 0.7718 - val_loss: 0.0744 - val_accuracy: 0.7372\n",
      "Epoch 1577/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0645 - accuracy: 0.7724 - val_loss: 0.0741 - val_accuracy: 0.7383\n",
      "Epoch 1578/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0645 - accuracy: 0.7721 - val_loss: 0.0743 - val_accuracy: 0.7388\n",
      "Epoch 1579/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0645 - accuracy: 0.7724 - val_loss: 0.0745 - val_accuracy: 0.7376\n",
      "Epoch 1580/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0646 - accuracy: 0.7719 - val_loss: 0.0743 - val_accuracy: 0.7393\n",
      "Epoch 1581/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0646 - accuracy: 0.7723 - val_loss: 0.0743 - val_accuracy: 0.7381\n",
      "Epoch 1582/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0645 - accuracy: 0.7718 - val_loss: 0.0740 - val_accuracy: 0.7396\n",
      "Epoch 1583/5000\n",
      "11786/11786 [==============================] - 8s 636us/step - loss: 0.0645 - accuracy: 0.7723 - val_loss: 0.0740 - val_accuracy: 0.7386\n",
      "Epoch 1584/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0645 - accuracy: 0.7720 - val_loss: 0.0762 - val_accuracy: 0.7319\n",
      "Epoch 1585/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0645 - accuracy: 0.7718 - val_loss: 0.0746 - val_accuracy: 0.7354\n",
      "Epoch 1586/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0644 - accuracy: 0.7725 - val_loss: 0.0746 - val_accuracy: 0.7378\n",
      "Epoch 1587/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0644 - accuracy: 0.7724 - val_loss: 0.0747 - val_accuracy: 0.7371\n",
      "Epoch 1588/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0643 - accuracy: 0.7734 - val_loss: 0.0745 - val_accuracy: 0.7369\n",
      "Epoch 1589/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0645 - accuracy: 0.7721 - val_loss: 0.0740 - val_accuracy: 0.7396\n",
      "Epoch 1590/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0646 - accuracy: 0.7719 - val_loss: 0.0748 - val_accuracy: 0.7368\n",
      "Epoch 1591/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0645 - accuracy: 0.7720 - val_loss: 0.0746 - val_accuracy: 0.7372\n",
      "Epoch 1592/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0645 - accuracy: 0.7726 - val_loss: 0.0744 - val_accuracy: 0.7391\n",
      "Epoch 1593/5000\n",
      "11786/11786 [==============================] - 8s 643us/step - loss: 0.0644 - accuracy: 0.7722 - val_loss: 0.0744 - val_accuracy: 0.7375\n",
      "Epoch 1594/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0645 - accuracy: 0.7721 - val_loss: 0.0745 - val_accuracy: 0.7375\n",
      "Epoch 1595/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0645 - accuracy: 0.7721 - val_loss: 0.0756 - val_accuracy: 0.7337\n",
      "Epoch 1596/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0645 - accuracy: 0.7720 - val_loss: 0.0741 - val_accuracy: 0.7365\n",
      "Epoch 1597/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0645 - accuracy: 0.7721 - val_loss: 0.0741 - val_accuracy: 0.7387\n",
      "Epoch 1598/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0644 - accuracy: 0.7721 - val_loss: 0.0748 - val_accuracy: 0.7362\n",
      "Epoch 1599/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0645 - accuracy: 0.7718 - val_loss: 0.0747 - val_accuracy: 0.7380\n",
      "Epoch 1600/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0645 - accuracy: 0.7724 - val_loss: 0.0752 - val_accuracy: 0.7359\n",
      "Epoch 1601/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0644 - accuracy: 0.7716 - val_loss: 0.0740 - val_accuracy: 0.7379\n",
      "Epoch 1602/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0644 - accuracy: 0.7725 - val_loss: 0.0745 - val_accuracy: 0.7371\n",
      "Epoch 1603/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0644 - accuracy: 0.7720 - val_loss: 0.0749 - val_accuracy: 0.7350\n",
      "Epoch 1604/5000\n",
      "11786/11786 [==============================] - 7s 626us/step - loss: 0.0644 - accuracy: 0.7724 - val_loss: 0.0740 - val_accuracy: 0.7387\n",
      "Epoch 1605/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0646 - accuracy: 0.7716 - val_loss: 0.0749 - val_accuracy: 0.7373\n",
      "Epoch 1606/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0646 - accuracy: 0.7715 - val_loss: 0.0745 - val_accuracy: 0.7376\n",
      "Epoch 1607/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0741 - val_accuracy: 0.7385\n",
      "Epoch 1608/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0747 - val_accuracy: 0.7367\n",
      "Epoch 1609/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0645 - accuracy: 0.7723 - val_loss: 0.0743 - val_accuracy: 0.7378\n",
      "Epoch 1610/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0646 - accuracy: 0.7719 - val_loss: 0.0756 - val_accuracy: 0.7353\n",
      "Epoch 1611/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0644 - accuracy: 0.7723 - val_loss: 0.0749 - val_accuracy: 0.7366\n",
      "Epoch 1612/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0741 - val_accuracy: 0.7360\n",
      "Epoch 1613/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0644 - accuracy: 0.7725 - val_loss: 0.0746 - val_accuracy: 0.7374\n",
      "Epoch 1614/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0646 - accuracy: 0.7713 - val_loss: 0.0743 - val_accuracy: 0.7387\n",
      "Epoch 1615/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0645 - accuracy: 0.7717 - val_loss: 0.0740 - val_accuracy: 0.7373\n",
      "Epoch 1616/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0644 - accuracy: 0.7724 - val_loss: 0.0750 - val_accuracy: 0.7376\n",
      "Epoch 1617/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0646 - accuracy: 0.7715 - val_loss: 0.0744 - val_accuracy: 0.7390\n",
      "Epoch 1618/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0747 - val_accuracy: 0.7365\n",
      "Epoch 1619/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0646 - accuracy: 0.7712 - val_loss: 0.0748 - val_accuracy: 0.7357\n",
      "Epoch 1620/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0646 - accuracy: 0.7715 - val_loss: 0.0746 - val_accuracy: 0.7373\n",
      "Epoch 1621/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0646 - accuracy: 0.7715 - val_loss: 0.0744 - val_accuracy: 0.7390\n",
      "Epoch 1622/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0645 - accuracy: 0.7722 - val_loss: 0.0740 - val_accuracy: 0.7379\n",
      "Epoch 1623/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0646 - accuracy: 0.7719 - val_loss: 0.0748 - val_accuracy: 0.7376\n",
      "Epoch 1624/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0645 - accuracy: 0.7723 - val_loss: 0.0743 - val_accuracy: 0.7374\n",
      "Epoch 1625/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0645 - accuracy: 0.7720 - val_loss: 0.0742 - val_accuracy: 0.7384\n",
      "Epoch 1626/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0646 - accuracy: 0.7721 - val_loss: 0.0743 - val_accuracy: 0.7386\n",
      "Epoch 1627/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0646 - accuracy: 0.7720 - val_loss: 0.0752 - val_accuracy: 0.7370\n",
      "Epoch 1628/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0646 - accuracy: 0.7721 - val_loss: 0.0744 - val_accuracy: 0.7375\n",
      "Epoch 1629/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0645 - accuracy: 0.7723 - val_loss: 0.0744 - val_accuracy: 0.7389\n",
      "Epoch 1630/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0646 - accuracy: 0.7720 - val_loss: 0.0739 - val_accuracy: 0.7396\n",
      "Epoch 1631/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0644 - accuracy: 0.7724 - val_loss: 0.0741 - val_accuracy: 0.7408\n",
      "Epoch 1632/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0735 - val_accuracy: 0.7399\n",
      "Epoch 1633/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0746 - val_accuracy: 0.7375\n",
      "Epoch 1634/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0746 - val_accuracy: 0.7371\n",
      "Epoch 1635/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0740 - val_accuracy: 0.7391\n",
      "Epoch 1636/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0645 - accuracy: 0.7720 - val_loss: 0.0748 - val_accuracy: 0.7367\n",
      "Epoch 1637/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0645 - accuracy: 0.7720 - val_loss: 0.0753 - val_accuracy: 0.7359\n",
      "Epoch 1638/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0645 - accuracy: 0.7725 - val_loss: 0.0741 - val_accuracy: 0.7394\n",
      "Epoch 1639/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0646 - accuracy: 0.7721 - val_loss: 0.0744 - val_accuracy: 0.7383\n",
      "Epoch 1640/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0645 - accuracy: 0.7725 - val_loss: 0.0750 - val_accuracy: 0.7363\n",
      "Epoch 1641/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0748 - val_accuracy: 0.7386\n",
      "Epoch 1642/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0645 - accuracy: 0.7721 - val_loss: 0.0746 - val_accuracy: 0.7397\n",
      "Epoch 1643/5000\n",
      "11786/11786 [==============================] - 8s 636us/step - loss: 0.0645 - accuracy: 0.7722 - val_loss: 0.0743 - val_accuracy: 0.7375\n",
      "Epoch 1644/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0646 - accuracy: 0.7721 - val_loss: 0.0743 - val_accuracy: 0.7365\n",
      "Epoch 1645/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0646 - accuracy: 0.7721 - val_loss: 0.0744 - val_accuracy: 0.7386\n",
      "Epoch 1646/5000\n",
      "11786/11786 [==============================] - 8s 636us/step - loss: 0.0647 - accuracy: 0.7716 - val_loss: 0.0746 - val_accuracy: 0.7363\n",
      "Epoch 1647/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0645 - accuracy: 0.7722 - val_loss: 0.0749 - val_accuracy: 0.7378\n",
      "Epoch 1648/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0645 - accuracy: 0.7720 - val_loss: 0.0743 - val_accuracy: 0.7386\n",
      "Epoch 1649/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0645 - accuracy: 0.7718 - val_loss: 0.0744 - val_accuracy: 0.7375\n",
      "Epoch 1650/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0645 - accuracy: 0.7720 - val_loss: 0.0745 - val_accuracy: 0.7393\n",
      "Epoch 1651/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0645 - accuracy: 0.7721 - val_loss: 0.0744 - val_accuracy: 0.7400\n",
      "Epoch 1652/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0645 - accuracy: 0.7720 - val_loss: 0.0743 - val_accuracy: 0.7403\n",
      "Epoch 1653/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0645 - accuracy: 0.7721 - val_loss: 0.0743 - val_accuracy: 0.7392\n",
      "Epoch 1654/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0645 - accuracy: 0.7723 - val_loss: 0.0751 - val_accuracy: 0.7374\n",
      "Epoch 1655/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0645 - accuracy: 0.7725 - val_loss: 0.0742 - val_accuracy: 0.7388\n",
      "Epoch 1656/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0645 - accuracy: 0.7725 - val_loss: 0.0747 - val_accuracy: 0.7376\n",
      "Epoch 1657/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0645 - accuracy: 0.7717 - val_loss: 0.0742 - val_accuracy: 0.7392\n",
      "Epoch 1658/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0645 - accuracy: 0.7722 - val_loss: 0.0744 - val_accuracy: 0.7385\n",
      "Epoch 1659/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0646 - accuracy: 0.7716 - val_loss: 0.0748 - val_accuracy: 0.7375\n",
      "Epoch 1660/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0741 - val_accuracy: 0.7384\n",
      "Epoch 1661/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0645 - accuracy: 0.7721 - val_loss: 0.0742 - val_accuracy: 0.7389\n",
      "Epoch 1662/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0646 - accuracy: 0.7714 - val_loss: 0.0748 - val_accuracy: 0.7374\n",
      "Epoch 1663/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0645 - accuracy: 0.7724 - val_loss: 0.0746 - val_accuracy: 0.7364\n",
      "Epoch 1664/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0646 - accuracy: 0.7720 - val_loss: 0.0747 - val_accuracy: 0.7382\n",
      "Epoch 1665/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0646 - accuracy: 0.7717 - val_loss: 0.0737 - val_accuracy: 0.7397\n",
      "Epoch 1666/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0645 - accuracy: 0.7720 - val_loss: 0.0744 - val_accuracy: 0.7377\n",
      "Epoch 1667/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0645 - accuracy: 0.7724 - val_loss: 0.0743 - val_accuracy: 0.7393\n",
      "Epoch 1668/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0646 - accuracy: 0.7718 - val_loss: 0.0740 - val_accuracy: 0.7386\n",
      "Epoch 1669/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0645 - accuracy: 0.7721 - val_loss: 0.0745 - val_accuracy: 0.7360\n",
      "Epoch 1670/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0645 - accuracy: 0.7723 - val_loss: 0.0750 - val_accuracy: 0.7363\n",
      "Epoch 1671/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0645 - accuracy: 0.7717 - val_loss: 0.0768 - val_accuracy: 0.7263\n",
      "Epoch 1672/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0646 - accuracy: 0.7718 - val_loss: 0.0747 - val_accuracy: 0.7374\n",
      "Epoch 1673/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0646 - accuracy: 0.7716 - val_loss: 0.0742 - val_accuracy: 0.7384\n",
      "Epoch 1674/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0645 - accuracy: 0.7721 - val_loss: 0.0747 - val_accuracy: 0.7367\n",
      "Epoch 1675/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0645 - accuracy: 0.7723 - val_loss: 0.0747 - val_accuracy: 0.7373\n",
      "Epoch 1676/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0645 - accuracy: 0.7722 - val_loss: 0.0745 - val_accuracy: 0.7385\n",
      "Epoch 1677/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0646 - accuracy: 0.7720 - val_loss: 0.0747 - val_accuracy: 0.7366\n",
      "Epoch 1678/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0645 - accuracy: 0.7720 - val_loss: 0.0752 - val_accuracy: 0.7367\n",
      "Epoch 1679/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0645 - accuracy: 0.7720 - val_loss: 0.0749 - val_accuracy: 0.7377\n",
      "Epoch 1680/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0645 - accuracy: 0.7722 - val_loss: 0.0742 - val_accuracy: 0.7376\n",
      "Epoch 1681/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0645 - accuracy: 0.7721 - val_loss: 0.0746 - val_accuracy: 0.7378\n",
      "Epoch 1682/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0745 - val_accuracy: 0.7379\n",
      "Epoch 1683/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0646 - accuracy: 0.7717 - val_loss: 0.0739 - val_accuracy: 0.7396\n",
      "Epoch 1684/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0646 - accuracy: 0.7718 - val_loss: 0.0746 - val_accuracy: 0.7369\n",
      "Epoch 1685/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0645 - accuracy: 0.7728 - val_loss: 0.0749 - val_accuracy: 0.7371\n",
      "Epoch 1686/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0646 - accuracy: 0.7719 - val_loss: 0.0743 - val_accuracy: 0.7378\n",
      "Epoch 1687/5000\n",
      "11786/11786 [==============================] - 8s 636us/step - loss: 0.0645 - accuracy: 0.7721 - val_loss: 0.0746 - val_accuracy: 0.7387\n",
      "Epoch 1688/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0646 - accuracy: 0.7716 - val_loss: 0.0760 - val_accuracy: 0.7366\n",
      "Epoch 1689/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0645 - accuracy: 0.7724 - val_loss: 0.0737 - val_accuracy: 0.7390\n",
      "Epoch 1690/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0646 - accuracy: 0.7720 - val_loss: 0.0752 - val_accuracy: 0.7359\n",
      "Epoch 1691/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0646 - accuracy: 0.7718 - val_loss: 0.0742 - val_accuracy: 0.7375\n",
      "Epoch 1692/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0645 - accuracy: 0.7720 - val_loss: 0.0745 - val_accuracy: 0.7374\n",
      "Epoch 1693/5000\n",
      "11786/11786 [==============================] - 8s 643us/step - loss: 0.0645 - accuracy: 0.7718 - val_loss: 0.0746 - val_accuracy: 0.7369\n",
      "Epoch 1694/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0645 - accuracy: 0.7718 - val_loss: 0.0741 - val_accuracy: 0.7406\n",
      "Epoch 1695/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0646 - accuracy: 0.7714 - val_loss: 0.0746 - val_accuracy: 0.7382\n",
      "Epoch 1696/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0646 - accuracy: 0.7719 - val_loss: 0.0744 - val_accuracy: 0.7397\n",
      "Epoch 1697/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0750 - val_accuracy: 0.7399\n",
      "Epoch 1698/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0646 - accuracy: 0.7714 - val_loss: 0.0747 - val_accuracy: 0.7382\n",
      "Epoch 1699/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0645 - accuracy: 0.7717 - val_loss: 0.0743 - val_accuracy: 0.7389\n",
      "Epoch 1700/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0743 - val_accuracy: 0.7373\n",
      "Epoch 1701/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0646 - accuracy: 0.7720 - val_loss: 0.0749 - val_accuracy: 0.7375\n",
      "Epoch 1702/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0646 - accuracy: 0.7716 - val_loss: 0.0744 - val_accuracy: 0.7390\n",
      "Epoch 1703/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0646 - accuracy: 0.7719 - val_loss: 0.0748 - val_accuracy: 0.7368\n",
      "Epoch 1704/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0645 - accuracy: 0.7727 - val_loss: 0.0746 - val_accuracy: 0.7367\n",
      "Epoch 1705/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0646 - accuracy: 0.7718 - val_loss: 0.0747 - val_accuracy: 0.7378\n",
      "Epoch 1706/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0646 - accuracy: 0.7721 - val_loss: 0.0748 - val_accuracy: 0.7365\n",
      "Epoch 1707/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0646 - accuracy: 0.7722 - val_loss: 0.0742 - val_accuracy: 0.7397\n",
      "Epoch 1708/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0646 - accuracy: 0.7714 - val_loss: 0.0752 - val_accuracy: 0.7351\n",
      "Epoch 1709/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0644 - accuracy: 0.7720 - val_loss: 0.0748 - val_accuracy: 0.7371\n",
      "Epoch 1710/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0646 - accuracy: 0.7718 - val_loss: 0.0753 - val_accuracy: 0.7329\n",
      "Epoch 1711/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0646 - accuracy: 0.7723 - val_loss: 0.0751 - val_accuracy: 0.7377\n",
      "Epoch 1712/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0646 - accuracy: 0.7717 - val_loss: 0.0749 - val_accuracy: 0.7364\n",
      "Epoch 1713/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0645 - accuracy: 0.7724 - val_loss: 0.0745 - val_accuracy: 0.7362\n",
      "Epoch 1714/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0644 - accuracy: 0.7722 - val_loss: 0.0741 - val_accuracy: 0.7370\n",
      "Epoch 1715/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0645 - accuracy: 0.7720 - val_loss: 0.0743 - val_accuracy: 0.7393\n",
      "Epoch 1716/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0646 - accuracy: 0.7723 - val_loss: 0.0748 - val_accuracy: 0.7356\n",
      "Epoch 1717/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0645 - accuracy: 0.7724 - val_loss: 0.0756 - val_accuracy: 0.7364\n",
      "Epoch 1718/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0645 - accuracy: 0.7727 - val_loss: 0.0742 - val_accuracy: 0.7381\n",
      "Epoch 1719/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0644 - accuracy: 0.7726 - val_loss: 0.0749 - val_accuracy: 0.7384\n",
      "Epoch 1720/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0646 - accuracy: 0.7714 - val_loss: 0.0749 - val_accuracy: 0.7355\n",
      "Epoch 1721/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0646 - accuracy: 0.7715 - val_loss: 0.0747 - val_accuracy: 0.7377\n",
      "Epoch 1722/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0645 - accuracy: 0.7723 - val_loss: 0.0747 - val_accuracy: 0.7372\n",
      "Epoch 1723/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0645 - accuracy: 0.7725 - val_loss: 0.0750 - val_accuracy: 0.7389\n",
      "Epoch 1724/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0646 - accuracy: 0.7718 - val_loss: 0.0746 - val_accuracy: 0.7376\n",
      "Epoch 1725/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0647 - accuracy: 0.7713 - val_loss: 0.0746 - val_accuracy: 0.7387\n",
      "Epoch 1726/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0647 - accuracy: 0.7715 - val_loss: 0.0745 - val_accuracy: 0.7379\n",
      "Epoch 1727/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0646 - accuracy: 0.7721 - val_loss: 0.0752 - val_accuracy: 0.7362\n",
      "Epoch 1728/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0645 - accuracy: 0.7721 - val_loss: 0.0746 - val_accuracy: 0.7384\n",
      "Epoch 1729/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0647 - accuracy: 0.7715 - val_loss: 0.0745 - val_accuracy: 0.7381\n",
      "Epoch 1730/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0647 - accuracy: 0.7720 - val_loss: 0.0748 - val_accuracy: 0.7368\n",
      "Epoch 1731/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0647 - accuracy: 0.7716 - val_loss: 0.0749 - val_accuracy: 0.7368\n",
      "Epoch 1732/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0646 - accuracy: 0.7718 - val_loss: 0.0743 - val_accuracy: 0.7390\n",
      "Epoch 1733/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0646 - accuracy: 0.7718 - val_loss: 0.0740 - val_accuracy: 0.7383\n",
      "Epoch 1734/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0646 - accuracy: 0.7714 - val_loss: 0.0746 - val_accuracy: 0.7377\n",
      "Epoch 1735/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0646 - accuracy: 0.7719 - val_loss: 0.0742 - val_accuracy: 0.7402\n",
      "Epoch 1736/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0646 - accuracy: 0.7717 - val_loss: 0.0748 - val_accuracy: 0.7380\n",
      "Epoch 1737/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0645 - accuracy: 0.7725 - val_loss: 0.0745 - val_accuracy: 0.7397\n",
      "Epoch 1738/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0746 - val_accuracy: 0.7361\n",
      "Epoch 1739/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0647 - accuracy: 0.7717 - val_loss: 0.0744 - val_accuracy: 0.7379\n",
      "Epoch 1740/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0745 - val_accuracy: 0.7375\n",
      "Epoch 1741/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0646 - accuracy: 0.7717 - val_loss: 0.0764 - val_accuracy: 0.7346\n",
      "Epoch 1742/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0644 - accuracy: 0.7722 - val_loss: 0.0754 - val_accuracy: 0.7378\n",
      "Epoch 1743/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0646 - accuracy: 0.7720 - val_loss: 0.0741 - val_accuracy: 0.7395\n",
      "Epoch 1744/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0645 - accuracy: 0.7720 - val_loss: 0.0747 - val_accuracy: 0.7387\n",
      "Epoch 1745/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0645 - accuracy: 0.7718 - val_loss: 0.0749 - val_accuracy: 0.7365\n",
      "Epoch 1746/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0646 - accuracy: 0.7722 - val_loss: 0.0755 - val_accuracy: 0.7343\n",
      "Epoch 1747/5000\n",
      "11786/11786 [==============================] - 8s 636us/step - loss: 0.0646 - accuracy: 0.7723 - val_loss: 0.0743 - val_accuracy: 0.7368\n",
      "Epoch 1748/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0646 - accuracy: 0.7716 - val_loss: 0.0740 - val_accuracy: 0.7389\n",
      "Epoch 1749/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0646 - accuracy: 0.7719 - val_loss: 0.0746 - val_accuracy: 0.7374\n",
      "Epoch 1750/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0646 - accuracy: 0.7722 - val_loss: 0.0754 - val_accuracy: 0.7344\n",
      "Epoch 1751/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0646 - accuracy: 0.7718 - val_loss: 0.0745 - val_accuracy: 0.7384\n",
      "Epoch 1752/5000\n",
      "11786/11786 [==============================] - 8s 636us/step - loss: 0.0646 - accuracy: 0.7715 - val_loss: 0.0742 - val_accuracy: 0.7387\n",
      "Epoch 1753/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0645 - accuracy: 0.7722 - val_loss: 0.0747 - val_accuracy: 0.7371\n",
      "Epoch 1754/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0646 - accuracy: 0.7718 - val_loss: 0.0746 - val_accuracy: 0.7393\n",
      "Epoch 1755/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0645 - accuracy: 0.7720 - val_loss: 0.0750 - val_accuracy: 0.7355\n",
      "Epoch 1756/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0646 - accuracy: 0.7717 - val_loss: 0.0738 - val_accuracy: 0.7384\n",
      "Epoch 1757/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0646 - accuracy: 0.7718 - val_loss: 0.0739 - val_accuracy: 0.7391\n",
      "Epoch 1758/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0749 - val_accuracy: 0.7377\n",
      "Epoch 1759/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0646 - accuracy: 0.7714 - val_loss: 0.0754 - val_accuracy: 0.7349\n",
      "Epoch 1760/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0646 - accuracy: 0.7719 - val_loss: 0.0750 - val_accuracy: 0.7366\n",
      "Epoch 1761/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0646 - accuracy: 0.7720 - val_loss: 0.0748 - val_accuracy: 0.7376\n",
      "Epoch 1762/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0645 - accuracy: 0.7718 - val_loss: 0.0744 - val_accuracy: 0.7368\n",
      "Epoch 1763/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0646 - accuracy: 0.7719 - val_loss: 0.0741 - val_accuracy: 0.7388\n",
      "Epoch 1764/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0759 - val_accuracy: 0.7351\n",
      "Epoch 1765/5000\n",
      "11786/11786 [==============================] - 8s 643us/step - loss: 0.0645 - accuracy: 0.7716 - val_loss: 0.0750 - val_accuracy: 0.7369\n",
      "Epoch 1766/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0646 - accuracy: 0.7716 - val_loss: 0.0748 - val_accuracy: 0.7386\n",
      "Epoch 1767/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0645 - accuracy: 0.7722 - val_loss: 0.0742 - val_accuracy: 0.7391\n",
      "Epoch 1768/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0742 - val_accuracy: 0.7389\n",
      "Epoch 1769/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0749 - val_accuracy: 0.7369\n",
      "Epoch 1770/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0645 - accuracy: 0.7720 - val_loss: 0.0750 - val_accuracy: 0.7356\n",
      "Epoch 1771/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0644 - accuracy: 0.7725 - val_loss: 0.0750 - val_accuracy: 0.7362\n",
      "Epoch 1772/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0646 - accuracy: 0.7720 - val_loss: 0.0743 - val_accuracy: 0.7374\n",
      "Epoch 1773/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0647 - accuracy: 0.7719 - val_loss: 0.0752 - val_accuracy: 0.7371\n",
      "Epoch 1774/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0742 - val_accuracy: 0.7375\n",
      "Epoch 1775/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0645 - accuracy: 0.7722 - val_loss: 0.0744 - val_accuracy: 0.7374\n",
      "Epoch 1776/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0646 - accuracy: 0.7720 - val_loss: 0.0743 - val_accuracy: 0.7398\n",
      "Epoch 1777/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0645 - accuracy: 0.7720 - val_loss: 0.0751 - val_accuracy: 0.7349\n",
      "Epoch 1778/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0646 - accuracy: 0.7722 - val_loss: 0.0747 - val_accuracy: 0.7365\n",
      "Epoch 1779/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0747 - val_accuracy: 0.7359\n",
      "Epoch 1780/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0753 - val_accuracy: 0.7359\n",
      "Epoch 1781/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0646 - accuracy: 0.7719 - val_loss: 0.0743 - val_accuracy: 0.7389\n",
      "Epoch 1782/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0646 - accuracy: 0.7719 - val_loss: 0.0753 - val_accuracy: 0.7352\n",
      "Epoch 1783/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0750 - val_accuracy: 0.7369\n",
      "Epoch 1784/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0645 - accuracy: 0.7722 - val_loss: 0.0745 - val_accuracy: 0.7366\n",
      "Epoch 1785/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0645 - accuracy: 0.7718 - val_loss: 0.0745 - val_accuracy: 0.7382\n",
      "Epoch 1786/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0646 - accuracy: 0.7719 - val_loss: 0.0745 - val_accuracy: 0.7378\n",
      "Epoch 1787/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0645 - accuracy: 0.7722 - val_loss: 0.0744 - val_accuracy: 0.7386\n",
      "Epoch 1788/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0749 - val_accuracy: 0.7396\n",
      "Epoch 1789/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0645 - accuracy: 0.7723 - val_loss: 0.0754 - val_accuracy: 0.7344\n",
      "Epoch 1790/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0645 - accuracy: 0.7720 - val_loss: 0.0745 - val_accuracy: 0.7376\n",
      "Epoch 1791/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0645 - accuracy: 0.7724 - val_loss: 0.0740 - val_accuracy: 0.7392\n",
      "Epoch 1792/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0646 - accuracy: 0.7720 - val_loss: 0.0745 - val_accuracy: 0.7362\n",
      "Epoch 1793/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0647 - accuracy: 0.7714 - val_loss: 0.0745 - val_accuracy: 0.7385\n",
      "Epoch 1794/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0646 - accuracy: 0.7723 - val_loss: 0.0744 - val_accuracy: 0.7387\n",
      "Epoch 1795/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0645 - accuracy: 0.7723 - val_loss: 0.0747 - val_accuracy: 0.7370\n",
      "Epoch 1796/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0646 - accuracy: 0.7720 - val_loss: 0.0752 - val_accuracy: 0.7381\n",
      "Epoch 1797/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0647 - accuracy: 0.7717 - val_loss: 0.0753 - val_accuracy: 0.7363\n",
      "Epoch 1798/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0646 - accuracy: 0.7720 - val_loss: 0.0746 - val_accuracy: 0.7381\n",
      "Epoch 1799/5000\n",
      "11786/11786 [==============================] - 8s 643us/step - loss: 0.0646 - accuracy: 0.7724 - val_loss: 0.0749 - val_accuracy: 0.7366\n",
      "Epoch 1800/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0646 - accuracy: 0.7723 - val_loss: 0.0743 - val_accuracy: 0.7387\n",
      "Epoch 1801/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0646 - accuracy: 0.7721 - val_loss: 0.0746 - val_accuracy: 0.7378\n",
      "Epoch 1802/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0646 - accuracy: 0.7721 - val_loss: 0.0742 - val_accuracy: 0.7404\n",
      "Epoch 1803/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0646 - accuracy: 0.7722 - val_loss: 0.0743 - val_accuracy: 0.7376\n",
      "Epoch 1804/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0646 - accuracy: 0.7716 - val_loss: 0.0743 - val_accuracy: 0.7382\n",
      "Epoch 1805/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0646 - accuracy: 0.7720 - val_loss: 0.0748 - val_accuracy: 0.7357\n",
      "Epoch 1806/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0646 - accuracy: 0.7719 - val_loss: 0.0747 - val_accuracy: 0.7361\n",
      "Epoch 1807/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0645 - accuracy: 0.7723 - val_loss: 0.0744 - val_accuracy: 0.7386\n",
      "Epoch 1808/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0646 - accuracy: 0.7723 - val_loss: 0.0748 - val_accuracy: 0.7376\n",
      "Epoch 1809/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0646 - accuracy: 0.7722 - val_loss: 0.0756 - val_accuracy: 0.7347\n",
      "Epoch 1810/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0646 - accuracy: 0.7719 - val_loss: 0.0752 - val_accuracy: 0.7352\n",
      "Epoch 1811/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0646 - accuracy: 0.7716 - val_loss: 0.0747 - val_accuracy: 0.7372\n",
      "Epoch 1812/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0646 - accuracy: 0.7721 - val_loss: 0.0744 - val_accuracy: 0.7381\n",
      "Epoch 1813/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0743 - val_accuracy: 0.7374\n",
      "Epoch 1814/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0646 - accuracy: 0.7721 - val_loss: 0.0748 - val_accuracy: 0.7379\n",
      "Epoch 1815/5000\n",
      "11786/11786 [==============================] - 8s 644us/step - loss: 0.0645 - accuracy: 0.7722 - val_loss: 0.0748 - val_accuracy: 0.7387\n",
      "Epoch 1816/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0646 - accuracy: 0.7718 - val_loss: 0.0750 - val_accuracy: 0.7381\n",
      "Epoch 1817/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0647 - accuracy: 0.7716 - val_loss: 0.0754 - val_accuracy: 0.7344\n",
      "Epoch 1818/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0647 - accuracy: 0.7721 - val_loss: 0.0740 - val_accuracy: 0.7397\n",
      "Epoch 1819/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0646 - accuracy: 0.7716 - val_loss: 0.0747 - val_accuracy: 0.7373\n",
      "Epoch 1820/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0646 - accuracy: 0.7719 - val_loss: 0.0742 - val_accuracy: 0.7394\n",
      "Epoch 1821/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0647 - accuracy: 0.7717 - val_loss: 0.0751 - val_accuracy: 0.7354\n",
      "Epoch 1822/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0647 - accuracy: 0.7714 - val_loss: 0.0749 - val_accuracy: 0.7366\n",
      "Epoch 1823/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0645 - accuracy: 0.7723 - val_loss: 0.0748 - val_accuracy: 0.7372\n",
      "Epoch 1824/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0646 - accuracy: 0.7719 - val_loss: 0.0741 - val_accuracy: 0.7383\n",
      "Epoch 1825/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0646 - accuracy: 0.7719 - val_loss: 0.0751 - val_accuracy: 0.7368\n",
      "Epoch 1826/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0645 - accuracy: 0.7721 - val_loss: 0.0750 - val_accuracy: 0.7343\n",
      "Epoch 1827/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0646 - accuracy: 0.7722 - val_loss: 0.0745 - val_accuracy: 0.7370\n",
      "Epoch 1828/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0646 - accuracy: 0.7719 - val_loss: 0.0744 - val_accuracy: 0.7390\n",
      "Epoch 1829/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0646 - accuracy: 0.7713 - val_loss: 0.0745 - val_accuracy: 0.7378\n",
      "Epoch 1830/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0646 - accuracy: 0.7719 - val_loss: 0.0754 - val_accuracy: 0.7348\n",
      "Epoch 1831/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0647 - accuracy: 0.7713 - val_loss: 0.0745 - val_accuracy: 0.7370\n",
      "Epoch 1832/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0647 - accuracy: 0.7717 - val_loss: 0.0759 - val_accuracy: 0.7373\n",
      "Epoch 1833/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0646 - accuracy: 0.7720 - val_loss: 0.0748 - val_accuracy: 0.7374\n",
      "Epoch 1834/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0646 - accuracy: 0.7719 - val_loss: 0.0746 - val_accuracy: 0.7378\n",
      "Epoch 1835/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0647 - accuracy: 0.7718 - val_loss: 0.0751 - val_accuracy: 0.7357\n",
      "Epoch 1836/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0648 - accuracy: 0.7714 - val_loss: 0.0747 - val_accuracy: 0.7357\n",
      "Epoch 1837/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0647 - accuracy: 0.7712 - val_loss: 0.0746 - val_accuracy: 0.7374\n",
      "Epoch 1838/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0646 - accuracy: 0.7717 - val_loss: 0.0750 - val_accuracy: 0.7381\n",
      "Epoch 1839/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0646 - accuracy: 0.7718 - val_loss: 0.0746 - val_accuracy: 0.7384\n",
      "Epoch 1840/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0646 - accuracy: 0.7722 - val_loss: 0.0747 - val_accuracy: 0.7369\n",
      "Epoch 1841/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0647 - accuracy: 0.7716 - val_loss: 0.0741 - val_accuracy: 0.7380\n",
      "Epoch 1842/5000\n",
      "11786/11786 [==============================] - 7s 627us/step - loss: 0.0646 - accuracy: 0.7715 - val_loss: 0.0744 - val_accuracy: 0.7388\n",
      "Epoch 1843/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0647 - accuracy: 0.7714 - val_loss: 0.0745 - val_accuracy: 0.7371\n",
      "Epoch 1844/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0647 - accuracy: 0.7714 - val_loss: 0.0745 - val_accuracy: 0.7381\n",
      "Epoch 1845/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0647 - accuracy: 0.7716 - val_loss: 0.0744 - val_accuracy: 0.7373\n",
      "Epoch 1846/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0647 - accuracy: 0.7718 - val_loss: 0.0745 - val_accuracy: 0.7374\n",
      "Epoch 1847/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0646 - accuracy: 0.7723 - val_loss: 0.0748 - val_accuracy: 0.7376\n",
      "Epoch 1848/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0648 - accuracy: 0.7711 - val_loss: 0.0744 - val_accuracy: 0.7383\n",
      "Epoch 1849/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0646 - accuracy: 0.7714 - val_loss: 0.0749 - val_accuracy: 0.7377\n",
      "Epoch 1850/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0646 - accuracy: 0.7719 - val_loss: 0.0743 - val_accuracy: 0.7396\n",
      "Epoch 1851/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0646 - accuracy: 0.7719 - val_loss: 0.0751 - val_accuracy: 0.7346\n",
      "Epoch 1852/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0646 - accuracy: 0.7717 - val_loss: 0.0745 - val_accuracy: 0.7382\n",
      "Epoch 1853/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0646 - accuracy: 0.7720 - val_loss: 0.0742 - val_accuracy: 0.7395\n",
      "Epoch 1854/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0647 - accuracy: 0.7721 - val_loss: 0.0742 - val_accuracy: 0.7382\n",
      "Epoch 1855/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0647 - accuracy: 0.7713 - val_loss: 0.0753 - val_accuracy: 0.7354\n",
      "Epoch 1856/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0647 - accuracy: 0.7717 - val_loss: 0.0745 - val_accuracy: 0.7371\n",
      "Epoch 1857/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0645 - accuracy: 0.7718 - val_loss: 0.0759 - val_accuracy: 0.7345\n",
      "Epoch 1858/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0646 - accuracy: 0.7723 - val_loss: 0.0746 - val_accuracy: 0.7373\n",
      "Epoch 1859/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0647 - accuracy: 0.7719 - val_loss: 0.0756 - val_accuracy: 0.7347\n",
      "Epoch 1860/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0647 - accuracy: 0.7718 - val_loss: 0.0743 - val_accuracy: 0.7384\n",
      "Epoch 1861/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0646 - accuracy: 0.7715 - val_loss: 0.0747 - val_accuracy: 0.7375\n",
      "Epoch 1862/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0647 - accuracy: 0.7716 - val_loss: 0.0746 - val_accuracy: 0.7374\n",
      "Epoch 1863/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0646 - accuracy: 0.7719 - val_loss: 0.0747 - val_accuracy: 0.7394\n",
      "Epoch 1864/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0647 - accuracy: 0.7718 - val_loss: 0.0744 - val_accuracy: 0.7383\n",
      "Epoch 1865/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0647 - accuracy: 0.7713 - val_loss: 0.0749 - val_accuracy: 0.7363\n",
      "Epoch 1866/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0647 - accuracy: 0.7718 - val_loss: 0.0746 - val_accuracy: 0.7384\n",
      "Epoch 1867/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0647 - accuracy: 0.7716 - val_loss: 0.0741 - val_accuracy: 0.7382\n",
      "Epoch 1868/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0646 - accuracy: 0.7721 - val_loss: 0.0745 - val_accuracy: 0.7391\n",
      "Epoch 1869/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0647 - accuracy: 0.7718 - val_loss: 0.0754 - val_accuracy: 0.7347\n",
      "Epoch 1870/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0646 - accuracy: 0.7718 - val_loss: 0.0742 - val_accuracy: 0.7373\n",
      "Epoch 1871/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0756 - val_accuracy: 0.7337\n",
      "Epoch 1872/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0647 - accuracy: 0.7723 - val_loss: 0.0747 - val_accuracy: 0.7365\n",
      "Epoch 1873/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0646 - accuracy: 0.7717 - val_loss: 0.0750 - val_accuracy: 0.7375\n",
      "Epoch 1874/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0646 - accuracy: 0.7722 - val_loss: 0.0744 - val_accuracy: 0.7383\n",
      "Epoch 1875/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0645 - accuracy: 0.7721 - val_loss: 0.0752 - val_accuracy: 0.7366\n",
      "Epoch 1876/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0647 - accuracy: 0.7722 - val_loss: 0.0744 - val_accuracy: 0.7384\n",
      "Epoch 1877/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0646 - accuracy: 0.7722 - val_loss: 0.0749 - val_accuracy: 0.7383\n",
      "Epoch 1878/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0646 - accuracy: 0.7720 - val_loss: 0.0742 - val_accuracy: 0.7403\n",
      "Epoch 1879/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0646 - accuracy: 0.7718 - val_loss: 0.0750 - val_accuracy: 0.7380\n",
      "Epoch 1880/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0648 - accuracy: 0.7716 - val_loss: 0.0750 - val_accuracy: 0.7376\n",
      "Epoch 1881/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0646 - accuracy: 0.7723 - val_loss: 0.0752 - val_accuracy: 0.7340\n",
      "Epoch 1882/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0647 - accuracy: 0.7715 - val_loss: 0.0746 - val_accuracy: 0.7381\n",
      "Epoch 1883/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0647 - accuracy: 0.7717 - val_loss: 0.0752 - val_accuracy: 0.7376\n",
      "Epoch 1884/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0646 - accuracy: 0.7720 - val_loss: 0.0747 - val_accuracy: 0.7368\n",
      "Epoch 1885/5000\n",
      "11786/11786 [==============================] - 7s 625us/step - loss: 0.0646 - accuracy: 0.7722 - val_loss: 0.0743 - val_accuracy: 0.7386\n",
      "Epoch 1886/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0646 - accuracy: 0.7725 - val_loss: 0.0744 - val_accuracy: 0.7389\n",
      "Epoch 1887/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0646 - accuracy: 0.7722 - val_loss: 0.0744 - val_accuracy: 0.7382\n",
      "Epoch 1888/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0646 - accuracy: 0.7723 - val_loss: 0.0749 - val_accuracy: 0.7382\n",
      "Epoch 1889/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0646 - accuracy: 0.7720 - val_loss: 0.0752 - val_accuracy: 0.7352\n",
      "Epoch 1890/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0646 - accuracy: 0.7722 - val_loss: 0.0752 - val_accuracy: 0.7366\n",
      "Epoch 1891/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0646 - accuracy: 0.7720 - val_loss: 0.0743 - val_accuracy: 0.7377\n",
      "Epoch 1892/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0646 - accuracy: 0.7719 - val_loss: 0.0750 - val_accuracy: 0.7368\n",
      "Epoch 1893/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0647 - accuracy: 0.7715 - val_loss: 0.0749 - val_accuracy: 0.7365\n",
      "Epoch 1894/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0647 - accuracy: 0.7717 - val_loss: 0.0748 - val_accuracy: 0.7372\n",
      "Epoch 1895/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0646 - accuracy: 0.7726 - val_loss: 0.0745 - val_accuracy: 0.7386\n",
      "Epoch 1896/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0646 - accuracy: 0.7720 - val_loss: 0.0754 - val_accuracy: 0.7360\n",
      "Epoch 1897/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0646 - accuracy: 0.7716 - val_loss: 0.0743 - val_accuracy: 0.7371\n",
      "Epoch 1898/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0646 - accuracy: 0.7722 - val_loss: 0.0753 - val_accuracy: 0.7370\n",
      "Epoch 1899/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0646 - accuracy: 0.7721 - val_loss: 0.0750 - val_accuracy: 0.7376\n",
      "Epoch 1900/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0647 - accuracy: 0.7716 - val_loss: 0.0744 - val_accuracy: 0.7386\n",
      "Epoch 1901/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0645 - accuracy: 0.7720 - val_loss: 0.0746 - val_accuracy: 0.7379\n",
      "Epoch 1902/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0645 - accuracy: 0.7720 - val_loss: 0.0757 - val_accuracy: 0.7324\n",
      "Epoch 1903/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0646 - accuracy: 0.7720 - val_loss: 0.0743 - val_accuracy: 0.7376\n",
      "Epoch 1904/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0646 - accuracy: 0.7717 - val_loss: 0.0744 - val_accuracy: 0.7386\n",
      "Epoch 1905/5000\n",
      "11786/11786 [==============================] - 8s 643us/step - loss: 0.0646 - accuracy: 0.7720 - val_loss: 0.0749 - val_accuracy: 0.7382\n",
      "Epoch 1906/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0646 - accuracy: 0.7716 - val_loss: 0.0747 - val_accuracy: 0.7375\n",
      "Epoch 1907/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0646 - accuracy: 0.7721 - val_loss: 0.0750 - val_accuracy: 0.7368\n",
      "Epoch 1908/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0646 - accuracy: 0.7727 - val_loss: 0.0747 - val_accuracy: 0.7389\n",
      "Epoch 1909/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0646 - accuracy: 0.7718 - val_loss: 0.0745 - val_accuracy: 0.7373\n",
      "Epoch 1910/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0646 - accuracy: 0.7720 - val_loss: 0.0746 - val_accuracy: 0.7384\n",
      "Epoch 1911/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0646 - accuracy: 0.7719 - val_loss: 0.0745 - val_accuracy: 0.7386\n",
      "Epoch 1912/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0646 - accuracy: 0.7728 - val_loss: 0.0744 - val_accuracy: 0.7389\n",
      "Epoch 1913/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0647 - accuracy: 0.7715 - val_loss: 0.0753 - val_accuracy: 0.7365\n",
      "Epoch 1914/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0646 - accuracy: 0.7715 - val_loss: 0.0751 - val_accuracy: 0.7374\n",
      "Epoch 1915/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0647 - accuracy: 0.7720 - val_loss: 0.0745 - val_accuracy: 0.7380\n",
      "Epoch 1916/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0647 - accuracy: 0.7715 - val_loss: 0.0746 - val_accuracy: 0.7380\n",
      "Epoch 1917/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0647 - accuracy: 0.7714 - val_loss: 0.0747 - val_accuracy: 0.7355\n",
      "Epoch 1918/5000\n",
      "11786/11786 [==============================] - 8s 644us/step - loss: 0.0646 - accuracy: 0.7721 - val_loss: 0.0751 - val_accuracy: 0.7350\n",
      "Epoch 1919/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0646 - accuracy: 0.7717 - val_loss: 0.0742 - val_accuracy: 0.7376\n",
      "Epoch 1920/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0646 - accuracy: 0.7722 - val_loss: 0.0754 - val_accuracy: 0.7362\n",
      "Epoch 1921/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0646 - accuracy: 0.7721 - val_loss: 0.0744 - val_accuracy: 0.7376\n",
      "Epoch 1922/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0646 - accuracy: 0.7723 - val_loss: 0.0752 - val_accuracy: 0.7363\n",
      "Epoch 1923/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0646 - accuracy: 0.7721 - val_loss: 0.0750 - val_accuracy: 0.7359\n",
      "Epoch 1924/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0646 - accuracy: 0.7718 - val_loss: 0.0742 - val_accuracy: 0.7376\n",
      "Epoch 1925/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0645 - accuracy: 0.7721 - val_loss: 0.0745 - val_accuracy: 0.7367\n",
      "Epoch 1926/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0647 - accuracy: 0.7715 - val_loss: 0.0749 - val_accuracy: 0.7371\n",
      "Epoch 1927/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0646 - accuracy: 0.7720 - val_loss: 0.0747 - val_accuracy: 0.7385\n",
      "Epoch 1928/5000\n",
      "11786/11786 [==============================] - 8s 636us/step - loss: 0.0647 - accuracy: 0.7712 - val_loss: 0.0747 - val_accuracy: 0.7376\n",
      "Epoch 1929/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0646 - accuracy: 0.7722 - val_loss: 0.0747 - val_accuracy: 0.7374\n",
      "Epoch 1930/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0648 - accuracy: 0.7711 - val_loss: 0.0746 - val_accuracy: 0.7364\n",
      "Epoch 1931/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0646 - accuracy: 0.7721 - val_loss: 0.0755 - val_accuracy: 0.7358\n",
      "Epoch 1932/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0645 - accuracy: 0.7723 - val_loss: 0.0756 - val_accuracy: 0.7353\n",
      "Epoch 1933/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0646 - accuracy: 0.7725 - val_loss: 0.0750 - val_accuracy: 0.7385\n",
      "Epoch 1934/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0646 - accuracy: 0.7722 - val_loss: 0.0746 - val_accuracy: 0.7370\n",
      "Epoch 1935/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0646 - accuracy: 0.7717 - val_loss: 0.0744 - val_accuracy: 0.7384\n",
      "Epoch 1936/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0647 - accuracy: 0.7717 - val_loss: 0.0746 - val_accuracy: 0.7389\n",
      "Epoch 1937/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0646 - accuracy: 0.7720 - val_loss: 0.0744 - val_accuracy: 0.7371\n",
      "Epoch 1938/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0645 - accuracy: 0.7720 - val_loss: 0.0749 - val_accuracy: 0.7369\n",
      "Epoch 1939/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0646 - accuracy: 0.7722 - val_loss: 0.0749 - val_accuracy: 0.7359\n",
      "Epoch 1940/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0645 - accuracy: 0.7720 - val_loss: 0.0747 - val_accuracy: 0.7366\n",
      "Epoch 1941/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0645 - accuracy: 0.7719 - val_loss: 0.0755 - val_accuracy: 0.7329\n",
      "Epoch 1942/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0647 - accuracy: 0.7721 - val_loss: 0.0747 - val_accuracy: 0.7378\n",
      "Epoch 1943/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0647 - accuracy: 0.7713 - val_loss: 0.0747 - val_accuracy: 0.7377\n",
      "Epoch 1944/5000\n",
      "11786/11786 [==============================] - 7s 632us/step - loss: 0.0646 - accuracy: 0.7720 - val_loss: 0.0752 - val_accuracy: 0.7368\n",
      "Epoch 1945/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0646 - accuracy: 0.7722 - val_loss: 0.0747 - val_accuracy: 0.7373\n",
      "Epoch 1946/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0647 - accuracy: 0.7717 - val_loss: 0.0755 - val_accuracy: 0.7360\n",
      "Epoch 1947/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0646 - accuracy: 0.7721 - val_loss: 0.0745 - val_accuracy: 0.7377\n",
      "Epoch 1948/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0645 - accuracy: 0.7728 - val_loss: 0.0746 - val_accuracy: 0.7386\n",
      "Epoch 1949/5000\n",
      "11786/11786 [==============================] - 8s 644us/step - loss: 0.0647 - accuracy: 0.7714 - val_loss: 0.0744 - val_accuracy: 0.7383\n",
      "Epoch 1950/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0647 - accuracy: 0.7717 - val_loss: 0.0760 - val_accuracy: 0.7341\n",
      "Epoch 1951/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0647 - accuracy: 0.7714 - val_loss: 0.0748 - val_accuracy: 0.7381\n",
      "Epoch 1952/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0647 - accuracy: 0.7714 - val_loss: 0.0744 - val_accuracy: 0.7385\n",
      "Epoch 1953/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0647 - accuracy: 0.7719 - val_loss: 0.0744 - val_accuracy: 0.7399\n",
      "Epoch 1954/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0647 - accuracy: 0.7717 - val_loss: 0.0748 - val_accuracy: 0.7374\n",
      "Epoch 1955/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0647 - accuracy: 0.7718 - val_loss: 0.0754 - val_accuracy: 0.7344\n",
      "Epoch 1956/5000\n",
      "11786/11786 [==============================] - 7s 629us/step - loss: 0.0646 - accuracy: 0.7717 - val_loss: 0.0750 - val_accuracy: 0.7367\n",
      "Epoch 1957/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0647 - accuracy: 0.7720 - val_loss: 0.0748 - val_accuracy: 0.7372\n",
      "Epoch 1958/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0646 - accuracy: 0.7720 - val_loss: 0.0748 - val_accuracy: 0.7371\n",
      "Epoch 1959/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0646 - accuracy: 0.7722 - val_loss: 0.0745 - val_accuracy: 0.7383\n",
      "Epoch 1960/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0646 - accuracy: 0.7721 - val_loss: 0.0750 - val_accuracy: 0.7359\n",
      "Epoch 1961/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0648 - accuracy: 0.7716 - val_loss: 0.0753 - val_accuracy: 0.7372\n",
      "Epoch 1962/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0646 - accuracy: 0.7718 - val_loss: 0.0745 - val_accuracy: 0.7388\n",
      "Epoch 1963/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0646 - accuracy: 0.7721 - val_loss: 0.0753 - val_accuracy: 0.7385\n",
      "Epoch 1964/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0646 - accuracy: 0.7723 - val_loss: 0.0753 - val_accuracy: 0.7344\n",
      "Epoch 1965/5000\n",
      "11786/11786 [==============================] - 8s 644us/step - loss: 0.0646 - accuracy: 0.7722 - val_loss: 0.0749 - val_accuracy: 0.7366\n",
      "Epoch 1966/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0647 - accuracy: 0.7717 - val_loss: 0.0751 - val_accuracy: 0.7359\n",
      "Epoch 1967/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0646 - accuracy: 0.7727 - val_loss: 0.0751 - val_accuracy: 0.7378\n",
      "Epoch 1968/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0647 - accuracy: 0.7714 - val_loss: 0.0752 - val_accuracy: 0.7374\n",
      "Epoch 1969/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0646 - accuracy: 0.7721 - val_loss: 0.0749 - val_accuracy: 0.7380\n",
      "Epoch 1970/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0647 - accuracy: 0.7719 - val_loss: 0.0742 - val_accuracy: 0.7381\n",
      "Epoch 1971/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0646 - accuracy: 0.7722 - val_loss: 0.0757 - val_accuracy: 0.7367\n",
      "Epoch 1972/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0647 - accuracy: 0.7720 - val_loss: 0.0744 - val_accuracy: 0.7376\n",
      "Epoch 1973/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0646 - accuracy: 0.7720 - val_loss: 0.0756 - val_accuracy: 0.7345\n",
      "Epoch 1974/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0646 - accuracy: 0.7721 - val_loss: 0.0750 - val_accuracy: 0.7385\n",
      "Epoch 1975/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0647 - accuracy: 0.7721 - val_loss: 0.0748 - val_accuracy: 0.7371\n",
      "Epoch 1976/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0646 - accuracy: 0.7716 - val_loss: 0.0749 - val_accuracy: 0.7374\n",
      "Epoch 1977/5000\n",
      "11786/11786 [==============================] - 8s 644us/step - loss: 0.0645 - accuracy: 0.7725 - val_loss: 0.0754 - val_accuracy: 0.7345\n",
      "Epoch 1978/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0647 - accuracy: 0.7718 - val_loss: 0.0746 - val_accuracy: 0.7375\n",
      "Epoch 1979/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0647 - accuracy: 0.7720 - val_loss: 0.0757 - val_accuracy: 0.7334\n",
      "Epoch 1980/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0647 - accuracy: 0.7722 - val_loss: 0.0748 - val_accuracy: 0.7360\n",
      "Epoch 1981/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0647 - accuracy: 0.7719 - val_loss: 0.0752 - val_accuracy: 0.7374\n",
      "Epoch 1982/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0647 - accuracy: 0.7720 - val_loss: 0.0754 - val_accuracy: 0.7361\n",
      "Epoch 1983/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0646 - accuracy: 0.7724 - val_loss: 0.0745 - val_accuracy: 0.7386\n",
      "Epoch 1984/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0647 - accuracy: 0.7725 - val_loss: 0.0743 - val_accuracy: 0.7368\n",
      "Epoch 1985/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0646 - accuracy: 0.7720 - val_loss: 0.0743 - val_accuracy: 0.7366\n",
      "Epoch 1986/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0647 - accuracy: 0.7722 - val_loss: 0.0746 - val_accuracy: 0.7375\n",
      "Epoch 1987/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0647 - accuracy: 0.7722 - val_loss: 0.0747 - val_accuracy: 0.7343\n",
      "Epoch 1988/5000\n",
      "11786/11786 [==============================] - 8s 643us/step - loss: 0.0647 - accuracy: 0.7721 - val_loss: 0.0747 - val_accuracy: 0.7374\n",
      "Epoch 1989/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0647 - accuracy: 0.7725 - val_loss: 0.0746 - val_accuracy: 0.7377\n",
      "Epoch 1990/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0647 - accuracy: 0.7718 - val_loss: 0.0753 - val_accuracy: 0.7346\n",
      "Epoch 1991/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0646 - accuracy: 0.7725 - val_loss: 0.0750 - val_accuracy: 0.7362\n",
      "Epoch 1992/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0648 - accuracy: 0.7718 - val_loss: 0.0755 - val_accuracy: 0.7364\n",
      "Epoch 1993/5000\n",
      "11786/11786 [==============================] - 8s 643us/step - loss: 0.0646 - accuracy: 0.7725 - val_loss: 0.0748 - val_accuracy: 0.7378\n",
      "Epoch 1994/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0649 - accuracy: 0.7716 - val_loss: 0.0747 - val_accuracy: 0.7363\n",
      "Epoch 1995/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0646 - accuracy: 0.7725 - val_loss: 0.0754 - val_accuracy: 0.7377\n",
      "Epoch 1996/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0647 - accuracy: 0.7724 - val_loss: 0.0741 - val_accuracy: 0.7386\n",
      "Epoch 1997/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0646 - accuracy: 0.7719 - val_loss: 0.0752 - val_accuracy: 0.7359\n",
      "Epoch 1998/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0646 - accuracy: 0.7726 - val_loss: 0.0748 - val_accuracy: 0.7369\n",
      "Epoch 1999/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0646 - accuracy: 0.7723 - val_loss: 0.0750 - val_accuracy: 0.7373\n",
      "Epoch 2000/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0647 - accuracy: 0.7728 - val_loss: 0.0748 - val_accuracy: 0.7367\n",
      "Epoch 2001/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0647 - accuracy: 0.7719 - val_loss: 0.0755 - val_accuracy: 0.7367\n",
      "Epoch 2002/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0648 - accuracy: 0.7721 - val_loss: 0.0748 - val_accuracy: 0.7369\n",
      "Epoch 2003/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0647 - accuracy: 0.7723 - val_loss: 0.0754 - val_accuracy: 0.7349\n",
      "Epoch 2004/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0647 - accuracy: 0.7722 - val_loss: 0.0747 - val_accuracy: 0.7379\n",
      "Epoch 2005/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0647 - accuracy: 0.7717 - val_loss: 0.0744 - val_accuracy: 0.7375\n",
      "Epoch 2006/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0646 - accuracy: 0.7721 - val_loss: 0.0759 - val_accuracy: 0.7326\n",
      "Epoch 2007/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0646 - accuracy: 0.7727 - val_loss: 0.0753 - val_accuracy: 0.7354\n",
      "Epoch 2008/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0648 - accuracy: 0.7715 - val_loss: 0.0750 - val_accuracy: 0.7359\n",
      "Epoch 2009/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0646 - accuracy: 0.7722 - val_loss: 0.0751 - val_accuracy: 0.7360\n",
      "Epoch 2010/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0647 - accuracy: 0.7719 - val_loss: 0.0742 - val_accuracy: 0.7391\n",
      "Epoch 2011/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0648 - accuracy: 0.7719 - val_loss: 0.0741 - val_accuracy: 0.7387\n",
      "Epoch 2012/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0647 - accuracy: 0.7721 - val_loss: 0.0746 - val_accuracy: 0.7381\n",
      "Epoch 2013/5000\n",
      "11786/11786 [==============================] - 8s 643us/step - loss: 0.0647 - accuracy: 0.7718 - val_loss: 0.0752 - val_accuracy: 0.7372\n",
      "Epoch 2014/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0647 - accuracy: 0.7721 - val_loss: 0.0742 - val_accuracy: 0.7387\n",
      "Epoch 2015/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0647 - accuracy: 0.7719 - val_loss: 0.0749 - val_accuracy: 0.7371\n",
      "Epoch 2016/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0647 - accuracy: 0.7721 - val_loss: 0.0757 - val_accuracy: 0.7341\n",
      "Epoch 2017/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0647 - accuracy: 0.7719 - val_loss: 0.0746 - val_accuracy: 0.7384\n",
      "Epoch 2018/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0646 - accuracy: 0.7723 - val_loss: 0.0758 - val_accuracy: 0.7363\n",
      "Epoch 2019/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0646 - accuracy: 0.7725 - val_loss: 0.0754 - val_accuracy: 0.7369\n",
      "Epoch 2020/5000\n",
      "11786/11786 [==============================] - 8s 644us/step - loss: 0.0647 - accuracy: 0.7722 - val_loss: 0.0750 - val_accuracy: 0.7344\n",
      "Epoch 2021/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0647 - accuracy: 0.7720 - val_loss: 0.0752 - val_accuracy: 0.7354\n",
      "Epoch 2022/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0647 - accuracy: 0.7721 - val_loss: 0.0746 - val_accuracy: 0.7371\n",
      "Epoch 2023/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0647 - accuracy: 0.7721 - val_loss: 0.0754 - val_accuracy: 0.7373\n",
      "Epoch 2024/5000\n",
      "11786/11786 [==============================] - 8s 643us/step - loss: 0.0646 - accuracy: 0.7720 - val_loss: 0.0752 - val_accuracy: 0.7360\n",
      "Epoch 2025/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0646 - accuracy: 0.7721 - val_loss: 0.0750 - val_accuracy: 0.7356\n",
      "Epoch 2026/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0648 - accuracy: 0.7721 - val_loss: 0.0752 - val_accuracy: 0.7368\n",
      "Epoch 2027/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0647 - accuracy: 0.7718 - val_loss: 0.0754 - val_accuracy: 0.7367\n",
      "Epoch 2028/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0646 - accuracy: 0.7723 - val_loss: 0.0744 - val_accuracy: 0.7402\n",
      "Epoch 2029/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0647 - accuracy: 0.7718 - val_loss: 0.0749 - val_accuracy: 0.7383\n",
      "Epoch 2030/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0647 - accuracy: 0.7719 - val_loss: 0.0742 - val_accuracy: 0.7384\n",
      "Epoch 2031/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0647 - accuracy: 0.7718 - val_loss: 0.0751 - val_accuracy: 0.7357\n",
      "Epoch 2032/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0648 - accuracy: 0.7715 - val_loss: 0.0746 - val_accuracy: 0.7372\n",
      "Epoch 2033/5000\n",
      "11786/11786 [==============================] - 7s 628us/step - loss: 0.0648 - accuracy: 0.7715 - val_loss: 0.0752 - val_accuracy: 0.7385\n",
      "Epoch 2034/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0648 - accuracy: 0.7719 - val_loss: 0.0747 - val_accuracy: 0.7376\n",
      "Epoch 2035/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0648 - accuracy: 0.7715 - val_loss: 0.0747 - val_accuracy: 0.7380\n",
      "Epoch 2036/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0647 - accuracy: 0.7722 - val_loss: 0.0746 - val_accuracy: 0.7390\n",
      "Epoch 2037/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0647 - accuracy: 0.7726 - val_loss: 0.0749 - val_accuracy: 0.7357\n",
      "Epoch 2038/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0647 - accuracy: 0.7719 - val_loss: 0.0745 - val_accuracy: 0.7388\n",
      "Epoch 2039/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0648 - accuracy: 0.7712 - val_loss: 0.0745 - val_accuracy: 0.7369\n",
      "Epoch 2040/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0648 - accuracy: 0.7714 - val_loss: 0.0749 - val_accuracy: 0.7353\n",
      "Epoch 2041/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0647 - accuracy: 0.7719 - val_loss: 0.0747 - val_accuracy: 0.7358\n",
      "Epoch 2042/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0648 - accuracy: 0.7716 - val_loss: 0.0745 - val_accuracy: 0.7392\n",
      "Epoch 2043/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0647 - accuracy: 0.7719 - val_loss: 0.0745 - val_accuracy: 0.7375\n",
      "Epoch 2044/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0648 - accuracy: 0.7718 - val_loss: 0.0755 - val_accuracy: 0.7368\n",
      "Epoch 2045/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0648 - accuracy: 0.7712 - val_loss: 0.0759 - val_accuracy: 0.7354\n",
      "Epoch 2046/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0648 - accuracy: 0.7716 - val_loss: 0.0747 - val_accuracy: 0.7367\n",
      "Epoch 2047/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0648 - accuracy: 0.7715 - val_loss: 0.0758 - val_accuracy: 0.7363\n",
      "Epoch 2048/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0648 - accuracy: 0.7714 - val_loss: 0.0745 - val_accuracy: 0.7393\n",
      "Epoch 2049/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0646 - accuracy: 0.7725 - val_loss: 0.0746 - val_accuracy: 0.7374\n",
      "Epoch 2050/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0647 - accuracy: 0.7714 - val_loss: 0.0746 - val_accuracy: 0.7378\n",
      "Epoch 2051/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0648 - accuracy: 0.7716 - val_loss: 0.0758 - val_accuracy: 0.7348\n",
      "Epoch 2052/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0647 - accuracy: 0.7717 - val_loss: 0.0749 - val_accuracy: 0.7379\n",
      "Epoch 2053/5000\n",
      "11786/11786 [==============================] - 8s 643us/step - loss: 0.0647 - accuracy: 0.7719 - val_loss: 0.0750 - val_accuracy: 0.7361\n",
      "Epoch 2054/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0647 - accuracy: 0.7717 - val_loss: 0.0750 - val_accuracy: 0.7346\n",
      "Epoch 2055/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0647 - accuracy: 0.7717 - val_loss: 0.0753 - val_accuracy: 0.7349\n",
      "Epoch 2056/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0647 - accuracy: 0.7719 - val_loss: 0.0744 - val_accuracy: 0.7380\n",
      "Epoch 2057/5000\n",
      "11786/11786 [==============================] - 8s 644us/step - loss: 0.0648 - accuracy: 0.7715 - val_loss: 0.0746 - val_accuracy: 0.7371\n",
      "Epoch 2058/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0648 - accuracy: 0.7717 - val_loss: 0.0748 - val_accuracy: 0.7385\n",
      "Epoch 2059/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0646 - accuracy: 0.7722 - val_loss: 0.0754 - val_accuracy: 0.7378\n",
      "Epoch 2060/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0647 - accuracy: 0.7716 - val_loss: 0.0752 - val_accuracy: 0.7359\n",
      "Epoch 2061/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0648 - accuracy: 0.7716 - val_loss: 0.0749 - val_accuracy: 0.7383\n",
      "Epoch 2062/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0646 - accuracy: 0.7718 - val_loss: 0.0749 - val_accuracy: 0.7370\n",
      "Epoch 2063/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0647 - accuracy: 0.7721 - val_loss: 0.0746 - val_accuracy: 0.7390\n",
      "Epoch 2064/5000\n",
      "11786/11786 [==============================] - 8s 643us/step - loss: 0.0647 - accuracy: 0.7716 - val_loss: 0.0748 - val_accuracy: 0.7380\n",
      "Epoch 2065/5000\n",
      "11786/11786 [==============================] - 8s 643us/step - loss: 0.0647 - accuracy: 0.7718 - val_loss: 0.0747 - val_accuracy: 0.7372\n",
      "Epoch 2066/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0647 - accuracy: 0.7719 - val_loss: 0.0747 - val_accuracy: 0.7377\n",
      "Epoch 2067/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0648 - accuracy: 0.7717 - val_loss: 0.0751 - val_accuracy: 0.7362\n",
      "Epoch 2068/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0647 - accuracy: 0.7716 - val_loss: 0.0742 - val_accuracy: 0.7381\n",
      "Epoch 2069/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0648 - accuracy: 0.7716 - val_loss: 0.0745 - val_accuracy: 0.7356\n",
      "Epoch 2070/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0648 - accuracy: 0.7716 - val_loss: 0.0751 - val_accuracy: 0.7380\n",
      "Epoch 2071/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0646 - accuracy: 0.7725 - val_loss: 0.0753 - val_accuracy: 0.7354\n",
      "Epoch 2072/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0647 - accuracy: 0.7715 - val_loss: 0.0747 - val_accuracy: 0.7370\n",
      "Epoch 2073/5000\n",
      "11786/11786 [==============================] - 7s 630us/step - loss: 0.0647 - accuracy: 0.7720 - val_loss: 0.0754 - val_accuracy: 0.7378\n",
      "Epoch 2074/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0646 - accuracy: 0.7728 - val_loss: 0.0748 - val_accuracy: 0.7358\n",
      "Epoch 2075/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0649 - accuracy: 0.7719 - val_loss: 0.0752 - val_accuracy: 0.7372\n",
      "Epoch 2076/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0649 - accuracy: 0.7714 - val_loss: 0.0749 - val_accuracy: 0.7374\n",
      "Epoch 2077/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0646 - accuracy: 0.7719 - val_loss: 0.0752 - val_accuracy: 0.7350\n",
      "Epoch 2078/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0647 - accuracy: 0.7717 - val_loss: 0.0755 - val_accuracy: 0.7360\n",
      "Epoch 2079/5000\n",
      "11786/11786 [==============================] - 8s 643us/step - loss: 0.0647 - accuracy: 0.7722 - val_loss: 0.0752 - val_accuracy: 0.7359\n",
      "Epoch 2080/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0647 - accuracy: 0.7718 - val_loss: 0.0752 - val_accuracy: 0.7373\n",
      "Epoch 2081/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0647 - accuracy: 0.7721 - val_loss: 0.0750 - val_accuracy: 0.7356\n",
      "Epoch 2082/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0648 - accuracy: 0.7712 - val_loss: 0.0744 - val_accuracy: 0.7376\n",
      "Epoch 2083/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0648 - accuracy: 0.7718 - val_loss: 0.0749 - val_accuracy: 0.7373\n",
      "Epoch 2084/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0648 - accuracy: 0.7718 - val_loss: 0.0744 - val_accuracy: 0.7382\n",
      "Epoch 2085/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0648 - accuracy: 0.7718 - val_loss: 0.0748 - val_accuracy: 0.7367\n",
      "Epoch 2086/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0648 - accuracy: 0.7717 - val_loss: 0.0749 - val_accuracy: 0.7357\n",
      "Epoch 2087/5000\n",
      "11786/11786 [==============================] - 8s 643us/step - loss: 0.0648 - accuracy: 0.7720 - val_loss: 0.0750 - val_accuracy: 0.7357\n",
      "Epoch 2088/5000\n",
      "11786/11786 [==============================] - 7s 633us/step - loss: 0.0650 - accuracy: 0.7709 - val_loss: 0.0744 - val_accuracy: 0.7372\n",
      "Epoch 2089/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0648 - accuracy: 0.7716 - val_loss: 0.0747 - val_accuracy: 0.7371\n",
      "Epoch 2090/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0648 - accuracy: 0.7715 - val_loss: 0.0752 - val_accuracy: 0.7348\n",
      "Epoch 2091/5000\n",
      "11786/11786 [==============================] - 8s 644us/step - loss: 0.0648 - accuracy: 0.7720 - val_loss: 0.0751 - val_accuracy: 0.7346\n",
      "Epoch 2092/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0648 - accuracy: 0.7721 - val_loss: 0.0744 - val_accuracy: 0.7391\n",
      "Epoch 2093/5000\n",
      "11786/11786 [==============================] - 8s 644us/step - loss: 0.0648 - accuracy: 0.7712 - val_loss: 0.0754 - val_accuracy: 0.7346\n",
      "Epoch 2094/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0647 - accuracy: 0.7718 - val_loss: 0.0752 - val_accuracy: 0.7355\n",
      "Epoch 2095/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0647 - accuracy: 0.7718 - val_loss: 0.0748 - val_accuracy: 0.7369\n",
      "Epoch 2096/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0647 - accuracy: 0.7717 - val_loss: 0.0749 - val_accuracy: 0.7357\n",
      "Epoch 2097/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0647 - accuracy: 0.7716 - val_loss: 0.0758 - val_accuracy: 0.7365\n",
      "Epoch 2098/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0647 - accuracy: 0.7721 - val_loss: 0.0749 - val_accuracy: 0.7372\n",
      "Epoch 2099/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0648 - accuracy: 0.7714 - val_loss: 0.0745 - val_accuracy: 0.7368\n",
      "Epoch 2100/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0647 - accuracy: 0.7716 - val_loss: 0.0751 - val_accuracy: 0.7374\n",
      "Epoch 2101/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0647 - accuracy: 0.7718 - val_loss: 0.0751 - val_accuracy: 0.7372\n",
      "Epoch 2102/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0646 - accuracy: 0.7725 - val_loss: 0.0746 - val_accuracy: 0.7383\n",
      "Epoch 2103/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0646 - accuracy: 0.7721 - val_loss: 0.0746 - val_accuracy: 0.7383\n",
      "Epoch 2104/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0646 - accuracy: 0.7720 - val_loss: 0.0756 - val_accuracy: 0.7356\n",
      "Epoch 2105/5000\n",
      "11786/11786 [==============================] - 8s 644us/step - loss: 0.0648 - accuracy: 0.7715 - val_loss: 0.0751 - val_accuracy: 0.7369\n",
      "Epoch 2106/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0647 - accuracy: 0.7720 - val_loss: 0.0756 - val_accuracy: 0.7356\n",
      "Epoch 2107/5000\n",
      "11786/11786 [==============================] - 8s 643us/step - loss: 0.0648 - accuracy: 0.7714 - val_loss: 0.0744 - val_accuracy: 0.7381\n",
      "Epoch 2108/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0648 - accuracy: 0.7716 - val_loss: 0.0752 - val_accuracy: 0.7364\n",
      "Epoch 2109/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0647 - accuracy: 0.7719 - val_loss: 0.0746 - val_accuracy: 0.7375\n",
      "Epoch 2110/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0648 - accuracy: 0.7716 - val_loss: 0.0744 - val_accuracy: 0.7391\n",
      "Epoch 2111/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0649 - accuracy: 0.7715 - val_loss: 0.0745 - val_accuracy: 0.7376\n",
      "Epoch 2112/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0648 - accuracy: 0.7714 - val_loss: 0.0747 - val_accuracy: 0.7364\n",
      "Epoch 2113/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0648 - accuracy: 0.7715 - val_loss: 0.0753 - val_accuracy: 0.7366\n",
      "Epoch 2114/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0648 - accuracy: 0.7714 - val_loss: 0.0750 - val_accuracy: 0.7348\n",
      "Epoch 2115/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0647 - accuracy: 0.7721 - val_loss: 0.0750 - val_accuracy: 0.7356\n",
      "Epoch 2116/5000\n",
      "11786/11786 [==============================] - 8s 643us/step - loss: 0.0648 - accuracy: 0.7714 - val_loss: 0.0748 - val_accuracy: 0.7355\n",
      "Epoch 2117/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0647 - accuracy: 0.7718 - val_loss: 0.0750 - val_accuracy: 0.7363\n",
      "Epoch 2118/5000\n",
      "11786/11786 [==============================] - 8s 636us/step - loss: 0.0647 - accuracy: 0.7717 - val_loss: 0.0747 - val_accuracy: 0.7374\n",
      "Epoch 2119/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0648 - accuracy: 0.7716 - val_loss: 0.0748 - val_accuracy: 0.7380\n",
      "Epoch 2120/5000\n",
      "11786/11786 [==============================] - 8s 643us/step - loss: 0.0647 - accuracy: 0.7723 - val_loss: 0.0752 - val_accuracy: 0.7367\n",
      "Epoch 2121/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0647 - accuracy: 0.7725 - val_loss: 0.0750 - val_accuracy: 0.7359\n",
      "Epoch 2122/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0647 - accuracy: 0.7720 - val_loss: 0.0754 - val_accuracy: 0.7355\n",
      "Epoch 2123/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0647 - accuracy: 0.7720 - val_loss: 0.0758 - val_accuracy: 0.7357\n",
      "Epoch 2124/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0648 - accuracy: 0.7720 - val_loss: 0.0747 - val_accuracy: 0.7373\n",
      "Epoch 2125/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0648 - accuracy: 0.7716 - val_loss: 0.0747 - val_accuracy: 0.7384\n",
      "Epoch 2126/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0647 - accuracy: 0.7722 - val_loss: 0.0757 - val_accuracy: 0.7374\n",
      "Epoch 2127/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0648 - accuracy: 0.7714 - val_loss: 0.0745 - val_accuracy: 0.7384\n",
      "Epoch 2128/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0649 - accuracy: 0.7714 - val_loss: 0.0749 - val_accuracy: 0.7382\n",
      "Epoch 2129/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0647 - accuracy: 0.7719 - val_loss: 0.0751 - val_accuracy: 0.7356\n",
      "Epoch 2130/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0649 - accuracy: 0.7713 - val_loss: 0.0747 - val_accuracy: 0.7367\n",
      "Epoch 2131/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0648 - accuracy: 0.7715 - val_loss: 0.0748 - val_accuracy: 0.7361\n",
      "Epoch 2132/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0648 - accuracy: 0.7717 - val_loss: 0.0750 - val_accuracy: 0.7360\n",
      "Epoch 2133/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0648 - accuracy: 0.7712 - val_loss: 0.0747 - val_accuracy: 0.7383\n",
      "Epoch 2134/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0647 - accuracy: 0.7721 - val_loss: 0.0754 - val_accuracy: 0.7361\n",
      "Epoch 2135/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0647 - accuracy: 0.7719 - val_loss: 0.0749 - val_accuracy: 0.7370\n",
      "Epoch 2136/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0647 - accuracy: 0.7721 - val_loss: 0.0746 - val_accuracy: 0.7365\n",
      "Epoch 2137/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0647 - accuracy: 0.7719 - val_loss: 0.0753 - val_accuracy: 0.7375\n",
      "Epoch 2138/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0648 - accuracy: 0.7717 - val_loss: 0.0749 - val_accuracy: 0.7358\n",
      "Epoch 2139/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0647 - accuracy: 0.7715 - val_loss: 0.0751 - val_accuracy: 0.7359\n",
      "Epoch 2140/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0648 - accuracy: 0.7711 - val_loss: 0.0749 - val_accuracy: 0.7366\n",
      "Epoch 2141/5000\n",
      "11786/11786 [==============================] - 8s 643us/step - loss: 0.0647 - accuracy: 0.7722 - val_loss: 0.0759 - val_accuracy: 0.7337\n",
      "Epoch 2142/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0648 - accuracy: 0.7715 - val_loss: 0.0744 - val_accuracy: 0.7389\n",
      "Epoch 2143/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0647 - accuracy: 0.7721 - val_loss: 0.0752 - val_accuracy: 0.7386\n",
      "Epoch 2144/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0646 - accuracy: 0.7723 - val_loss: 0.0746 - val_accuracy: 0.7384\n",
      "Epoch 2145/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0648 - accuracy: 0.7717 - val_loss: 0.0749 - val_accuracy: 0.7356\n",
      "Epoch 2146/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0647 - accuracy: 0.7718 - val_loss: 0.0746 - val_accuracy: 0.7378\n",
      "Epoch 2147/5000\n",
      "11786/11786 [==============================] - 8s 643us/step - loss: 0.0647 - accuracy: 0.7722 - val_loss: 0.0759 - val_accuracy: 0.7344\n",
      "Epoch 2148/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0647 - accuracy: 0.7720 - val_loss: 0.0745 - val_accuracy: 0.7374\n",
      "Epoch 2149/5000\n",
      "11786/11786 [==============================] - 8s 644us/step - loss: 0.0648 - accuracy: 0.7719 - val_loss: 0.0743 - val_accuracy: 0.7382\n",
      "Epoch 2150/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0647 - accuracy: 0.7722 - val_loss: 0.0752 - val_accuracy: 0.7397\n",
      "Epoch 2151/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0649 - accuracy: 0.7715 - val_loss: 0.0743 - val_accuracy: 0.7383\n",
      "Epoch 2152/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0648 - accuracy: 0.7720 - val_loss: 0.0749 - val_accuracy: 0.7375\n",
      "Epoch 2153/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0648 - accuracy: 0.7721 - val_loss: 0.0752 - val_accuracy: 0.7379\n",
      "Epoch 2154/5000\n",
      "11786/11786 [==============================] - 8s 636us/step - loss: 0.0647 - accuracy: 0.7721 - val_loss: 0.0745 - val_accuracy: 0.7373\n",
      "Epoch 2155/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0648 - accuracy: 0.7718 - val_loss: 0.0748 - val_accuracy: 0.7380\n",
      "Epoch 2156/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0649 - accuracy: 0.7715 - val_loss: 0.0754 - val_accuracy: 0.7374\n",
      "Epoch 2157/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0648 - accuracy: 0.7720 - val_loss: 0.0748 - val_accuracy: 0.7359\n",
      "Epoch 2158/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0648 - accuracy: 0.7714 - val_loss: 0.0753 - val_accuracy: 0.7356\n",
      "Epoch 2159/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0649 - accuracy: 0.7717 - val_loss: 0.0744 - val_accuracy: 0.7386\n",
      "Epoch 2160/5000\n",
      "11786/11786 [==============================] - 7s 631us/step - loss: 0.0648 - accuracy: 0.7720 - val_loss: 0.0749 - val_accuracy: 0.7373\n",
      "Epoch 2161/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0648 - accuracy: 0.7720 - val_loss: 0.0748 - val_accuracy: 0.7374\n",
      "Epoch 2162/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0647 - accuracy: 0.7719 - val_loss: 0.0750 - val_accuracy: 0.7366\n",
      "Epoch 2163/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0648 - accuracy: 0.7720 - val_loss: 0.0748 - val_accuracy: 0.7371\n",
      "Epoch 2164/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0649 - accuracy: 0.7716 - val_loss: 0.0750 - val_accuracy: 0.7370\n",
      "Epoch 2165/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0647 - accuracy: 0.7717 - val_loss: 0.0757 - val_accuracy: 0.7371\n",
      "Epoch 2166/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0646 - accuracy: 0.7727 - val_loss: 0.0751 - val_accuracy: 0.7366\n",
      "Epoch 2167/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0647 - accuracy: 0.7724 - val_loss: 0.0756 - val_accuracy: 0.7365\n",
      "Epoch 2168/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0648 - accuracy: 0.7721 - val_loss: 0.0748 - val_accuracy: 0.7370\n",
      "Epoch 2169/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0647 - accuracy: 0.7718 - val_loss: 0.0747 - val_accuracy: 0.7380\n",
      "Epoch 2170/5000\n",
      "11786/11786 [==============================] - 8s 644us/step - loss: 0.0647 - accuracy: 0.7722 - val_loss: 0.0744 - val_accuracy: 0.7379\n",
      "Epoch 2171/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0647 - accuracy: 0.7721 - val_loss: 0.0753 - val_accuracy: 0.7369\n",
      "Epoch 2172/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0647 - accuracy: 0.7722 - val_loss: 0.0761 - val_accuracy: 0.7320\n",
      "Epoch 2173/5000\n",
      "11786/11786 [==============================] - 8s 643us/step - loss: 0.0648 - accuracy: 0.7717 - val_loss: 0.0745 - val_accuracy: 0.7380\n",
      "Epoch 2174/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0647 - accuracy: 0.7724 - val_loss: 0.0751 - val_accuracy: 0.7374\n",
      "Epoch 2175/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0647 - accuracy: 0.7720 - val_loss: 0.0744 - val_accuracy: 0.7374\n",
      "Epoch 2176/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0648 - accuracy: 0.7716 - val_loss: 0.0752 - val_accuracy: 0.7379\n",
      "Epoch 2177/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0648 - accuracy: 0.7714 - val_loss: 0.0749 - val_accuracy: 0.7366\n",
      "Epoch 2178/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0648 - accuracy: 0.7716 - val_loss: 0.0756 - val_accuracy: 0.7339\n",
      "Epoch 2179/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0646 - accuracy: 0.7726 - val_loss: 0.0750 - val_accuracy: 0.7367\n",
      "Epoch 2180/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0648 - accuracy: 0.7718 - val_loss: 0.0749 - val_accuracy: 0.7390\n",
      "Epoch 2181/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0647 - accuracy: 0.7720 - val_loss: 0.0746 - val_accuracy: 0.7366\n",
      "Epoch 2182/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0647 - accuracy: 0.7722 - val_loss: 0.0747 - val_accuracy: 0.7369\n",
      "Epoch 2183/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0648 - accuracy: 0.7726 - val_loss: 0.0746 - val_accuracy: 0.7367\n",
      "Epoch 2184/5000\n",
      "11786/11786 [==============================] - 8s 643us/step - loss: 0.0648 - accuracy: 0.7719 - val_loss: 0.0746 - val_accuracy: 0.7365\n",
      "Epoch 2185/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0649 - accuracy: 0.7717 - val_loss: 0.0749 - val_accuracy: 0.7382\n",
      "Epoch 2186/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0647 - accuracy: 0.7716 - val_loss: 0.0747 - val_accuracy: 0.7376\n",
      "Epoch 2187/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0648 - accuracy: 0.7721 - val_loss: 0.0744 - val_accuracy: 0.7386\n",
      "Epoch 2188/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0647 - accuracy: 0.7724 - val_loss: 0.0750 - val_accuracy: 0.7354\n",
      "Epoch 2189/5000\n",
      "11786/11786 [==============================] - 8s 644us/step - loss: 0.0648 - accuracy: 0.7719 - val_loss: 0.0748 - val_accuracy: 0.7375\n",
      "Epoch 2190/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0649 - accuracy: 0.7719 - val_loss: 0.0742 - val_accuracy: 0.7397\n",
      "Epoch 2191/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0648 - accuracy: 0.7717 - val_loss: 0.0751 - val_accuracy: 0.7363\n",
      "Epoch 2192/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0648 - accuracy: 0.7721 - val_loss: 0.0750 - val_accuracy: 0.7379\n",
      "Epoch 2193/5000\n",
      "11786/11786 [==============================] - 8s 644us/step - loss: 0.0648 - accuracy: 0.7722 - val_loss: 0.0747 - val_accuracy: 0.7378\n",
      "Epoch 2194/5000\n",
      "11786/11786 [==============================] - 8s 643us/step - loss: 0.0648 - accuracy: 0.7717 - val_loss: 0.0753 - val_accuracy: 0.7364\n",
      "Epoch 2195/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0648 - accuracy: 0.7718 - val_loss: 0.0748 - val_accuracy: 0.7361\n",
      "Epoch 2196/5000\n",
      "11786/11786 [==============================] - 8s 643us/step - loss: 0.0647 - accuracy: 0.7723 - val_loss: 0.0756 - val_accuracy: 0.7359\n",
      "Epoch 2197/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0648 - accuracy: 0.7722 - val_loss: 0.0749 - val_accuracy: 0.7361\n",
      "Epoch 2198/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0648 - accuracy: 0.7720 - val_loss: 0.0750 - val_accuracy: 0.7378\n",
      "Epoch 2199/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0649 - accuracy: 0.7715 - val_loss: 0.0755 - val_accuracy: 0.7361\n",
      "Epoch 2200/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0647 - accuracy: 0.7715 - val_loss: 0.0748 - val_accuracy: 0.7362\n",
      "Epoch 2201/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0648 - accuracy: 0.7719 - val_loss: 0.0750 - val_accuracy: 0.7361\n",
      "Epoch 2202/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0647 - accuracy: 0.7723 - val_loss: 0.0749 - val_accuracy: 0.7374\n",
      "Epoch 2203/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0648 - accuracy: 0.7719 - val_loss: 0.0760 - val_accuracy: 0.7358\n",
      "Epoch 2204/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0648 - accuracy: 0.7715 - val_loss: 0.0754 - val_accuracy: 0.7360\n",
      "Epoch 2205/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0649 - accuracy: 0.7713 - val_loss: 0.0754 - val_accuracy: 0.7368\n",
      "Epoch 2206/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0649 - accuracy: 0.7714 - val_loss: 0.0748 - val_accuracy: 0.7370\n",
      "Epoch 2207/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0648 - accuracy: 0.7718 - val_loss: 0.0746 - val_accuracy: 0.7371\n",
      "Epoch 2208/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0649 - accuracy: 0.7710 - val_loss: 0.0749 - val_accuracy: 0.7365\n",
      "Epoch 2209/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0649 - accuracy: 0.7717 - val_loss: 0.0750 - val_accuracy: 0.7381\n",
      "Epoch 2210/5000\n",
      "11786/11786 [==============================] - 8s 644us/step - loss: 0.0650 - accuracy: 0.7716 - val_loss: 0.0747 - val_accuracy: 0.7370\n",
      "Epoch 2211/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0647 - accuracy: 0.7724 - val_loss: 0.0752 - val_accuracy: 0.7355\n",
      "Epoch 2212/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0649 - accuracy: 0.7718 - val_loss: 0.0748 - val_accuracy: 0.7375\n",
      "Epoch 2213/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0649 - accuracy: 0.7716 - val_loss: 0.0753 - val_accuracy: 0.7372\n",
      "Epoch 2214/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0649 - accuracy: 0.7718 - val_loss: 0.0747 - val_accuracy: 0.7386\n",
      "Epoch 2215/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0648 - accuracy: 0.7724 - val_loss: 0.0749 - val_accuracy: 0.7372\n",
      "Epoch 2216/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0648 - accuracy: 0.7719 - val_loss: 0.0754 - val_accuracy: 0.7371\n",
      "Epoch 2217/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0648 - accuracy: 0.7723 - val_loss: 0.0753 - val_accuracy: 0.7344\n",
      "Epoch 2218/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0647 - accuracy: 0.7719 - val_loss: 0.0748 - val_accuracy: 0.7360\n",
      "Epoch 2219/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0648 - accuracy: 0.7721 - val_loss: 0.0753 - val_accuracy: 0.7372\n",
      "Epoch 2220/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0649 - accuracy: 0.7711 - val_loss: 0.0750 - val_accuracy: 0.7352\n",
      "Epoch 2221/5000\n",
      "11786/11786 [==============================] - 8s 644us/step - loss: 0.0648 - accuracy: 0.7717 - val_loss: 0.0748 - val_accuracy: 0.7372\n",
      "Epoch 2222/5000\n",
      "11786/11786 [==============================] - 8s 644us/step - loss: 0.0648 - accuracy: 0.7719 - val_loss: 0.0756 - val_accuracy: 0.7363\n",
      "Epoch 2223/5000\n",
      "11786/11786 [==============================] - 8s 644us/step - loss: 0.0648 - accuracy: 0.7722 - val_loss: 0.0752 - val_accuracy: 0.7355\n",
      "Epoch 2224/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0649 - accuracy: 0.7715 - val_loss: 0.0750 - val_accuracy: 0.7357\n",
      "Epoch 2225/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0650 - accuracy: 0.7715 - val_loss: 0.0746 - val_accuracy: 0.7367\n",
      "Epoch 2226/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0648 - accuracy: 0.7721 - val_loss: 0.0751 - val_accuracy: 0.7375\n",
      "Epoch 2227/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0649 - accuracy: 0.7714 - val_loss: 0.0752 - val_accuracy: 0.7372\n",
      "Epoch 2228/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0648 - accuracy: 0.7721 - val_loss: 0.0747 - val_accuracy: 0.7372\n",
      "Epoch 2229/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0649 - accuracy: 0.7713 - val_loss: 0.0760 - val_accuracy: 0.7362\n",
      "Epoch 2230/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0650 - accuracy: 0.7711 - val_loss: 0.0757 - val_accuracy: 0.7348\n",
      "Epoch 2231/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0650 - accuracy: 0.7712 - val_loss: 0.0750 - val_accuracy: 0.7369\n",
      "Epoch 2232/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0648 - accuracy: 0.7723 - val_loss: 0.0751 - val_accuracy: 0.7368\n",
      "Epoch 2233/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0647 - accuracy: 0.7722 - val_loss: 0.0748 - val_accuracy: 0.7379\n",
      "Epoch 2234/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0649 - accuracy: 0.7719 - val_loss: 0.0750 - val_accuracy: 0.7368\n",
      "Epoch 2235/5000\n",
      "11786/11786 [==============================] - 8s 643us/step - loss: 0.0649 - accuracy: 0.7716 - val_loss: 0.0749 - val_accuracy: 0.7369\n",
      "Epoch 2236/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0651 - accuracy: 0.7710 - val_loss: 0.0747 - val_accuracy: 0.7377\n",
      "Epoch 2237/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0650 - accuracy: 0.7714 - val_loss: 0.0749 - val_accuracy: 0.7367\n",
      "Epoch 2238/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0650 - accuracy: 0.7713 - val_loss: 0.0761 - val_accuracy: 0.7335\n",
      "Epoch 2239/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0651 - accuracy: 0.7711 - val_loss: 0.0750 - val_accuracy: 0.7381\n",
      "Epoch 2240/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0649 - accuracy: 0.7715 - val_loss: 0.0752 - val_accuracy: 0.7368\n",
      "Epoch 2241/5000\n",
      "11786/11786 [==============================] - 7s 636us/step - loss: 0.0649 - accuracy: 0.7720 - val_loss: 0.0754 - val_accuracy: 0.7384\n",
      "Epoch 2242/5000\n",
      "11786/11786 [==============================] - 7s 634us/step - loss: 0.0649 - accuracy: 0.7718 - val_loss: 0.0749 - val_accuracy: 0.7379\n",
      "Epoch 2243/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0649 - accuracy: 0.7720 - val_loss: 0.0752 - val_accuracy: 0.7378\n",
      "Epoch 2244/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0648 - accuracy: 0.7719 - val_loss: 0.0749 - val_accuracy: 0.7376\n",
      "Epoch 2245/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0650 - accuracy: 0.7710 - val_loss: 0.0757 - val_accuracy: 0.7372\n",
      "Epoch 2246/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0651 - accuracy: 0.7712 - val_loss: 0.0751 - val_accuracy: 0.7367\n",
      "Epoch 2247/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0650 - accuracy: 0.7717 - val_loss: 0.0752 - val_accuracy: 0.7369\n",
      "Epoch 2248/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0650 - accuracy: 0.7711 - val_loss: 0.0752 - val_accuracy: 0.7375\n",
      "Epoch 2249/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0650 - accuracy: 0.7713 - val_loss: 0.0749 - val_accuracy: 0.7381\n",
      "Epoch 2250/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0650 - accuracy: 0.7710 - val_loss: 0.0754 - val_accuracy: 0.7346\n",
      "Epoch 2251/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0650 - accuracy: 0.7711 - val_loss: 0.0760 - val_accuracy: 0.7321\n",
      "Epoch 2252/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0650 - accuracy: 0.7710 - val_loss: 0.0751 - val_accuracy: 0.7361\n",
      "Epoch 2253/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0650 - accuracy: 0.7710 - val_loss: 0.0748 - val_accuracy: 0.7369\n",
      "Epoch 2254/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0650 - accuracy: 0.7712 - val_loss: 0.0754 - val_accuracy: 0.7370\n",
      "Epoch 2255/5000\n",
      "11786/11786 [==============================] - 8s 644us/step - loss: 0.0649 - accuracy: 0.7717 - val_loss: 0.0751 - val_accuracy: 0.7361\n",
      "Epoch 2256/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0650 - accuracy: 0.7714 - val_loss: 0.0751 - val_accuracy: 0.7374\n",
      "Epoch 2257/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0649 - accuracy: 0.7717 - val_loss: 0.0748 - val_accuracy: 0.7374\n",
      "Epoch 2258/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0649 - accuracy: 0.7723 - val_loss: 0.0745 - val_accuracy: 0.7391\n",
      "Epoch 2259/5000\n",
      "11786/11786 [==============================] - 8s 643us/step - loss: 0.0649 - accuracy: 0.7716 - val_loss: 0.0753 - val_accuracy: 0.7376\n",
      "Epoch 2260/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0649 - accuracy: 0.7715 - val_loss: 0.0755 - val_accuracy: 0.7342\n",
      "Epoch 2261/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0651 - accuracy: 0.7711 - val_loss: 0.0753 - val_accuracy: 0.7354\n",
      "Epoch 2262/5000\n",
      "11786/11786 [==============================] - 8s 644us/step - loss: 0.0650 - accuracy: 0.7714 - val_loss: 0.0751 - val_accuracy: 0.7368\n",
      "Epoch 2263/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0649 - accuracy: 0.7719 - val_loss: 0.0746 - val_accuracy: 0.7373\n",
      "Epoch 2264/5000\n",
      "11786/11786 [==============================] - 8s 643us/step - loss: 0.0649 - accuracy: 0.7715 - val_loss: 0.0748 - val_accuracy: 0.7375\n",
      "Epoch 2265/5000\n",
      "11786/11786 [==============================] - 7s 635us/step - loss: 0.0649 - accuracy: 0.7717 - val_loss: 0.0748 - val_accuracy: 0.7379\n",
      "Epoch 2266/5000\n",
      "11786/11786 [==============================] - 8s 636us/step - loss: 0.0649 - accuracy: 0.7719 - val_loss: 0.0749 - val_accuracy: 0.7374\n",
      "Epoch 2267/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0650 - accuracy: 0.7715 - val_loss: 0.0744 - val_accuracy: 0.7389\n",
      "Epoch 2268/5000\n",
      "11786/11786 [==============================] - 8s 637us/step - loss: 0.0650 - accuracy: 0.7713 - val_loss: 0.0747 - val_accuracy: 0.7373\n",
      "Epoch 2269/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0649 - accuracy: 0.7718 - val_loss: 0.0748 - val_accuracy: 0.7376\n",
      "Epoch 2270/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0650 - accuracy: 0.7717 - val_loss: 0.0759 - val_accuracy: 0.7358\n",
      "Epoch 2271/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0649 - accuracy: 0.7720 - val_loss: 0.0747 - val_accuracy: 0.7369\n",
      "Epoch 2272/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0649 - accuracy: 0.7710 - val_loss: 0.0749 - val_accuracy: 0.7380\n",
      "Epoch 2273/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0650 - accuracy: 0.7714 - val_loss: 0.0747 - val_accuracy: 0.7370\n",
      "Epoch 2274/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0650 - accuracy: 0.7707 - val_loss: 0.0755 - val_accuracy: 0.7343\n",
      "Epoch 2275/5000\n",
      "11786/11786 [==============================] - 8s 643us/step - loss: 0.0650 - accuracy: 0.7716 - val_loss: 0.0751 - val_accuracy: 0.7376\n",
      "Epoch 2276/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0649 - accuracy: 0.7719 - val_loss: 0.0754 - val_accuracy: 0.7358\n",
      "Epoch 2277/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0649 - accuracy: 0.7716 - val_loss: 0.0755 - val_accuracy: 0.7344\n",
      "Epoch 2278/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0648 - accuracy: 0.7721 - val_loss: 0.0751 - val_accuracy: 0.7364\n",
      "Epoch 2279/5000\n",
      "11786/11786 [==============================] - 8s 644us/step - loss: 0.0649 - accuracy: 0.7714 - val_loss: 0.0748 - val_accuracy: 0.7377\n",
      "Epoch 2280/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0649 - accuracy: 0.7717 - val_loss: 0.0754 - val_accuracy: 0.7366\n",
      "Epoch 2281/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0649 - accuracy: 0.7715 - val_loss: 0.0753 - val_accuracy: 0.7364\n",
      "Epoch 2282/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0651 - accuracy: 0.7710 - val_loss: 0.0748 - val_accuracy: 0.7367\n",
      "Epoch 2283/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0650 - accuracy: 0.7712 - val_loss: 0.0756 - val_accuracy: 0.7357\n",
      "Epoch 2284/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0651 - accuracy: 0.7714 - val_loss: 0.0757 - val_accuracy: 0.7339\n",
      "Epoch 2285/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0650 - accuracy: 0.7712 - val_loss: 0.0756 - val_accuracy: 0.7339\n",
      "Epoch 2286/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0650 - accuracy: 0.7711 - val_loss: 0.0751 - val_accuracy: 0.7358\n",
      "Epoch 2287/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0650 - accuracy: 0.7712 - val_loss: 0.0755 - val_accuracy: 0.7352\n",
      "Epoch 2288/5000\n",
      "11786/11786 [==============================] - 8s 638us/step - loss: 0.0650 - accuracy: 0.7712 - val_loss: 0.0746 - val_accuracy: 0.7373\n",
      "Epoch 2289/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0649 - accuracy: 0.7714 - val_loss: 0.0750 - val_accuracy: 0.7380\n",
      "Epoch 2290/5000\n",
      "11786/11786 [==============================] - 8s 643us/step - loss: 0.0649 - accuracy: 0.7716 - val_loss: 0.0749 - val_accuracy: 0.7367\n",
      "Epoch 2291/5000\n",
      "11786/11786 [==============================] - 8s 644us/step - loss: 0.0648 - accuracy: 0.7714 - val_loss: 0.0751 - val_accuracy: 0.7351\n",
      "Epoch 2292/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0649 - accuracy: 0.7718 - val_loss: 0.0748 - val_accuracy: 0.7366\n",
      "Epoch 2293/5000\n",
      "11786/11786 [==============================] - 8s 643us/step - loss: 0.0650 - accuracy: 0.7716 - val_loss: 0.0757 - val_accuracy: 0.7370\n",
      "Epoch 2294/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0649 - accuracy: 0.7712 - val_loss: 0.0753 - val_accuracy: 0.7351\n",
      "Epoch 2295/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0650 - accuracy: 0.7710 - val_loss: 0.0754 - val_accuracy: 0.7372\n",
      "Epoch 2296/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0649 - accuracy: 0.7718 - val_loss: 0.0757 - val_accuracy: 0.7339\n",
      "Epoch 2297/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0649 - accuracy: 0.7716 - val_loss: 0.0749 - val_accuracy: 0.7373\n",
      "Epoch 2298/5000\n",
      "11786/11786 [==============================] - 8s 644us/step - loss: 0.0651 - accuracy: 0.7711 - val_loss: 0.0751 - val_accuracy: 0.7361\n",
      "Epoch 2299/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0650 - accuracy: 0.7715 - val_loss: 0.0751 - val_accuracy: 0.7379\n",
      "Epoch 2300/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0650 - accuracy: 0.7713 - val_loss: 0.0752 - val_accuracy: 0.7364\n",
      "Epoch 2301/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0648 - accuracy: 0.7723 - val_loss: 0.0756 - val_accuracy: 0.7332\n",
      "Epoch 2302/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0650 - accuracy: 0.7714 - val_loss: 0.0749 - val_accuracy: 0.7374\n",
      "Epoch 2303/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0651 - accuracy: 0.7712 - val_loss: 0.0760 - val_accuracy: 0.7333\n",
      "Epoch 2304/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0651 - accuracy: 0.7713 - val_loss: 0.0753 - val_accuracy: 0.7364\n",
      "Epoch 2305/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0650 - accuracy: 0.7712 - val_loss: 0.0749 - val_accuracy: 0.7370\n",
      "Epoch 2306/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0651 - accuracy: 0.7707 - val_loss: 0.0751 - val_accuracy: 0.7377\n",
      "Epoch 2307/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0650 - accuracy: 0.7717 - val_loss: 0.0751 - val_accuracy: 0.7360\n",
      "Epoch 2308/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0648 - accuracy: 0.7719 - val_loss: 0.0744 - val_accuracy: 0.7377\n",
      "Epoch 2309/5000\n",
      "11786/11786 [==============================] - 8s 643us/step - loss: 0.0649 - accuracy: 0.7716 - val_loss: 0.0755 - val_accuracy: 0.7360\n",
      "Epoch 2310/5000\n",
      "11786/11786 [==============================] - 8s 644us/step - loss: 0.0651 - accuracy: 0.7710 - val_loss: 0.0760 - val_accuracy: 0.7318\n",
      "Epoch 2311/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0650 - accuracy: 0.7709 - val_loss: 0.0751 - val_accuracy: 0.7354\n",
      "Epoch 2312/5000\n",
      "11786/11786 [==============================] - 8s 643us/step - loss: 0.0651 - accuracy: 0.7716 - val_loss: 0.0751 - val_accuracy: 0.7346\n",
      "Epoch 2313/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0650 - accuracy: 0.7712 - val_loss: 0.0755 - val_accuracy: 0.7351\n",
      "Epoch 2314/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0651 - accuracy: 0.7709 - val_loss: 0.0753 - val_accuracy: 0.7374\n",
      "Epoch 2315/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0651 - accuracy: 0.7712 - val_loss: 0.0746 - val_accuracy: 0.7382\n",
      "Epoch 2316/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0651 - accuracy: 0.7710 - val_loss: 0.0754 - val_accuracy: 0.7360\n",
      "Epoch 2317/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0649 - accuracy: 0.7712 - val_loss: 0.0748 - val_accuracy: 0.7370\n",
      "Epoch 2318/5000\n",
      "11786/11786 [==============================] - 8s 643us/step - loss: 0.0649 - accuracy: 0.7716 - val_loss: 0.0746 - val_accuracy: 0.7376\n",
      "Epoch 2319/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0649 - accuracy: 0.7714 - val_loss: 0.0743 - val_accuracy: 0.7383\n",
      "Epoch 2320/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0651 - accuracy: 0.7717 - val_loss: 0.0755 - val_accuracy: 0.7352\n",
      "Epoch 2321/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0650 - accuracy: 0.7708 - val_loss: 0.0760 - val_accuracy: 0.7339\n",
      "Epoch 2322/5000\n",
      "11786/11786 [==============================] - 8s 644us/step - loss: 0.0650 - accuracy: 0.7712 - val_loss: 0.0748 - val_accuracy: 0.7390\n",
      "Epoch 2323/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0649 - accuracy: 0.7709 - val_loss: 0.0750 - val_accuracy: 0.7362\n",
      "Epoch 2324/5000\n",
      "11786/11786 [==============================] - 8s 644us/step - loss: 0.0651 - accuracy: 0.7711 - val_loss: 0.0750 - val_accuracy: 0.7368\n",
      "Epoch 2325/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0651 - accuracy: 0.7709 - val_loss: 0.0748 - val_accuracy: 0.7358\n",
      "Epoch 2326/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0651 - accuracy: 0.7715 - val_loss: 0.0756 - val_accuracy: 0.7367\n",
      "Epoch 2327/5000\n",
      "11786/11786 [==============================] - 8s 643us/step - loss: 0.0652 - accuracy: 0.7710 - val_loss: 0.0752 - val_accuracy: 0.7365\n",
      "Epoch 2328/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0650 - accuracy: 0.7714 - val_loss: 0.0749 - val_accuracy: 0.7351\n",
      "Epoch 2329/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0651 - accuracy: 0.7710 - val_loss: 0.0747 - val_accuracy: 0.7366\n",
      "Epoch 2330/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0650 - accuracy: 0.7716 - val_loss: 0.0755 - val_accuracy: 0.7365\n",
      "Epoch 2331/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0651 - accuracy: 0.7711 - val_loss: 0.0756 - val_accuracy: 0.7351\n",
      "Epoch 2332/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0651 - accuracy: 0.7709 - val_loss: 0.0749 - val_accuracy: 0.7361\n",
      "Epoch 2333/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0650 - accuracy: 0.7711 - val_loss: 0.0753 - val_accuracy: 0.7357\n",
      "Epoch 2334/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0650 - accuracy: 0.7711 - val_loss: 0.0751 - val_accuracy: 0.7364\n",
      "Epoch 2335/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0651 - accuracy: 0.7712 - val_loss: 0.0753 - val_accuracy: 0.7345\n",
      "Epoch 2336/5000\n",
      "11786/11786 [==============================] - 8s 643us/step - loss: 0.0651 - accuracy: 0.7706 - val_loss: 0.0749 - val_accuracy: 0.7357\n",
      "Epoch 2337/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0650 - accuracy: 0.7709 - val_loss: 0.0743 - val_accuracy: 0.7375\n",
      "Epoch 2338/5000\n",
      "11786/11786 [==============================] - 8s 643us/step - loss: 0.0651 - accuracy: 0.7706 - val_loss: 0.0759 - val_accuracy: 0.7324\n",
      "Epoch 2339/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0651 - accuracy: 0.7711 - val_loss: 0.0750 - val_accuracy: 0.7371\n",
      "Epoch 2340/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0652 - accuracy: 0.7713 - val_loss: 0.0756 - val_accuracy: 0.7331\n",
      "Epoch 2341/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0651 - accuracy: 0.7709 - val_loss: 0.0756 - val_accuracy: 0.7339\n",
      "Epoch 2342/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0651 - accuracy: 0.7708 - val_loss: 0.0750 - val_accuracy: 0.7366\n",
      "Epoch 2343/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0651 - accuracy: 0.7711 - val_loss: 0.0756 - val_accuracy: 0.7363\n",
      "Epoch 2344/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0652 - accuracy: 0.7704 - val_loss: 0.0752 - val_accuracy: 0.7366\n",
      "Epoch 2345/5000\n",
      "11786/11786 [==============================] - 8s 644us/step - loss: 0.0653 - accuracy: 0.7697 - val_loss: 0.0751 - val_accuracy: 0.7364\n",
      "Epoch 2346/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0650 - accuracy: 0.7709 - val_loss: 0.0744 - val_accuracy: 0.7372\n",
      "Epoch 2347/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0650 - accuracy: 0.7712 - val_loss: 0.0749 - val_accuracy: 0.7365\n",
      "Epoch 2348/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0650 - accuracy: 0.7709 - val_loss: 0.0764 - val_accuracy: 0.7362\n",
      "Epoch 2349/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0652 - accuracy: 0.7709 - val_loss: 0.0745 - val_accuracy: 0.7387\n",
      "Epoch 2350/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0651 - accuracy: 0.7710 - val_loss: 0.0746 - val_accuracy: 0.7385\n",
      "Epoch 2351/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0652 - accuracy: 0.7707 - val_loss: 0.0758 - val_accuracy: 0.7350\n",
      "Epoch 2352/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0651 - accuracy: 0.7709 - val_loss: 0.0750 - val_accuracy: 0.7368\n",
      "Epoch 2353/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0649 - accuracy: 0.7715 - val_loss: 0.0751 - val_accuracy: 0.7352\n",
      "Epoch 2354/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0650 - accuracy: 0.7713 - val_loss: 0.0748 - val_accuracy: 0.7368\n",
      "Epoch 2355/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0649 - accuracy: 0.7717 - val_loss: 0.0752 - val_accuracy: 0.7359\n",
      "Epoch 2356/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0651 - accuracy: 0.7708 - val_loss: 0.0752 - val_accuracy: 0.7347\n",
      "Epoch 2357/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0651 - accuracy: 0.7709 - val_loss: 0.0750 - val_accuracy: 0.7360\n",
      "Epoch 2358/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0651 - accuracy: 0.7707 - val_loss: 0.0752 - val_accuracy: 0.7363\n",
      "Epoch 2359/5000\n",
      "11786/11786 [==============================] - 8s 644us/step - loss: 0.0651 - accuracy: 0.7712 - val_loss: 0.0755 - val_accuracy: 0.7377\n",
      "Epoch 2360/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0651 - accuracy: 0.7707 - val_loss: 0.0756 - val_accuracy: 0.7353\n",
      "Epoch 2361/5000\n",
      "11786/11786 [==============================] - 8s 644us/step - loss: 0.0650 - accuracy: 0.7719 - val_loss: 0.0760 - val_accuracy: 0.7350\n",
      "Epoch 2362/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0651 - accuracy: 0.7710 - val_loss: 0.0750 - val_accuracy: 0.7363\n",
      "Epoch 2363/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0650 - accuracy: 0.7715 - val_loss: 0.0748 - val_accuracy: 0.7375\n",
      "Epoch 2364/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0652 - accuracy: 0.7706 - val_loss: 0.0746 - val_accuracy: 0.7374\n",
      "Epoch 2365/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0650 - accuracy: 0.7713 - val_loss: 0.0756 - val_accuracy: 0.7373\n",
      "Epoch 2366/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0651 - accuracy: 0.7712 - val_loss: 0.0746 - val_accuracy: 0.7371\n",
      "Epoch 2367/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0651 - accuracy: 0.7708 - val_loss: 0.0751 - val_accuracy: 0.7361\n",
      "Epoch 2368/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0651 - accuracy: 0.7711 - val_loss: 0.0753 - val_accuracy: 0.7361\n",
      "Epoch 2369/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0651 - accuracy: 0.7708 - val_loss: 0.0748 - val_accuracy: 0.7377\n",
      "Epoch 2370/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0651 - accuracy: 0.7710 - val_loss: 0.0746 - val_accuracy: 0.7366\n",
      "Epoch 2371/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0652 - accuracy: 0.7705 - val_loss: 0.0750 - val_accuracy: 0.7362\n",
      "Epoch 2372/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0651 - accuracy: 0.7713 - val_loss: 0.0751 - val_accuracy: 0.7364\n",
      "Epoch 2373/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0651 - accuracy: 0.7715 - val_loss: 0.0751 - val_accuracy: 0.7352\n",
      "Epoch 2374/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0651 - accuracy: 0.7711 - val_loss: 0.0749 - val_accuracy: 0.7374\n",
      "Epoch 2375/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0650 - accuracy: 0.7720 - val_loss: 0.0750 - val_accuracy: 0.7375\n",
      "Epoch 2376/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0651 - accuracy: 0.7711 - val_loss: 0.0750 - val_accuracy: 0.7368\n",
      "Epoch 2377/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0651 - accuracy: 0.7711 - val_loss: 0.0747 - val_accuracy: 0.7363\n",
      "Epoch 2378/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0651 - accuracy: 0.7714 - val_loss: 0.0753 - val_accuracy: 0.7359\n",
      "Epoch 2379/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0653 - accuracy: 0.7701 - val_loss: 0.0753 - val_accuracy: 0.7345\n",
      "Epoch 2380/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0652 - accuracy: 0.7710 - val_loss: 0.0753 - val_accuracy: 0.7358\n",
      "Epoch 2381/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0651 - accuracy: 0.7709 - val_loss: 0.0754 - val_accuracy: 0.7362\n",
      "Epoch 2382/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0652 - accuracy: 0.7709 - val_loss: 0.0758 - val_accuracy: 0.7359\n",
      "Epoch 2383/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0652 - accuracy: 0.7708 - val_loss: 0.0759 - val_accuracy: 0.7346\n",
      "Epoch 2384/5000\n",
      "11786/11786 [==============================] - 8s 644us/step - loss: 0.0651 - accuracy: 0.7715 - val_loss: 0.0751 - val_accuracy: 0.7364\n",
      "Epoch 2385/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0651 - accuracy: 0.7715 - val_loss: 0.0751 - val_accuracy: 0.7365\n",
      "Epoch 2386/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0651 - accuracy: 0.7711 - val_loss: 0.0750 - val_accuracy: 0.7362\n",
      "Epoch 2387/5000\n",
      "11786/11786 [==============================] - 8s 644us/step - loss: 0.0652 - accuracy: 0.7716 - val_loss: 0.0755 - val_accuracy: 0.7360\n",
      "Epoch 2388/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0652 - accuracy: 0.7708 - val_loss: 0.0752 - val_accuracy: 0.7368\n",
      "Epoch 2389/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0651 - accuracy: 0.7712 - val_loss: 0.0750 - val_accuracy: 0.7380\n",
      "Epoch 2390/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0651 - accuracy: 0.7715 - val_loss: 0.0754 - val_accuracy: 0.7350\n",
      "Epoch 2391/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0651 - accuracy: 0.7713 - val_loss: 0.0749 - val_accuracy: 0.7377\n",
      "Epoch 2392/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0651 - accuracy: 0.7711 - val_loss: 0.0750 - val_accuracy: 0.7368\n",
      "Epoch 2393/5000\n",
      "11786/11786 [==============================] - 8s 644us/step - loss: 0.0651 - accuracy: 0.7712 - val_loss: 0.0750 - val_accuracy: 0.7364\n",
      "Epoch 2394/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0651 - accuracy: 0.7710 - val_loss: 0.0752 - val_accuracy: 0.7366\n",
      "Epoch 2395/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0651 - accuracy: 0.7715 - val_loss: 0.0761 - val_accuracy: 0.7351\n",
      "Epoch 2396/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0651 - accuracy: 0.7713 - val_loss: 0.0752 - val_accuracy: 0.7383\n",
      "Epoch 2397/5000\n",
      "11786/11786 [==============================] - 8s 644us/step - loss: 0.0651 - accuracy: 0.7713 - val_loss: 0.0763 - val_accuracy: 0.7339\n",
      "Epoch 2398/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0651 - accuracy: 0.7713 - val_loss: 0.0758 - val_accuracy: 0.7354\n",
      "Epoch 2399/5000\n",
      "11786/11786 [==============================] - 8s 643us/step - loss: 0.0651 - accuracy: 0.7715 - val_loss: 0.0750 - val_accuracy: 0.7383\n",
      "Epoch 2400/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0651 - accuracy: 0.7712 - val_loss: 0.0755 - val_accuracy: 0.7372\n",
      "Epoch 2401/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0652 - accuracy: 0.7712 - val_loss: 0.0752 - val_accuracy: 0.7359\n",
      "Epoch 2402/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0651 - accuracy: 0.7711 - val_loss: 0.0751 - val_accuracy: 0.7372\n",
      "Epoch 2403/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0651 - accuracy: 0.7717 - val_loss: 0.0753 - val_accuracy: 0.7338\n",
      "Epoch 2404/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0651 - accuracy: 0.7710 - val_loss: 0.0761 - val_accuracy: 0.7332\n",
      "Epoch 2405/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0652 - accuracy: 0.7709 - val_loss: 0.0750 - val_accuracy: 0.7370\n",
      "Epoch 2406/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0652 - accuracy: 0.7707 - val_loss: 0.0756 - val_accuracy: 0.7354\n",
      "Epoch 2407/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0651 - accuracy: 0.7711 - val_loss: 0.0750 - val_accuracy: 0.7381\n",
      "Epoch 2408/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0653 - accuracy: 0.7706 - val_loss: 0.0751 - val_accuracy: 0.7348\n",
      "Epoch 2409/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0652 - accuracy: 0.7709 - val_loss: 0.0745 - val_accuracy: 0.7386\n",
      "Epoch 2410/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0652 - accuracy: 0.7710 - val_loss: 0.0753 - val_accuracy: 0.7356\n",
      "Epoch 2411/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0653 - accuracy: 0.7705 - val_loss: 0.0752 - val_accuracy: 0.7337\n",
      "Epoch 2412/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0652 - accuracy: 0.7710 - val_loss: 0.0752 - val_accuracy: 0.7357\n",
      "Epoch 2413/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0652 - accuracy: 0.7705 - val_loss: 0.0747 - val_accuracy: 0.7374\n",
      "Epoch 2414/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0651 - accuracy: 0.7711 - val_loss: 0.0753 - val_accuracy: 0.7350\n",
      "Epoch 2415/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0652 - accuracy: 0.7710 - val_loss: 0.0753 - val_accuracy: 0.7352\n",
      "Epoch 2416/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0651 - accuracy: 0.7709 - val_loss: 0.0758 - val_accuracy: 0.7330\n",
      "Epoch 2417/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0652 - accuracy: 0.7707 - val_loss: 0.0751 - val_accuracy: 0.7355\n",
      "Epoch 2418/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0652 - accuracy: 0.7708 - val_loss: 0.0754 - val_accuracy: 0.7359\n",
      "Epoch 2419/5000\n",
      "11786/11786 [==============================] - 8s 643us/step - loss: 0.0651 - accuracy: 0.7711 - val_loss: 0.0751 - val_accuracy: 0.7374\n",
      "Epoch 2420/5000\n",
      "11786/11786 [==============================] - 8s 644us/step - loss: 0.0650 - accuracy: 0.7712 - val_loss: 0.0762 - val_accuracy: 0.7335\n",
      "Epoch 2421/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0652 - accuracy: 0.7707 - val_loss: 0.0754 - val_accuracy: 0.7352\n",
      "Epoch 2422/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0651 - accuracy: 0.7714 - val_loss: 0.0756 - val_accuracy: 0.7357\n",
      "Epoch 2423/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0652 - accuracy: 0.7709 - val_loss: 0.0752 - val_accuracy: 0.7365\n",
      "Epoch 2424/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0652 - accuracy: 0.7711 - val_loss: 0.0747 - val_accuracy: 0.7381\n",
      "Epoch 2425/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0651 - accuracy: 0.7712 - val_loss: 0.0752 - val_accuracy: 0.7362\n",
      "Epoch 2426/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0652 - accuracy: 0.7712 - val_loss: 0.0757 - val_accuracy: 0.7342\n",
      "Epoch 2427/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0652 - accuracy: 0.7711 - val_loss: 0.0750 - val_accuracy: 0.7367\n",
      "Epoch 2428/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0652 - accuracy: 0.7708 - val_loss: 0.0763 - val_accuracy: 0.7357\n",
      "Epoch 2429/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0652 - accuracy: 0.7710 - val_loss: 0.0754 - val_accuracy: 0.7346\n",
      "Epoch 2430/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0653 - accuracy: 0.7709 - val_loss: 0.0754 - val_accuracy: 0.7354\n",
      "Epoch 2431/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0652 - accuracy: 0.7709 - val_loss: 0.0755 - val_accuracy: 0.7351\n",
      "Epoch 2432/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0652 - accuracy: 0.7705 - val_loss: 0.0751 - val_accuracy: 0.7368\n",
      "Epoch 2433/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0653 - accuracy: 0.7708 - val_loss: 0.0751 - val_accuracy: 0.7358\n",
      "Epoch 2434/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0652 - accuracy: 0.7713 - val_loss: 0.0754 - val_accuracy: 0.7345\n",
      "Epoch 2435/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0653 - accuracy: 0.7709 - val_loss: 0.0753 - val_accuracy: 0.7364\n",
      "Epoch 2436/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0653 - accuracy: 0.7707 - val_loss: 0.0763 - val_accuracy: 0.7349\n",
      "Epoch 2437/5000\n",
      "11786/11786 [==============================] - 8s 643us/step - loss: 0.0652 - accuracy: 0.7715 - val_loss: 0.0766 - val_accuracy: 0.7347\n",
      "Epoch 2438/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0652 - accuracy: 0.7707 - val_loss: 0.0757 - val_accuracy: 0.7342\n",
      "Epoch 2439/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0652 - accuracy: 0.7710 - val_loss: 0.0751 - val_accuracy: 0.7371\n",
      "Epoch 2440/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0651 - accuracy: 0.7715 - val_loss: 0.0754 - val_accuracy: 0.7383\n",
      "Epoch 2441/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0651 - accuracy: 0.7713 - val_loss: 0.0760 - val_accuracy: 0.7375\n",
      "Epoch 2442/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0653 - accuracy: 0.7706 - val_loss: 0.0750 - val_accuracy: 0.7369\n",
      "Epoch 2443/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0653 - accuracy: 0.7706 - val_loss: 0.0750 - val_accuracy: 0.7373\n",
      "Epoch 2444/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0654 - accuracy: 0.7706 - val_loss: 0.0757 - val_accuracy: 0.7353\n",
      "Epoch 2445/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0654 - accuracy: 0.7701 - val_loss: 0.0758 - val_accuracy: 0.7339\n",
      "Epoch 2446/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0652 - accuracy: 0.7708 - val_loss: 0.0747 - val_accuracy: 0.7377\n",
      "Epoch 2447/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0654 - accuracy: 0.7703 - val_loss: 0.0753 - val_accuracy: 0.7376\n",
      "Epoch 2448/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0652 - accuracy: 0.7709 - val_loss: 0.0758 - val_accuracy: 0.7333\n",
      "Epoch 2449/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0653 - accuracy: 0.7707 - val_loss: 0.0747 - val_accuracy: 0.7377\n",
      "Epoch 2450/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0655 - accuracy: 0.7700 - val_loss: 0.0760 - val_accuracy: 0.7364\n",
      "Epoch 2451/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0653 - accuracy: 0.7705 - val_loss: 0.0751 - val_accuracy: 0.7367\n",
      "Epoch 2452/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0654 - accuracy: 0.7702 - val_loss: 0.0757 - val_accuracy: 0.7361\n",
      "Epoch 2453/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0655 - accuracy: 0.7702 - val_loss: 0.0751 - val_accuracy: 0.7360\n",
      "Epoch 2454/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0654 - accuracy: 0.7705 - val_loss: 0.0759 - val_accuracy: 0.7359\n",
      "Epoch 2455/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0653 - accuracy: 0.7705 - val_loss: 0.0755 - val_accuracy: 0.7366\n",
      "Epoch 2456/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0652 - accuracy: 0.7712 - val_loss: 0.0754 - val_accuracy: 0.7354\n",
      "Epoch 2457/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0652 - accuracy: 0.7712 - val_loss: 0.0752 - val_accuracy: 0.7378\n",
      "Epoch 2458/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0655 - accuracy: 0.7698 - val_loss: 0.0754 - val_accuracy: 0.7351\n",
      "Epoch 2459/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0653 - accuracy: 0.7707 - val_loss: 0.0756 - val_accuracy: 0.7369\n",
      "Epoch 2460/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0652 - accuracy: 0.7706 - val_loss: 0.0759 - val_accuracy: 0.7354\n",
      "Epoch 2461/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0653 - accuracy: 0.7703 - val_loss: 0.0752 - val_accuracy: 0.7372\n",
      "Epoch 2462/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0655 - accuracy: 0.7698 - val_loss: 0.0754 - val_accuracy: 0.7364\n",
      "Epoch 2463/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0653 - accuracy: 0.7704 - val_loss: 0.0758 - val_accuracy: 0.7322\n",
      "Epoch 2464/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0652 - accuracy: 0.7705 - val_loss: 0.0753 - val_accuracy: 0.7355\n",
      "Epoch 2465/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0653 - accuracy: 0.7705 - val_loss: 0.0755 - val_accuracy: 0.7376\n",
      "Epoch 2466/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0654 - accuracy: 0.7707 - val_loss: 0.0756 - val_accuracy: 0.7352\n",
      "Epoch 2467/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0653 - accuracy: 0.7703 - val_loss: 0.0753 - val_accuracy: 0.7353\n",
      "Epoch 2468/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0653 - accuracy: 0.7709 - val_loss: 0.0754 - val_accuracy: 0.7361\n",
      "Epoch 2469/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0653 - accuracy: 0.7713 - val_loss: 0.0749 - val_accuracy: 0.7352\n",
      "Epoch 2470/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0653 - accuracy: 0.7700 - val_loss: 0.0749 - val_accuracy: 0.7360\n",
      "Epoch 2471/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0653 - accuracy: 0.7702 - val_loss: 0.0750 - val_accuracy: 0.7358\n",
      "Epoch 2472/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0653 - accuracy: 0.7705 - val_loss: 0.0775 - val_accuracy: 0.7315\n",
      "Epoch 2473/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0654 - accuracy: 0.7705 - val_loss: 0.0752 - val_accuracy: 0.7365\n",
      "Epoch 2474/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0654 - accuracy: 0.7705 - val_loss: 0.0757 - val_accuracy: 0.7376\n",
      "Epoch 2475/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0654 - accuracy: 0.7703 - val_loss: 0.0751 - val_accuracy: 0.7352\n",
      "Epoch 2476/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0655 - accuracy: 0.7699 - val_loss: 0.0750 - val_accuracy: 0.7371\n",
      "Epoch 2477/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0654 - accuracy: 0.7701 - val_loss: 0.0752 - val_accuracy: 0.7352\n",
      "Epoch 2478/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0654 - accuracy: 0.7704 - val_loss: 0.0750 - val_accuracy: 0.7376\n",
      "Epoch 2479/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0654 - accuracy: 0.7704 - val_loss: 0.0751 - val_accuracy: 0.7360\n",
      "Epoch 2480/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0654 - accuracy: 0.7702 - val_loss: 0.0753 - val_accuracy: 0.7360\n",
      "Epoch 2481/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0654 - accuracy: 0.7695 - val_loss: 0.0758 - val_accuracy: 0.7334\n",
      "Epoch 2482/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0654 - accuracy: 0.7704 - val_loss: 0.0752 - val_accuracy: 0.7363\n",
      "Epoch 2483/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0655 - accuracy: 0.7698 - val_loss: 0.0778 - val_accuracy: 0.7311\n",
      "Epoch 2484/5000\n",
      "11786/11786 [==============================] - 8s 643us/step - loss: 0.0654 - accuracy: 0.7706 - val_loss: 0.0759 - val_accuracy: 0.7351\n",
      "Epoch 2485/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0654 - accuracy: 0.7702 - val_loss: 0.0753 - val_accuracy: 0.7366\n",
      "Epoch 2486/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0654 - accuracy: 0.7703 - val_loss: 0.0753 - val_accuracy: 0.7352\n",
      "Epoch 2487/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0655 - accuracy: 0.7698 - val_loss: 0.0769 - val_accuracy: 0.7332\n",
      "Epoch 2488/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0656 - accuracy: 0.7696 - val_loss: 0.0761 - val_accuracy: 0.7356\n",
      "Epoch 2489/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0655 - accuracy: 0.7697 - val_loss: 0.0765 - val_accuracy: 0.7339\n",
      "Epoch 2490/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0655 - accuracy: 0.7700 - val_loss: 0.0753 - val_accuracy: 0.7351\n",
      "Epoch 2491/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0655 - accuracy: 0.7702 - val_loss: 0.0749 - val_accuracy: 0.7374\n",
      "Epoch 2492/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0655 - accuracy: 0.7703 - val_loss: 0.0760 - val_accuracy: 0.7330\n",
      "Epoch 2493/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0656 - accuracy: 0.7695 - val_loss: 0.0760 - val_accuracy: 0.7348\n",
      "Epoch 2494/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0656 - accuracy: 0.7692 - val_loss: 0.0756 - val_accuracy: 0.7339\n",
      "Epoch 2495/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0656 - accuracy: 0.7694 - val_loss: 0.0761 - val_accuracy: 0.7346\n",
      "Epoch 2496/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0654 - accuracy: 0.7702 - val_loss: 0.0755 - val_accuracy: 0.7368\n",
      "Epoch 2497/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0655 - accuracy: 0.7697 - val_loss: 0.0754 - val_accuracy: 0.7341\n",
      "Epoch 2498/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0656 - accuracy: 0.7698 - val_loss: 0.0757 - val_accuracy: 0.7342\n",
      "Epoch 2499/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0656 - accuracy: 0.7696 - val_loss: 0.0756 - val_accuracy: 0.7346\n",
      "Epoch 2500/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0657 - accuracy: 0.7688 - val_loss: 0.0754 - val_accuracy: 0.7357\n",
      "Epoch 2501/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0654 - accuracy: 0.7700 - val_loss: 0.0757 - val_accuracy: 0.7346\n",
      "Epoch 2502/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0655 - accuracy: 0.7694 - val_loss: 0.0758 - val_accuracy: 0.7354\n",
      "Epoch 2503/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0655 - accuracy: 0.7698 - val_loss: 0.0751 - val_accuracy: 0.7376\n",
      "Epoch 2504/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0654 - accuracy: 0.7702 - val_loss: 0.0755 - val_accuracy: 0.7346\n",
      "Epoch 2505/5000\n",
      "11786/11786 [==============================] - 8s 643us/step - loss: 0.0655 - accuracy: 0.7696 - val_loss: 0.0760 - val_accuracy: 0.7347\n",
      "Epoch 2506/5000\n",
      "11786/11786 [==============================] - 8s 644us/step - loss: 0.0656 - accuracy: 0.7696 - val_loss: 0.0752 - val_accuracy: 0.7351\n",
      "Epoch 2507/5000\n",
      "11786/11786 [==============================] - 8s 644us/step - loss: 0.0655 - accuracy: 0.7695 - val_loss: 0.0752 - val_accuracy: 0.7358\n",
      "Epoch 2508/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0655 - accuracy: 0.7697 - val_loss: 0.0753 - val_accuracy: 0.7362\n",
      "Epoch 2509/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0653 - accuracy: 0.7704 - val_loss: 0.0753 - val_accuracy: 0.7376\n",
      "Epoch 2510/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0654 - accuracy: 0.7698 - val_loss: 0.0753 - val_accuracy: 0.7365\n",
      "Epoch 2511/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0655 - accuracy: 0.7695 - val_loss: 0.0755 - val_accuracy: 0.7365\n",
      "Epoch 2512/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0656 - accuracy: 0.7694 - val_loss: 0.0750 - val_accuracy: 0.7358\n",
      "Epoch 2513/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0655 - accuracy: 0.7698 - val_loss: 0.0757 - val_accuracy: 0.7355\n",
      "Epoch 2514/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0655 - accuracy: 0.7696 - val_loss: 0.0750 - val_accuracy: 0.7375\n",
      "Epoch 2515/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0656 - accuracy: 0.7696 - val_loss: 0.0754 - val_accuracy: 0.7368\n",
      "Epoch 2516/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0656 - accuracy: 0.7696 - val_loss: 0.0762 - val_accuracy: 0.7347\n",
      "Epoch 2517/5000\n",
      "11786/11786 [==============================] - 8s 643us/step - loss: 0.0654 - accuracy: 0.7698 - val_loss: 0.0755 - val_accuracy: 0.7336\n",
      "Epoch 2518/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0656 - accuracy: 0.7691 - val_loss: 0.0756 - val_accuracy: 0.7327\n",
      "Epoch 2519/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0656 - accuracy: 0.7694 - val_loss: 0.0758 - val_accuracy: 0.7318\n",
      "Epoch 2520/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0656 - accuracy: 0.7695 - val_loss: 0.0759 - val_accuracy: 0.7331\n",
      "Epoch 2521/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0655 - accuracy: 0.7697 - val_loss: 0.0762 - val_accuracy: 0.7328\n",
      "Epoch 2522/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0656 - accuracy: 0.7691 - val_loss: 0.0762 - val_accuracy: 0.7332\n",
      "Epoch 2523/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0655 - accuracy: 0.7695 - val_loss: 0.0751 - val_accuracy: 0.7350\n",
      "Epoch 2524/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0656 - accuracy: 0.7694 - val_loss: 0.0758 - val_accuracy: 0.7348\n",
      "Epoch 2525/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0656 - accuracy: 0.7694 - val_loss: 0.0748 - val_accuracy: 0.7366\n",
      "Epoch 2526/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0655 - accuracy: 0.7692 - val_loss: 0.0759 - val_accuracy: 0.7335\n",
      "Epoch 2527/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0656 - accuracy: 0.7698 - val_loss: 0.0754 - val_accuracy: 0.7354\n",
      "Epoch 2528/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0655 - accuracy: 0.7698 - val_loss: 0.0753 - val_accuracy: 0.7361\n",
      "Epoch 2529/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0655 - accuracy: 0.7695 - val_loss: 0.0759 - val_accuracy: 0.7347\n",
      "Epoch 2530/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0654 - accuracy: 0.7699 - val_loss: 0.0749 - val_accuracy: 0.7368\n",
      "Epoch 2531/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0655 - accuracy: 0.7700 - val_loss: 0.0751 - val_accuracy: 0.7356\n",
      "Epoch 2532/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0655 - accuracy: 0.7697 - val_loss: 0.0754 - val_accuracy: 0.7359\n",
      "Epoch 2533/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0655 - accuracy: 0.7698 - val_loss: 0.0763 - val_accuracy: 0.7334\n",
      "Epoch 2534/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0654 - accuracy: 0.7703 - val_loss: 0.0763 - val_accuracy: 0.7351\n",
      "Epoch 2535/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0655 - accuracy: 0.7693 - val_loss: 0.0751 - val_accuracy: 0.7369\n",
      "Epoch 2536/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0656 - accuracy: 0.7693 - val_loss: 0.0759 - val_accuracy: 0.7339\n",
      "Epoch 2537/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0656 - accuracy: 0.7695 - val_loss: 0.0753 - val_accuracy: 0.7361\n",
      "Epoch 2538/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0656 - accuracy: 0.7695 - val_loss: 0.0754 - val_accuracy: 0.7338\n",
      "Epoch 2539/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0656 - accuracy: 0.7697 - val_loss: 0.0755 - val_accuracy: 0.7350\n",
      "Epoch 2540/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0655 - accuracy: 0.7696 - val_loss: 0.0752 - val_accuracy: 0.7372\n",
      "Epoch 2541/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0655 - accuracy: 0.7698 - val_loss: 0.0753 - val_accuracy: 0.7359\n",
      "Epoch 2542/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0656 - accuracy: 0.7694 - val_loss: 0.0749 - val_accuracy: 0.7370\n",
      "Epoch 2543/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0657 - accuracy: 0.7691 - val_loss: 0.0754 - val_accuracy: 0.7379\n",
      "Epoch 2544/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0656 - accuracy: 0.7694 - val_loss: 0.0762 - val_accuracy: 0.7336\n",
      "Epoch 2545/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0657 - accuracy: 0.7691 - val_loss: 0.0763 - val_accuracy: 0.7319\n",
      "Epoch 2546/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0656 - accuracy: 0.7695 - val_loss: 0.0753 - val_accuracy: 0.7340\n",
      "Epoch 2547/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0657 - accuracy: 0.7696 - val_loss: 0.0757 - val_accuracy: 0.7324\n",
      "Epoch 2548/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0657 - accuracy: 0.7694 - val_loss: 0.0759 - val_accuracy: 0.7344\n",
      "Epoch 2549/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0656 - accuracy: 0.7700 - val_loss: 0.0753 - val_accuracy: 0.7370\n",
      "Epoch 2550/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0655 - accuracy: 0.7700 - val_loss: 0.0752 - val_accuracy: 0.7378\n",
      "Epoch 2551/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0657 - accuracy: 0.7693 - val_loss: 0.0755 - val_accuracy: 0.7343\n",
      "Epoch 2552/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0656 - accuracy: 0.7692 - val_loss: 0.0759 - val_accuracy: 0.7363\n",
      "Epoch 2553/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0657 - accuracy: 0.7693 - val_loss: 0.0754 - val_accuracy: 0.7354\n",
      "Epoch 2554/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0655 - accuracy: 0.7698 - val_loss: 0.0757 - val_accuracy: 0.7339\n",
      "Epoch 2555/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0655 - accuracy: 0.7693 - val_loss: 0.0759 - val_accuracy: 0.7353\n",
      "Epoch 2556/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0656 - accuracy: 0.7690 - val_loss: 0.0755 - val_accuracy: 0.7350\n",
      "Epoch 2557/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0655 - accuracy: 0.7696 - val_loss: 0.0757 - val_accuracy: 0.7337\n",
      "Epoch 2558/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0655 - accuracy: 0.7700 - val_loss: 0.0752 - val_accuracy: 0.7356\n",
      "Epoch 2559/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0656 - accuracy: 0.7695 - val_loss: 0.0753 - val_accuracy: 0.7358\n",
      "Epoch 2560/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0656 - accuracy: 0.7690 - val_loss: 0.0755 - val_accuracy: 0.7360\n",
      "Epoch 2561/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0657 - accuracy: 0.7695 - val_loss: 0.0758 - val_accuracy: 0.7341\n",
      "Epoch 2562/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0656 - accuracy: 0.7696 - val_loss: 0.0749 - val_accuracy: 0.7374\n",
      "Epoch 2563/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0656 - accuracy: 0.7696 - val_loss: 0.0753 - val_accuracy: 0.7369\n",
      "Epoch 2564/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0656 - accuracy: 0.7693 - val_loss: 0.0760 - val_accuracy: 0.7359\n",
      "Epoch 2565/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0656 - accuracy: 0.7696 - val_loss: 0.0753 - val_accuracy: 0.7363\n",
      "Epoch 2566/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0656 - accuracy: 0.7697 - val_loss: 0.0757 - val_accuracy: 0.7333\n",
      "Epoch 2567/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0654 - accuracy: 0.7705 - val_loss: 0.0750 - val_accuracy: 0.7360\n",
      "Epoch 2568/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0654 - accuracy: 0.7705 - val_loss: 0.0752 - val_accuracy: 0.7359\n",
      "Epoch 2569/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0656 - accuracy: 0.7698 - val_loss: 0.0755 - val_accuracy: 0.7369\n",
      "Epoch 2570/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0655 - accuracy: 0.7698 - val_loss: 0.0760 - val_accuracy: 0.7349\n",
      "Epoch 2571/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0655 - accuracy: 0.7706 - val_loss: 0.0755 - val_accuracy: 0.7350\n",
      "Epoch 2572/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0655 - accuracy: 0.7707 - val_loss: 0.0764 - val_accuracy: 0.7331\n",
      "Epoch 2573/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0655 - accuracy: 0.7699 - val_loss: 0.0756 - val_accuracy: 0.7347\n",
      "Epoch 2574/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0657 - accuracy: 0.7695 - val_loss: 0.0755 - val_accuracy: 0.7363\n",
      "Epoch 2575/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0654 - accuracy: 0.7703 - val_loss: 0.0748 - val_accuracy: 0.7384\n",
      "Epoch 2576/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0656 - accuracy: 0.7702 - val_loss: 0.0762 - val_accuracy: 0.7314\n",
      "Epoch 2577/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0656 - accuracy: 0.7696 - val_loss: 0.0759 - val_accuracy: 0.7344\n",
      "Epoch 2578/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0656 - accuracy: 0.7695 - val_loss: 0.0755 - val_accuracy: 0.7354\n",
      "Epoch 2579/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0655 - accuracy: 0.7699 - val_loss: 0.0748 - val_accuracy: 0.7370\n",
      "Epoch 2580/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0656 - accuracy: 0.7696 - val_loss: 0.0749 - val_accuracy: 0.7387\n",
      "Epoch 2581/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0656 - accuracy: 0.7696 - val_loss: 0.0756 - val_accuracy: 0.7362\n",
      "Epoch 2582/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0656 - accuracy: 0.7690 - val_loss: 0.0749 - val_accuracy: 0.7379\n",
      "Epoch 2583/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0656 - accuracy: 0.7692 - val_loss: 0.0765 - val_accuracy: 0.7307\n",
      "Epoch 2584/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0656 - accuracy: 0.7698 - val_loss: 0.0761 - val_accuracy: 0.7334\n",
      "Epoch 2585/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0655 - accuracy: 0.7698 - val_loss: 0.0755 - val_accuracy: 0.7353\n",
      "Epoch 2586/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0657 - accuracy: 0.7695 - val_loss: 0.0756 - val_accuracy: 0.7348\n",
      "Epoch 2587/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0656 - accuracy: 0.7696 - val_loss: 0.0755 - val_accuracy: 0.7351\n",
      "Epoch 2588/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0656 - accuracy: 0.7695 - val_loss: 0.0763 - val_accuracy: 0.7333\n",
      "Epoch 2589/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0655 - accuracy: 0.7701 - val_loss: 0.0758 - val_accuracy: 0.7359\n",
      "Epoch 2590/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0656 - accuracy: 0.7696 - val_loss: 0.0757 - val_accuracy: 0.7365\n",
      "Epoch 2591/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0657 - accuracy: 0.7687 - val_loss: 0.0763 - val_accuracy: 0.7354\n",
      "Epoch 2592/5000\n",
      "11786/11786 [==============================] - 8s 644us/step - loss: 0.0657 - accuracy: 0.7698 - val_loss: 0.0756 - val_accuracy: 0.7343\n",
      "Epoch 2593/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0658 - accuracy: 0.7692 - val_loss: 0.0756 - val_accuracy: 0.7341\n",
      "Epoch 2594/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0658 - accuracy: 0.7691 - val_loss: 0.0758 - val_accuracy: 0.7346\n",
      "Epoch 2595/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0657 - accuracy: 0.7693 - val_loss: 0.0755 - val_accuracy: 0.7358\n",
      "Epoch 2596/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0657 - accuracy: 0.7695 - val_loss: 0.0754 - val_accuracy: 0.7346\n",
      "Epoch 2597/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0656 - accuracy: 0.7698 - val_loss: 0.0760 - val_accuracy: 0.7327\n",
      "Epoch 2598/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0656 - accuracy: 0.7696 - val_loss: 0.0761 - val_accuracy: 0.7344\n",
      "Epoch 2599/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0658 - accuracy: 0.7686 - val_loss: 0.0755 - val_accuracy: 0.7347\n",
      "Epoch 2600/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0657 - accuracy: 0.7694 - val_loss: 0.0760 - val_accuracy: 0.7339\n",
      "Epoch 2601/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0659 - accuracy: 0.7683 - val_loss: 0.0757 - val_accuracy: 0.7350\n",
      "Epoch 2602/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0656 - accuracy: 0.7696 - val_loss: 0.0756 - val_accuracy: 0.7347\n",
      "Epoch 2603/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0657 - accuracy: 0.7690 - val_loss: 0.0758 - val_accuracy: 0.7336\n",
      "Epoch 2604/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0656 - accuracy: 0.7701 - val_loss: 0.0759 - val_accuracy: 0.7332\n",
      "Epoch 2605/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0657 - accuracy: 0.7691 - val_loss: 0.0757 - val_accuracy: 0.7342\n",
      "Epoch 2606/5000\n",
      "11786/11786 [==============================] - 8s 644us/step - loss: 0.0657 - accuracy: 0.7696 - val_loss: 0.0753 - val_accuracy: 0.7346\n",
      "Epoch 2607/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0657 - accuracy: 0.7697 - val_loss: 0.0755 - val_accuracy: 0.7369\n",
      "Epoch 2608/5000\n",
      "11786/11786 [==============================] - 8s 639us/step - loss: 0.0656 - accuracy: 0.7696 - val_loss: 0.0755 - val_accuracy: 0.7339\n",
      "Epoch 2609/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0659 - accuracy: 0.7690 - val_loss: 0.0757 - val_accuracy: 0.7348\n",
      "Epoch 2610/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0656 - accuracy: 0.7699 - val_loss: 0.0764 - val_accuracy: 0.7339\n",
      "Epoch 2611/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0657 - accuracy: 0.7696 - val_loss: 0.0760 - val_accuracy: 0.7328\n",
      "Epoch 2612/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0656 - accuracy: 0.7697 - val_loss: 0.0761 - val_accuracy: 0.7353\n",
      "Epoch 2613/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0656 - accuracy: 0.7692 - val_loss: 0.0758 - val_accuracy: 0.7359\n",
      "Epoch 2614/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0658 - accuracy: 0.7691 - val_loss: 0.0756 - val_accuracy: 0.7360\n",
      "Epoch 2615/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0658 - accuracy: 0.7687 - val_loss: 0.0758 - val_accuracy: 0.7330\n",
      "Epoch 2616/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0657 - accuracy: 0.7695 - val_loss: 0.0764 - val_accuracy: 0.7333\n",
      "Epoch 2617/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0657 - accuracy: 0.7693 - val_loss: 0.0757 - val_accuracy: 0.7352\n",
      "Epoch 2618/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0658 - accuracy: 0.7692 - val_loss: 0.0755 - val_accuracy: 0.7357\n",
      "Epoch 2619/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0658 - accuracy: 0.7690 - val_loss: 0.0763 - val_accuracy: 0.7320\n",
      "Epoch 2620/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0658 - accuracy: 0.7693 - val_loss: 0.0756 - val_accuracy: 0.7354\n",
      "Epoch 2621/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0657 - accuracy: 0.7692 - val_loss: 0.0752 - val_accuracy: 0.7365\n",
      "Epoch 2622/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0658 - accuracy: 0.7687 - val_loss: 0.0761 - val_accuracy: 0.7348\n",
      "Epoch 2623/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0657 - accuracy: 0.7698 - val_loss: 0.0756 - val_accuracy: 0.7354\n",
      "Epoch 2624/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0657 - accuracy: 0.7692 - val_loss: 0.0762 - val_accuracy: 0.7354\n",
      "Epoch 2625/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0656 - accuracy: 0.7693 - val_loss: 0.0753 - val_accuracy: 0.7366\n",
      "Epoch 2626/5000\n",
      "11786/11786 [==============================] - 8s 644us/step - loss: 0.0656 - accuracy: 0.7693 - val_loss: 0.0756 - val_accuracy: 0.7334\n",
      "Epoch 2627/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0656 - accuracy: 0.7696 - val_loss: 0.0761 - val_accuracy: 0.7348\n",
      "Epoch 2628/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0657 - accuracy: 0.7695 - val_loss: 0.0756 - val_accuracy: 0.7341\n",
      "Epoch 2629/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0656 - accuracy: 0.7703 - val_loss: 0.0753 - val_accuracy: 0.7362\n",
      "Epoch 2630/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0656 - accuracy: 0.7698 - val_loss: 0.0759 - val_accuracy: 0.7327\n",
      "Epoch 2631/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0657 - accuracy: 0.7695 - val_loss: 0.0758 - val_accuracy: 0.7364\n",
      "Epoch 2632/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0656 - accuracy: 0.7702 - val_loss: 0.0766 - val_accuracy: 0.7319\n",
      "Epoch 2633/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0656 - accuracy: 0.7698 - val_loss: 0.0748 - val_accuracy: 0.7358\n",
      "Epoch 2634/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0656 - accuracy: 0.7702 - val_loss: 0.0762 - val_accuracy: 0.7349\n",
      "Epoch 2635/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0657 - accuracy: 0.7697 - val_loss: 0.0749 - val_accuracy: 0.7366\n",
      "Epoch 2636/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0657 - accuracy: 0.7694 - val_loss: 0.0757 - val_accuracy: 0.7347\n",
      "Epoch 2637/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0658 - accuracy: 0.7686 - val_loss: 0.0761 - val_accuracy: 0.7340\n",
      "Epoch 2638/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0658 - accuracy: 0.7686 - val_loss: 0.0751 - val_accuracy: 0.7360\n",
      "Epoch 2639/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0657 - accuracy: 0.7689 - val_loss: 0.0766 - val_accuracy: 0.7324\n",
      "Epoch 2640/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0657 - accuracy: 0.7696 - val_loss: 0.0751 - val_accuracy: 0.7366\n",
      "Epoch 2641/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0657 - accuracy: 0.7696 - val_loss: 0.0755 - val_accuracy: 0.7338\n",
      "Epoch 2642/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0658 - accuracy: 0.7692 - val_loss: 0.0755 - val_accuracy: 0.7344\n",
      "Epoch 2643/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0658 - accuracy: 0.7690 - val_loss: 0.0756 - val_accuracy: 0.7346\n",
      "Epoch 2644/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0657 - accuracy: 0.7692 - val_loss: 0.0763 - val_accuracy: 0.7340\n",
      "Epoch 2645/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0658 - accuracy: 0.7695 - val_loss: 0.0753 - val_accuracy: 0.7366\n",
      "Epoch 2646/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0658 - accuracy: 0.7689 - val_loss: 0.0756 - val_accuracy: 0.7363\n",
      "Epoch 2647/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0657 - accuracy: 0.7693 - val_loss: 0.0759 - val_accuracy: 0.7331\n",
      "Epoch 2648/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0658 - accuracy: 0.7690 - val_loss: 0.0763 - val_accuracy: 0.7333\n",
      "Epoch 2649/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0659 - accuracy: 0.7687 - val_loss: 0.0753 - val_accuracy: 0.7358\n",
      "Epoch 2650/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0658 - accuracy: 0.7691 - val_loss: 0.0748 - val_accuracy: 0.7345\n",
      "Epoch 2651/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0656 - accuracy: 0.7694 - val_loss: 0.0759 - val_accuracy: 0.7341\n",
      "Epoch 2652/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0657 - accuracy: 0.7695 - val_loss: 0.0757 - val_accuracy: 0.7371\n",
      "Epoch 2653/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0657 - accuracy: 0.7696 - val_loss: 0.0750 - val_accuracy: 0.7368\n",
      "Epoch 2654/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0656 - accuracy: 0.7696 - val_loss: 0.0755 - val_accuracy: 0.7328\n",
      "Epoch 2655/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0657 - accuracy: 0.7689 - val_loss: 0.0751 - val_accuracy: 0.7356\n",
      "Epoch 2656/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0658 - accuracy: 0.7690 - val_loss: 0.0750 - val_accuracy: 0.7358\n",
      "Epoch 2657/5000\n",
      "11786/11786 [==============================] - 8s 644us/step - loss: 0.0658 - accuracy: 0.7691 - val_loss: 0.0755 - val_accuracy: 0.7353\n",
      "Epoch 2658/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0658 - accuracy: 0.7689 - val_loss: 0.0763 - val_accuracy: 0.7351\n",
      "Epoch 2659/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0659 - accuracy: 0.7686 - val_loss: 0.0759 - val_accuracy: 0.7336\n",
      "Epoch 2660/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0658 - accuracy: 0.7690 - val_loss: 0.0753 - val_accuracy: 0.7352\n",
      "Epoch 2661/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0658 - accuracy: 0.7694 - val_loss: 0.0751 - val_accuracy: 0.7365\n",
      "Epoch 2662/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0657 - accuracy: 0.7697 - val_loss: 0.0767 - val_accuracy: 0.7346\n",
      "Epoch 2663/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0657 - accuracy: 0.7695 - val_loss: 0.0755 - val_accuracy: 0.7371\n",
      "Epoch 2664/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0659 - accuracy: 0.7686 - val_loss: 0.0752 - val_accuracy: 0.7367\n",
      "Epoch 2665/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0658 - accuracy: 0.7691 - val_loss: 0.0759 - val_accuracy: 0.7359\n",
      "Epoch 2666/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0658 - accuracy: 0.7691 - val_loss: 0.0762 - val_accuracy: 0.7335\n",
      "Epoch 2667/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0658 - accuracy: 0.7692 - val_loss: 0.0756 - val_accuracy: 0.7370\n",
      "Epoch 2668/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0657 - accuracy: 0.7692 - val_loss: 0.0761 - val_accuracy: 0.7331\n",
      "Epoch 2669/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0658 - accuracy: 0.7695 - val_loss: 0.0759 - val_accuracy: 0.7348\n",
      "Epoch 2670/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0659 - accuracy: 0.7692 - val_loss: 0.0753 - val_accuracy: 0.7357\n",
      "Epoch 2671/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0658 - accuracy: 0.7691 - val_loss: 0.0757 - val_accuracy: 0.7342\n",
      "Epoch 2672/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0657 - accuracy: 0.7696 - val_loss: 0.0754 - val_accuracy: 0.7374\n",
      "Epoch 2673/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0657 - accuracy: 0.7690 - val_loss: 0.0758 - val_accuracy: 0.7328\n",
      "Epoch 2674/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0658 - accuracy: 0.7687 - val_loss: 0.0760 - val_accuracy: 0.7353\n",
      "Epoch 2675/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0659 - accuracy: 0.7685 - val_loss: 0.0760 - val_accuracy: 0.7343\n",
      "Epoch 2676/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0659 - accuracy: 0.7694 - val_loss: 0.0759 - val_accuracy: 0.7343\n",
      "Epoch 2677/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0658 - accuracy: 0.7695 - val_loss: 0.0753 - val_accuracy: 0.7356\n",
      "Epoch 2678/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0658 - accuracy: 0.7690 - val_loss: 0.0755 - val_accuracy: 0.7348\n",
      "Epoch 2679/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0659 - accuracy: 0.7690 - val_loss: 0.0759 - val_accuracy: 0.7340\n",
      "Epoch 2680/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0659 - accuracy: 0.7683 - val_loss: 0.0753 - val_accuracy: 0.7359\n",
      "Epoch 2681/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0658 - accuracy: 0.7692 - val_loss: 0.0754 - val_accuracy: 0.7360\n",
      "Epoch 2682/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0658 - accuracy: 0.7691 - val_loss: 0.0757 - val_accuracy: 0.7355\n",
      "Epoch 2683/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0658 - accuracy: 0.7689 - val_loss: 0.0759 - val_accuracy: 0.7349\n",
      "Epoch 2684/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0657 - accuracy: 0.7692 - val_loss: 0.0755 - val_accuracy: 0.7352\n",
      "Epoch 2685/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0657 - accuracy: 0.7695 - val_loss: 0.0763 - val_accuracy: 0.7313\n",
      "Epoch 2686/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0658 - accuracy: 0.7694 - val_loss: 0.0755 - val_accuracy: 0.7365\n",
      "Epoch 2687/5000\n",
      "11786/11786 [==============================] - 8s 644us/step - loss: 0.0659 - accuracy: 0.7688 - val_loss: 0.0761 - val_accuracy: 0.7328\n",
      "Epoch 2688/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0657 - accuracy: 0.7693 - val_loss: 0.0765 - val_accuracy: 0.7330\n",
      "Epoch 2689/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0659 - accuracy: 0.7688 - val_loss: 0.0763 - val_accuracy: 0.7350\n",
      "Epoch 2690/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0659 - accuracy: 0.7683 - val_loss: 0.0760 - val_accuracy: 0.7319\n",
      "Epoch 2691/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0661 - accuracy: 0.7683 - val_loss: 0.0759 - val_accuracy: 0.7335\n",
      "Epoch 2692/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0659 - accuracy: 0.7687 - val_loss: 0.0770 - val_accuracy: 0.7308\n",
      "Epoch 2693/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0658 - accuracy: 0.7688 - val_loss: 0.0763 - val_accuracy: 0.7334\n",
      "Epoch 2694/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0658 - accuracy: 0.7688 - val_loss: 0.0768 - val_accuracy: 0.7352\n",
      "Epoch 2695/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0658 - accuracy: 0.7686 - val_loss: 0.0760 - val_accuracy: 0.7334\n",
      "Epoch 2696/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0658 - accuracy: 0.7689 - val_loss: 0.0752 - val_accuracy: 0.7353\n",
      "Epoch 2697/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0658 - accuracy: 0.7691 - val_loss: 0.0755 - val_accuracy: 0.7353\n",
      "Epoch 2698/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0657 - accuracy: 0.7693 - val_loss: 0.0760 - val_accuracy: 0.7350\n",
      "Epoch 2699/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0660 - accuracy: 0.7685 - val_loss: 0.0757 - val_accuracy: 0.7349\n",
      "Epoch 2700/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0658 - accuracy: 0.7687 - val_loss: 0.0763 - val_accuracy: 0.7335\n",
      "Epoch 2701/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0659 - accuracy: 0.7687 - val_loss: 0.0753 - val_accuracy: 0.7349\n",
      "Epoch 2702/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0657 - accuracy: 0.7695 - val_loss: 0.0759 - val_accuracy: 0.7343\n",
      "Epoch 2703/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0660 - accuracy: 0.7683 - val_loss: 0.0757 - val_accuracy: 0.7343\n",
      "Epoch 2704/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0659 - accuracy: 0.7690 - val_loss: 0.0760 - val_accuracy: 0.7345\n",
      "Epoch 2705/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0658 - accuracy: 0.7683 - val_loss: 0.0757 - val_accuracy: 0.7350\n",
      "Epoch 2706/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0658 - accuracy: 0.7690 - val_loss: 0.0760 - val_accuracy: 0.7365\n",
      "Epoch 2707/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0658 - accuracy: 0.7693 - val_loss: 0.0758 - val_accuracy: 0.7336\n",
      "Epoch 2708/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0658 - accuracy: 0.7692 - val_loss: 0.0759 - val_accuracy: 0.7336\n",
      "Epoch 2709/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0659 - accuracy: 0.7689 - val_loss: 0.0757 - val_accuracy: 0.7348\n",
      "Epoch 2710/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0658 - accuracy: 0.7693 - val_loss: 0.0758 - val_accuracy: 0.7348\n",
      "Epoch 2711/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0659 - accuracy: 0.7687 - val_loss: 0.0756 - val_accuracy: 0.7355\n",
      "Epoch 2712/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0659 - accuracy: 0.7687 - val_loss: 0.0761 - val_accuracy: 0.7333\n",
      "Epoch 2713/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0658 - accuracy: 0.7691 - val_loss: 0.0760 - val_accuracy: 0.7347\n",
      "Epoch 2714/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0658 - accuracy: 0.7689 - val_loss: 0.0760 - val_accuracy: 0.7349\n",
      "Epoch 2715/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0660 - accuracy: 0.7683 - val_loss: 0.0761 - val_accuracy: 0.7330\n",
      "Epoch 2716/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0659 - accuracy: 0.7685 - val_loss: 0.0765 - val_accuracy: 0.7334\n",
      "Epoch 2717/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0660 - accuracy: 0.7687 - val_loss: 0.0760 - val_accuracy: 0.7330\n",
      "Epoch 2718/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0660 - accuracy: 0.7684 - val_loss: 0.0766 - val_accuracy: 0.7321\n",
      "Epoch 2719/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0659 - accuracy: 0.7689 - val_loss: 0.0765 - val_accuracy: 0.7316\n",
      "Epoch 2720/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0659 - accuracy: 0.7688 - val_loss: 0.0759 - val_accuracy: 0.7332\n",
      "Epoch 2721/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0659 - accuracy: 0.7687 - val_loss: 0.0755 - val_accuracy: 0.7346\n",
      "Epoch 2722/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0660 - accuracy: 0.7682 - val_loss: 0.0757 - val_accuracy: 0.7334\n",
      "Epoch 2723/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0659 - accuracy: 0.7693 - val_loss: 0.0768 - val_accuracy: 0.7311\n",
      "Epoch 2724/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0659 - accuracy: 0.7694 - val_loss: 0.0760 - val_accuracy: 0.7352\n",
      "Epoch 2725/5000\n",
      "11786/11786 [==============================] - 8s 641us/step - loss: 0.0659 - accuracy: 0.7686 - val_loss: 0.0761 - val_accuracy: 0.7336\n",
      "Epoch 2726/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0660 - accuracy: 0.7686 - val_loss: 0.0762 - val_accuracy: 0.7323\n",
      "Epoch 2727/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0660 - accuracy: 0.7689 - val_loss: 0.0750 - val_accuracy: 0.7365\n",
      "Epoch 2728/5000\n",
      "11786/11786 [==============================] - 8s 644us/step - loss: 0.0658 - accuracy: 0.7693 - val_loss: 0.0767 - val_accuracy: 0.7309\n",
      "Epoch 2729/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0659 - accuracy: 0.7684 - val_loss: 0.0757 - val_accuracy: 0.7355\n",
      "Epoch 2730/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0660 - accuracy: 0.7680 - val_loss: 0.0760 - val_accuracy: 0.7343\n",
      "Epoch 2731/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0660 - accuracy: 0.7686 - val_loss: 0.0764 - val_accuracy: 0.7333\n",
      "Epoch 2732/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0661 - accuracy: 0.7684 - val_loss: 0.0756 - val_accuracy: 0.7362\n",
      "Epoch 2733/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0659 - accuracy: 0.7685 - val_loss: 0.0757 - val_accuracy: 0.7352\n",
      "Epoch 2734/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0660 - accuracy: 0.7686 - val_loss: 0.0755 - val_accuracy: 0.7349\n",
      "Epoch 2735/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0661 - accuracy: 0.7681 - val_loss: 0.0761 - val_accuracy: 0.7342\n",
      "Epoch 2736/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0660 - accuracy: 0.7682 - val_loss: 0.0758 - val_accuracy: 0.7329\n",
      "Epoch 2737/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0660 - accuracy: 0.7683 - val_loss: 0.0759 - val_accuracy: 0.7324\n",
      "Epoch 2738/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0661 - accuracy: 0.7684 - val_loss: 0.0757 - val_accuracy: 0.7340\n",
      "Epoch 2739/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0661 - accuracy: 0.7679 - val_loss: 0.0757 - val_accuracy: 0.7344\n",
      "Epoch 2740/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0660 - accuracy: 0.7684 - val_loss: 0.0757 - val_accuracy: 0.7347\n",
      "Epoch 2741/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0661 - accuracy: 0.7675 - val_loss: 0.0754 - val_accuracy: 0.7352\n",
      "Epoch 2742/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0661 - accuracy: 0.7681 - val_loss: 0.0758 - val_accuracy: 0.7353\n",
      "Epoch 2743/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0659 - accuracy: 0.7687 - val_loss: 0.0758 - val_accuracy: 0.7333\n",
      "Epoch 2744/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0661 - accuracy: 0.7683 - val_loss: 0.0761 - val_accuracy: 0.7343\n",
      "Epoch 2745/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0662 - accuracy: 0.7674 - val_loss: 0.0761 - val_accuracy: 0.7337\n",
      "Epoch 2746/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0662 - accuracy: 0.7679 - val_loss: 0.0762 - val_accuracy: 0.7352\n",
      "Epoch 2747/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0660 - accuracy: 0.7688 - val_loss: 0.0760 - val_accuracy: 0.7326\n",
      "Epoch 2748/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0662 - accuracy: 0.7683 - val_loss: 0.0754 - val_accuracy: 0.7349\n",
      "Epoch 2749/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0660 - accuracy: 0.7687 - val_loss: 0.0758 - val_accuracy: 0.7348\n",
      "Epoch 2750/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0661 - accuracy: 0.7685 - val_loss: 0.0761 - val_accuracy: 0.7344\n",
      "Epoch 2751/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0660 - accuracy: 0.7685 - val_loss: 0.0755 - val_accuracy: 0.7337\n",
      "Epoch 2752/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0661 - accuracy: 0.7681 - val_loss: 0.0758 - val_accuracy: 0.7347\n",
      "Epoch 2753/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0660 - accuracy: 0.7684 - val_loss: 0.0763 - val_accuracy: 0.7334\n",
      "Epoch 2754/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0662 - accuracy: 0.7680 - val_loss: 0.0764 - val_accuracy: 0.7310\n",
      "Epoch 2755/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0661 - accuracy: 0.7685 - val_loss: 0.0762 - val_accuracy: 0.7328\n",
      "Epoch 2756/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0661 - accuracy: 0.7682 - val_loss: 0.0755 - val_accuracy: 0.7347\n",
      "Epoch 2757/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0661 - accuracy: 0.7684 - val_loss: 0.0762 - val_accuracy: 0.7337\n",
      "Epoch 2758/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0660 - accuracy: 0.7680 - val_loss: 0.0754 - val_accuracy: 0.7347\n",
      "Epoch 2759/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0662 - accuracy: 0.7680 - val_loss: 0.0762 - val_accuracy: 0.7343\n",
      "Epoch 2760/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0661 - accuracy: 0.7680 - val_loss: 0.0760 - val_accuracy: 0.7336\n",
      "Epoch 2761/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0662 - accuracy: 0.7681 - val_loss: 0.0762 - val_accuracy: 0.7335\n",
      "Epoch 2762/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0663 - accuracy: 0.7672 - val_loss: 0.0767 - val_accuracy: 0.7317\n",
      "Epoch 2763/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0662 - accuracy: 0.7677 - val_loss: 0.0756 - val_accuracy: 0.7333\n",
      "Epoch 2764/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0662 - accuracy: 0.7676 - val_loss: 0.0764 - val_accuracy: 0.7345\n",
      "Epoch 2765/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0662 - accuracy: 0.7679 - val_loss: 0.0761 - val_accuracy: 0.7328\n",
      "Epoch 2766/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0661 - accuracy: 0.7681 - val_loss: 0.0764 - val_accuracy: 0.7321\n",
      "Epoch 2767/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0661 - accuracy: 0.7680 - val_loss: 0.0756 - val_accuracy: 0.7339\n",
      "Epoch 2768/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0662 - accuracy: 0.7677 - val_loss: 0.0762 - val_accuracy: 0.7328\n",
      "Epoch 2769/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0660 - accuracy: 0.7688 - val_loss: 0.0756 - val_accuracy: 0.7342\n",
      "Epoch 2770/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0663 - accuracy: 0.7678 - val_loss: 0.0764 - val_accuracy: 0.7342\n",
      "Epoch 2771/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0660 - accuracy: 0.7682 - val_loss: 0.0754 - val_accuracy: 0.7335\n",
      "Epoch 2772/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0661 - accuracy: 0.7683 - val_loss: 0.0774 - val_accuracy: 0.7298\n",
      "Epoch 2773/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0661 - accuracy: 0.7685 - val_loss: 0.0762 - val_accuracy: 0.7340\n",
      "Epoch 2774/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0661 - accuracy: 0.7684 - val_loss: 0.0766 - val_accuracy: 0.7327\n",
      "Epoch 2775/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0662 - accuracy: 0.7677 - val_loss: 0.0758 - val_accuracy: 0.7340\n",
      "Epoch 2776/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0663 - accuracy: 0.7678 - val_loss: 0.0775 - val_accuracy: 0.7310\n",
      "Epoch 2777/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0664 - accuracy: 0.7676 - val_loss: 0.0770 - val_accuracy: 0.7322\n",
      "Epoch 2778/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0661 - accuracy: 0.7681 - val_loss: 0.0763 - val_accuracy: 0.7340\n",
      "Epoch 2779/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0663 - accuracy: 0.7677 - val_loss: 0.0765 - val_accuracy: 0.7354\n",
      "Epoch 2780/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0662 - accuracy: 0.7682 - val_loss: 0.0755 - val_accuracy: 0.7358\n",
      "Epoch 2781/5000\n",
      "11786/11786 [==============================] - 8s 643us/step - loss: 0.0662 - accuracy: 0.7681 - val_loss: 0.0759 - val_accuracy: 0.7352\n",
      "Epoch 2782/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0662 - accuracy: 0.7681 - val_loss: 0.0759 - val_accuracy: 0.7341\n",
      "Epoch 2783/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0662 - accuracy: 0.7678 - val_loss: 0.0762 - val_accuracy: 0.7334\n",
      "Epoch 2784/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0663 - accuracy: 0.7678 - val_loss: 0.0763 - val_accuracy: 0.7337\n",
      "Epoch 2785/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0662 - accuracy: 0.7682 - val_loss: 0.0759 - val_accuracy: 0.7346\n",
      "Epoch 2786/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0663 - accuracy: 0.7672 - val_loss: 0.0769 - val_accuracy: 0.7313\n",
      "Epoch 2787/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0663 - accuracy: 0.7676 - val_loss: 0.0763 - val_accuracy: 0.7331\n",
      "Epoch 2788/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0661 - accuracy: 0.7683 - val_loss: 0.0766 - val_accuracy: 0.7317\n",
      "Epoch 2789/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0662 - accuracy: 0.7675 - val_loss: 0.0765 - val_accuracy: 0.7348\n",
      "Epoch 2790/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0662 - accuracy: 0.7680 - val_loss: 0.0760 - val_accuracy: 0.7331\n",
      "Epoch 2791/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0663 - accuracy: 0.7681 - val_loss: 0.0764 - val_accuracy: 0.7347\n",
      "Epoch 2792/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0663 - accuracy: 0.7682 - val_loss: 0.0758 - val_accuracy: 0.7338\n",
      "Epoch 2793/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0664 - accuracy: 0.7678 - val_loss: 0.0768 - val_accuracy: 0.7335\n",
      "Epoch 2794/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0662 - accuracy: 0.7679 - val_loss: 0.0758 - val_accuracy: 0.7361\n",
      "Epoch 2795/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0662 - accuracy: 0.7681 - val_loss: 0.0763 - val_accuracy: 0.7327\n",
      "Epoch 2796/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0665 - accuracy: 0.7675 - val_loss: 0.0761 - val_accuracy: 0.7343\n",
      "Epoch 2797/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0664 - accuracy: 0.7673 - val_loss: 0.0760 - val_accuracy: 0.7333\n",
      "Epoch 2798/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0662 - accuracy: 0.7683 - val_loss: 0.0764 - val_accuracy: 0.7324\n",
      "Epoch 2799/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0662 - accuracy: 0.7675 - val_loss: 0.0766 - val_accuracy: 0.7340\n",
      "Epoch 2800/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0665 - accuracy: 0.7668 - val_loss: 0.0760 - val_accuracy: 0.7337\n",
      "Epoch 2801/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0661 - accuracy: 0.7679 - val_loss: 0.0761 - val_accuracy: 0.7337\n",
      "Epoch 2802/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0663 - accuracy: 0.7680 - val_loss: 0.0765 - val_accuracy: 0.7315\n",
      "Epoch 2803/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0663 - accuracy: 0.7675 - val_loss: 0.0762 - val_accuracy: 0.7351\n",
      "Epoch 2804/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0663 - accuracy: 0.7675 - val_loss: 0.0768 - val_accuracy: 0.7316\n",
      "Epoch 2805/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0663 - accuracy: 0.7677 - val_loss: 0.0764 - val_accuracy: 0.7346\n",
      "Epoch 2806/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0663 - accuracy: 0.7680 - val_loss: 0.0770 - val_accuracy: 0.7326\n",
      "Epoch 2807/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0663 - accuracy: 0.7676 - val_loss: 0.0768 - val_accuracy: 0.7332\n",
      "Epoch 2808/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0663 - accuracy: 0.7680 - val_loss: 0.0760 - val_accuracy: 0.7346\n",
      "Epoch 2809/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0663 - accuracy: 0.7676 - val_loss: 0.0763 - val_accuracy: 0.7342\n",
      "Epoch 2810/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0661 - accuracy: 0.7687 - val_loss: 0.0763 - val_accuracy: 0.7350\n",
      "Epoch 2811/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0664 - accuracy: 0.7670 - val_loss: 0.0762 - val_accuracy: 0.7338\n",
      "Epoch 2812/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0662 - accuracy: 0.7677 - val_loss: 0.0760 - val_accuracy: 0.7335\n",
      "Epoch 2813/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0661 - accuracy: 0.7678 - val_loss: 0.0763 - val_accuracy: 0.7325\n",
      "Epoch 2814/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0661 - accuracy: 0.7683 - val_loss: 0.0761 - val_accuracy: 0.7350\n",
      "Epoch 2815/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0662 - accuracy: 0.7682 - val_loss: 0.0769 - val_accuracy: 0.7346\n",
      "Epoch 2816/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0661 - accuracy: 0.7688 - val_loss: 0.0763 - val_accuracy: 0.7326\n",
      "Epoch 2817/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0662 - accuracy: 0.7682 - val_loss: 0.0761 - val_accuracy: 0.7349\n",
      "Epoch 2818/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0663 - accuracy: 0.7678 - val_loss: 0.0761 - val_accuracy: 0.7331\n",
      "Epoch 2819/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0664 - accuracy: 0.7675 - val_loss: 0.0766 - val_accuracy: 0.7318\n",
      "Epoch 2820/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0664 - accuracy: 0.7675 - val_loss: 0.0766 - val_accuracy: 0.7322\n",
      "Epoch 2821/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0663 - accuracy: 0.7673 - val_loss: 0.0765 - val_accuracy: 0.7336\n",
      "Epoch 2822/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0663 - accuracy: 0.7679 - val_loss: 0.0761 - val_accuracy: 0.7329\n",
      "Epoch 2823/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0663 - accuracy: 0.7675 - val_loss: 0.0760 - val_accuracy: 0.7325\n",
      "Epoch 2824/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0663 - accuracy: 0.7670 - val_loss: 0.0758 - val_accuracy: 0.7332\n",
      "Epoch 2825/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0663 - accuracy: 0.7678 - val_loss: 0.0763 - val_accuracy: 0.7344\n",
      "Epoch 2826/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0664 - accuracy: 0.7670 - val_loss: 0.0775 - val_accuracy: 0.7314\n",
      "Epoch 2827/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0664 - accuracy: 0.7678 - val_loss: 0.0760 - val_accuracy: 0.7342\n",
      "Epoch 2828/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0664 - accuracy: 0.7674 - val_loss: 0.0765 - val_accuracy: 0.7338\n",
      "Epoch 2829/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0665 - accuracy: 0.7669 - val_loss: 0.0767 - val_accuracy: 0.7319\n",
      "Epoch 2830/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0661 - accuracy: 0.7683 - val_loss: 0.0763 - val_accuracy: 0.7329\n",
      "Epoch 2831/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0665 - accuracy: 0.7672 - val_loss: 0.0762 - val_accuracy: 0.7331\n",
      "Epoch 2832/5000\n",
      "11786/11786 [==============================] - 8s 644us/step - loss: 0.0662 - accuracy: 0.7683 - val_loss: 0.0770 - val_accuracy: 0.7320\n",
      "Epoch 2833/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0663 - accuracy: 0.7678 - val_loss: 0.0761 - val_accuracy: 0.7332\n",
      "Epoch 2834/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0664 - accuracy: 0.7678 - val_loss: 0.0774 - val_accuracy: 0.7285\n",
      "Epoch 2835/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0664 - accuracy: 0.7675 - val_loss: 0.0767 - val_accuracy: 0.7328\n",
      "Epoch 2836/5000\n",
      "11786/11786 [==============================] - 8s 645us/step - loss: 0.0665 - accuracy: 0.7671 - val_loss: 0.0763 - val_accuracy: 0.7341\n",
      "Epoch 2837/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0665 - accuracy: 0.7671 - val_loss: 0.0761 - val_accuracy: 0.7336\n",
      "Epoch 2838/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0665 - accuracy: 0.7670 - val_loss: 0.0774 - val_accuracy: 0.7305\n",
      "Epoch 2839/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0663 - accuracy: 0.7680 - val_loss: 0.0765 - val_accuracy: 0.7334\n",
      "Epoch 2840/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0666 - accuracy: 0.7670 - val_loss: 0.0771 - val_accuracy: 0.7314\n",
      "Epoch 2841/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0665 - accuracy: 0.7671 - val_loss: 0.0765 - val_accuracy: 0.7340\n",
      "Epoch 2842/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0665 - accuracy: 0.7672 - val_loss: 0.0764 - val_accuracy: 0.7333\n",
      "Epoch 2843/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0664 - accuracy: 0.7675 - val_loss: 0.0775 - val_accuracy: 0.7292\n",
      "Epoch 2844/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0665 - accuracy: 0.7672 - val_loss: 0.0764 - val_accuracy: 0.7348\n",
      "Epoch 2845/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0664 - accuracy: 0.7676 - val_loss: 0.0761 - val_accuracy: 0.7338\n",
      "Epoch 2846/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0664 - accuracy: 0.7678 - val_loss: 0.0766 - val_accuracy: 0.7331\n",
      "Epoch 2847/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0664 - accuracy: 0.7674 - val_loss: 0.0765 - val_accuracy: 0.7316\n",
      "Epoch 2848/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0664 - accuracy: 0.7672 - val_loss: 0.0777 - val_accuracy: 0.7280\n",
      "Epoch 2849/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0664 - accuracy: 0.7676 - val_loss: 0.0766 - val_accuracy: 0.7323\n",
      "Epoch 2850/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0664 - accuracy: 0.7682 - val_loss: 0.0766 - val_accuracy: 0.7324\n",
      "Epoch 2851/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0666 - accuracy: 0.7669 - val_loss: 0.0763 - val_accuracy: 0.7317\n",
      "Epoch 2852/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0665 - accuracy: 0.7671 - val_loss: 0.0758 - val_accuracy: 0.7354\n",
      "Epoch 2853/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0664 - accuracy: 0.7667 - val_loss: 0.0771 - val_accuracy: 0.7327\n",
      "Epoch 2854/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0665 - accuracy: 0.7667 - val_loss: 0.0760 - val_accuracy: 0.7337\n",
      "Epoch 2855/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0664 - accuracy: 0.7672 - val_loss: 0.0755 - val_accuracy: 0.7344\n",
      "Epoch 2856/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0662 - accuracy: 0.7677 - val_loss: 0.0764 - val_accuracy: 0.7327\n",
      "Epoch 2857/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0663 - accuracy: 0.7675 - val_loss: 0.0768 - val_accuracy: 0.7326\n",
      "Epoch 2858/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0664 - accuracy: 0.7673 - val_loss: 0.0765 - val_accuracy: 0.7336\n",
      "Epoch 2859/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0663 - accuracy: 0.7671 - val_loss: 0.0768 - val_accuracy: 0.7303\n",
      "Epoch 2860/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0665 - accuracy: 0.7671 - val_loss: 0.0758 - val_accuracy: 0.7340\n",
      "Epoch 2861/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0664 - accuracy: 0.7672 - val_loss: 0.0757 - val_accuracy: 0.7355\n",
      "Epoch 2862/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0665 - accuracy: 0.7672 - val_loss: 0.0770 - val_accuracy: 0.7303\n",
      "Epoch 2863/5000\n",
      "11786/11786 [==============================] - 8s 640us/step - loss: 0.0664 - accuracy: 0.7673 - val_loss: 0.0761 - val_accuracy: 0.7345\n",
      "Epoch 2864/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0664 - accuracy: 0.7675 - val_loss: 0.0761 - val_accuracy: 0.7330\n",
      "Epoch 2865/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0665 - accuracy: 0.7672 - val_loss: 0.0769 - val_accuracy: 0.7300\n",
      "Epoch 2866/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0665 - accuracy: 0.7669 - val_loss: 0.0764 - val_accuracy: 0.7317\n",
      "Epoch 2867/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0665 - accuracy: 0.7672 - val_loss: 0.0764 - val_accuracy: 0.7325\n",
      "Epoch 2868/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0665 - accuracy: 0.7679 - val_loss: 0.0764 - val_accuracy: 0.7323\n",
      "Epoch 2869/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0665 - accuracy: 0.7677 - val_loss: 0.0760 - val_accuracy: 0.7338\n",
      "Epoch 2870/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0665 - accuracy: 0.7668 - val_loss: 0.0765 - val_accuracy: 0.7313\n",
      "Epoch 2871/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0663 - accuracy: 0.7682 - val_loss: 0.0762 - val_accuracy: 0.7343\n",
      "Epoch 2872/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0663 - accuracy: 0.7673 - val_loss: 0.0771 - val_accuracy: 0.7340\n",
      "Epoch 2873/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0665 - accuracy: 0.7672 - val_loss: 0.0762 - val_accuracy: 0.7322\n",
      "Epoch 2874/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0665 - accuracy: 0.7670 - val_loss: 0.0771 - val_accuracy: 0.7327\n",
      "Epoch 2875/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0664 - accuracy: 0.7674 - val_loss: 0.0763 - val_accuracy: 0.7313\n",
      "Epoch 2876/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0663 - accuracy: 0.7679 - val_loss: 0.0770 - val_accuracy: 0.7310\n",
      "Epoch 2877/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0664 - accuracy: 0.7678 - val_loss: 0.0776 - val_accuracy: 0.7284\n",
      "Epoch 2878/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0663 - accuracy: 0.7675 - val_loss: 0.0764 - val_accuracy: 0.7346\n",
      "Epoch 2879/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0663 - accuracy: 0.7682 - val_loss: 0.0765 - val_accuracy: 0.7333\n",
      "Epoch 2880/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0664 - accuracy: 0.7673 - val_loss: 0.0761 - val_accuracy: 0.7348\n",
      "Epoch 2881/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0664 - accuracy: 0.7679 - val_loss: 0.0766 - val_accuracy: 0.7324\n",
      "Epoch 2882/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0664 - accuracy: 0.7674 - val_loss: 0.0761 - val_accuracy: 0.7335\n",
      "Epoch 2883/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0665 - accuracy: 0.7672 - val_loss: 0.0761 - val_accuracy: 0.7342\n",
      "Epoch 2884/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0665 - accuracy: 0.7673 - val_loss: 0.0761 - val_accuracy: 0.7346\n",
      "Epoch 2885/5000\n",
      "11786/11786 [==============================] - 8s 643us/step - loss: 0.0668 - accuracy: 0.7662 - val_loss: 0.0768 - val_accuracy: 0.7323\n",
      "Epoch 2886/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0665 - accuracy: 0.7671 - val_loss: 0.0764 - val_accuracy: 0.7335\n",
      "Epoch 2887/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0665 - accuracy: 0.7673 - val_loss: 0.0763 - val_accuracy: 0.7335\n",
      "Epoch 2888/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0665 - accuracy: 0.7673 - val_loss: 0.0760 - val_accuracy: 0.7343\n",
      "Epoch 2889/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0663 - accuracy: 0.7678 - val_loss: 0.0769 - val_accuracy: 0.7328\n",
      "Epoch 2890/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0664 - accuracy: 0.7674 - val_loss: 0.0765 - val_accuracy: 0.7309\n",
      "Epoch 2891/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0665 - accuracy: 0.7669 - val_loss: 0.0761 - val_accuracy: 0.7346\n",
      "Epoch 2892/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0664 - accuracy: 0.7673 - val_loss: 0.0765 - val_accuracy: 0.7325\n",
      "Epoch 2893/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0664 - accuracy: 0.7675 - val_loss: 0.0771 - val_accuracy: 0.7322\n",
      "Epoch 2894/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0665 - accuracy: 0.7672 - val_loss: 0.0766 - val_accuracy: 0.7323\n",
      "Epoch 2895/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0664 - accuracy: 0.7680 - val_loss: 0.0766 - val_accuracy: 0.7307\n",
      "Epoch 2896/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0664 - accuracy: 0.7675 - val_loss: 0.0778 - val_accuracy: 0.7293\n",
      "Epoch 2897/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0665 - accuracy: 0.7673 - val_loss: 0.0767 - val_accuracy: 0.7326\n",
      "Epoch 2898/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0664 - accuracy: 0.7675 - val_loss: 0.0762 - val_accuracy: 0.7351\n",
      "Epoch 2899/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0665 - accuracy: 0.7672 - val_loss: 0.0764 - val_accuracy: 0.7346\n",
      "Epoch 2900/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0665 - accuracy: 0.7674 - val_loss: 0.0762 - val_accuracy: 0.7319\n",
      "Epoch 2901/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0665 - accuracy: 0.7672 - val_loss: 0.0771 - val_accuracy: 0.7311\n",
      "Epoch 2902/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0667 - accuracy: 0.7664 - val_loss: 0.0765 - val_accuracy: 0.7314\n",
      "Epoch 2903/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0667 - accuracy: 0.7665 - val_loss: 0.0767 - val_accuracy: 0.7307\n",
      "Epoch 2904/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0668 - accuracy: 0.7661 - val_loss: 0.0759 - val_accuracy: 0.7333\n",
      "Epoch 2905/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0664 - accuracy: 0.7667 - val_loss: 0.0766 - val_accuracy: 0.7317\n",
      "Epoch 2906/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0664 - accuracy: 0.7672 - val_loss: 0.0762 - val_accuracy: 0.7333\n",
      "Epoch 2907/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0664 - accuracy: 0.7672 - val_loss: 0.0772 - val_accuracy: 0.7311\n",
      "Epoch 2908/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0666 - accuracy: 0.7670 - val_loss: 0.0773 - val_accuracy: 0.7310\n",
      "Epoch 2909/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0666 - accuracy: 0.7670 - val_loss: 0.0760 - val_accuracy: 0.7328\n",
      "Epoch 2910/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0663 - accuracy: 0.7681 - val_loss: 0.0764 - val_accuracy: 0.7341\n",
      "Epoch 2911/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0666 - accuracy: 0.7668 - val_loss: 0.0765 - val_accuracy: 0.7341\n",
      "Epoch 2912/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0665 - accuracy: 0.7674 - val_loss: 0.0766 - val_accuracy: 0.7337\n",
      "Epoch 2913/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0665 - accuracy: 0.7671 - val_loss: 0.0768 - val_accuracy: 0.7328\n",
      "Epoch 2914/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0666 - accuracy: 0.7672 - val_loss: 0.0768 - val_accuracy: 0.7322\n",
      "Epoch 2915/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0665 - accuracy: 0.7678 - val_loss: 0.0763 - val_accuracy: 0.7331\n",
      "Epoch 2916/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0666 - accuracy: 0.7667 - val_loss: 0.0769 - val_accuracy: 0.7313\n",
      "Epoch 2917/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0667 - accuracy: 0.7670 - val_loss: 0.0776 - val_accuracy: 0.7306\n",
      "Epoch 2918/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0664 - accuracy: 0.7678 - val_loss: 0.0759 - val_accuracy: 0.7333\n",
      "Epoch 2919/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0666 - accuracy: 0.7670 - val_loss: 0.0770 - val_accuracy: 0.7300\n",
      "Epoch 2920/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0664 - accuracy: 0.7669 - val_loss: 0.0767 - val_accuracy: 0.7313\n",
      "Epoch 2921/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0666 - accuracy: 0.7673 - val_loss: 0.0760 - val_accuracy: 0.7344\n",
      "Epoch 2922/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0667 - accuracy: 0.7669 - val_loss: 0.0763 - val_accuracy: 0.7343\n",
      "Epoch 2923/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0664 - accuracy: 0.7675 - val_loss: 0.0765 - val_accuracy: 0.7340\n",
      "Epoch 2924/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0664 - accuracy: 0.7676 - val_loss: 0.0772 - val_accuracy: 0.7327\n",
      "Epoch 2925/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0665 - accuracy: 0.7674 - val_loss: 0.0763 - val_accuracy: 0.7362\n",
      "Epoch 2926/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0664 - accuracy: 0.7675 - val_loss: 0.0771 - val_accuracy: 0.7304\n",
      "Epoch 2927/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0665 - accuracy: 0.7670 - val_loss: 0.0761 - val_accuracy: 0.7327\n",
      "Epoch 2928/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0665 - accuracy: 0.7672 - val_loss: 0.0767 - val_accuracy: 0.7334\n",
      "Epoch 2929/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0663 - accuracy: 0.7676 - val_loss: 0.0760 - val_accuracy: 0.7341\n",
      "Epoch 2930/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0665 - accuracy: 0.7668 - val_loss: 0.0761 - val_accuracy: 0.7335\n",
      "Epoch 2931/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0664 - accuracy: 0.7676 - val_loss: 0.0763 - val_accuracy: 0.7335\n",
      "Epoch 2932/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0665 - accuracy: 0.7670 - val_loss: 0.0766 - val_accuracy: 0.7332\n",
      "Epoch 2933/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0665 - accuracy: 0.7674 - val_loss: 0.0768 - val_accuracy: 0.7335\n",
      "Epoch 2934/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0664 - accuracy: 0.7671 - val_loss: 0.0768 - val_accuracy: 0.7299\n",
      "Epoch 2935/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0665 - accuracy: 0.7678 - val_loss: 0.0768 - val_accuracy: 0.7307\n",
      "Epoch 2936/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0665 - accuracy: 0.7670 - val_loss: 0.0768 - val_accuracy: 0.7334\n",
      "Epoch 2937/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0665 - accuracy: 0.7674 - val_loss: 0.0763 - val_accuracy: 0.7334\n",
      "Epoch 2938/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0664 - accuracy: 0.7675 - val_loss: 0.0763 - val_accuracy: 0.7326\n",
      "Epoch 2939/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0664 - accuracy: 0.7676 - val_loss: 0.0774 - val_accuracy: 0.7307\n",
      "Epoch 2940/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0665 - accuracy: 0.7673 - val_loss: 0.0765 - val_accuracy: 0.7338\n",
      "Epoch 2941/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0666 - accuracy: 0.7671 - val_loss: 0.0766 - val_accuracy: 0.7328\n",
      "Epoch 2942/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0665 - accuracy: 0.7675 - val_loss: 0.0763 - val_accuracy: 0.7315\n",
      "Epoch 2943/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0665 - accuracy: 0.7673 - val_loss: 0.0772 - val_accuracy: 0.7306\n",
      "Epoch 2944/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0667 - accuracy: 0.7662 - val_loss: 0.0768 - val_accuracy: 0.7327\n",
      "Epoch 2945/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0667 - accuracy: 0.7665 - val_loss: 0.0761 - val_accuracy: 0.7344\n",
      "Epoch 2946/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0666 - accuracy: 0.7672 - val_loss: 0.0781 - val_accuracy: 0.7310\n",
      "Epoch 2947/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0666 - accuracy: 0.7663 - val_loss: 0.0757 - val_accuracy: 0.7347\n",
      "Epoch 2948/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0665 - accuracy: 0.7671 - val_loss: 0.0768 - val_accuracy: 0.7307\n",
      "Epoch 2949/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0666 - accuracy: 0.7671 - val_loss: 0.0758 - val_accuracy: 0.7342\n",
      "Epoch 2950/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0666 - accuracy: 0.7668 - val_loss: 0.0754 - val_accuracy: 0.7357\n",
      "Epoch 2951/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0666 - accuracy: 0.7668 - val_loss: 0.0769 - val_accuracy: 0.7310\n",
      "Epoch 2952/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0666 - accuracy: 0.7670 - val_loss: 0.0762 - val_accuracy: 0.7332\n",
      "Epoch 2953/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0666 - accuracy: 0.7672 - val_loss: 0.0763 - val_accuracy: 0.7334\n",
      "Epoch 2954/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0666 - accuracy: 0.7668 - val_loss: 0.0769 - val_accuracy: 0.7332\n",
      "Epoch 2955/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0666 - accuracy: 0.7668 - val_loss: 0.0763 - val_accuracy: 0.7336\n",
      "Epoch 2956/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0666 - accuracy: 0.7672 - val_loss: 0.0757 - val_accuracy: 0.7343\n",
      "Epoch 2957/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0665 - accuracy: 0.7672 - val_loss: 0.0766 - val_accuracy: 0.7335\n",
      "Epoch 2958/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0666 - accuracy: 0.7670 - val_loss: 0.0766 - val_accuracy: 0.7333\n",
      "Epoch 2959/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0666 - accuracy: 0.7668 - val_loss: 0.0760 - val_accuracy: 0.7333\n",
      "Epoch 2960/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0666 - accuracy: 0.7670 - val_loss: 0.0761 - val_accuracy: 0.7349\n",
      "Epoch 2961/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0667 - accuracy: 0.7666 - val_loss: 0.0768 - val_accuracy: 0.7335\n",
      "Epoch 2962/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0665 - accuracy: 0.7670 - val_loss: 0.0764 - val_accuracy: 0.7337\n",
      "Epoch 2963/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0666 - accuracy: 0.7664 - val_loss: 0.0762 - val_accuracy: 0.7346\n",
      "Epoch 2964/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0665 - accuracy: 0.7675 - val_loss: 0.0762 - val_accuracy: 0.7316\n",
      "Epoch 2965/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0666 - accuracy: 0.7665 - val_loss: 0.0769 - val_accuracy: 0.7316\n",
      "Epoch 2966/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0664 - accuracy: 0.7676 - val_loss: 0.0763 - val_accuracy: 0.7321\n",
      "Epoch 2967/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0667 - accuracy: 0.7662 - val_loss: 0.0760 - val_accuracy: 0.7343\n",
      "Epoch 2968/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0665 - accuracy: 0.7667 - val_loss: 0.0765 - val_accuracy: 0.7333\n",
      "Epoch 2969/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0667 - accuracy: 0.7665 - val_loss: 0.0762 - val_accuracy: 0.7349\n",
      "Epoch 2970/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0666 - accuracy: 0.7667 - val_loss: 0.0760 - val_accuracy: 0.7341\n",
      "Epoch 2971/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0667 - accuracy: 0.7669 - val_loss: 0.0770 - val_accuracy: 0.7331\n",
      "Epoch 2972/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0667 - accuracy: 0.7665 - val_loss: 0.0767 - val_accuracy: 0.7326\n",
      "Epoch 2973/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0667 - accuracy: 0.7667 - val_loss: 0.0768 - val_accuracy: 0.7317\n",
      "Epoch 2974/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0665 - accuracy: 0.7668 - val_loss: 0.0770 - val_accuracy: 0.7332\n",
      "Epoch 2975/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0667 - accuracy: 0.7665 - val_loss: 0.0762 - val_accuracy: 0.7342\n",
      "Epoch 2976/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0667 - accuracy: 0.7662 - val_loss: 0.0762 - val_accuracy: 0.7346\n",
      "Epoch 2977/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0667 - accuracy: 0.7668 - val_loss: 0.0763 - val_accuracy: 0.7331\n",
      "Epoch 2978/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0665 - accuracy: 0.7673 - val_loss: 0.0773 - val_accuracy: 0.7308\n",
      "Epoch 2979/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0665 - accuracy: 0.7672 - val_loss: 0.0774 - val_accuracy: 0.7317\n",
      "Epoch 2980/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0667 - accuracy: 0.7666 - val_loss: 0.0763 - val_accuracy: 0.7333\n",
      "Epoch 2981/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0666 - accuracy: 0.7669 - val_loss: 0.0768 - val_accuracy: 0.7300\n",
      "Epoch 2982/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0664 - accuracy: 0.7674 - val_loss: 0.0779 - val_accuracy: 0.7290\n",
      "Epoch 2983/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0666 - accuracy: 0.7666 - val_loss: 0.0778 - val_accuracy: 0.7314\n",
      "Epoch 2984/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0663 - accuracy: 0.7676 - val_loss: 0.0768 - val_accuracy: 0.7312\n",
      "Epoch 2985/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0664 - accuracy: 0.7674 - val_loss: 0.0758 - val_accuracy: 0.7357\n",
      "Epoch 2986/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0666 - accuracy: 0.7667 - val_loss: 0.0769 - val_accuracy: 0.7337\n",
      "Epoch 2987/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0666 - accuracy: 0.7668 - val_loss: 0.0763 - val_accuracy: 0.7330\n",
      "Epoch 2988/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0667 - accuracy: 0.7669 - val_loss: 0.0772 - val_accuracy: 0.7312\n",
      "Epoch 2989/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0665 - accuracy: 0.7675 - val_loss: 0.0765 - val_accuracy: 0.7324\n",
      "Epoch 2990/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0665 - accuracy: 0.7676 - val_loss: 0.0764 - val_accuracy: 0.7336\n",
      "Epoch 2991/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0666 - accuracy: 0.7664 - val_loss: 0.0762 - val_accuracy: 0.7340\n",
      "Epoch 2992/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0665 - accuracy: 0.7669 - val_loss: 0.0777 - val_accuracy: 0.7278\n",
      "Epoch 2993/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0665 - accuracy: 0.7670 - val_loss: 0.0763 - val_accuracy: 0.7321\n",
      "Epoch 2994/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0666 - accuracy: 0.7665 - val_loss: 0.0771 - val_accuracy: 0.7322\n",
      "Epoch 2995/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0664 - accuracy: 0.7680 - val_loss: 0.0765 - val_accuracy: 0.7307\n",
      "Epoch 2996/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0666 - accuracy: 0.7670 - val_loss: 0.0761 - val_accuracy: 0.7335\n",
      "Epoch 2997/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0665 - accuracy: 0.7668 - val_loss: 0.0763 - val_accuracy: 0.7320\n",
      "Epoch 2998/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0668 - accuracy: 0.7662 - val_loss: 0.0766 - val_accuracy: 0.7323\n",
      "Epoch 2999/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0666 - accuracy: 0.7666 - val_loss: 0.0773 - val_accuracy: 0.7308\n",
      "Epoch 3000/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0665 - accuracy: 0.7671 - val_loss: 0.0770 - val_accuracy: 0.7324\n",
      "Epoch 3001/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0665 - accuracy: 0.7669 - val_loss: 0.0766 - val_accuracy: 0.7328\n",
      "Epoch 3002/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0665 - accuracy: 0.7671 - val_loss: 0.0766 - val_accuracy: 0.7334\n",
      "Epoch 3003/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0665 - accuracy: 0.7672 - val_loss: 0.0769 - val_accuracy: 0.7326\n",
      "Epoch 3004/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0665 - accuracy: 0.7670 - val_loss: 0.0766 - val_accuracy: 0.7333\n",
      "Epoch 3005/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0667 - accuracy: 0.7667 - val_loss: 0.0765 - val_accuracy: 0.7337\n",
      "Epoch 3006/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0666 - accuracy: 0.7668 - val_loss: 0.0769 - val_accuracy: 0.7306\n",
      "Epoch 3007/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0668 - accuracy: 0.7671 - val_loss: 0.0762 - val_accuracy: 0.7328\n",
      "Epoch 3008/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0668 - accuracy: 0.7660 - val_loss: 0.0767 - val_accuracy: 0.7303\n",
      "Epoch 3009/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0668 - accuracy: 0.7662 - val_loss: 0.0763 - val_accuracy: 0.7330\n",
      "Epoch 3010/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0670 - accuracy: 0.7659 - val_loss: 0.0765 - val_accuracy: 0.7355\n",
      "Epoch 3011/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0666 - accuracy: 0.7666 - val_loss: 0.0761 - val_accuracy: 0.7343\n",
      "Epoch 3012/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0665 - accuracy: 0.7673 - val_loss: 0.0761 - val_accuracy: 0.7348\n",
      "Epoch 3013/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0665 - accuracy: 0.7666 - val_loss: 0.0774 - val_accuracy: 0.7287\n",
      "Epoch 3014/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0666 - accuracy: 0.7675 - val_loss: 0.0767 - val_accuracy: 0.7331\n",
      "Epoch 3015/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0666 - accuracy: 0.7665 - val_loss: 0.0757 - val_accuracy: 0.7341\n",
      "Epoch 3016/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0666 - accuracy: 0.7670 - val_loss: 0.0767 - val_accuracy: 0.7319\n",
      "Epoch 3017/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0668 - accuracy: 0.7659 - val_loss: 0.0757 - val_accuracy: 0.7340\n",
      "Epoch 3018/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0665 - accuracy: 0.7671 - val_loss: 0.0760 - val_accuracy: 0.7336\n",
      "Epoch 3019/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0666 - accuracy: 0.7669 - val_loss: 0.0765 - val_accuracy: 0.7324\n",
      "Epoch 3020/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0666 - accuracy: 0.7669 - val_loss: 0.0763 - val_accuracy: 0.7342\n",
      "Epoch 3021/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0667 - accuracy: 0.7667 - val_loss: 0.0763 - val_accuracy: 0.7324\n",
      "Epoch 3022/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0669 - accuracy: 0.7658 - val_loss: 0.0760 - val_accuracy: 0.7330\n",
      "Epoch 3023/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0666 - accuracy: 0.7666 - val_loss: 0.0762 - val_accuracy: 0.7326\n",
      "Epoch 3024/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0667 - accuracy: 0.7665 - val_loss: 0.0764 - val_accuracy: 0.7319\n",
      "Epoch 3025/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0667 - accuracy: 0.7668 - val_loss: 0.0759 - val_accuracy: 0.7346\n",
      "Epoch 3026/5000\n",
      "11786/11786 [==============================] - 8s 642us/step - loss: 0.0665 - accuracy: 0.7665 - val_loss: 0.0761 - val_accuracy: 0.7347\n",
      "Epoch 3027/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0666 - accuracy: 0.7666 - val_loss: 0.0767 - val_accuracy: 0.7333\n",
      "Epoch 3028/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0666 - accuracy: 0.7672 - val_loss: 0.0758 - val_accuracy: 0.7339\n",
      "Epoch 3029/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0666 - accuracy: 0.7666 - val_loss: 0.0771 - val_accuracy: 0.7299\n",
      "Epoch 3030/5000\n",
      "11786/11786 [==============================] - 8s 643us/step - loss: 0.0667 - accuracy: 0.7663 - val_loss: 0.0770 - val_accuracy: 0.7329\n",
      "Epoch 3031/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0665 - accuracy: 0.7670 - val_loss: 0.0762 - val_accuracy: 0.7331\n",
      "Epoch 3032/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0666 - accuracy: 0.7674 - val_loss: 0.0767 - val_accuracy: 0.7316\n",
      "Epoch 3033/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0668 - accuracy: 0.7666 - val_loss: 0.0761 - val_accuracy: 0.7334\n",
      "Epoch 3034/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0666 - accuracy: 0.7667 - val_loss: 0.0767 - val_accuracy: 0.7328\n",
      "Epoch 3035/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0667 - accuracy: 0.7663 - val_loss: 0.0767 - val_accuracy: 0.7322\n",
      "Epoch 3036/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0666 - accuracy: 0.7669 - val_loss: 0.0774 - val_accuracy: 0.7299\n",
      "Epoch 3037/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0667 - accuracy: 0.7671 - val_loss: 0.0767 - val_accuracy: 0.7349\n",
      "Epoch 3038/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0664 - accuracy: 0.7677 - val_loss: 0.0769 - val_accuracy: 0.7308\n",
      "Epoch 3039/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0666 - accuracy: 0.7673 - val_loss: 0.0765 - val_accuracy: 0.7336\n",
      "Epoch 3040/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0667 - accuracy: 0.7667 - val_loss: 0.0771 - val_accuracy: 0.7326\n",
      "Epoch 3041/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0665 - accuracy: 0.7674 - val_loss: 0.0766 - val_accuracy: 0.7321\n",
      "Epoch 3042/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0666 - accuracy: 0.7668 - val_loss: 0.0777 - val_accuracy: 0.7292\n",
      "Epoch 3043/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0667 - accuracy: 0.7664 - val_loss: 0.0767 - val_accuracy: 0.7343\n",
      "Epoch 3044/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0665 - accuracy: 0.7672 - val_loss: 0.0765 - val_accuracy: 0.7321\n",
      "Epoch 3045/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0666 - accuracy: 0.7667 - val_loss: 0.0762 - val_accuracy: 0.7318\n",
      "Epoch 3046/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0666 - accuracy: 0.7668 - val_loss: 0.0767 - val_accuracy: 0.7308\n",
      "Epoch 3047/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0664 - accuracy: 0.7675 - val_loss: 0.0763 - val_accuracy: 0.7320\n",
      "Epoch 3048/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0667 - accuracy: 0.7669 - val_loss: 0.0767 - val_accuracy: 0.7319\n",
      "Epoch 3049/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0667 - accuracy: 0.7665 - val_loss: 0.0766 - val_accuracy: 0.7319\n",
      "Epoch 3050/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0665 - accuracy: 0.7677 - val_loss: 0.0763 - val_accuracy: 0.7340\n",
      "Epoch 3051/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0667 - accuracy: 0.7665 - val_loss: 0.0762 - val_accuracy: 0.7348\n",
      "Epoch 3052/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0667 - accuracy: 0.7670 - val_loss: 0.0766 - val_accuracy: 0.7336\n",
      "Epoch 3053/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0667 - accuracy: 0.7671 - val_loss: 0.0760 - val_accuracy: 0.7341\n",
      "Epoch 3054/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0666 - accuracy: 0.7670 - val_loss: 0.0759 - val_accuracy: 0.7332\n",
      "Epoch 3055/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0667 - accuracy: 0.7666 - val_loss: 0.0768 - val_accuracy: 0.7338\n",
      "Epoch 3056/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0666 - accuracy: 0.7671 - val_loss: 0.0763 - val_accuracy: 0.7330\n",
      "Epoch 3057/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0665 - accuracy: 0.7676 - val_loss: 0.0754 - val_accuracy: 0.7361\n",
      "Epoch 3058/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0666 - accuracy: 0.7672 - val_loss: 0.0761 - val_accuracy: 0.7353\n",
      "Epoch 3059/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0666 - accuracy: 0.7671 - val_loss: 0.0759 - val_accuracy: 0.7345\n",
      "Epoch 3060/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0664 - accuracy: 0.7675 - val_loss: 0.0766 - val_accuracy: 0.7337\n",
      "Epoch 3061/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0665 - accuracy: 0.7674 - val_loss: 0.0766 - val_accuracy: 0.7348\n",
      "Epoch 3062/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0666 - accuracy: 0.7672 - val_loss: 0.0765 - val_accuracy: 0.7337\n",
      "Epoch 3063/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0666 - accuracy: 0.7671 - val_loss: 0.0764 - val_accuracy: 0.7337\n",
      "Epoch 3064/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0665 - accuracy: 0.7673 - val_loss: 0.0764 - val_accuracy: 0.7342\n",
      "Epoch 3065/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0667 - accuracy: 0.7667 - val_loss: 0.0762 - val_accuracy: 0.7326\n",
      "Epoch 3066/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0666 - accuracy: 0.7670 - val_loss: 0.0767 - val_accuracy: 0.7316\n",
      "Epoch 3067/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0667 - accuracy: 0.7663 - val_loss: 0.0761 - val_accuracy: 0.7350\n",
      "Epoch 3068/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0667 - accuracy: 0.7663 - val_loss: 0.0765 - val_accuracy: 0.7331\n",
      "Epoch 3069/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0667 - accuracy: 0.7668 - val_loss: 0.0763 - val_accuracy: 0.7336\n",
      "Epoch 3070/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0666 - accuracy: 0.7674 - val_loss: 0.0769 - val_accuracy: 0.7307\n",
      "Epoch 3071/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0665 - accuracy: 0.7672 - val_loss: 0.0774 - val_accuracy: 0.7329\n",
      "Epoch 3072/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0666 - accuracy: 0.7670 - val_loss: 0.0762 - val_accuracy: 0.7339\n",
      "Epoch 3073/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0669 - accuracy: 0.7663 - val_loss: 0.0764 - val_accuracy: 0.7324\n",
      "Epoch 3074/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0665 - accuracy: 0.7671 - val_loss: 0.0768 - val_accuracy: 0.7340\n",
      "Epoch 3075/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0667 - accuracy: 0.7671 - val_loss: 0.0770 - val_accuracy: 0.7292\n",
      "Epoch 3076/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0667 - accuracy: 0.7669 - val_loss: 0.0767 - val_accuracy: 0.7319\n",
      "Epoch 3077/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0666 - accuracy: 0.7668 - val_loss: 0.0759 - val_accuracy: 0.7349\n",
      "Epoch 3078/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0666 - accuracy: 0.7669 - val_loss: 0.0769 - val_accuracy: 0.7331\n",
      "Epoch 3079/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0667 - accuracy: 0.7665 - val_loss: 0.0755 - val_accuracy: 0.7341\n",
      "Epoch 3080/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0668 - accuracy: 0.7667 - val_loss: 0.0771 - val_accuracy: 0.7328\n",
      "Epoch 3081/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0667 - accuracy: 0.7665 - val_loss: 0.0766 - val_accuracy: 0.7317\n",
      "Epoch 3082/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0667 - accuracy: 0.7662 - val_loss: 0.0765 - val_accuracy: 0.7322\n",
      "Epoch 3083/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0666 - accuracy: 0.7670 - val_loss: 0.0771 - val_accuracy: 0.7307\n",
      "Epoch 3084/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0665 - accuracy: 0.7673 - val_loss: 0.0778 - val_accuracy: 0.7281\n",
      "Epoch 3085/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0668 - accuracy: 0.7664 - val_loss: 0.0769 - val_accuracy: 0.7344\n",
      "Epoch 3086/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0666 - accuracy: 0.7671 - val_loss: 0.0763 - val_accuracy: 0.7353\n",
      "Epoch 3087/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0667 - accuracy: 0.7666 - val_loss: 0.0769 - val_accuracy: 0.7304\n",
      "Epoch 3088/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0667 - accuracy: 0.7667 - val_loss: 0.0764 - val_accuracy: 0.7330\n",
      "Epoch 3089/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0668 - accuracy: 0.7664 - val_loss: 0.0763 - val_accuracy: 0.7338\n",
      "Epoch 3090/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0667 - accuracy: 0.7667 - val_loss: 0.0772 - val_accuracy: 0.7294\n",
      "Epoch 3091/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0667 - accuracy: 0.7667 - val_loss: 0.0768 - val_accuracy: 0.7334\n",
      "Epoch 3092/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0666 - accuracy: 0.7668 - val_loss: 0.0777 - val_accuracy: 0.7302\n",
      "Epoch 3093/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0666 - accuracy: 0.7667 - val_loss: 0.0760 - val_accuracy: 0.7329\n",
      "Epoch 3094/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0667 - accuracy: 0.7669 - val_loss: 0.0766 - val_accuracy: 0.7341\n",
      "Epoch 3095/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0667 - accuracy: 0.7667 - val_loss: 0.0776 - val_accuracy: 0.7311\n",
      "Epoch 3096/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0666 - accuracy: 0.7665 - val_loss: 0.0764 - val_accuracy: 0.7341\n",
      "Epoch 3097/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0666 - accuracy: 0.7669 - val_loss: 0.0773 - val_accuracy: 0.7317\n",
      "Epoch 3098/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0668 - accuracy: 0.7658 - val_loss: 0.0764 - val_accuracy: 0.7327\n",
      "Epoch 3099/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0668 - accuracy: 0.7664 - val_loss: 0.0764 - val_accuracy: 0.7317\n",
      "Epoch 3100/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0667 - accuracy: 0.7663 - val_loss: 0.0765 - val_accuracy: 0.7340\n",
      "Epoch 3101/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0668 - accuracy: 0.7663 - val_loss: 0.0771 - val_accuracy: 0.7289\n",
      "Epoch 3102/5000\n",
      "11786/11786 [==============================] - 8s 644us/step - loss: 0.0670 - accuracy: 0.7653 - val_loss: 0.0763 - val_accuracy: 0.7324\n",
      "Epoch 3103/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0667 - accuracy: 0.7665 - val_loss: 0.0768 - val_accuracy: 0.7330\n",
      "Epoch 3104/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0667 - accuracy: 0.7665 - val_loss: 0.0771 - val_accuracy: 0.7295\n",
      "Epoch 3105/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0668 - accuracy: 0.7663 - val_loss: 0.0770 - val_accuracy: 0.7327\n",
      "Epoch 3106/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0668 - accuracy: 0.7665 - val_loss: 0.0769 - val_accuracy: 0.7337\n",
      "Epoch 3107/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0668 - accuracy: 0.7668 - val_loss: 0.0765 - val_accuracy: 0.7330\n",
      "Epoch 3108/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0666 - accuracy: 0.7672 - val_loss: 0.0760 - val_accuracy: 0.7334\n",
      "Epoch 3109/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0669 - accuracy: 0.7662 - val_loss: 0.0767 - val_accuracy: 0.7329\n",
      "Epoch 3110/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0668 - accuracy: 0.7664 - val_loss: 0.0760 - val_accuracy: 0.7343\n",
      "Epoch 3111/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0668 - accuracy: 0.7663 - val_loss: 0.0766 - val_accuracy: 0.7338\n",
      "Epoch 3112/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0668 - accuracy: 0.7661 - val_loss: 0.0759 - val_accuracy: 0.7341\n",
      "Epoch 3113/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0668 - accuracy: 0.7661 - val_loss: 0.0767 - val_accuracy: 0.7342\n",
      "Epoch 3114/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0667 - accuracy: 0.7667 - val_loss: 0.0767 - val_accuracy: 0.7330\n",
      "Epoch 3115/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0668 - accuracy: 0.7663 - val_loss: 0.0769 - val_accuracy: 0.7312\n",
      "Epoch 3116/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0669 - accuracy: 0.7661 - val_loss: 0.0762 - val_accuracy: 0.7348\n",
      "Epoch 3117/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0666 - accuracy: 0.7671 - val_loss: 0.0765 - val_accuracy: 0.7339\n",
      "Epoch 3118/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0667 - accuracy: 0.7665 - val_loss: 0.0766 - val_accuracy: 0.7327\n",
      "Epoch 3119/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0668 - accuracy: 0.7668 - val_loss: 0.0768 - val_accuracy: 0.7318\n",
      "Epoch 3120/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0667 - accuracy: 0.7664 - val_loss: 0.0769 - val_accuracy: 0.7334\n",
      "Epoch 3121/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0667 - accuracy: 0.7668 - val_loss: 0.0762 - val_accuracy: 0.7346\n",
      "Epoch 3122/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0667 - accuracy: 0.7664 - val_loss: 0.0775 - val_accuracy: 0.7312\n",
      "Epoch 3123/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0668 - accuracy: 0.7664 - val_loss: 0.0761 - val_accuracy: 0.7343\n",
      "Epoch 3124/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0669 - accuracy: 0.7658 - val_loss: 0.0768 - val_accuracy: 0.7336\n",
      "Epoch 3125/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0670 - accuracy: 0.7659 - val_loss: 0.0769 - val_accuracy: 0.7319\n",
      "Epoch 3126/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0669 - accuracy: 0.7665 - val_loss: 0.0766 - val_accuracy: 0.7324\n",
      "Epoch 3127/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0670 - accuracy: 0.7655 - val_loss: 0.0763 - val_accuracy: 0.7327\n",
      "Epoch 3128/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0670 - accuracy: 0.7657 - val_loss: 0.0768 - val_accuracy: 0.7317\n",
      "Epoch 3129/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0669 - accuracy: 0.7658 - val_loss: 0.0767 - val_accuracy: 0.7336\n",
      "Epoch 3130/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0669 - accuracy: 0.7660 - val_loss: 0.0770 - val_accuracy: 0.7317\n",
      "Epoch 3131/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0669 - accuracy: 0.7661 - val_loss: 0.0780 - val_accuracy: 0.7292\n",
      "Epoch 3132/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0669 - accuracy: 0.7659 - val_loss: 0.0769 - val_accuracy: 0.7327\n",
      "Epoch 3133/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0669 - accuracy: 0.7666 - val_loss: 0.0774 - val_accuracy: 0.7308\n",
      "Epoch 3134/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0670 - accuracy: 0.7657 - val_loss: 0.0770 - val_accuracy: 0.7316\n",
      "Epoch 3135/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0670 - accuracy: 0.7657 - val_loss: 0.0764 - val_accuracy: 0.7319\n",
      "Epoch 3136/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0666 - accuracy: 0.7667 - val_loss: 0.0767 - val_accuracy: 0.7314\n",
      "Epoch 3137/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0670 - accuracy: 0.7661 - val_loss: 0.0766 - val_accuracy: 0.7322\n",
      "Epoch 3138/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0669 - accuracy: 0.7656 - val_loss: 0.0774 - val_accuracy: 0.7336\n",
      "Epoch 3139/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0669 - accuracy: 0.7661 - val_loss: 0.0760 - val_accuracy: 0.7335\n",
      "Epoch 3140/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0668 - accuracy: 0.7661 - val_loss: 0.0772 - val_accuracy: 0.7332\n",
      "Epoch 3141/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0668 - accuracy: 0.7661 - val_loss: 0.0774 - val_accuracy: 0.7279\n",
      "Epoch 3142/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0668 - accuracy: 0.7659 - val_loss: 0.0764 - val_accuracy: 0.7320\n",
      "Epoch 3143/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0668 - accuracy: 0.7662 - val_loss: 0.0769 - val_accuracy: 0.7308\n",
      "Epoch 3144/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0667 - accuracy: 0.7668 - val_loss: 0.0766 - val_accuracy: 0.7329\n",
      "Epoch 3145/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0667 - accuracy: 0.7667 - val_loss: 0.0769 - val_accuracy: 0.7312\n",
      "Epoch 3146/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0668 - accuracy: 0.7662 - val_loss: 0.0763 - val_accuracy: 0.7326\n",
      "Epoch 3147/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0668 - accuracy: 0.7664 - val_loss: 0.0765 - val_accuracy: 0.7325\n",
      "Epoch 3148/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0667 - accuracy: 0.7666 - val_loss: 0.0759 - val_accuracy: 0.7359\n",
      "Epoch 3149/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0668 - accuracy: 0.7665 - val_loss: 0.0767 - val_accuracy: 0.7335\n",
      "Epoch 3150/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0667 - accuracy: 0.7668 - val_loss: 0.0766 - val_accuracy: 0.7312\n",
      "Epoch 3151/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0670 - accuracy: 0.7649 - val_loss: 0.0761 - val_accuracy: 0.7333\n",
      "Epoch 3152/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0670 - accuracy: 0.7655 - val_loss: 0.0767 - val_accuracy: 0.7313\n",
      "Epoch 3153/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0670 - accuracy: 0.7661 - val_loss: 0.0764 - val_accuracy: 0.7343\n",
      "Epoch 3154/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0670 - accuracy: 0.7657 - val_loss: 0.0767 - val_accuracy: 0.7324\n",
      "Epoch 3155/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0670 - accuracy: 0.7656 - val_loss: 0.0764 - val_accuracy: 0.7348\n",
      "Epoch 3156/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0667 - accuracy: 0.7666 - val_loss: 0.0772 - val_accuracy: 0.7319\n",
      "Epoch 3157/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0669 - accuracy: 0.7661 - val_loss: 0.0772 - val_accuracy: 0.7307\n",
      "Epoch 3158/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0668 - accuracy: 0.7665 - val_loss: 0.0771 - val_accuracy: 0.7325\n",
      "Epoch 3159/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0669 - accuracy: 0.7660 - val_loss: 0.0772 - val_accuracy: 0.7313\n",
      "Epoch 3160/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0667 - accuracy: 0.7669 - val_loss: 0.0765 - val_accuracy: 0.7327\n",
      "Epoch 3161/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0669 - accuracy: 0.7656 - val_loss: 0.0762 - val_accuracy: 0.7335\n",
      "Epoch 3162/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0670 - accuracy: 0.7663 - val_loss: 0.0769 - val_accuracy: 0.7313\n",
      "Epoch 3163/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0669 - accuracy: 0.7660 - val_loss: 0.0777 - val_accuracy: 0.7295\n",
      "Epoch 3164/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0671 - accuracy: 0.7650 - val_loss: 0.0767 - val_accuracy: 0.7306\n",
      "Epoch 3165/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0669 - accuracy: 0.7664 - val_loss: 0.0764 - val_accuracy: 0.7306\n",
      "Epoch 3166/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0670 - accuracy: 0.7654 - val_loss: 0.0765 - val_accuracy: 0.7337\n",
      "Epoch 3167/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0669 - accuracy: 0.7660 - val_loss: 0.0768 - val_accuracy: 0.7322\n",
      "Epoch 3168/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0669 - accuracy: 0.7657 - val_loss: 0.0760 - val_accuracy: 0.7331\n",
      "Epoch 3169/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0671 - accuracy: 0.7654 - val_loss: 0.0769 - val_accuracy: 0.7311\n",
      "Epoch 3170/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0670 - accuracy: 0.7662 - val_loss: 0.0772 - val_accuracy: 0.7324\n",
      "Epoch 3171/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0670 - accuracy: 0.7660 - val_loss: 0.0770 - val_accuracy: 0.7323\n",
      "Epoch 3172/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0670 - accuracy: 0.7655 - val_loss: 0.0765 - val_accuracy: 0.7330\n",
      "Epoch 3173/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0668 - accuracy: 0.7659 - val_loss: 0.0785 - val_accuracy: 0.7302\n",
      "Epoch 3174/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0670 - accuracy: 0.7656 - val_loss: 0.0769 - val_accuracy: 0.7327\n",
      "Epoch 3175/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0670 - accuracy: 0.7658 - val_loss: 0.0769 - val_accuracy: 0.7329\n",
      "Epoch 3176/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0670 - accuracy: 0.7661 - val_loss: 0.0763 - val_accuracy: 0.7335\n",
      "Epoch 3177/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0669 - accuracy: 0.7659 - val_loss: 0.0764 - val_accuracy: 0.7330\n",
      "Epoch 3178/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0667 - accuracy: 0.7667 - val_loss: 0.0765 - val_accuracy: 0.7336\n",
      "Epoch 3179/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0668 - accuracy: 0.7665 - val_loss: 0.0768 - val_accuracy: 0.7326\n",
      "Epoch 3180/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0668 - accuracy: 0.7671 - val_loss: 0.0772 - val_accuracy: 0.7299\n",
      "Epoch 3181/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0668 - accuracy: 0.7666 - val_loss: 0.0774 - val_accuracy: 0.7307\n",
      "Epoch 3182/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0668 - accuracy: 0.7665 - val_loss: 0.0773 - val_accuracy: 0.7326\n",
      "Epoch 3183/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0669 - accuracy: 0.7661 - val_loss: 0.0772 - val_accuracy: 0.7319\n",
      "Epoch 3184/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0669 - accuracy: 0.7659 - val_loss: 0.0762 - val_accuracy: 0.7330\n",
      "Epoch 3185/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0667 - accuracy: 0.7665 - val_loss: 0.0770 - val_accuracy: 0.7330\n",
      "Epoch 3186/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0670 - accuracy: 0.7653 - val_loss: 0.0774 - val_accuracy: 0.7297\n",
      "Epoch 3187/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0669 - accuracy: 0.7660 - val_loss: 0.0769 - val_accuracy: 0.7320\n",
      "Epoch 3188/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0670 - accuracy: 0.7661 - val_loss: 0.0771 - val_accuracy: 0.7296\n",
      "Epoch 3189/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0668 - accuracy: 0.7666 - val_loss: 0.0765 - val_accuracy: 0.7342\n",
      "Epoch 3190/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0671 - accuracy: 0.7660 - val_loss: 0.0767 - val_accuracy: 0.7305\n",
      "Epoch 3191/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0671 - accuracy: 0.7652 - val_loss: 0.0767 - val_accuracy: 0.7334\n",
      "Epoch 3192/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0671 - accuracy: 0.7651 - val_loss: 0.0772 - val_accuracy: 0.7311\n",
      "Epoch 3193/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0669 - accuracy: 0.7666 - val_loss: 0.0762 - val_accuracy: 0.7350\n",
      "Epoch 3194/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0668 - accuracy: 0.7668 - val_loss: 0.0760 - val_accuracy: 0.7341\n",
      "Epoch 3195/5000\n",
      "11786/11786 [==============================] - 8s 647us/step - loss: 0.0668 - accuracy: 0.7662 - val_loss: 0.0764 - val_accuracy: 0.7326\n",
      "Epoch 3196/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0671 - accuracy: 0.7650 - val_loss: 0.0770 - val_accuracy: 0.7323\n",
      "Epoch 3197/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0669 - accuracy: 0.7665 - val_loss: 0.0773 - val_accuracy: 0.7308\n",
      "Epoch 3198/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0669 - accuracy: 0.7667 - val_loss: 0.0769 - val_accuracy: 0.7335\n",
      "Epoch 3199/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0671 - accuracy: 0.7653 - val_loss: 0.0768 - val_accuracy: 0.7333\n",
      "Epoch 3200/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0671 - accuracy: 0.7658 - val_loss: 0.0777 - val_accuracy: 0.7304\n",
      "Epoch 3201/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0670 - accuracy: 0.7659 - val_loss: 0.0761 - val_accuracy: 0.7331\n",
      "Epoch 3202/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0670 - accuracy: 0.7661 - val_loss: 0.0766 - val_accuracy: 0.7316\n",
      "Epoch 3203/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0669 - accuracy: 0.7656 - val_loss: 0.0764 - val_accuracy: 0.7338\n",
      "Epoch 3204/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0670 - accuracy: 0.7657 - val_loss: 0.0779 - val_accuracy: 0.7280\n",
      "Epoch 3205/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0669 - accuracy: 0.7663 - val_loss: 0.0769 - val_accuracy: 0.7308\n",
      "Epoch 3206/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0669 - accuracy: 0.7667 - val_loss: 0.0765 - val_accuracy: 0.7325\n",
      "Epoch 3207/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0669 - accuracy: 0.7658 - val_loss: 0.0763 - val_accuracy: 0.7323\n",
      "Epoch 3208/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0669 - accuracy: 0.7663 - val_loss: 0.0767 - val_accuracy: 0.7330\n",
      "Epoch 3209/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0671 - accuracy: 0.7658 - val_loss: 0.0765 - val_accuracy: 0.7325\n",
      "Epoch 3210/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0671 - accuracy: 0.7658 - val_loss: 0.0766 - val_accuracy: 0.7315\n",
      "Epoch 3211/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0669 - accuracy: 0.7661 - val_loss: 0.0773 - val_accuracy: 0.7306\n",
      "Epoch 3212/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0672 - accuracy: 0.7655 - val_loss: 0.0769 - val_accuracy: 0.7296\n",
      "Epoch 3213/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0670 - accuracy: 0.7657 - val_loss: 0.0772 - val_accuracy: 0.7324\n",
      "Epoch 3214/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0669 - accuracy: 0.7662 - val_loss: 0.0769 - val_accuracy: 0.7316\n",
      "Epoch 3215/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0670 - accuracy: 0.7661 - val_loss: 0.0767 - val_accuracy: 0.7304\n",
      "Epoch 3216/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0670 - accuracy: 0.7657 - val_loss: 0.0769 - val_accuracy: 0.7328\n",
      "Epoch 3217/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0669 - accuracy: 0.7658 - val_loss: 0.0775 - val_accuracy: 0.7305\n",
      "Epoch 3218/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0669 - accuracy: 0.7661 - val_loss: 0.0769 - val_accuracy: 0.7327\n",
      "Epoch 3219/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0671 - accuracy: 0.7658 - val_loss: 0.0767 - val_accuracy: 0.7339\n",
      "Epoch 3220/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0670 - accuracy: 0.7660 - val_loss: 0.0778 - val_accuracy: 0.7301\n",
      "Epoch 3221/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0671 - accuracy: 0.7655 - val_loss: 0.0780 - val_accuracy: 0.7296\n",
      "Epoch 3222/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0670 - accuracy: 0.7661 - val_loss: 0.0768 - val_accuracy: 0.7322\n",
      "Epoch 3223/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0670 - accuracy: 0.7657 - val_loss: 0.0774 - val_accuracy: 0.7304\n",
      "Epoch 3224/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0671 - accuracy: 0.7658 - val_loss: 0.0763 - val_accuracy: 0.7329\n",
      "Epoch 3225/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0669 - accuracy: 0.7660 - val_loss: 0.0768 - val_accuracy: 0.7338\n",
      "Epoch 3226/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0671 - accuracy: 0.7654 - val_loss: 0.0761 - val_accuracy: 0.7338\n",
      "Epoch 3227/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0669 - accuracy: 0.7665 - val_loss: 0.0770 - val_accuracy: 0.7321\n",
      "Epoch 3228/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0669 - accuracy: 0.7659 - val_loss: 0.0767 - val_accuracy: 0.7326\n",
      "Epoch 3229/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0669 - accuracy: 0.7658 - val_loss: 0.0779 - val_accuracy: 0.7301\n",
      "Epoch 3230/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0670 - accuracy: 0.7658 - val_loss: 0.0772 - val_accuracy: 0.7322\n",
      "Epoch 3231/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0670 - accuracy: 0.7660 - val_loss: 0.0766 - val_accuracy: 0.7334\n",
      "Epoch 3232/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0669 - accuracy: 0.7665 - val_loss: 0.0766 - val_accuracy: 0.7329\n",
      "Epoch 3233/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0670 - accuracy: 0.7657 - val_loss: 0.0768 - val_accuracy: 0.7324\n",
      "Epoch 3234/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0670 - accuracy: 0.7658 - val_loss: 0.0771 - val_accuracy: 0.7321\n",
      "Epoch 3235/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0670 - accuracy: 0.7662 - val_loss: 0.0771 - val_accuracy: 0.7309\n",
      "Epoch 3236/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0670 - accuracy: 0.7662 - val_loss: 0.0768 - val_accuracy: 0.7315\n",
      "Epoch 3237/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0670 - accuracy: 0.7652 - val_loss: 0.0777 - val_accuracy: 0.7276\n",
      "Epoch 3238/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0671 - accuracy: 0.7655 - val_loss: 0.0772 - val_accuracy: 0.7317\n",
      "Epoch 3239/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0671 - accuracy: 0.7655 - val_loss: 0.0767 - val_accuracy: 0.7324\n",
      "Epoch 3240/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0670 - accuracy: 0.7655 - val_loss: 0.0769 - val_accuracy: 0.7314\n",
      "Epoch 3241/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0671 - accuracy: 0.7654 - val_loss: 0.0770 - val_accuracy: 0.7312\n",
      "Epoch 3242/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0671 - accuracy: 0.7660 - val_loss: 0.0780 - val_accuracy: 0.7288\n",
      "Epoch 3243/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0671 - accuracy: 0.7651 - val_loss: 0.0769 - val_accuracy: 0.7319\n",
      "Epoch 3244/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0671 - accuracy: 0.7656 - val_loss: 0.0769 - val_accuracy: 0.7324\n",
      "Epoch 3245/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0673 - accuracy: 0.7645 - val_loss: 0.0770 - val_accuracy: 0.7326\n",
      "Epoch 3246/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0671 - accuracy: 0.7653 - val_loss: 0.0778 - val_accuracy: 0.7277\n",
      "Epoch 3247/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0671 - accuracy: 0.7652 - val_loss: 0.0769 - val_accuracy: 0.7332\n",
      "Epoch 3248/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0672 - accuracy: 0.7650 - val_loss: 0.0768 - val_accuracy: 0.7311\n",
      "Epoch 3249/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0672 - accuracy: 0.7649 - val_loss: 0.0783 - val_accuracy: 0.7304\n",
      "Epoch 3250/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0670 - accuracy: 0.7657 - val_loss: 0.0765 - val_accuracy: 0.7314\n",
      "Epoch 3251/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0672 - accuracy: 0.7648 - val_loss: 0.0772 - val_accuracy: 0.7316\n",
      "Epoch 3252/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0672 - accuracy: 0.7642 - val_loss: 0.0765 - val_accuracy: 0.7327\n",
      "Epoch 3253/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0673 - accuracy: 0.7648 - val_loss: 0.0770 - val_accuracy: 0.7320\n",
      "Epoch 3254/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0673 - accuracy: 0.7647 - val_loss: 0.0772 - val_accuracy: 0.7308\n",
      "Epoch 3255/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0672 - accuracy: 0.7653 - val_loss: 0.0768 - val_accuracy: 0.7307\n",
      "Epoch 3256/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0675 - accuracy: 0.7647 - val_loss: 0.0788 - val_accuracy: 0.7279\n",
      "Epoch 3257/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0674 - accuracy: 0.7643 - val_loss: 0.0765 - val_accuracy: 0.7329\n",
      "Epoch 3258/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0674 - accuracy: 0.7643 - val_loss: 0.0771 - val_accuracy: 0.7318\n",
      "Epoch 3259/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0673 - accuracy: 0.7642 - val_loss: 0.0773 - val_accuracy: 0.7319\n",
      "Epoch 3260/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0672 - accuracy: 0.7653 - val_loss: 0.0769 - val_accuracy: 0.7317\n",
      "Epoch 3261/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0673 - accuracy: 0.7647 - val_loss: 0.0776 - val_accuracy: 0.7310\n",
      "Epoch 3262/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0674 - accuracy: 0.7650 - val_loss: 0.0763 - val_accuracy: 0.7333\n",
      "Epoch 3263/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0674 - accuracy: 0.7652 - val_loss: 0.0769 - val_accuracy: 0.7320\n",
      "Epoch 3264/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0673 - accuracy: 0.7648 - val_loss: 0.0769 - val_accuracy: 0.7325\n",
      "Epoch 3265/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0671 - accuracy: 0.7657 - val_loss: 0.0770 - val_accuracy: 0.7313\n",
      "Epoch 3266/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0671 - accuracy: 0.7657 - val_loss: 0.0763 - val_accuracy: 0.7318\n",
      "Epoch 3267/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0672 - accuracy: 0.7648 - val_loss: 0.0771 - val_accuracy: 0.7309\n",
      "Epoch 3268/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0673 - accuracy: 0.7650 - val_loss: 0.0770 - val_accuracy: 0.7330\n",
      "Epoch 3269/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0671 - accuracy: 0.7656 - val_loss: 0.0768 - val_accuracy: 0.7314\n",
      "Epoch 3270/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0671 - accuracy: 0.7653 - val_loss: 0.0771 - val_accuracy: 0.7317\n",
      "Epoch 3271/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0671 - accuracy: 0.7657 - val_loss: 0.0767 - val_accuracy: 0.7338\n",
      "Epoch 3272/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0672 - accuracy: 0.7649 - val_loss: 0.0764 - val_accuracy: 0.7320\n",
      "Epoch 3273/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0671 - accuracy: 0.7652 - val_loss: 0.0767 - val_accuracy: 0.7334\n",
      "Epoch 3274/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0671 - accuracy: 0.7645 - val_loss: 0.0764 - val_accuracy: 0.7330\n",
      "Epoch 3275/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0672 - accuracy: 0.7647 - val_loss: 0.0765 - val_accuracy: 0.7331\n",
      "Epoch 3276/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0673 - accuracy: 0.7650 - val_loss: 0.0769 - val_accuracy: 0.7318\n",
      "Epoch 3277/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0672 - accuracy: 0.7650 - val_loss: 0.0767 - val_accuracy: 0.7322\n",
      "Epoch 3278/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0671 - accuracy: 0.7654 - val_loss: 0.0764 - val_accuracy: 0.7318\n",
      "Epoch 3279/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0673 - accuracy: 0.7649 - val_loss: 0.0764 - val_accuracy: 0.7338\n",
      "Epoch 3280/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0672 - accuracy: 0.7654 - val_loss: 0.0766 - val_accuracy: 0.7333\n",
      "Epoch 3281/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0672 - accuracy: 0.7655 - val_loss: 0.0776 - val_accuracy: 0.7278\n",
      "Epoch 3282/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0672 - accuracy: 0.7648 - val_loss: 0.0768 - val_accuracy: 0.7315\n",
      "Epoch 3283/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0673 - accuracy: 0.7648 - val_loss: 0.0765 - val_accuracy: 0.7343\n",
      "Epoch 3284/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0670 - accuracy: 0.7654 - val_loss: 0.0766 - val_accuracy: 0.7322\n",
      "Epoch 3285/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0671 - accuracy: 0.7655 - val_loss: 0.0763 - val_accuracy: 0.7322\n",
      "Epoch 3286/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0671 - accuracy: 0.7655 - val_loss: 0.0769 - val_accuracy: 0.7336\n",
      "Epoch 3287/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0673 - accuracy: 0.7650 - val_loss: 0.0770 - val_accuracy: 0.7312\n",
      "Epoch 3288/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0673 - accuracy: 0.7647 - val_loss: 0.0776 - val_accuracy: 0.7284\n",
      "Epoch 3289/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0673 - accuracy: 0.7647 - val_loss: 0.0769 - val_accuracy: 0.7302\n",
      "Epoch 3290/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0672 - accuracy: 0.7654 - val_loss: 0.0769 - val_accuracy: 0.7324\n",
      "Epoch 3291/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0673 - accuracy: 0.7653 - val_loss: 0.0763 - val_accuracy: 0.7328\n",
      "Epoch 3292/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0673 - accuracy: 0.7649 - val_loss: 0.0763 - val_accuracy: 0.7325\n",
      "Epoch 3293/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0674 - accuracy: 0.7644 - val_loss: 0.0775 - val_accuracy: 0.7322\n",
      "Epoch 3294/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0672 - accuracy: 0.7652 - val_loss: 0.0779 - val_accuracy: 0.7290\n",
      "Epoch 3295/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0671 - accuracy: 0.7660 - val_loss: 0.0771 - val_accuracy: 0.7306\n",
      "Epoch 3296/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0672 - accuracy: 0.7657 - val_loss: 0.0769 - val_accuracy: 0.7311\n",
      "Epoch 3297/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0672 - accuracy: 0.7652 - val_loss: 0.0774 - val_accuracy: 0.7309\n",
      "Epoch 3298/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0672 - accuracy: 0.7654 - val_loss: 0.0764 - val_accuracy: 0.7342\n",
      "Epoch 3299/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0675 - accuracy: 0.7642 - val_loss: 0.0764 - val_accuracy: 0.7312\n",
      "Epoch 3300/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0674 - accuracy: 0.7647 - val_loss: 0.0766 - val_accuracy: 0.7319\n",
      "Epoch 3301/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0674 - accuracy: 0.7649 - val_loss: 0.0772 - val_accuracy: 0.7305\n",
      "Epoch 3302/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0675 - accuracy: 0.7645 - val_loss: 0.0764 - val_accuracy: 0.7323\n",
      "Epoch 3303/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0674 - accuracy: 0.7647 - val_loss: 0.0771 - val_accuracy: 0.7312\n",
      "Epoch 3304/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0676 - accuracy: 0.7640 - val_loss: 0.0771 - val_accuracy: 0.7312\n",
      "Epoch 3305/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0673 - accuracy: 0.7645 - val_loss: 0.0773 - val_accuracy: 0.7290\n",
      "Epoch 3306/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0673 - accuracy: 0.7643 - val_loss: 0.0781 - val_accuracy: 0.7303\n",
      "Epoch 3307/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0675 - accuracy: 0.7646 - val_loss: 0.0770 - val_accuracy: 0.7299\n",
      "Epoch 3308/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0673 - accuracy: 0.7647 - val_loss: 0.0775 - val_accuracy: 0.7289\n",
      "Epoch 3309/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0673 - accuracy: 0.7648 - val_loss: 0.0773 - val_accuracy: 0.7310\n",
      "Epoch 3310/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0672 - accuracy: 0.7649 - val_loss: 0.0770 - val_accuracy: 0.7300\n",
      "Epoch 3311/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0674 - accuracy: 0.7644 - val_loss: 0.0775 - val_accuracy: 0.7313\n",
      "Epoch 3312/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0674 - accuracy: 0.7644 - val_loss: 0.0768 - val_accuracy: 0.7314\n",
      "Epoch 3313/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0675 - accuracy: 0.7642 - val_loss: 0.0774 - val_accuracy: 0.7338\n",
      "Epoch 3314/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0674 - accuracy: 0.7652 - val_loss: 0.0777 - val_accuracy: 0.7312\n",
      "Epoch 3315/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0674 - accuracy: 0.7651 - val_loss: 0.0771 - val_accuracy: 0.7319\n",
      "Epoch 3316/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0675 - accuracy: 0.7644 - val_loss: 0.0769 - val_accuracy: 0.7314\n",
      "Epoch 3317/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0674 - accuracy: 0.7645 - val_loss: 0.0774 - val_accuracy: 0.7324\n",
      "Epoch 3318/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0673 - accuracy: 0.7652 - val_loss: 0.0768 - val_accuracy: 0.7321\n",
      "Epoch 3319/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0676 - accuracy: 0.7642 - val_loss: 0.0768 - val_accuracy: 0.7316\n",
      "Epoch 3320/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0675 - accuracy: 0.7640 - val_loss: 0.0773 - val_accuracy: 0.7321\n",
      "Epoch 3321/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0676 - accuracy: 0.7646 - val_loss: 0.0771 - val_accuracy: 0.7316\n",
      "Epoch 3322/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0674 - accuracy: 0.7645 - val_loss: 0.0768 - val_accuracy: 0.7321\n",
      "Epoch 3323/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0673 - accuracy: 0.7650 - val_loss: 0.0776 - val_accuracy: 0.7296\n",
      "Epoch 3324/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0676 - accuracy: 0.7639 - val_loss: 0.0771 - val_accuracy: 0.7301\n",
      "Epoch 3325/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0675 - accuracy: 0.7637 - val_loss: 0.0770 - val_accuracy: 0.7308\n",
      "Epoch 3326/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0676 - accuracy: 0.7636 - val_loss: 0.0769 - val_accuracy: 0.7320\n",
      "Epoch 3327/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0674 - accuracy: 0.7644 - val_loss: 0.0769 - val_accuracy: 0.7312\n",
      "Epoch 3328/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0674 - accuracy: 0.7645 - val_loss: 0.0762 - val_accuracy: 0.7340\n",
      "Epoch 3329/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0674 - accuracy: 0.7649 - val_loss: 0.0773 - val_accuracy: 0.7320\n",
      "Epoch 3330/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0676 - accuracy: 0.7645 - val_loss: 0.0769 - val_accuracy: 0.7308\n",
      "Epoch 3331/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0676 - accuracy: 0.7638 - val_loss: 0.0772 - val_accuracy: 0.7308\n",
      "Epoch 3332/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0674 - accuracy: 0.7641 - val_loss: 0.0765 - val_accuracy: 0.7342\n",
      "Epoch 3333/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0675 - accuracy: 0.7646 - val_loss: 0.0771 - val_accuracy: 0.7339\n",
      "Epoch 3334/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0674 - accuracy: 0.7646 - val_loss: 0.0770 - val_accuracy: 0.7323\n",
      "Epoch 3335/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0676 - accuracy: 0.7637 - val_loss: 0.0772 - val_accuracy: 0.7327\n",
      "Epoch 3336/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0673 - accuracy: 0.7653 - val_loss: 0.0770 - val_accuracy: 0.7311\n",
      "Epoch 3337/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0676 - accuracy: 0.7646 - val_loss: 0.0772 - val_accuracy: 0.7282\n",
      "Epoch 3338/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0674 - accuracy: 0.7648 - val_loss: 0.0768 - val_accuracy: 0.7315\n",
      "Epoch 3339/5000\n",
      "11786/11786 [==============================] - 8s 646us/step - loss: 0.0673 - accuracy: 0.7647 - val_loss: 0.0765 - val_accuracy: 0.7317\n",
      "Epoch 3340/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0675 - accuracy: 0.7639 - val_loss: 0.0771 - val_accuracy: 0.7308\n",
      "Epoch 3341/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0675 - accuracy: 0.7638 - val_loss: 0.0765 - val_accuracy: 0.7322\n",
      "Epoch 3342/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0675 - accuracy: 0.7636 - val_loss: 0.0767 - val_accuracy: 0.7326\n",
      "Epoch 3343/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0674 - accuracy: 0.7642 - val_loss: 0.0772 - val_accuracy: 0.7308\n",
      "Epoch 3344/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0676 - accuracy: 0.7640 - val_loss: 0.0777 - val_accuracy: 0.7280\n",
      "Epoch 3345/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0677 - accuracy: 0.7638 - val_loss: 0.0773 - val_accuracy: 0.7301\n",
      "Epoch 3346/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0676 - accuracy: 0.7635 - val_loss: 0.0772 - val_accuracy: 0.7302\n",
      "Epoch 3347/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0677 - accuracy: 0.7633 - val_loss: 0.0771 - val_accuracy: 0.7306\n",
      "Epoch 3348/5000\n",
      "11786/11786 [==============================] - 8s 650us/step - loss: 0.0676 - accuracy: 0.7641 - val_loss: 0.0771 - val_accuracy: 0.7318\n",
      "Epoch 3349/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0678 - accuracy: 0.7636 - val_loss: 0.0771 - val_accuracy: 0.7318\n",
      "Epoch 3350/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0679 - accuracy: 0.7624 - val_loss: 0.0775 - val_accuracy: 0.7298\n",
      "Epoch 3351/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0677 - accuracy: 0.7632 - val_loss: 0.0785 - val_accuracy: 0.7285\n",
      "Epoch 3352/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0676 - accuracy: 0.7634 - val_loss: 0.0769 - val_accuracy: 0.7317\n",
      "Epoch 3353/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0676 - accuracy: 0.7636 - val_loss: 0.0772 - val_accuracy: 0.7316\n",
      "Epoch 3354/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0677 - accuracy: 0.7634 - val_loss: 0.0779 - val_accuracy: 0.7308\n",
      "Epoch 3355/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0677 - accuracy: 0.7629 - val_loss: 0.0766 - val_accuracy: 0.7321\n",
      "Epoch 3356/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0676 - accuracy: 0.7639 - val_loss: 0.0774 - val_accuracy: 0.7314\n",
      "Epoch 3357/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0675 - accuracy: 0.7643 - val_loss: 0.0769 - val_accuracy: 0.7305\n",
      "Epoch 3358/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0677 - accuracy: 0.7642 - val_loss: 0.0773 - val_accuracy: 0.7303\n",
      "Epoch 3359/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0676 - accuracy: 0.7645 - val_loss: 0.0770 - val_accuracy: 0.7323\n",
      "Epoch 3360/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0676 - accuracy: 0.7644 - val_loss: 0.0763 - val_accuracy: 0.7324\n",
      "Epoch 3361/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0676 - accuracy: 0.7643 - val_loss: 0.0770 - val_accuracy: 0.7319\n",
      "Epoch 3362/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0676 - accuracy: 0.7641 - val_loss: 0.0767 - val_accuracy: 0.7316\n",
      "Epoch 3363/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0676 - accuracy: 0.7636 - val_loss: 0.0772 - val_accuracy: 0.7304\n",
      "Epoch 3364/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0676 - accuracy: 0.7638 - val_loss: 0.0771 - val_accuracy: 0.7314\n",
      "Epoch 3365/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0678 - accuracy: 0.7637 - val_loss: 0.0767 - val_accuracy: 0.7323\n",
      "Epoch 3366/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0677 - accuracy: 0.7636 - val_loss: 0.0774 - val_accuracy: 0.7311\n",
      "Epoch 3367/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0676 - accuracy: 0.7637 - val_loss: 0.0778 - val_accuracy: 0.7300\n",
      "Epoch 3368/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0677 - accuracy: 0.7643 - val_loss: 0.0777 - val_accuracy: 0.7314\n",
      "Epoch 3369/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0676 - accuracy: 0.7634 - val_loss: 0.0771 - val_accuracy: 0.7295\n",
      "Epoch 3370/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0677 - accuracy: 0.7637 - val_loss: 0.0774 - val_accuracy: 0.7299\n",
      "Epoch 3371/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0677 - accuracy: 0.7637 - val_loss: 0.0777 - val_accuracy: 0.7305\n",
      "Epoch 3372/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0678 - accuracy: 0.7636 - val_loss: 0.0772 - val_accuracy: 0.7314\n",
      "Epoch 3373/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0678 - accuracy: 0.7636 - val_loss: 0.0777 - val_accuracy: 0.7296\n",
      "Epoch 3374/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0677 - accuracy: 0.7637 - val_loss: 0.0774 - val_accuracy: 0.7300\n",
      "Epoch 3375/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0679 - accuracy: 0.7631 - val_loss: 0.0768 - val_accuracy: 0.7336\n",
      "Epoch 3376/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0677 - accuracy: 0.7637 - val_loss: 0.0770 - val_accuracy: 0.7317\n",
      "Epoch 3377/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0675 - accuracy: 0.7642 - val_loss: 0.0773 - val_accuracy: 0.7305\n",
      "Epoch 3378/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0677 - accuracy: 0.7643 - val_loss: 0.0777 - val_accuracy: 0.7300\n",
      "Epoch 3379/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0678 - accuracy: 0.7633 - val_loss: 0.0770 - val_accuracy: 0.7315\n",
      "Epoch 3380/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0676 - accuracy: 0.7639 - val_loss: 0.0781 - val_accuracy: 0.7310\n",
      "Epoch 3381/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0676 - accuracy: 0.7637 - val_loss: 0.0769 - val_accuracy: 0.7325\n",
      "Epoch 3382/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0676 - accuracy: 0.7639 - val_loss: 0.0776 - val_accuracy: 0.7303\n",
      "Epoch 3383/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0679 - accuracy: 0.7628 - val_loss: 0.0769 - val_accuracy: 0.7313\n",
      "Epoch 3384/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0677 - accuracy: 0.7637 - val_loss: 0.0769 - val_accuracy: 0.7327\n",
      "Epoch 3385/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0677 - accuracy: 0.7640 - val_loss: 0.0774 - val_accuracy: 0.7294\n",
      "Epoch 3386/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0678 - accuracy: 0.7630 - val_loss: 0.0773 - val_accuracy: 0.7301\n",
      "Epoch 3387/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0677 - accuracy: 0.7638 - val_loss: 0.0774 - val_accuracy: 0.7308\n",
      "Epoch 3388/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0680 - accuracy: 0.7627 - val_loss: 0.0771 - val_accuracy: 0.7318\n",
      "Epoch 3389/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0677 - accuracy: 0.7637 - val_loss: 0.0772 - val_accuracy: 0.7324\n",
      "Epoch 3390/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0679 - accuracy: 0.7634 - val_loss: 0.0768 - val_accuracy: 0.7335\n",
      "Epoch 3391/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0676 - accuracy: 0.7640 - val_loss: 0.0771 - val_accuracy: 0.7315\n",
      "Epoch 3392/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0675 - accuracy: 0.7644 - val_loss: 0.0777 - val_accuracy: 0.7301\n",
      "Epoch 3393/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0674 - accuracy: 0.7646 - val_loss: 0.0782 - val_accuracy: 0.7285\n",
      "Epoch 3394/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0678 - accuracy: 0.7630 - val_loss: 0.0777 - val_accuracy: 0.7320\n",
      "Epoch 3395/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0679 - accuracy: 0.7634 - val_loss: 0.0781 - val_accuracy: 0.7298\n",
      "Epoch 3396/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0677 - accuracy: 0.7640 - val_loss: 0.0770 - val_accuracy: 0.7321\n",
      "Epoch 3397/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0676 - accuracy: 0.7641 - val_loss: 0.0779 - val_accuracy: 0.7317\n",
      "Epoch 3398/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0677 - accuracy: 0.7644 - val_loss: 0.0776 - val_accuracy: 0.7304\n",
      "Epoch 3399/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0678 - accuracy: 0.7632 - val_loss: 0.0768 - val_accuracy: 0.7328\n",
      "Epoch 3400/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0677 - accuracy: 0.7640 - val_loss: 0.0778 - val_accuracy: 0.7301\n",
      "Epoch 3401/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0677 - accuracy: 0.7635 - val_loss: 0.0770 - val_accuracy: 0.7324\n",
      "Epoch 3402/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0674 - accuracy: 0.7648 - val_loss: 0.0775 - val_accuracy: 0.7321\n",
      "Epoch 3403/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0677 - accuracy: 0.7640 - val_loss: 0.0770 - val_accuracy: 0.7325\n",
      "Epoch 3404/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0678 - accuracy: 0.7633 - val_loss: 0.0770 - val_accuracy: 0.7311\n",
      "Epoch 3405/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0677 - accuracy: 0.7638 - val_loss: 0.0768 - val_accuracy: 0.7325\n",
      "Epoch 3406/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0676 - accuracy: 0.7636 - val_loss: 0.0765 - val_accuracy: 0.7325\n",
      "Epoch 3407/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0677 - accuracy: 0.7638 - val_loss: 0.0763 - val_accuracy: 0.7327\n",
      "Epoch 3408/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0674 - accuracy: 0.7644 - val_loss: 0.0768 - val_accuracy: 0.7322\n",
      "Epoch 3409/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0675 - accuracy: 0.7636 - val_loss: 0.0769 - val_accuracy: 0.7313\n",
      "Epoch 3410/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0676 - accuracy: 0.7643 - val_loss: 0.0773 - val_accuracy: 0.7299\n",
      "Epoch 3411/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0675 - accuracy: 0.7646 - val_loss: 0.0772 - val_accuracy: 0.7323\n",
      "Epoch 3412/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0676 - accuracy: 0.7644 - val_loss: 0.0772 - val_accuracy: 0.7312\n",
      "Epoch 3413/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0673 - accuracy: 0.7647 - val_loss: 0.0773 - val_accuracy: 0.7317\n",
      "Epoch 3414/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0674 - accuracy: 0.7650 - val_loss: 0.0765 - val_accuracy: 0.7320\n",
      "Epoch 3415/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0676 - accuracy: 0.7641 - val_loss: 0.0774 - val_accuracy: 0.7315\n",
      "Epoch 3416/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0676 - accuracy: 0.7644 - val_loss: 0.0772 - val_accuracy: 0.7329\n",
      "Epoch 3417/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0673 - accuracy: 0.7649 - val_loss: 0.0771 - val_accuracy: 0.7306\n",
      "Epoch 3418/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0676 - accuracy: 0.7638 - val_loss: 0.0767 - val_accuracy: 0.7345\n",
      "Epoch 3419/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0674 - accuracy: 0.7644 - val_loss: 0.0777 - val_accuracy: 0.7304\n",
      "Epoch 3420/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0676 - accuracy: 0.7640 - val_loss: 0.0768 - val_accuracy: 0.7319\n",
      "Epoch 3421/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0675 - accuracy: 0.7643 - val_loss: 0.0767 - val_accuracy: 0.7328\n",
      "Epoch 3422/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0675 - accuracy: 0.7647 - val_loss: 0.0776 - val_accuracy: 0.7323\n",
      "Epoch 3423/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0676 - accuracy: 0.7636 - val_loss: 0.0777 - val_accuracy: 0.7279\n",
      "Epoch 3424/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0677 - accuracy: 0.7640 - val_loss: 0.0773 - val_accuracy: 0.7329\n",
      "Epoch 3425/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0677 - accuracy: 0.7636 - val_loss: 0.0769 - val_accuracy: 0.7305\n",
      "Epoch 3426/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0676 - accuracy: 0.7643 - val_loss: 0.0770 - val_accuracy: 0.7326\n",
      "Epoch 3427/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0677 - accuracy: 0.7634 - val_loss: 0.0765 - val_accuracy: 0.7332\n",
      "Epoch 3428/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0675 - accuracy: 0.7638 - val_loss: 0.0776 - val_accuracy: 0.7307\n",
      "Epoch 3429/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0675 - accuracy: 0.7649 - val_loss: 0.0765 - val_accuracy: 0.7318\n",
      "Epoch 3430/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0675 - accuracy: 0.7644 - val_loss: 0.0770 - val_accuracy: 0.7305\n",
      "Epoch 3431/5000\n",
      "11786/11786 [==============================] - 8s 648us/step - loss: 0.0677 - accuracy: 0.7638 - val_loss: 0.0769 - val_accuracy: 0.7325\n",
      "Epoch 3432/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0677 - accuracy: 0.7634 - val_loss: 0.0774 - val_accuracy: 0.7300\n",
      "Epoch 3433/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0678 - accuracy: 0.7634 - val_loss: 0.0774 - val_accuracy: 0.7315\n",
      "Epoch 3434/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0676 - accuracy: 0.7640 - val_loss: 0.0772 - val_accuracy: 0.7313\n",
      "Epoch 3435/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0675 - accuracy: 0.7641 - val_loss: 0.0778 - val_accuracy: 0.7300\n",
      "Epoch 3436/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0675 - accuracy: 0.7643 - val_loss: 0.0768 - val_accuracy: 0.7327\n",
      "Epoch 3437/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0676 - accuracy: 0.7643 - val_loss: 0.0771 - val_accuracy: 0.7310\n",
      "Epoch 3438/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0675 - accuracy: 0.7641 - val_loss: 0.0773 - val_accuracy: 0.7312\n",
      "Epoch 3439/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0675 - accuracy: 0.7646 - val_loss: 0.0768 - val_accuracy: 0.7325\n",
      "Epoch 3440/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0674 - accuracy: 0.7649 - val_loss: 0.0776 - val_accuracy: 0.7294\n",
      "Epoch 3441/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0677 - accuracy: 0.7636 - val_loss: 0.0775 - val_accuracy: 0.7309\n",
      "Epoch 3442/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0680 - accuracy: 0.7629 - val_loss: 0.0774 - val_accuracy: 0.7305\n",
      "Epoch 3443/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0678 - accuracy: 0.7638 - val_loss: 0.0768 - val_accuracy: 0.7335\n",
      "Epoch 3444/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0676 - accuracy: 0.7643 - val_loss: 0.0766 - val_accuracy: 0.7316\n",
      "Epoch 3445/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0677 - accuracy: 0.7639 - val_loss: 0.0773 - val_accuracy: 0.7326\n",
      "Epoch 3446/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0676 - accuracy: 0.7646 - val_loss: 0.0766 - val_accuracy: 0.7316\n",
      "Epoch 3447/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0676 - accuracy: 0.7635 - val_loss: 0.0770 - val_accuracy: 0.7322\n",
      "Epoch 3448/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0676 - accuracy: 0.7645 - val_loss: 0.0768 - val_accuracy: 0.7330\n",
      "Epoch 3449/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0676 - accuracy: 0.7645 - val_loss: 0.0773 - val_accuracy: 0.7322\n",
      "Epoch 3450/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0675 - accuracy: 0.7645 - val_loss: 0.0766 - val_accuracy: 0.7315\n",
      "Epoch 3451/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0674 - accuracy: 0.7650 - val_loss: 0.0765 - val_accuracy: 0.7336\n",
      "Epoch 3452/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0675 - accuracy: 0.7641 - val_loss: 0.0777 - val_accuracy: 0.7323\n",
      "Epoch 3453/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0678 - accuracy: 0.7642 - val_loss: 0.0773 - val_accuracy: 0.7303\n",
      "Epoch 3454/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0677 - accuracy: 0.7640 - val_loss: 0.0769 - val_accuracy: 0.7320\n",
      "Epoch 3455/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0676 - accuracy: 0.7642 - val_loss: 0.0769 - val_accuracy: 0.7313\n",
      "Epoch 3456/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0675 - accuracy: 0.7640 - val_loss: 0.0770 - val_accuracy: 0.7306\n",
      "Epoch 3457/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0674 - accuracy: 0.7643 - val_loss: 0.0769 - val_accuracy: 0.7309\n",
      "Epoch 3458/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0676 - accuracy: 0.7638 - val_loss: 0.0772 - val_accuracy: 0.7328\n",
      "Epoch 3459/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0678 - accuracy: 0.7637 - val_loss: 0.0771 - val_accuracy: 0.7312\n",
      "Epoch 3460/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0677 - accuracy: 0.7635 - val_loss: 0.0766 - val_accuracy: 0.7325\n",
      "Epoch 3461/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0675 - accuracy: 0.7645 - val_loss: 0.0773 - val_accuracy: 0.7308\n",
      "Epoch 3462/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0676 - accuracy: 0.7635 - val_loss: 0.0776 - val_accuracy: 0.7309\n",
      "Epoch 3463/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0675 - accuracy: 0.7641 - val_loss: 0.0767 - val_accuracy: 0.7307\n",
      "Epoch 3464/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0675 - accuracy: 0.7639 - val_loss: 0.0771 - val_accuracy: 0.7316\n",
      "Epoch 3465/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0677 - accuracy: 0.7631 - val_loss: 0.0770 - val_accuracy: 0.7310\n",
      "Epoch 3466/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0675 - accuracy: 0.7643 - val_loss: 0.0777 - val_accuracy: 0.7282\n",
      "Epoch 3467/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0675 - accuracy: 0.7644 - val_loss: 0.0763 - val_accuracy: 0.7324\n",
      "Epoch 3468/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0676 - accuracy: 0.7639 - val_loss: 0.0770 - val_accuracy: 0.7315\n",
      "Epoch 3469/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0674 - accuracy: 0.7644 - val_loss: 0.0769 - val_accuracy: 0.7327\n",
      "Epoch 3470/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0675 - accuracy: 0.7641 - val_loss: 0.0777 - val_accuracy: 0.7289\n",
      "Epoch 3471/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0675 - accuracy: 0.7641 - val_loss: 0.0774 - val_accuracy: 0.7308\n",
      "Epoch 3472/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0675 - accuracy: 0.7647 - val_loss: 0.0773 - val_accuracy: 0.7307\n",
      "Epoch 3473/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0676 - accuracy: 0.7642 - val_loss: 0.0769 - val_accuracy: 0.7330\n",
      "Epoch 3474/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0676 - accuracy: 0.7642 - val_loss: 0.0771 - val_accuracy: 0.7319\n",
      "Epoch 3475/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0676 - accuracy: 0.7636 - val_loss: 0.0773 - val_accuracy: 0.7303\n",
      "Epoch 3476/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0677 - accuracy: 0.7636 - val_loss: 0.0766 - val_accuracy: 0.7324\n",
      "Epoch 3477/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0675 - accuracy: 0.7646 - val_loss: 0.0773 - val_accuracy: 0.7311\n",
      "Epoch 3478/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0676 - accuracy: 0.7641 - val_loss: 0.0771 - val_accuracy: 0.7318\n",
      "Epoch 3479/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0676 - accuracy: 0.7633 - val_loss: 0.0772 - val_accuracy: 0.7294\n",
      "Epoch 3480/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0675 - accuracy: 0.7638 - val_loss: 0.0765 - val_accuracy: 0.7332\n",
      "Epoch 3481/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0675 - accuracy: 0.7642 - val_loss: 0.0767 - val_accuracy: 0.7299\n",
      "Epoch 3482/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0674 - accuracy: 0.7646 - val_loss: 0.0772 - val_accuracy: 0.7330\n",
      "Epoch 3483/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0674 - accuracy: 0.7643 - val_loss: 0.0766 - val_accuracy: 0.7323\n",
      "Epoch 3484/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0676 - accuracy: 0.7637 - val_loss: 0.0765 - val_accuracy: 0.7324\n",
      "Epoch 3485/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0675 - accuracy: 0.7645 - val_loss: 0.0771 - val_accuracy: 0.7310\n",
      "Epoch 3486/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0676 - accuracy: 0.7642 - val_loss: 0.0785 - val_accuracy: 0.7273\n",
      "Epoch 3487/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0678 - accuracy: 0.7634 - val_loss: 0.0778 - val_accuracy: 0.7315\n",
      "Epoch 3488/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0677 - accuracy: 0.7638 - val_loss: 0.0774 - val_accuracy: 0.7329\n",
      "Epoch 3489/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0676 - accuracy: 0.7641 - val_loss: 0.0770 - val_accuracy: 0.7314\n",
      "Epoch 3490/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0674 - accuracy: 0.7645 - val_loss: 0.0772 - val_accuracy: 0.7308\n",
      "Epoch 3491/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0675 - accuracy: 0.7647 - val_loss: 0.0767 - val_accuracy: 0.7325\n",
      "Epoch 3492/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0674 - accuracy: 0.7643 - val_loss: 0.0773 - val_accuracy: 0.7315\n",
      "Epoch 3493/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0675 - accuracy: 0.7645 - val_loss: 0.0772 - val_accuracy: 0.7308\n",
      "Epoch 3494/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0675 - accuracy: 0.7640 - val_loss: 0.0773 - val_accuracy: 0.7322\n",
      "Epoch 3495/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0676 - accuracy: 0.7643 - val_loss: 0.0774 - val_accuracy: 0.7298\n",
      "Epoch 3496/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0678 - accuracy: 0.7635 - val_loss: 0.0770 - val_accuracy: 0.7308\n",
      "Epoch 3497/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0676 - accuracy: 0.7634 - val_loss: 0.0783 - val_accuracy: 0.7283\n",
      "Epoch 3498/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0675 - accuracy: 0.7644 - val_loss: 0.0770 - val_accuracy: 0.7326\n",
      "Epoch 3499/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0677 - accuracy: 0.7640 - val_loss: 0.0769 - val_accuracy: 0.7312\n",
      "Epoch 3500/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0678 - accuracy: 0.7631 - val_loss: 0.0770 - val_accuracy: 0.7301\n",
      "Epoch 3501/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0676 - accuracy: 0.7647 - val_loss: 0.0772 - val_accuracy: 0.7327\n",
      "Epoch 3502/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0678 - accuracy: 0.7632 - val_loss: 0.0783 - val_accuracy: 0.7294\n",
      "Epoch 3503/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0675 - accuracy: 0.7645 - val_loss: 0.0773 - val_accuracy: 0.7308\n",
      "Epoch 3504/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0677 - accuracy: 0.7635 - val_loss: 0.0781 - val_accuracy: 0.7294\n",
      "Epoch 3505/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0679 - accuracy: 0.7639 - val_loss: 0.0774 - val_accuracy: 0.7304\n",
      "Epoch 3506/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0676 - accuracy: 0.7639 - val_loss: 0.0767 - val_accuracy: 0.7327\n",
      "Epoch 3507/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0676 - accuracy: 0.7640 - val_loss: 0.0767 - val_accuracy: 0.7313\n",
      "Epoch 3508/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0677 - accuracy: 0.7633 - val_loss: 0.0769 - val_accuracy: 0.7304\n",
      "Epoch 3509/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0676 - accuracy: 0.7642 - val_loss: 0.0788 - val_accuracy: 0.7284\n",
      "Epoch 3510/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0678 - accuracy: 0.7635 - val_loss: 0.0773 - val_accuracy: 0.7306\n",
      "Epoch 3511/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0677 - accuracy: 0.7640 - val_loss: 0.0772 - val_accuracy: 0.7295\n",
      "Epoch 3512/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0678 - accuracy: 0.7634 - val_loss: 0.0766 - val_accuracy: 0.7332\n",
      "Epoch 3513/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0678 - accuracy: 0.7641 - val_loss: 0.0767 - val_accuracy: 0.7315\n",
      "Epoch 3514/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0677 - accuracy: 0.7642 - val_loss: 0.0769 - val_accuracy: 0.7335\n",
      "Epoch 3515/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0678 - accuracy: 0.7637 - val_loss: 0.0769 - val_accuracy: 0.7326\n",
      "Epoch 3516/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0679 - accuracy: 0.7628 - val_loss: 0.0772 - val_accuracy: 0.7320\n",
      "Epoch 3517/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0678 - accuracy: 0.7636 - val_loss: 0.0779 - val_accuracy: 0.7290\n",
      "Epoch 3518/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0678 - accuracy: 0.7635 - val_loss: 0.0777 - val_accuracy: 0.7307\n",
      "Epoch 3519/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0678 - accuracy: 0.7633 - val_loss: 0.0765 - val_accuracy: 0.7328\n",
      "Epoch 3520/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0681 - accuracy: 0.7626 - val_loss: 0.0782 - val_accuracy: 0.7298\n",
      "Epoch 3521/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0680 - accuracy: 0.7633 - val_loss: 0.0772 - val_accuracy: 0.7308\n",
      "Epoch 3522/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0680 - accuracy: 0.7627 - val_loss: 0.0767 - val_accuracy: 0.7328\n",
      "Epoch 3523/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0677 - accuracy: 0.7638 - val_loss: 0.0779 - val_accuracy: 0.7278\n",
      "Epoch 3524/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0680 - accuracy: 0.7626 - val_loss: 0.0772 - val_accuracy: 0.7310\n",
      "Epoch 3525/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0679 - accuracy: 0.7631 - val_loss: 0.0781 - val_accuracy: 0.7297\n",
      "Epoch 3526/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0679 - accuracy: 0.7632 - val_loss: 0.0770 - val_accuracy: 0.7323\n",
      "Epoch 3527/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0677 - accuracy: 0.7635 - val_loss: 0.0772 - val_accuracy: 0.7328\n",
      "Epoch 3528/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0678 - accuracy: 0.7638 - val_loss: 0.0770 - val_accuracy: 0.7317\n",
      "Epoch 3529/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0679 - accuracy: 0.7635 - val_loss: 0.0773 - val_accuracy: 0.7323\n",
      "Epoch 3530/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0679 - accuracy: 0.7635 - val_loss: 0.0773 - val_accuracy: 0.7326\n",
      "Epoch 3531/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0680 - accuracy: 0.7628 - val_loss: 0.0776 - val_accuracy: 0.7319\n",
      "Epoch 3532/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0679 - accuracy: 0.7632 - val_loss: 0.0773 - val_accuracy: 0.7320\n",
      "Epoch 3533/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0680 - accuracy: 0.7632 - val_loss: 0.0772 - val_accuracy: 0.7305\n",
      "Epoch 3534/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0678 - accuracy: 0.7635 - val_loss: 0.0768 - val_accuracy: 0.7321\n",
      "Epoch 3535/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0681 - accuracy: 0.7628 - val_loss: 0.0778 - val_accuracy: 0.7312\n",
      "Epoch 3536/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0680 - accuracy: 0.7628 - val_loss: 0.0767 - val_accuracy: 0.7327\n",
      "Epoch 3537/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0680 - accuracy: 0.7623 - val_loss: 0.0768 - val_accuracy: 0.7313\n",
      "Epoch 3538/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0680 - accuracy: 0.7628 - val_loss: 0.0769 - val_accuracy: 0.7313\n",
      "Epoch 3539/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0680 - accuracy: 0.7627 - val_loss: 0.0772 - val_accuracy: 0.7315\n",
      "Epoch 3540/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0678 - accuracy: 0.7632 - val_loss: 0.0770 - val_accuracy: 0.7316\n",
      "Epoch 3541/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0679 - accuracy: 0.7633 - val_loss: 0.0771 - val_accuracy: 0.7315\n",
      "Epoch 3542/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0679 - accuracy: 0.7630 - val_loss: 0.0770 - val_accuracy: 0.7318\n",
      "Epoch 3543/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0678 - accuracy: 0.7635 - val_loss: 0.0776 - val_accuracy: 0.7323\n",
      "Epoch 3544/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0679 - accuracy: 0.7630 - val_loss: 0.0773 - val_accuracy: 0.7301\n",
      "Epoch 3545/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0679 - accuracy: 0.7629 - val_loss: 0.0780 - val_accuracy: 0.7297\n",
      "Epoch 3546/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0680 - accuracy: 0.7625 - val_loss: 0.0778 - val_accuracy: 0.7297\n",
      "Epoch 3547/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0680 - accuracy: 0.7629 - val_loss: 0.0775 - val_accuracy: 0.7312\n",
      "Epoch 3548/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0677 - accuracy: 0.7635 - val_loss: 0.0770 - val_accuracy: 0.7330\n",
      "Epoch 3549/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0678 - accuracy: 0.7633 - val_loss: 0.0776 - val_accuracy: 0.7314\n",
      "Epoch 3550/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0678 - accuracy: 0.7630 - val_loss: 0.0768 - val_accuracy: 0.7312\n",
      "Epoch 3551/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0676 - accuracy: 0.7638 - val_loss: 0.0772 - val_accuracy: 0.7287\n",
      "Epoch 3552/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0677 - accuracy: 0.7640 - val_loss: 0.0777 - val_accuracy: 0.7296\n",
      "Epoch 3553/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0678 - accuracy: 0.7636 - val_loss: 0.0771 - val_accuracy: 0.7314\n",
      "Epoch 3554/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0679 - accuracy: 0.7633 - val_loss: 0.0774 - val_accuracy: 0.7321\n",
      "Epoch 3555/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0679 - accuracy: 0.7632 - val_loss: 0.0770 - val_accuracy: 0.7320\n",
      "Epoch 3556/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0680 - accuracy: 0.7624 - val_loss: 0.0773 - val_accuracy: 0.7290\n",
      "Epoch 3557/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0680 - accuracy: 0.7627 - val_loss: 0.0774 - val_accuracy: 0.7316\n",
      "Epoch 3558/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0681 - accuracy: 0.7624 - val_loss: 0.0780 - val_accuracy: 0.7306\n",
      "Epoch 3559/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0679 - accuracy: 0.7626 - val_loss: 0.0774 - val_accuracy: 0.7303\n",
      "Epoch 3560/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0678 - accuracy: 0.7629 - val_loss: 0.0773 - val_accuracy: 0.7311\n",
      "Epoch 3561/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0679 - accuracy: 0.7630 - val_loss: 0.0777 - val_accuracy: 0.7321\n",
      "Epoch 3562/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0680 - accuracy: 0.7627 - val_loss: 0.0778 - val_accuracy: 0.7305\n",
      "Epoch 3563/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0678 - accuracy: 0.7631 - val_loss: 0.0774 - val_accuracy: 0.7312\n",
      "Epoch 3564/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0679 - accuracy: 0.7626 - val_loss: 0.0773 - val_accuracy: 0.7316\n",
      "Epoch 3565/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0681 - accuracy: 0.7620 - val_loss: 0.0774 - val_accuracy: 0.7290\n",
      "Epoch 3566/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0678 - accuracy: 0.7626 - val_loss: 0.0771 - val_accuracy: 0.7315\n",
      "Epoch 3567/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0679 - accuracy: 0.7626 - val_loss: 0.0775 - val_accuracy: 0.7306\n",
      "Epoch 3568/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0681 - accuracy: 0.7623 - val_loss: 0.0778 - val_accuracy: 0.7285\n",
      "Epoch 3569/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0679 - accuracy: 0.7632 - val_loss: 0.0776 - val_accuracy: 0.7291\n",
      "Epoch 3570/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0682 - accuracy: 0.7616 - val_loss: 0.0773 - val_accuracy: 0.7314\n",
      "Epoch 3571/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0680 - accuracy: 0.7625 - val_loss: 0.0776 - val_accuracy: 0.7304\n",
      "Epoch 3572/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0681 - accuracy: 0.7621 - val_loss: 0.0776 - val_accuracy: 0.7286\n",
      "Epoch 3573/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0678 - accuracy: 0.7630 - val_loss: 0.0768 - val_accuracy: 0.7325\n",
      "Epoch 3574/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0678 - accuracy: 0.7635 - val_loss: 0.0783 - val_accuracy: 0.7273\n",
      "Epoch 3575/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0680 - accuracy: 0.7626 - val_loss: 0.0769 - val_accuracy: 0.7311\n",
      "Epoch 3576/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0680 - accuracy: 0.7621 - val_loss: 0.0773 - val_accuracy: 0.7314\n",
      "Epoch 3577/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0681 - accuracy: 0.7619 - val_loss: 0.0774 - val_accuracy: 0.7301\n",
      "Epoch 3578/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0679 - accuracy: 0.7625 - val_loss: 0.0774 - val_accuracy: 0.7314\n",
      "Epoch 3579/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0680 - accuracy: 0.7626 - val_loss: 0.0776 - val_accuracy: 0.7298\n",
      "Epoch 3580/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0680 - accuracy: 0.7625 - val_loss: 0.0783 - val_accuracy: 0.7303\n",
      "Epoch 3581/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0679 - accuracy: 0.7625 - val_loss: 0.0778 - val_accuracy: 0.7297\n",
      "Epoch 3582/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0680 - accuracy: 0.7628 - val_loss: 0.0770 - val_accuracy: 0.7310\n",
      "Epoch 3583/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0679 - accuracy: 0.7626 - val_loss: 0.0776 - val_accuracy: 0.7299\n",
      "Epoch 3584/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0680 - accuracy: 0.7624 - val_loss: 0.0778 - val_accuracy: 0.7292\n",
      "Epoch 3585/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0681 - accuracy: 0.7624 - val_loss: 0.0770 - val_accuracy: 0.7308\n",
      "Epoch 3586/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0681 - accuracy: 0.7616 - val_loss: 0.0777 - val_accuracy: 0.7291\n",
      "Epoch 3587/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0680 - accuracy: 0.7623 - val_loss: 0.0776 - val_accuracy: 0.7285\n",
      "Epoch 3588/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0680 - accuracy: 0.7622 - val_loss: 0.0777 - val_accuracy: 0.7304\n",
      "Epoch 3589/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0680 - accuracy: 0.7625 - val_loss: 0.0780 - val_accuracy: 0.7293\n",
      "Epoch 3590/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0681 - accuracy: 0.7622 - val_loss: 0.0773 - val_accuracy: 0.7309\n",
      "Epoch 3591/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0680 - accuracy: 0.7623 - val_loss: 0.0769 - val_accuracy: 0.7314\n",
      "Epoch 3592/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0680 - accuracy: 0.7626 - val_loss: 0.0777 - val_accuracy: 0.7303\n",
      "Epoch 3593/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0682 - accuracy: 0.7618 - val_loss: 0.0772 - val_accuracy: 0.7313\n",
      "Epoch 3594/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0681 - accuracy: 0.7624 - val_loss: 0.0773 - val_accuracy: 0.7296\n",
      "Epoch 3595/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0682 - accuracy: 0.7624 - val_loss: 0.0775 - val_accuracy: 0.7291\n",
      "Epoch 3596/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0682 - accuracy: 0.7618 - val_loss: 0.0775 - val_accuracy: 0.7304\n",
      "Epoch 3597/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0681 - accuracy: 0.7617 - val_loss: 0.0779 - val_accuracy: 0.7304\n",
      "Epoch 3598/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0682 - accuracy: 0.7611 - val_loss: 0.0772 - val_accuracy: 0.7308\n",
      "Epoch 3599/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0682 - accuracy: 0.7623 - val_loss: 0.0770 - val_accuracy: 0.7319\n",
      "Epoch 3600/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0682 - accuracy: 0.7616 - val_loss: 0.0773 - val_accuracy: 0.7301\n",
      "Epoch 3601/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0682 - accuracy: 0.7610 - val_loss: 0.0774 - val_accuracy: 0.7300\n",
      "Epoch 3602/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0683 - accuracy: 0.7609 - val_loss: 0.0788 - val_accuracy: 0.7262\n",
      "Epoch 3603/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0681 - accuracy: 0.7620 - val_loss: 0.0779 - val_accuracy: 0.7280\n",
      "Epoch 3604/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0681 - accuracy: 0.7616 - val_loss: 0.0775 - val_accuracy: 0.7294\n",
      "Epoch 3605/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0683 - accuracy: 0.7617 - val_loss: 0.0780 - val_accuracy: 0.7274\n",
      "Epoch 3606/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0682 - accuracy: 0.7617 - val_loss: 0.0781 - val_accuracy: 0.7263\n",
      "Epoch 3607/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0682 - accuracy: 0.7619 - val_loss: 0.0774 - val_accuracy: 0.7301\n",
      "Epoch 3608/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0681 - accuracy: 0.7624 - val_loss: 0.0782 - val_accuracy: 0.7263\n",
      "Epoch 3609/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0682 - accuracy: 0.7616 - val_loss: 0.0771 - val_accuracy: 0.7310\n",
      "Epoch 3610/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0683 - accuracy: 0.7611 - val_loss: 0.0778 - val_accuracy: 0.7301\n",
      "Epoch 3611/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0683 - accuracy: 0.7610 - val_loss: 0.0776 - val_accuracy: 0.7282\n",
      "Epoch 3612/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0684 - accuracy: 0.7612 - val_loss: 0.0778 - val_accuracy: 0.7278\n",
      "Epoch 3613/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0683 - accuracy: 0.7613 - val_loss: 0.0780 - val_accuracy: 0.7299\n",
      "Epoch 3614/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0682 - accuracy: 0.7620 - val_loss: 0.0782 - val_accuracy: 0.7272\n",
      "Epoch 3615/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0682 - accuracy: 0.7620 - val_loss: 0.0783 - val_accuracy: 0.7283\n",
      "Epoch 3616/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0683 - accuracy: 0.7611 - val_loss: 0.0775 - val_accuracy: 0.7293\n",
      "Epoch 3617/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0683 - accuracy: 0.7611 - val_loss: 0.0774 - val_accuracy: 0.7299\n",
      "Epoch 3618/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0683 - accuracy: 0.7614 - val_loss: 0.0776 - val_accuracy: 0.7308\n",
      "Epoch 3619/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0683 - accuracy: 0.7613 - val_loss: 0.0774 - val_accuracy: 0.7298\n",
      "Epoch 3620/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0682 - accuracy: 0.7619 - val_loss: 0.0775 - val_accuracy: 0.7297\n",
      "Epoch 3621/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0684 - accuracy: 0.7615 - val_loss: 0.0791 - val_accuracy: 0.7257\n",
      "Epoch 3622/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0683 - accuracy: 0.7617 - val_loss: 0.0777 - val_accuracy: 0.7297\n",
      "Epoch 3623/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0682 - accuracy: 0.7611 - val_loss: 0.0774 - val_accuracy: 0.7287\n",
      "Epoch 3624/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0682 - accuracy: 0.7612 - val_loss: 0.0774 - val_accuracy: 0.7306\n",
      "Epoch 3625/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0684 - accuracy: 0.7609 - val_loss: 0.0772 - val_accuracy: 0.7297\n",
      "Epoch 3626/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0683 - accuracy: 0.7608 - val_loss: 0.0778 - val_accuracy: 0.7265\n",
      "Epoch 3627/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0682 - accuracy: 0.7612 - val_loss: 0.0787 - val_accuracy: 0.7280\n",
      "Epoch 3628/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0686 - accuracy: 0.7601 - val_loss: 0.0785 - val_accuracy: 0.7252\n",
      "Epoch 3629/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0683 - accuracy: 0.7611 - val_loss: 0.0777 - val_accuracy: 0.7279\n",
      "Epoch 3630/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0682 - accuracy: 0.7612 - val_loss: 0.0778 - val_accuracy: 0.7286\n",
      "Epoch 3631/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0685 - accuracy: 0.7602 - val_loss: 0.0788 - val_accuracy: 0.7253\n",
      "Epoch 3632/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0684 - accuracy: 0.7609 - val_loss: 0.0788 - val_accuracy: 0.7256\n",
      "Epoch 3633/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0683 - accuracy: 0.7618 - val_loss: 0.0776 - val_accuracy: 0.7289\n",
      "Epoch 3634/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0688 - accuracy: 0.7594 - val_loss: 0.0777 - val_accuracy: 0.7295\n",
      "Epoch 3635/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0687 - accuracy: 0.7606 - val_loss: 0.0771 - val_accuracy: 0.7314\n",
      "Epoch 3636/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0686 - accuracy: 0.7604 - val_loss: 0.0780 - val_accuracy: 0.7273\n",
      "Epoch 3637/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0686 - accuracy: 0.7604 - val_loss: 0.0779 - val_accuracy: 0.7287\n",
      "Epoch 3638/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0684 - accuracy: 0.7610 - val_loss: 0.0777 - val_accuracy: 0.7287\n",
      "Epoch 3639/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0688 - accuracy: 0.7596 - val_loss: 0.0784 - val_accuracy: 0.7270\n",
      "Epoch 3640/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0687 - accuracy: 0.7594 - val_loss: 0.0778 - val_accuracy: 0.7282\n",
      "Epoch 3641/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0689 - accuracy: 0.7592 - val_loss: 0.0781 - val_accuracy: 0.7275\n",
      "Epoch 3642/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0685 - accuracy: 0.7606 - val_loss: 0.0790 - val_accuracy: 0.7230\n",
      "Epoch 3643/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0689 - accuracy: 0.7595 - val_loss: 0.0789 - val_accuracy: 0.7303\n",
      "Epoch 3644/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0687 - accuracy: 0.7601 - val_loss: 0.0777 - val_accuracy: 0.7292\n",
      "Epoch 3645/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0685 - accuracy: 0.7605 - val_loss: 0.0780 - val_accuracy: 0.7277\n",
      "Epoch 3646/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0687 - accuracy: 0.7598 - val_loss: 0.0778 - val_accuracy: 0.7285\n",
      "Epoch 3647/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0686 - accuracy: 0.7607 - val_loss: 0.0786 - val_accuracy: 0.7258\n",
      "Epoch 3648/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0688 - accuracy: 0.7589 - val_loss: 0.0774 - val_accuracy: 0.7296\n",
      "Epoch 3649/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0687 - accuracy: 0.7594 - val_loss: 0.0780 - val_accuracy: 0.7295\n",
      "Epoch 3650/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0686 - accuracy: 0.7600 - val_loss: 0.0775 - val_accuracy: 0.7294\n",
      "Epoch 3651/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0688 - accuracy: 0.7596 - val_loss: 0.0778 - val_accuracy: 0.7293\n",
      "Epoch 3652/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0687 - accuracy: 0.7601 - val_loss: 0.0785 - val_accuracy: 0.7276\n",
      "Epoch 3653/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0688 - accuracy: 0.7599 - val_loss: 0.0784 - val_accuracy: 0.7271\n",
      "Epoch 3654/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0686 - accuracy: 0.7604 - val_loss: 0.0790 - val_accuracy: 0.7275\n",
      "Epoch 3655/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0685 - accuracy: 0.7605 - val_loss: 0.0778 - val_accuracy: 0.7297\n",
      "Epoch 3656/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0686 - accuracy: 0.7598 - val_loss: 0.0784 - val_accuracy: 0.7265\n",
      "Epoch 3657/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0687 - accuracy: 0.7596 - val_loss: 0.0783 - val_accuracy: 0.7260\n",
      "Epoch 3658/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0685 - accuracy: 0.7603 - val_loss: 0.0775 - val_accuracy: 0.7281\n",
      "Epoch 3659/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0688 - accuracy: 0.7597 - val_loss: 0.0779 - val_accuracy: 0.7292\n",
      "Epoch 3660/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0687 - accuracy: 0.7596 - val_loss: 0.0779 - val_accuracy: 0.7291\n",
      "Epoch 3661/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0685 - accuracy: 0.7607 - val_loss: 0.0782 - val_accuracy: 0.7266\n",
      "Epoch 3662/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0686 - accuracy: 0.7604 - val_loss: 0.0778 - val_accuracy: 0.7279\n",
      "Epoch 3663/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0687 - accuracy: 0.7594 - val_loss: 0.0777 - val_accuracy: 0.7303\n",
      "Epoch 3664/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0687 - accuracy: 0.7598 - val_loss: 0.0778 - val_accuracy: 0.7295\n",
      "Epoch 3665/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0686 - accuracy: 0.7599 - val_loss: 0.0772 - val_accuracy: 0.7303\n",
      "Epoch 3666/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0687 - accuracy: 0.7596 - val_loss: 0.0783 - val_accuracy: 0.7281\n",
      "Epoch 3667/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0687 - accuracy: 0.7602 - val_loss: 0.0777 - val_accuracy: 0.7278\n",
      "Epoch 3668/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0687 - accuracy: 0.7603 - val_loss: 0.0779 - val_accuracy: 0.7286\n",
      "Epoch 3669/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0687 - accuracy: 0.7594 - val_loss: 0.0774 - val_accuracy: 0.7297\n",
      "Epoch 3670/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0688 - accuracy: 0.7594 - val_loss: 0.0782 - val_accuracy: 0.7245\n",
      "Epoch 3671/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0688 - accuracy: 0.7590 - val_loss: 0.0777 - val_accuracy: 0.7281\n",
      "Epoch 3672/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0686 - accuracy: 0.7598 - val_loss: 0.0780 - val_accuracy: 0.7267\n",
      "Epoch 3673/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0689 - accuracy: 0.7593 - val_loss: 0.0781 - val_accuracy: 0.7287\n",
      "Epoch 3674/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0688 - accuracy: 0.7599 - val_loss: 0.0788 - val_accuracy: 0.7258\n",
      "Epoch 3675/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0689 - accuracy: 0.7591 - val_loss: 0.0777 - val_accuracy: 0.7298\n",
      "Epoch 3676/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0688 - accuracy: 0.7595 - val_loss: 0.0780 - val_accuracy: 0.7284\n",
      "Epoch 3677/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0688 - accuracy: 0.7593 - val_loss: 0.0780 - val_accuracy: 0.7269\n",
      "Epoch 3678/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0688 - accuracy: 0.7597 - val_loss: 0.0788 - val_accuracy: 0.7254\n",
      "Epoch 3679/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0689 - accuracy: 0.7586 - val_loss: 0.0781 - val_accuracy: 0.7280\n",
      "Epoch 3680/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0688 - accuracy: 0.7598 - val_loss: 0.0774 - val_accuracy: 0.7280\n",
      "Epoch 3681/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0686 - accuracy: 0.7604 - val_loss: 0.0780 - val_accuracy: 0.7272\n",
      "Epoch 3682/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0686 - accuracy: 0.7596 - val_loss: 0.0778 - val_accuracy: 0.7292\n",
      "Epoch 3683/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0687 - accuracy: 0.7596 - val_loss: 0.0785 - val_accuracy: 0.7271\n",
      "Epoch 3684/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0688 - accuracy: 0.7590 - val_loss: 0.0778 - val_accuracy: 0.7270\n",
      "Epoch 3685/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0687 - accuracy: 0.7586 - val_loss: 0.0782 - val_accuracy: 0.7250\n",
      "Epoch 3686/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0690 - accuracy: 0.7586 - val_loss: 0.0793 - val_accuracy: 0.7244\n",
      "Epoch 3687/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0691 - accuracy: 0.7583 - val_loss: 0.0786 - val_accuracy: 0.7250\n",
      "Epoch 3688/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0691 - accuracy: 0.7583 - val_loss: 0.0789 - val_accuracy: 0.7260\n",
      "Epoch 3689/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0689 - accuracy: 0.7591 - val_loss: 0.0786 - val_accuracy: 0.7271\n",
      "Epoch 3690/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0691 - accuracy: 0.7585 - val_loss: 0.0783 - val_accuracy: 0.7284\n",
      "Epoch 3691/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0688 - accuracy: 0.7587 - val_loss: 0.0783 - val_accuracy: 0.7261\n",
      "Epoch 3692/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0688 - accuracy: 0.7590 - val_loss: 0.0781 - val_accuracy: 0.7288\n",
      "Epoch 3693/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0689 - accuracy: 0.7589 - val_loss: 0.0777 - val_accuracy: 0.7292\n",
      "Epoch 3694/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0689 - accuracy: 0.7588 - val_loss: 0.0782 - val_accuracy: 0.7282\n",
      "Epoch 3695/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0691 - accuracy: 0.7581 - val_loss: 0.0774 - val_accuracy: 0.7291\n",
      "Epoch 3696/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0689 - accuracy: 0.7591 - val_loss: 0.0792 - val_accuracy: 0.7250\n",
      "Epoch 3697/5000\n",
      "11786/11786 [==============================] - 8s 654us/step - loss: 0.0690 - accuracy: 0.7586 - val_loss: 0.0780 - val_accuracy: 0.7266\n",
      "Epoch 3698/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0688 - accuracy: 0.7595 - val_loss: 0.0778 - val_accuracy: 0.7283\n",
      "Epoch 3699/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0689 - accuracy: 0.7590 - val_loss: 0.0781 - val_accuracy: 0.7282\n",
      "Epoch 3700/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0689 - accuracy: 0.7585 - val_loss: 0.0783 - val_accuracy: 0.7263\n",
      "Epoch 3701/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0688 - accuracy: 0.7593 - val_loss: 0.0777 - val_accuracy: 0.7305\n",
      "Epoch 3702/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0690 - accuracy: 0.7588 - val_loss: 0.0780 - val_accuracy: 0.7269\n",
      "Epoch 3703/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0689 - accuracy: 0.7588 - val_loss: 0.0788 - val_accuracy: 0.7264\n",
      "Epoch 3704/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0690 - accuracy: 0.7579 - val_loss: 0.0793 - val_accuracy: 0.7229\n",
      "Epoch 3705/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0690 - accuracy: 0.7586 - val_loss: 0.0777 - val_accuracy: 0.7272\n",
      "Epoch 3706/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0688 - accuracy: 0.7590 - val_loss: 0.0781 - val_accuracy: 0.7289\n",
      "Epoch 3707/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0688 - accuracy: 0.7592 - val_loss: 0.0788 - val_accuracy: 0.7282\n",
      "Epoch 3708/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0690 - accuracy: 0.7584 - val_loss: 0.0785 - val_accuracy: 0.7295\n",
      "Epoch 3709/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0689 - accuracy: 0.7589 - val_loss: 0.0782 - val_accuracy: 0.7274\n",
      "Epoch 3710/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0689 - accuracy: 0.7594 - val_loss: 0.0785 - val_accuracy: 0.7283\n",
      "Epoch 3711/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0689 - accuracy: 0.7596 - val_loss: 0.0781 - val_accuracy: 0.7277\n",
      "Epoch 3712/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0689 - accuracy: 0.7591 - val_loss: 0.0788 - val_accuracy: 0.7246\n",
      "Epoch 3713/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0690 - accuracy: 0.7584 - val_loss: 0.0783 - val_accuracy: 0.7280\n",
      "Epoch 3714/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0690 - accuracy: 0.7585 - val_loss: 0.0780 - val_accuracy: 0.7308\n",
      "Epoch 3715/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0689 - accuracy: 0.7586 - val_loss: 0.0784 - val_accuracy: 0.7261\n",
      "Epoch 3716/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0690 - accuracy: 0.7584 - val_loss: 0.0783 - val_accuracy: 0.7268\n",
      "Epoch 3717/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0691 - accuracy: 0.7589 - val_loss: 0.0790 - val_accuracy: 0.7266\n",
      "Epoch 3718/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0689 - accuracy: 0.7590 - val_loss: 0.0773 - val_accuracy: 0.7303\n",
      "Epoch 3719/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0690 - accuracy: 0.7586 - val_loss: 0.0785 - val_accuracy: 0.7282\n",
      "Epoch 3720/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0689 - accuracy: 0.7589 - val_loss: 0.0785 - val_accuracy: 0.7251\n",
      "Epoch 3721/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0693 - accuracy: 0.7571 - val_loss: 0.0786 - val_accuracy: 0.7277\n",
      "Epoch 3722/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0691 - accuracy: 0.7582 - val_loss: 0.0780 - val_accuracy: 0.7272\n",
      "Epoch 3723/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0692 - accuracy: 0.7578 - val_loss: 0.0787 - val_accuracy: 0.7282\n",
      "Epoch 3724/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0691 - accuracy: 0.7586 - val_loss: 0.0784 - val_accuracy: 0.7270\n",
      "Epoch 3725/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0691 - accuracy: 0.7587 - val_loss: 0.0784 - val_accuracy: 0.7254\n",
      "Epoch 3726/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0691 - accuracy: 0.7584 - val_loss: 0.0798 - val_accuracy: 0.7239\n",
      "Epoch 3727/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0690 - accuracy: 0.7587 - val_loss: 0.0785 - val_accuracy: 0.7268\n",
      "Epoch 3728/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0691 - accuracy: 0.7583 - val_loss: 0.0780 - val_accuracy: 0.7276\n",
      "Epoch 3729/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0691 - accuracy: 0.7583 - val_loss: 0.0785 - val_accuracy: 0.7243\n",
      "Epoch 3730/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0690 - accuracy: 0.7589 - val_loss: 0.0787 - val_accuracy: 0.7263\n",
      "Epoch 3731/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0691 - accuracy: 0.7585 - val_loss: 0.0793 - val_accuracy: 0.7250\n",
      "Epoch 3732/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0692 - accuracy: 0.7580 - val_loss: 0.0784 - val_accuracy: 0.7266\n",
      "Epoch 3733/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0692 - accuracy: 0.7576 - val_loss: 0.0787 - val_accuracy: 0.7257\n",
      "Epoch 3734/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0691 - accuracy: 0.7580 - val_loss: 0.0787 - val_accuracy: 0.7259\n",
      "Epoch 3735/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0691 - accuracy: 0.7578 - val_loss: 0.0778 - val_accuracy: 0.7277\n",
      "Epoch 3736/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0691 - accuracy: 0.7581 - val_loss: 0.0784 - val_accuracy: 0.7261\n",
      "Epoch 3737/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0691 - accuracy: 0.7582 - val_loss: 0.0781 - val_accuracy: 0.7263\n",
      "Epoch 3738/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0694 - accuracy: 0.7579 - val_loss: 0.0789 - val_accuracy: 0.7238\n",
      "Epoch 3739/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0692 - accuracy: 0.7582 - val_loss: 0.0784 - val_accuracy: 0.7259\n",
      "Epoch 3740/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0694 - accuracy: 0.7577 - val_loss: 0.0781 - val_accuracy: 0.7270\n",
      "Epoch 3741/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0694 - accuracy: 0.7567 - val_loss: 0.0788 - val_accuracy: 0.7269\n",
      "Epoch 3742/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0696 - accuracy: 0.7562 - val_loss: 0.0789 - val_accuracy: 0.7237\n",
      "Epoch 3743/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0694 - accuracy: 0.7574 - val_loss: 0.0796 - val_accuracy: 0.7233\n",
      "Epoch 3744/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0695 - accuracy: 0.7567 - val_loss: 0.0787 - val_accuracy: 0.7243\n",
      "Epoch 3745/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0695 - accuracy: 0.7566 - val_loss: 0.0784 - val_accuracy: 0.7261\n",
      "Epoch 3746/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0693 - accuracy: 0.7581 - val_loss: 0.0804 - val_accuracy: 0.7218\n",
      "Epoch 3747/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0693 - accuracy: 0.7575 - val_loss: 0.0794 - val_accuracy: 0.7206\n",
      "Epoch 3748/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0696 - accuracy: 0.7566 - val_loss: 0.0790 - val_accuracy: 0.7250\n",
      "Epoch 3749/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0693 - accuracy: 0.7575 - val_loss: 0.0790 - val_accuracy: 0.7272\n",
      "Epoch 3750/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0693 - accuracy: 0.7577 - val_loss: 0.0789 - val_accuracy: 0.7264\n",
      "Epoch 3751/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0694 - accuracy: 0.7579 - val_loss: 0.0796 - val_accuracy: 0.7227\n",
      "Epoch 3752/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0693 - accuracy: 0.7579 - val_loss: 0.0801 - val_accuracy: 0.7206\n",
      "Epoch 3753/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0695 - accuracy: 0.7570 - val_loss: 0.0793 - val_accuracy: 0.7256\n",
      "Epoch 3754/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0695 - accuracy: 0.7569 - val_loss: 0.0787 - val_accuracy: 0.7263\n",
      "Epoch 3755/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0694 - accuracy: 0.7571 - val_loss: 0.0783 - val_accuracy: 0.7267\n",
      "Epoch 3756/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0695 - accuracy: 0.7572 - val_loss: 0.0788 - val_accuracy: 0.7263\n",
      "Epoch 3757/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0695 - accuracy: 0.7572 - val_loss: 0.0792 - val_accuracy: 0.7245\n",
      "Epoch 3758/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0696 - accuracy: 0.7563 - val_loss: 0.0794 - val_accuracy: 0.7248\n",
      "Epoch 3759/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0696 - accuracy: 0.7563 - val_loss: 0.0786 - val_accuracy: 0.7251\n",
      "Epoch 3760/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0696 - accuracy: 0.7568 - val_loss: 0.0795 - val_accuracy: 0.7248\n",
      "Epoch 3761/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0694 - accuracy: 0.7571 - val_loss: 0.0787 - val_accuracy: 0.7241\n",
      "Epoch 3762/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0694 - accuracy: 0.7570 - val_loss: 0.0794 - val_accuracy: 0.7229\n",
      "Epoch 3763/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0694 - accuracy: 0.7574 - val_loss: 0.0783 - val_accuracy: 0.7262\n",
      "Epoch 3764/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0692 - accuracy: 0.7577 - val_loss: 0.0787 - val_accuracy: 0.7243\n",
      "Epoch 3765/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0693 - accuracy: 0.7577 - val_loss: 0.0783 - val_accuracy: 0.7258\n",
      "Epoch 3766/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0694 - accuracy: 0.7569 - val_loss: 0.0789 - val_accuracy: 0.7222\n",
      "Epoch 3767/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0695 - accuracy: 0.7562 - val_loss: 0.0794 - val_accuracy: 0.7252\n",
      "Epoch 3768/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0696 - accuracy: 0.7565 - val_loss: 0.0788 - val_accuracy: 0.7240\n",
      "Epoch 3769/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0695 - accuracy: 0.7568 - val_loss: 0.0787 - val_accuracy: 0.7257\n",
      "Epoch 3770/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0696 - accuracy: 0.7563 - val_loss: 0.0791 - val_accuracy: 0.7242\n",
      "Epoch 3771/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0695 - accuracy: 0.7571 - val_loss: 0.0795 - val_accuracy: 0.7217\n",
      "Epoch 3772/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0696 - accuracy: 0.7564 - val_loss: 0.0794 - val_accuracy: 0.7243\n",
      "Epoch 3773/5000\n",
      "11786/11786 [==============================] - 8s 653us/step - loss: 0.0695 - accuracy: 0.7568 - val_loss: 0.0778 - val_accuracy: 0.7271\n",
      "Epoch 3774/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0696 - accuracy: 0.7564 - val_loss: 0.0796 - val_accuracy: 0.7227\n",
      "Epoch 3775/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0695 - accuracy: 0.7565 - val_loss: 0.0794 - val_accuracy: 0.7213\n",
      "Epoch 3776/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0694 - accuracy: 0.7565 - val_loss: 0.0795 - val_accuracy: 0.7238\n",
      "Epoch 3777/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0694 - accuracy: 0.7571 - val_loss: 0.0785 - val_accuracy: 0.7272\n",
      "Epoch 3778/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0692 - accuracy: 0.7579 - val_loss: 0.0785 - val_accuracy: 0.7263\n",
      "Epoch 3779/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0691 - accuracy: 0.7578 - val_loss: 0.0786 - val_accuracy: 0.7280\n",
      "Epoch 3780/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0691 - accuracy: 0.7583 - val_loss: 0.0782 - val_accuracy: 0.7261\n",
      "Epoch 3781/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0689 - accuracy: 0.7586 - val_loss: 0.0783 - val_accuracy: 0.7275\n",
      "Epoch 3782/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0692 - accuracy: 0.7576 - val_loss: 0.0788 - val_accuracy: 0.7270\n",
      "Epoch 3783/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0691 - accuracy: 0.7588 - val_loss: 0.0789 - val_accuracy: 0.7232\n",
      "Epoch 3784/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0691 - accuracy: 0.7589 - val_loss: 0.0789 - val_accuracy: 0.7252\n",
      "Epoch 3785/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0693 - accuracy: 0.7580 - val_loss: 0.0783 - val_accuracy: 0.7252\n",
      "Epoch 3786/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0692 - accuracy: 0.7583 - val_loss: 0.0792 - val_accuracy: 0.7269\n",
      "Epoch 3787/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0690 - accuracy: 0.7594 - val_loss: 0.0786 - val_accuracy: 0.7265\n",
      "Epoch 3788/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0690 - accuracy: 0.7593 - val_loss: 0.0784 - val_accuracy: 0.7274\n",
      "Epoch 3789/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0692 - accuracy: 0.7583 - val_loss: 0.0787 - val_accuracy: 0.7265\n",
      "Epoch 3790/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0693 - accuracy: 0.7574 - val_loss: 0.0793 - val_accuracy: 0.7227\n",
      "Epoch 3791/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0692 - accuracy: 0.7578 - val_loss: 0.0786 - val_accuracy: 0.7267\n",
      "Epoch 3792/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0692 - accuracy: 0.7574 - val_loss: 0.0788 - val_accuracy: 0.7236\n",
      "Epoch 3793/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0692 - accuracy: 0.7579 - val_loss: 0.0781 - val_accuracy: 0.7269\n",
      "Epoch 3794/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0691 - accuracy: 0.7586 - val_loss: 0.0781 - val_accuracy: 0.7265\n",
      "Epoch 3795/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0693 - accuracy: 0.7581 - val_loss: 0.0793 - val_accuracy: 0.7260\n",
      "Epoch 3796/5000\n",
      "11786/11786 [==============================] - 8s 651us/step - loss: 0.0693 - accuracy: 0.7583 - val_loss: 0.0785 - val_accuracy: 0.7253\n",
      "Epoch 3797/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0692 - accuracy: 0.7581 - val_loss: 0.0784 - val_accuracy: 0.7270\n",
      "Epoch 3798/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0691 - accuracy: 0.7591 - val_loss: 0.0793 - val_accuracy: 0.7257\n",
      "Epoch 3799/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0691 - accuracy: 0.7593 - val_loss: 0.0782 - val_accuracy: 0.7277\n",
      "Epoch 3800/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0692 - accuracy: 0.7588 - val_loss: 0.0786 - val_accuracy: 0.7280\n",
      "Epoch 3801/5000\n",
      "11786/11786 [==============================] - 8s 649us/step - loss: 0.0692 - accuracy: 0.7581 - val_loss: 0.0787 - val_accuracy: 0.7261\n",
      "Epoch 3802/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0693 - accuracy: 0.7572 - val_loss: 0.0790 - val_accuracy: 0.7253\n",
      "Epoch 3803/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0695 - accuracy: 0.7578 - val_loss: 0.0786 - val_accuracy: 0.7238\n",
      "Epoch 3804/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0692 - accuracy: 0.7584 - val_loss: 0.0779 - val_accuracy: 0.7285\n",
      "Epoch 3805/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0691 - accuracy: 0.7592 - val_loss: 0.0789 - val_accuracy: 0.7257\n",
      "Epoch 3806/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0692 - accuracy: 0.7586 - val_loss: 0.0789 - val_accuracy: 0.7287\n",
      "Epoch 3807/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0693 - accuracy: 0.7581 - val_loss: 0.0786 - val_accuracy: 0.7273\n",
      "Epoch 3808/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0691 - accuracy: 0.7592 - val_loss: 0.0799 - val_accuracy: 0.7248\n",
      "Epoch 3809/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0693 - accuracy: 0.7576 - val_loss: 0.0791 - val_accuracy: 0.7246\n",
      "Epoch 3810/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0692 - accuracy: 0.7585 - val_loss: 0.0780 - val_accuracy: 0.7276\n",
      "Epoch 3811/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0690 - accuracy: 0.7594 - val_loss: 0.0783 - val_accuracy: 0.7267\n",
      "Epoch 3812/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0694 - accuracy: 0.7579 - val_loss: 0.0782 - val_accuracy: 0.7266\n",
      "Epoch 3813/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0693 - accuracy: 0.7579 - val_loss: 0.0779 - val_accuracy: 0.7274\n",
      "Epoch 3814/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0692 - accuracy: 0.7586 - val_loss: 0.0781 - val_accuracy: 0.7276\n",
      "Epoch 3815/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0693 - accuracy: 0.7576 - val_loss: 0.0786 - val_accuracy: 0.7276\n",
      "Epoch 3816/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0693 - accuracy: 0.7584 - val_loss: 0.0781 - val_accuracy: 0.7285\n",
      "Epoch 3817/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0692 - accuracy: 0.7580 - val_loss: 0.0785 - val_accuracy: 0.7265\n",
      "Epoch 3818/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0691 - accuracy: 0.7592 - val_loss: 0.0785 - val_accuracy: 0.7269\n",
      "Epoch 3819/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0690 - accuracy: 0.7586 - val_loss: 0.0775 - val_accuracy: 0.7292\n",
      "Epoch 3820/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0690 - accuracy: 0.7589 - val_loss: 0.0789 - val_accuracy: 0.7267\n",
      "Epoch 3821/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0693 - accuracy: 0.7581 - val_loss: 0.0778 - val_accuracy: 0.7279\n",
      "Epoch 3822/5000\n",
      "11786/11786 [==============================] - 8s 652us/step - loss: 0.0692 - accuracy: 0.7584 - val_loss: 0.0782 - val_accuracy: 0.7271\n",
      "Epoch 3823/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0692 - accuracy: 0.7576 - val_loss: 0.0779 - val_accuracy: 0.7268\n",
      "Epoch 3824/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0690 - accuracy: 0.7591 - val_loss: 0.0774 - val_accuracy: 0.7304\n",
      "Epoch 3825/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0691 - accuracy: 0.7590 - val_loss: 0.0793 - val_accuracy: 0.7247\n",
      "Epoch 3826/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0693 - accuracy: 0.7579 - val_loss: 0.0780 - val_accuracy: 0.7292\n",
      "Epoch 3827/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0690 - accuracy: 0.7591 - val_loss: 0.0788 - val_accuracy: 0.7276\n",
      "Epoch 3828/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0697 - accuracy: 0.7575 - val_loss: 0.0781 - val_accuracy: 0.7306\n",
      "Epoch 3829/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0692 - accuracy: 0.7587 - val_loss: 0.0782 - val_accuracy: 0.7273\n",
      "Epoch 3830/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0691 - accuracy: 0.7592 - val_loss: 0.0795 - val_accuracy: 0.7235\n",
      "Epoch 3831/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0691 - accuracy: 0.7596 - val_loss: 0.0784 - val_accuracy: 0.7274\n",
      "Epoch 3832/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0692 - accuracy: 0.7582 - val_loss: 0.0784 - val_accuracy: 0.7264\n",
      "Epoch 3833/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0692 - accuracy: 0.7586 - val_loss: 0.0779 - val_accuracy: 0.7261\n",
      "Epoch 3834/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0693 - accuracy: 0.7584 - val_loss: 0.0780 - val_accuracy: 0.7279\n",
      "Epoch 3835/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0693 - accuracy: 0.7584 - val_loss: 0.0794 - val_accuracy: 0.7260\n",
      "Epoch 3836/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0693 - accuracy: 0.7579 - val_loss: 0.0784 - val_accuracy: 0.7269\n",
      "Epoch 3837/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0693 - accuracy: 0.7578 - val_loss: 0.0781 - val_accuracy: 0.7285\n",
      "Epoch 3838/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0692 - accuracy: 0.7584 - val_loss: 0.0781 - val_accuracy: 0.7266\n",
      "Epoch 3839/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0691 - accuracy: 0.7587 - val_loss: 0.0783 - val_accuracy: 0.7268\n",
      "Epoch 3840/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0692 - accuracy: 0.7587 - val_loss: 0.0784 - val_accuracy: 0.7266\n",
      "Epoch 3841/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0691 - accuracy: 0.7583 - val_loss: 0.0775 - val_accuracy: 0.7278\n",
      "Epoch 3842/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0695 - accuracy: 0.7572 - val_loss: 0.0784 - val_accuracy: 0.7273\n",
      "Epoch 3843/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0692 - accuracy: 0.7575 - val_loss: 0.0787 - val_accuracy: 0.7266\n",
      "Epoch 3844/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0693 - accuracy: 0.7578 - val_loss: 0.0782 - val_accuracy: 0.7287\n",
      "Epoch 3845/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0693 - accuracy: 0.7580 - val_loss: 0.0780 - val_accuracy: 0.7288\n",
      "Epoch 3846/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0694 - accuracy: 0.7578 - val_loss: 0.0803 - val_accuracy: 0.7228\n",
      "Epoch 3847/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0694 - accuracy: 0.7579 - val_loss: 0.0781 - val_accuracy: 0.7264\n",
      "Epoch 3848/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0695 - accuracy: 0.7572 - val_loss: 0.0789 - val_accuracy: 0.7274\n",
      "Epoch 3849/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0696 - accuracy: 0.7571 - val_loss: 0.0780 - val_accuracy: 0.7289\n",
      "Epoch 3850/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0693 - accuracy: 0.7574 - val_loss: 0.0775 - val_accuracy: 0.7270\n",
      "Epoch 3851/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0694 - accuracy: 0.7572 - val_loss: 0.0777 - val_accuracy: 0.7287\n",
      "Epoch 3852/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0693 - accuracy: 0.7585 - val_loss: 0.0781 - val_accuracy: 0.7280\n",
      "Epoch 3853/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0693 - accuracy: 0.7574 - val_loss: 0.0785 - val_accuracy: 0.7278\n",
      "Epoch 3854/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0692 - accuracy: 0.7588 - val_loss: 0.0789 - val_accuracy: 0.7231\n",
      "Epoch 3855/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0692 - accuracy: 0.7590 - val_loss: 0.0785 - val_accuracy: 0.7269\n",
      "Epoch 3856/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0696 - accuracy: 0.7575 - val_loss: 0.0799 - val_accuracy: 0.7203\n",
      "Epoch 3857/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0693 - accuracy: 0.7577 - val_loss: 0.0785 - val_accuracy: 0.7253\n",
      "Epoch 3858/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0693 - accuracy: 0.7575 - val_loss: 0.0783 - val_accuracy: 0.7278\n",
      "Epoch 3859/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0694 - accuracy: 0.7587 - val_loss: 0.0789 - val_accuracy: 0.7281\n",
      "Epoch 3860/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0693 - accuracy: 0.7580 - val_loss: 0.0788 - val_accuracy: 0.7273\n",
      "Epoch 3861/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0694 - accuracy: 0.7575 - val_loss: 0.0781 - val_accuracy: 0.7269\n",
      "Epoch 3862/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0695 - accuracy: 0.7575 - val_loss: 0.0785 - val_accuracy: 0.7254\n",
      "Epoch 3863/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0693 - accuracy: 0.7591 - val_loss: 0.0783 - val_accuracy: 0.7278\n",
      "Epoch 3864/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0693 - accuracy: 0.7578 - val_loss: 0.0781 - val_accuracy: 0.7275\n",
      "Epoch 3865/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0693 - accuracy: 0.7581 - val_loss: 0.0785 - val_accuracy: 0.7241\n",
      "Epoch 3866/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0694 - accuracy: 0.7575 - val_loss: 0.0787 - val_accuracy: 0.7259\n",
      "Epoch 3867/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0695 - accuracy: 0.7573 - val_loss: 0.0787 - val_accuracy: 0.7237\n",
      "Epoch 3868/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0695 - accuracy: 0.7573 - val_loss: 0.0777 - val_accuracy: 0.7289\n",
      "Epoch 3869/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0693 - accuracy: 0.7580 - val_loss: 0.0791 - val_accuracy: 0.7259\n",
      "Epoch 3870/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0694 - accuracy: 0.7575 - val_loss: 0.0782 - val_accuracy: 0.7275\n",
      "Epoch 3871/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0693 - accuracy: 0.7579 - val_loss: 0.0787 - val_accuracy: 0.7237\n",
      "Epoch 3872/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0695 - accuracy: 0.7572 - val_loss: 0.0784 - val_accuracy: 0.7244\n",
      "Epoch 3873/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0695 - accuracy: 0.7576 - val_loss: 0.0787 - val_accuracy: 0.7260\n",
      "Epoch 3874/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0694 - accuracy: 0.7576 - val_loss: 0.0786 - val_accuracy: 0.7279\n",
      "Epoch 3875/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0696 - accuracy: 0.7574 - val_loss: 0.0795 - val_accuracy: 0.7240\n",
      "Epoch 3876/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0697 - accuracy: 0.7568 - val_loss: 0.0787 - val_accuracy: 0.7249\n",
      "Epoch 3877/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0698 - accuracy: 0.7561 - val_loss: 0.0792 - val_accuracy: 0.7253\n",
      "Epoch 3878/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0700 - accuracy: 0.7557 - val_loss: 0.0788 - val_accuracy: 0.7263\n",
      "Epoch 3879/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0697 - accuracy: 0.7574 - val_loss: 0.0789 - val_accuracy: 0.7274\n",
      "Epoch 3880/5000\n",
      "11786/11786 [==============================] - 8s 655us/step - loss: 0.0695 - accuracy: 0.7583 - val_loss: 0.0783 - val_accuracy: 0.7288\n",
      "Epoch 3881/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0694 - accuracy: 0.7582 - val_loss: 0.0782 - val_accuracy: 0.7263\n",
      "Epoch 3882/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0694 - accuracy: 0.7580 - val_loss: 0.0786 - val_accuracy: 0.7249\n",
      "Epoch 3883/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0692 - accuracy: 0.7580 - val_loss: 0.0782 - val_accuracy: 0.7265\n",
      "Epoch 3884/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0694 - accuracy: 0.7578 - val_loss: 0.0779 - val_accuracy: 0.7279\n",
      "Epoch 3885/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0693 - accuracy: 0.7580 - val_loss: 0.0794 - val_accuracy: 0.7262\n",
      "Epoch 3886/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0692 - accuracy: 0.7591 - val_loss: 0.0774 - val_accuracy: 0.7298\n",
      "Epoch 3887/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0696 - accuracy: 0.7573 - val_loss: 0.0785 - val_accuracy: 0.7255\n",
      "Epoch 3888/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0692 - accuracy: 0.7583 - val_loss: 0.0782 - val_accuracy: 0.7270\n",
      "Epoch 3889/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0693 - accuracy: 0.7582 - val_loss: 0.0776 - val_accuracy: 0.7297\n",
      "Epoch 3890/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0694 - accuracy: 0.7583 - val_loss: 0.0781 - val_accuracy: 0.7265\n",
      "Epoch 3891/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0692 - accuracy: 0.7586 - val_loss: 0.0792 - val_accuracy: 0.7261\n",
      "Epoch 3892/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0696 - accuracy: 0.7577 - val_loss: 0.0782 - val_accuracy: 0.7276\n",
      "Epoch 3893/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0695 - accuracy: 0.7579 - val_loss: 0.0785 - val_accuracy: 0.7258\n",
      "Epoch 3894/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0693 - accuracy: 0.7584 - val_loss: 0.0795 - val_accuracy: 0.7209\n",
      "Epoch 3895/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0692 - accuracy: 0.7584 - val_loss: 0.0780 - val_accuracy: 0.7264\n",
      "Epoch 3896/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0691 - accuracy: 0.7587 - val_loss: 0.0777 - val_accuracy: 0.7291\n",
      "Epoch 3897/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0693 - accuracy: 0.7579 - val_loss: 0.0803 - val_accuracy: 0.7240\n",
      "Epoch 3898/5000\n",
      "11786/11786 [==============================] - 8s 656us/step - loss: 0.0694 - accuracy: 0.7571 - val_loss: 0.0800 - val_accuracy: 0.7187\n",
      "Epoch 3899/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0690 - accuracy: 0.7587 - val_loss: 0.0779 - val_accuracy: 0.7282\n",
      "Epoch 3900/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0694 - accuracy: 0.7579 - val_loss: 0.0790 - val_accuracy: 0.7246\n",
      "Epoch 3901/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0694 - accuracy: 0.7579 - val_loss: 0.0779 - val_accuracy: 0.7263\n",
      "Epoch 3902/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0694 - accuracy: 0.7576 - val_loss: 0.0779 - val_accuracy: 0.7263\n",
      "Epoch 3903/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0694 - accuracy: 0.7576 - val_loss: 0.0789 - val_accuracy: 0.7250\n",
      "Epoch 3904/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0695 - accuracy: 0.7579 - val_loss: 0.0784 - val_accuracy: 0.7283\n",
      "Epoch 3905/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0695 - accuracy: 0.7566 - val_loss: 0.0788 - val_accuracy: 0.7265\n",
      "Epoch 3906/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0696 - accuracy: 0.7571 - val_loss: 0.0785 - val_accuracy: 0.7239\n",
      "Epoch 3907/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0695 - accuracy: 0.7575 - val_loss: 0.0786 - val_accuracy: 0.7245\n",
      "Epoch 3908/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0693 - accuracy: 0.7583 - val_loss: 0.0781 - val_accuracy: 0.7266\n",
      "Epoch 3909/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0695 - accuracy: 0.7573 - val_loss: 0.0782 - val_accuracy: 0.7272\n",
      "Epoch 3910/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0695 - accuracy: 0.7575 - val_loss: 0.0780 - val_accuracy: 0.7286\n",
      "Epoch 3911/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0695 - accuracy: 0.7573 - val_loss: 0.0785 - val_accuracy: 0.7285\n",
      "Epoch 3912/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0694 - accuracy: 0.7578 - val_loss: 0.0793 - val_accuracy: 0.7237\n",
      "Epoch 3913/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0694 - accuracy: 0.7580 - val_loss: 0.0794 - val_accuracy: 0.7262\n",
      "Epoch 3914/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0696 - accuracy: 0.7572 - val_loss: 0.0795 - val_accuracy: 0.7234\n",
      "Epoch 3915/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0698 - accuracy: 0.7561 - val_loss: 0.0783 - val_accuracy: 0.7278\n",
      "Epoch 3916/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0694 - accuracy: 0.7579 - val_loss: 0.0788 - val_accuracy: 0.7291\n",
      "Epoch 3917/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0693 - accuracy: 0.7581 - val_loss: 0.0782 - val_accuracy: 0.7270\n",
      "Epoch 3918/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0696 - accuracy: 0.7572 - val_loss: 0.0785 - val_accuracy: 0.7256\n",
      "Epoch 3919/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0697 - accuracy: 0.7573 - val_loss: 0.0788 - val_accuracy: 0.7277\n",
      "Epoch 3920/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0697 - accuracy: 0.7571 - val_loss: 0.0782 - val_accuracy: 0.7275\n",
      "Epoch 3921/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0695 - accuracy: 0.7578 - val_loss: 0.0786 - val_accuracy: 0.7280\n",
      "Epoch 3922/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0695 - accuracy: 0.7577 - val_loss: 0.0787 - val_accuracy: 0.7285\n",
      "Epoch 3923/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0699 - accuracy: 0.7561 - val_loss: 0.0788 - val_accuracy: 0.7232\n",
      "Epoch 3924/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0697 - accuracy: 0.7565 - val_loss: 0.0780 - val_accuracy: 0.7289\n",
      "Epoch 3925/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0694 - accuracy: 0.7578 - val_loss: 0.0777 - val_accuracy: 0.7287\n",
      "Epoch 3926/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0695 - accuracy: 0.7573 - val_loss: 0.0779 - val_accuracy: 0.7286\n",
      "Epoch 3927/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0696 - accuracy: 0.7572 - val_loss: 0.0781 - val_accuracy: 0.7264\n",
      "Epoch 3928/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0696 - accuracy: 0.7569 - val_loss: 0.0787 - val_accuracy: 0.7272\n",
      "Epoch 3929/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0695 - accuracy: 0.7576 - val_loss: 0.0780 - val_accuracy: 0.7263\n",
      "Epoch 3930/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0697 - accuracy: 0.7562 - val_loss: 0.0790 - val_accuracy: 0.7245\n",
      "Epoch 3931/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0697 - accuracy: 0.7562 - val_loss: 0.0784 - val_accuracy: 0.7270\n",
      "Epoch 3932/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0696 - accuracy: 0.7572 - val_loss: 0.0786 - val_accuracy: 0.7268\n",
      "Epoch 3933/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0699 - accuracy: 0.7558 - val_loss: 0.0795 - val_accuracy: 0.7207\n",
      "Epoch 3934/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0696 - accuracy: 0.7569 - val_loss: 0.0810 - val_accuracy: 0.7189\n",
      "Epoch 3935/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0700 - accuracy: 0.7553 - val_loss: 0.0786 - val_accuracy: 0.7253\n",
      "Epoch 3936/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0696 - accuracy: 0.7575 - val_loss: 0.0792 - val_accuracy: 0.7233\n",
      "Epoch 3937/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0697 - accuracy: 0.7565 - val_loss: 0.0786 - val_accuracy: 0.7246\n",
      "Epoch 3938/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0698 - accuracy: 0.7565 - val_loss: 0.0782 - val_accuracy: 0.7278\n",
      "Epoch 3939/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0699 - accuracy: 0.7558 - val_loss: 0.0785 - val_accuracy: 0.7253\n",
      "Epoch 3940/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0692 - accuracy: 0.7585 - val_loss: 0.0781 - val_accuracy: 0.7252\n",
      "Epoch 3941/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0694 - accuracy: 0.7577 - val_loss: 0.0783 - val_accuracy: 0.7283\n",
      "Epoch 3942/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0695 - accuracy: 0.7575 - val_loss: 0.0778 - val_accuracy: 0.7279\n",
      "Epoch 3943/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0694 - accuracy: 0.7577 - val_loss: 0.0788 - val_accuracy: 0.7274\n",
      "Epoch 3944/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0696 - accuracy: 0.7572 - val_loss: 0.0779 - val_accuracy: 0.7278\n",
      "Epoch 3945/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0697 - accuracy: 0.7567 - val_loss: 0.0780 - val_accuracy: 0.7288\n",
      "Epoch 3946/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0697 - accuracy: 0.7565 - val_loss: 0.0781 - val_accuracy: 0.7276\n",
      "Epoch 3947/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0697 - accuracy: 0.7567 - val_loss: 0.0783 - val_accuracy: 0.7266\n",
      "Epoch 3948/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0696 - accuracy: 0.7568 - val_loss: 0.0783 - val_accuracy: 0.7251\n",
      "Epoch 3949/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0696 - accuracy: 0.7575 - val_loss: 0.0778 - val_accuracy: 0.7299\n",
      "Epoch 3950/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0698 - accuracy: 0.7571 - val_loss: 0.0790 - val_accuracy: 0.7251\n",
      "Epoch 3951/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0696 - accuracy: 0.7567 - val_loss: 0.0795 - val_accuracy: 0.7244\n",
      "Epoch 3952/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0694 - accuracy: 0.7578 - val_loss: 0.0791 - val_accuracy: 0.7251\n",
      "Epoch 3953/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0697 - accuracy: 0.7562 - val_loss: 0.0786 - val_accuracy: 0.7256\n",
      "Epoch 3954/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0697 - accuracy: 0.7566 - val_loss: 0.0779 - val_accuracy: 0.7284\n",
      "Epoch 3955/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0697 - accuracy: 0.7569 - val_loss: 0.0787 - val_accuracy: 0.7277\n",
      "Epoch 3956/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0697 - accuracy: 0.7559 - val_loss: 0.0781 - val_accuracy: 0.7275\n",
      "Epoch 3957/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0695 - accuracy: 0.7566 - val_loss: 0.0786 - val_accuracy: 0.7253\n",
      "Epoch 3958/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0695 - accuracy: 0.7571 - val_loss: 0.0790 - val_accuracy: 0.7252\n",
      "Epoch 3959/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0698 - accuracy: 0.7559 - val_loss: 0.0789 - val_accuracy: 0.7261\n",
      "Epoch 3960/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0696 - accuracy: 0.7567 - val_loss: 0.0784 - val_accuracy: 0.7262\n",
      "Epoch 3961/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0695 - accuracy: 0.7565 - val_loss: 0.0781 - val_accuracy: 0.7262\n",
      "Epoch 3962/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0696 - accuracy: 0.7563 - val_loss: 0.0778 - val_accuracy: 0.7280\n",
      "Epoch 3963/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0697 - accuracy: 0.7567 - val_loss: 0.0779 - val_accuracy: 0.7268\n",
      "Epoch 3964/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0696 - accuracy: 0.7570 - val_loss: 0.0786 - val_accuracy: 0.7256\n",
      "Epoch 3965/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0695 - accuracy: 0.7576 - val_loss: 0.0783 - val_accuracy: 0.7277\n",
      "Epoch 3966/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0697 - accuracy: 0.7568 - val_loss: 0.0785 - val_accuracy: 0.7253\n",
      "Epoch 3967/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0697 - accuracy: 0.7565 - val_loss: 0.0787 - val_accuracy: 0.7266\n",
      "Epoch 3968/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0693 - accuracy: 0.7576 - val_loss: 0.0794 - val_accuracy: 0.7240\n",
      "Epoch 3969/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0695 - accuracy: 0.7572 - val_loss: 0.0792 - val_accuracy: 0.7259\n",
      "Epoch 3970/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0697 - accuracy: 0.7562 - val_loss: 0.0789 - val_accuracy: 0.7257\n",
      "Epoch 3971/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0698 - accuracy: 0.7563 - val_loss: 0.0785 - val_accuracy: 0.7276\n",
      "Epoch 3972/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0696 - accuracy: 0.7574 - val_loss: 0.0789 - val_accuracy: 0.7245\n",
      "Epoch 3973/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0700 - accuracy: 0.7552 - val_loss: 0.0805 - val_accuracy: 0.7211\n",
      "Epoch 3974/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0698 - accuracy: 0.7561 - val_loss: 0.0785 - val_accuracy: 0.7264\n",
      "Epoch 3975/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0697 - accuracy: 0.7559 - val_loss: 0.0791 - val_accuracy: 0.7250\n",
      "Epoch 3976/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0698 - accuracy: 0.7566 - val_loss: 0.0778 - val_accuracy: 0.7287\n",
      "Epoch 3977/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0697 - accuracy: 0.7570 - val_loss: 0.0787 - val_accuracy: 0.7234\n",
      "Epoch 3978/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0697 - accuracy: 0.7562 - val_loss: 0.0780 - val_accuracy: 0.7269\n",
      "Epoch 3979/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0696 - accuracy: 0.7566 - val_loss: 0.0783 - val_accuracy: 0.7263\n",
      "Epoch 3980/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0696 - accuracy: 0.7567 - val_loss: 0.0783 - val_accuracy: 0.7248\n",
      "Epoch 3981/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0696 - accuracy: 0.7566 - val_loss: 0.0787 - val_accuracy: 0.7270\n",
      "Epoch 3982/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0696 - accuracy: 0.7562 - val_loss: 0.0794 - val_accuracy: 0.7252\n",
      "Epoch 3983/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0699 - accuracy: 0.7559 - val_loss: 0.0782 - val_accuracy: 0.7259\n",
      "Epoch 3984/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0701 - accuracy: 0.7546 - val_loss: 0.0786 - val_accuracy: 0.7270\n",
      "Epoch 3985/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0699 - accuracy: 0.7549 - val_loss: 0.0780 - val_accuracy: 0.7272\n",
      "Epoch 3986/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0698 - accuracy: 0.7566 - val_loss: 0.0782 - val_accuracy: 0.7251\n",
      "Epoch 3987/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0698 - accuracy: 0.7562 - val_loss: 0.0792 - val_accuracy: 0.7236\n",
      "Epoch 3988/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0696 - accuracy: 0.7562 - val_loss: 0.0791 - val_accuracy: 0.7257\n",
      "Epoch 3989/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0697 - accuracy: 0.7565 - val_loss: 0.0788 - val_accuracy: 0.7261\n",
      "Epoch 3990/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0696 - accuracy: 0.7566 - val_loss: 0.0788 - val_accuracy: 0.7266\n",
      "Epoch 3991/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0698 - accuracy: 0.7560 - val_loss: 0.0782 - val_accuracy: 0.7254\n",
      "Epoch 3992/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0696 - accuracy: 0.7572 - val_loss: 0.0783 - val_accuracy: 0.7287\n",
      "Epoch 3993/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0695 - accuracy: 0.7565 - val_loss: 0.0794 - val_accuracy: 0.7215\n",
      "Epoch 3994/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0696 - accuracy: 0.7566 - val_loss: 0.0779 - val_accuracy: 0.7251\n",
      "Epoch 3995/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0697 - accuracy: 0.7567 - val_loss: 0.0794 - val_accuracy: 0.7263\n",
      "Epoch 3996/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0693 - accuracy: 0.7576 - val_loss: 0.0777 - val_accuracy: 0.7271\n",
      "Epoch 3997/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0696 - accuracy: 0.7568 - val_loss: 0.0784 - val_accuracy: 0.7277\n",
      "Epoch 3998/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0696 - accuracy: 0.7567 - val_loss: 0.0782 - val_accuracy: 0.7280\n",
      "Epoch 3999/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0695 - accuracy: 0.7570 - val_loss: 0.0783 - val_accuracy: 0.7273\n",
      "Epoch 4000/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0696 - accuracy: 0.7561 - val_loss: 0.0783 - val_accuracy: 0.7258\n",
      "Epoch 4001/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0694 - accuracy: 0.7569 - val_loss: 0.0787 - val_accuracy: 0.7237\n",
      "Epoch 4002/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0696 - accuracy: 0.7562 - val_loss: 0.0783 - val_accuracy: 0.7269\n",
      "Epoch 4003/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0698 - accuracy: 0.7566 - val_loss: 0.0783 - val_accuracy: 0.7273\n",
      "Epoch 4004/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0697 - accuracy: 0.7567 - val_loss: 0.0783 - val_accuracy: 0.7277\n",
      "Epoch 4005/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0698 - accuracy: 0.7561 - val_loss: 0.0785 - val_accuracy: 0.7244\n",
      "Epoch 4006/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0696 - accuracy: 0.7563 - val_loss: 0.0783 - val_accuracy: 0.7264\n",
      "Epoch 4007/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0694 - accuracy: 0.7575 - val_loss: 0.0790 - val_accuracy: 0.7256\n",
      "Epoch 4008/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0699 - accuracy: 0.7566 - val_loss: 0.0783 - val_accuracy: 0.7250\n",
      "Epoch 4009/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0696 - accuracy: 0.7567 - val_loss: 0.0782 - val_accuracy: 0.7267\n",
      "Epoch 4010/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0698 - accuracy: 0.7557 - val_loss: 0.0786 - val_accuracy: 0.7226\n",
      "Epoch 4011/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0696 - accuracy: 0.7565 - val_loss: 0.0794 - val_accuracy: 0.7227\n",
      "Epoch 4012/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0700 - accuracy: 0.7553 - val_loss: 0.0787 - val_accuracy: 0.7241\n",
      "Epoch 4013/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0698 - accuracy: 0.7555 - val_loss: 0.0793 - val_accuracy: 0.7240\n",
      "Epoch 4014/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0697 - accuracy: 0.7560 - val_loss: 0.0784 - val_accuracy: 0.7243\n",
      "Epoch 4015/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0696 - accuracy: 0.7566 - val_loss: 0.0789 - val_accuracy: 0.7220\n",
      "Epoch 4016/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0695 - accuracy: 0.7566 - val_loss: 0.0782 - val_accuracy: 0.7256\n",
      "Epoch 4017/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0699 - accuracy: 0.7557 - val_loss: 0.0795 - val_accuracy: 0.7240\n",
      "Epoch 4018/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0700 - accuracy: 0.7556 - val_loss: 0.0787 - val_accuracy: 0.7263\n",
      "Epoch 4019/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0697 - accuracy: 0.7559 - val_loss: 0.0788 - val_accuracy: 0.7247\n",
      "Epoch 4020/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0697 - accuracy: 0.7562 - val_loss: 0.0789 - val_accuracy: 0.7243\n",
      "Epoch 4021/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0702 - accuracy: 0.7547 - val_loss: 0.0785 - val_accuracy: 0.7265\n",
      "Epoch 4022/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0699 - accuracy: 0.7561 - val_loss: 0.0789 - val_accuracy: 0.7231\n",
      "Epoch 4023/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0699 - accuracy: 0.7559 - val_loss: 0.0787 - val_accuracy: 0.7248\n",
      "Epoch 4024/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0700 - accuracy: 0.7558 - val_loss: 0.0789 - val_accuracy: 0.7252\n",
      "Epoch 4025/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0701 - accuracy: 0.7554 - val_loss: 0.0793 - val_accuracy: 0.7247\n",
      "Epoch 4026/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0698 - accuracy: 0.7564 - val_loss: 0.0787 - val_accuracy: 0.7270\n",
      "Epoch 4027/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0696 - accuracy: 0.7569 - val_loss: 0.0788 - val_accuracy: 0.7250\n",
      "Epoch 4028/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0699 - accuracy: 0.7554 - val_loss: 0.0794 - val_accuracy: 0.7243\n",
      "Epoch 4029/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0698 - accuracy: 0.7557 - val_loss: 0.0785 - val_accuracy: 0.7266\n",
      "Epoch 4030/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0697 - accuracy: 0.7563 - val_loss: 0.0792 - val_accuracy: 0.7226\n",
      "Epoch 4031/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0697 - accuracy: 0.7566 - val_loss: 0.0794 - val_accuracy: 0.7238\n",
      "Epoch 4032/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0698 - accuracy: 0.7560 - val_loss: 0.0786 - val_accuracy: 0.7259\n",
      "Epoch 4033/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0701 - accuracy: 0.7558 - val_loss: 0.0785 - val_accuracy: 0.7249\n",
      "Epoch 4034/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0699 - accuracy: 0.7553 - val_loss: 0.0788 - val_accuracy: 0.7249\n",
      "Epoch 4035/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0696 - accuracy: 0.7571 - val_loss: 0.0791 - val_accuracy: 0.7257\n",
      "Epoch 4036/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0696 - accuracy: 0.7560 - val_loss: 0.0792 - val_accuracy: 0.7244\n",
      "Epoch 4037/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0698 - accuracy: 0.7564 - val_loss: 0.0788 - val_accuracy: 0.7260\n",
      "Epoch 4038/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0698 - accuracy: 0.7563 - val_loss: 0.0789 - val_accuracy: 0.7238\n",
      "Epoch 4039/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0697 - accuracy: 0.7560 - val_loss: 0.0788 - val_accuracy: 0.7242\n",
      "Epoch 4040/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0700 - accuracy: 0.7551 - val_loss: 0.0785 - val_accuracy: 0.7253\n",
      "Epoch 4041/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0700 - accuracy: 0.7553 - val_loss: 0.0796 - val_accuracy: 0.7197\n",
      "Epoch 4042/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0699 - accuracy: 0.7553 - val_loss: 0.0778 - val_accuracy: 0.7262\n",
      "Epoch 4043/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0699 - accuracy: 0.7555 - val_loss: 0.0787 - val_accuracy: 0.7254\n",
      "Epoch 4044/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0697 - accuracy: 0.7565 - val_loss: 0.0783 - val_accuracy: 0.7263\n",
      "Epoch 4045/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0701 - accuracy: 0.7548 - val_loss: 0.0793 - val_accuracy: 0.7255\n",
      "Epoch 4046/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0702 - accuracy: 0.7544 - val_loss: 0.0788 - val_accuracy: 0.7260\n",
      "Epoch 4047/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0698 - accuracy: 0.7558 - val_loss: 0.0784 - val_accuracy: 0.7253\n",
      "Epoch 4048/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0700 - accuracy: 0.7558 - val_loss: 0.0790 - val_accuracy: 0.7226\n",
      "Epoch 4049/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0700 - accuracy: 0.7555 - val_loss: 0.0783 - val_accuracy: 0.7269\n",
      "Epoch 4050/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0698 - accuracy: 0.7560 - val_loss: 0.0798 - val_accuracy: 0.7215\n",
      "Epoch 4051/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0700 - accuracy: 0.7556 - val_loss: 0.0794 - val_accuracy: 0.7229\n",
      "Epoch 4052/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0698 - accuracy: 0.7556 - val_loss: 0.0788 - val_accuracy: 0.7251\n",
      "Epoch 4053/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0701 - accuracy: 0.7546 - val_loss: 0.0798 - val_accuracy: 0.7226\n",
      "Epoch 4054/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0701 - accuracy: 0.7548 - val_loss: 0.0786 - val_accuracy: 0.7255\n",
      "Epoch 4055/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0700 - accuracy: 0.7545 - val_loss: 0.0789 - val_accuracy: 0.7228\n",
      "Epoch 4056/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0698 - accuracy: 0.7559 - val_loss: 0.0790 - val_accuracy: 0.7236\n",
      "Epoch 4057/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0699 - accuracy: 0.7551 - val_loss: 0.0781 - val_accuracy: 0.7250\n",
      "Epoch 4058/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0700 - accuracy: 0.7551 - val_loss: 0.0788 - val_accuracy: 0.7244\n",
      "Epoch 4059/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0701 - accuracy: 0.7551 - val_loss: 0.0792 - val_accuracy: 0.7266\n",
      "Epoch 4060/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0702 - accuracy: 0.7547 - val_loss: 0.0798 - val_accuracy: 0.7225\n",
      "Epoch 4061/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0704 - accuracy: 0.7547 - val_loss: 0.0803 - val_accuracy: 0.7197\n",
      "Epoch 4062/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0703 - accuracy: 0.7548 - val_loss: 0.0791 - val_accuracy: 0.7230\n",
      "Epoch 4063/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0702 - accuracy: 0.7550 - val_loss: 0.0791 - val_accuracy: 0.7254\n",
      "Epoch 4064/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0701 - accuracy: 0.7545 - val_loss: 0.0792 - val_accuracy: 0.7227\n",
      "Epoch 4065/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0700 - accuracy: 0.7550 - val_loss: 0.0790 - val_accuracy: 0.7243\n",
      "Epoch 4066/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0699 - accuracy: 0.7559 - val_loss: 0.0801 - val_accuracy: 0.7223\n",
      "Epoch 4067/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0703 - accuracy: 0.7544 - val_loss: 0.0786 - val_accuracy: 0.7264\n",
      "Epoch 4068/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0702 - accuracy: 0.7548 - val_loss: 0.0786 - val_accuracy: 0.7226\n",
      "Epoch 4069/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0700 - accuracy: 0.7546 - val_loss: 0.0790 - val_accuracy: 0.7254\n",
      "Epoch 4070/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0700 - accuracy: 0.7549 - val_loss: 0.0793 - val_accuracy: 0.7212\n",
      "Epoch 4071/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0698 - accuracy: 0.7553 - val_loss: 0.0791 - val_accuracy: 0.7220\n",
      "Epoch 4072/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0700 - accuracy: 0.7551 - val_loss: 0.0791 - val_accuracy: 0.7249\n",
      "Epoch 4073/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0701 - accuracy: 0.7544 - val_loss: 0.0790 - val_accuracy: 0.7235\n",
      "Epoch 4074/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0698 - accuracy: 0.7562 - val_loss: 0.0791 - val_accuracy: 0.7253\n",
      "Epoch 4075/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0701 - accuracy: 0.7552 - val_loss: 0.0785 - val_accuracy: 0.7250\n",
      "Epoch 4076/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0701 - accuracy: 0.7553 - val_loss: 0.0803 - val_accuracy: 0.7191\n",
      "Epoch 4077/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0699 - accuracy: 0.7559 - val_loss: 0.0784 - val_accuracy: 0.7254\n",
      "Epoch 4078/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0700 - accuracy: 0.7556 - val_loss: 0.0796 - val_accuracy: 0.7223\n",
      "Epoch 4079/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0699 - accuracy: 0.7554 - val_loss: 0.0782 - val_accuracy: 0.7273\n",
      "Epoch 4080/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0699 - accuracy: 0.7550 - val_loss: 0.0802 - val_accuracy: 0.7203\n",
      "Epoch 4081/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0698 - accuracy: 0.7553 - val_loss: 0.0788 - val_accuracy: 0.7261\n",
      "Epoch 4082/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0699 - accuracy: 0.7553 - val_loss: 0.0790 - val_accuracy: 0.7238\n",
      "Epoch 4083/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0699 - accuracy: 0.7558 - val_loss: 0.0786 - val_accuracy: 0.7245\n",
      "Epoch 4084/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0700 - accuracy: 0.7552 - val_loss: 0.0793 - val_accuracy: 0.7246\n",
      "Epoch 4085/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0700 - accuracy: 0.7552 - val_loss: 0.0787 - val_accuracy: 0.7247\n",
      "Epoch 4086/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0698 - accuracy: 0.7559 - val_loss: 0.0796 - val_accuracy: 0.7250\n",
      "Epoch 4087/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0700 - accuracy: 0.7553 - val_loss: 0.0809 - val_accuracy: 0.7191\n",
      "Epoch 4088/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0700 - accuracy: 0.7561 - val_loss: 0.0796 - val_accuracy: 0.7260\n",
      "Epoch 4089/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0700 - accuracy: 0.7547 - val_loss: 0.0792 - val_accuracy: 0.7216\n",
      "Epoch 4090/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0701 - accuracy: 0.7543 - val_loss: 0.0788 - val_accuracy: 0.7223\n",
      "Epoch 4091/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0699 - accuracy: 0.7554 - val_loss: 0.0778 - val_accuracy: 0.7277\n",
      "Epoch 4092/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0701 - accuracy: 0.7546 - val_loss: 0.0804 - val_accuracy: 0.7219\n",
      "Epoch 4093/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0697 - accuracy: 0.7565 - val_loss: 0.0790 - val_accuracy: 0.7235\n",
      "Epoch 4094/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0699 - accuracy: 0.7554 - val_loss: 0.0789 - val_accuracy: 0.7272\n",
      "Epoch 4095/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0700 - accuracy: 0.7553 - val_loss: 0.0792 - val_accuracy: 0.7228\n",
      "Epoch 4096/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0701 - accuracy: 0.7544 - val_loss: 0.0794 - val_accuracy: 0.7232\n",
      "Epoch 4097/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0700 - accuracy: 0.7553 - val_loss: 0.0785 - val_accuracy: 0.7259\n",
      "Epoch 4098/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0698 - accuracy: 0.7559 - val_loss: 0.0796 - val_accuracy: 0.7224\n",
      "Epoch 4099/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0699 - accuracy: 0.7555 - val_loss: 0.0785 - val_accuracy: 0.7280\n",
      "Epoch 4100/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0700 - accuracy: 0.7552 - val_loss: 0.0783 - val_accuracy: 0.7262\n",
      "Epoch 4101/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0700 - accuracy: 0.7556 - val_loss: 0.0794 - val_accuracy: 0.7220\n",
      "Epoch 4102/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0702 - accuracy: 0.7544 - val_loss: 0.0790 - val_accuracy: 0.7239\n",
      "Epoch 4103/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0702 - accuracy: 0.7544 - val_loss: 0.0795 - val_accuracy: 0.7233\n",
      "Epoch 4104/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0701 - accuracy: 0.7543 - val_loss: 0.0784 - val_accuracy: 0.7269\n",
      "Epoch 4105/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0698 - accuracy: 0.7551 - val_loss: 0.0785 - val_accuracy: 0.7249\n",
      "Epoch 4106/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0699 - accuracy: 0.7557 - val_loss: 0.0781 - val_accuracy: 0.7262\n",
      "Epoch 4107/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0697 - accuracy: 0.7562 - val_loss: 0.0787 - val_accuracy: 0.7270\n",
      "Epoch 4108/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0697 - accuracy: 0.7558 - val_loss: 0.0789 - val_accuracy: 0.7263\n",
      "Epoch 4109/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0698 - accuracy: 0.7560 - val_loss: 0.0790 - val_accuracy: 0.7240\n",
      "Epoch 4110/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0701 - accuracy: 0.7552 - val_loss: 0.0785 - val_accuracy: 0.7267\n",
      "Epoch 4111/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0696 - accuracy: 0.7560 - val_loss: 0.0790 - val_accuracy: 0.7262\n",
      "Epoch 4112/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0698 - accuracy: 0.7561 - val_loss: 0.0791 - val_accuracy: 0.7279\n",
      "Epoch 4113/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0700 - accuracy: 0.7555 - val_loss: 0.0790 - val_accuracy: 0.7263\n",
      "Epoch 4114/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0697 - accuracy: 0.7568 - val_loss: 0.0785 - val_accuracy: 0.7253\n",
      "Epoch 4115/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0698 - accuracy: 0.7560 - val_loss: 0.0789 - val_accuracy: 0.7251\n",
      "Epoch 4116/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0700 - accuracy: 0.7559 - val_loss: 0.0786 - val_accuracy: 0.7234\n",
      "Epoch 4117/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0697 - accuracy: 0.7565 - val_loss: 0.0796 - val_accuracy: 0.7253\n",
      "Epoch 4118/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0699 - accuracy: 0.7554 - val_loss: 0.0799 - val_accuracy: 0.7228\n",
      "Epoch 4119/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0702 - accuracy: 0.7550 - val_loss: 0.0782 - val_accuracy: 0.7272\n",
      "Epoch 4120/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0702 - accuracy: 0.7544 - val_loss: 0.0790 - val_accuracy: 0.7237\n",
      "Epoch 4121/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0700 - accuracy: 0.7549 - val_loss: 0.0784 - val_accuracy: 0.7258\n",
      "Epoch 4122/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0698 - accuracy: 0.7559 - val_loss: 0.0791 - val_accuracy: 0.7210\n",
      "Epoch 4123/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0701 - accuracy: 0.7548 - val_loss: 0.0777 - val_accuracy: 0.7272\n",
      "Epoch 4124/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0701 - accuracy: 0.7546 - val_loss: 0.0782 - val_accuracy: 0.7256\n",
      "Epoch 4125/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0700 - accuracy: 0.7544 - val_loss: 0.0780 - val_accuracy: 0.7276\n",
      "Epoch 4126/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0700 - accuracy: 0.7552 - val_loss: 0.0786 - val_accuracy: 0.7249\n",
      "Epoch 4127/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0701 - accuracy: 0.7555 - val_loss: 0.0789 - val_accuracy: 0.7238\n",
      "Epoch 4128/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0700 - accuracy: 0.7550 - val_loss: 0.0786 - val_accuracy: 0.7243\n",
      "Epoch 4129/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0699 - accuracy: 0.7557 - val_loss: 0.0780 - val_accuracy: 0.7284\n",
      "Epoch 4130/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0697 - accuracy: 0.7558 - val_loss: 0.0792 - val_accuracy: 0.7244\n",
      "Epoch 4131/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0695 - accuracy: 0.7562 - val_loss: 0.0780 - val_accuracy: 0.7269\n",
      "Epoch 4132/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0695 - accuracy: 0.7565 - val_loss: 0.0784 - val_accuracy: 0.7274\n",
      "Epoch 4133/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0697 - accuracy: 0.7565 - val_loss: 0.0783 - val_accuracy: 0.7271\n",
      "Epoch 4134/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0698 - accuracy: 0.7553 - val_loss: 0.0785 - val_accuracy: 0.7253\n",
      "Epoch 4135/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0699 - accuracy: 0.7555 - val_loss: 0.0780 - val_accuracy: 0.7262\n",
      "Epoch 4136/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0699 - accuracy: 0.7554 - val_loss: 0.0806 - val_accuracy: 0.7157\n",
      "Epoch 4137/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0700 - accuracy: 0.7547 - val_loss: 0.0790 - val_accuracy: 0.7241\n",
      "Epoch 4138/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0698 - accuracy: 0.7559 - val_loss: 0.0785 - val_accuracy: 0.7245\n",
      "Epoch 4139/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0698 - accuracy: 0.7557 - val_loss: 0.0784 - val_accuracy: 0.7262\n",
      "Epoch 4140/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0699 - accuracy: 0.7562 - val_loss: 0.0789 - val_accuracy: 0.7247\n",
      "Epoch 4141/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0699 - accuracy: 0.7562 - val_loss: 0.0794 - val_accuracy: 0.7222\n",
      "Epoch 4142/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0698 - accuracy: 0.7558 - val_loss: 0.0782 - val_accuracy: 0.7263\n",
      "Epoch 4143/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0697 - accuracy: 0.7564 - val_loss: 0.0790 - val_accuracy: 0.7227\n",
      "Epoch 4144/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0697 - accuracy: 0.7559 - val_loss: 0.0790 - val_accuracy: 0.7232\n",
      "Epoch 4145/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0699 - accuracy: 0.7552 - val_loss: 0.0805 - val_accuracy: 0.7227\n",
      "Epoch 4146/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0696 - accuracy: 0.7562 - val_loss: 0.0785 - val_accuracy: 0.7260\n",
      "Epoch 4147/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0698 - accuracy: 0.7563 - val_loss: 0.0783 - val_accuracy: 0.7273\n",
      "Epoch 4148/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0698 - accuracy: 0.7559 - val_loss: 0.0788 - val_accuracy: 0.7247\n",
      "Epoch 4149/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0698 - accuracy: 0.7560 - val_loss: 0.0801 - val_accuracy: 0.7192\n",
      "Epoch 4150/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0699 - accuracy: 0.7558 - val_loss: 0.0783 - val_accuracy: 0.7266\n",
      "Epoch 4151/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0698 - accuracy: 0.7563 - val_loss: 0.0784 - val_accuracy: 0.7268\n",
      "Epoch 4152/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0697 - accuracy: 0.7557 - val_loss: 0.0792 - val_accuracy: 0.7253\n",
      "Epoch 4153/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0697 - accuracy: 0.7565 - val_loss: 0.0797 - val_accuracy: 0.7251\n",
      "Epoch 4154/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0699 - accuracy: 0.7561 - val_loss: 0.0787 - val_accuracy: 0.7255\n",
      "Epoch 4155/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0699 - accuracy: 0.7556 - val_loss: 0.0781 - val_accuracy: 0.7245\n",
      "Epoch 4156/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0698 - accuracy: 0.7555 - val_loss: 0.0786 - val_accuracy: 0.7262\n",
      "Epoch 4157/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0699 - accuracy: 0.7554 - val_loss: 0.0808 - val_accuracy: 0.7166\n",
      "Epoch 4158/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0701 - accuracy: 0.7554 - val_loss: 0.0784 - val_accuracy: 0.7259\n",
      "Epoch 4159/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0700 - accuracy: 0.7549 - val_loss: 0.0793 - val_accuracy: 0.7233\n",
      "Epoch 4160/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0699 - accuracy: 0.7551 - val_loss: 0.0795 - val_accuracy: 0.7229\n",
      "Epoch 4161/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0698 - accuracy: 0.7556 - val_loss: 0.0786 - val_accuracy: 0.7248\n",
      "Epoch 4162/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0697 - accuracy: 0.7562 - val_loss: 0.0785 - val_accuracy: 0.7275\n",
      "Epoch 4163/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0699 - accuracy: 0.7561 - val_loss: 0.0785 - val_accuracy: 0.7265\n",
      "Epoch 4164/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0699 - accuracy: 0.7552 - val_loss: 0.0785 - val_accuracy: 0.7236\n",
      "Epoch 4165/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0702 - accuracy: 0.7546 - val_loss: 0.0801 - val_accuracy: 0.7205\n",
      "Epoch 4166/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0701 - accuracy: 0.7553 - val_loss: 0.0785 - val_accuracy: 0.7260\n",
      "Epoch 4167/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0698 - accuracy: 0.7563 - val_loss: 0.0796 - val_accuracy: 0.7247\n",
      "Epoch 4168/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0702 - accuracy: 0.7551 - val_loss: 0.0788 - val_accuracy: 0.7249\n",
      "Epoch 4169/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0699 - accuracy: 0.7554 - val_loss: 0.0783 - val_accuracy: 0.7262\n",
      "Epoch 4170/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0703 - accuracy: 0.7546 - val_loss: 0.0791 - val_accuracy: 0.7249\n",
      "Epoch 4171/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0700 - accuracy: 0.7553 - val_loss: 0.0802 - val_accuracy: 0.7220\n",
      "Epoch 4172/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0702 - accuracy: 0.7542 - val_loss: 0.0787 - val_accuracy: 0.7252\n",
      "Epoch 4173/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0701 - accuracy: 0.7546 - val_loss: 0.0786 - val_accuracy: 0.7248\n",
      "Epoch 4174/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0699 - accuracy: 0.7553 - val_loss: 0.0775 - val_accuracy: 0.7276\n",
      "Epoch 4175/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0700 - accuracy: 0.7550 - val_loss: 0.0786 - val_accuracy: 0.7246\n",
      "Epoch 4176/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0701 - accuracy: 0.7553 - val_loss: 0.0789 - val_accuracy: 0.7227\n",
      "Epoch 4177/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0701 - accuracy: 0.7547 - val_loss: 0.0788 - val_accuracy: 0.7246\n",
      "Epoch 4178/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0704 - accuracy: 0.7541 - val_loss: 0.0805 - val_accuracy: 0.7201\n",
      "Epoch 4179/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0701 - accuracy: 0.7553 - val_loss: 0.0787 - val_accuracy: 0.7239\n",
      "Epoch 4180/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0700 - accuracy: 0.7556 - val_loss: 0.0780 - val_accuracy: 0.7268\n",
      "Epoch 4181/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0697 - accuracy: 0.7560 - val_loss: 0.0778 - val_accuracy: 0.7282\n",
      "Epoch 4182/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0700 - accuracy: 0.7555 - val_loss: 0.0786 - val_accuracy: 0.7240\n",
      "Epoch 4183/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0700 - accuracy: 0.7558 - val_loss: 0.0784 - val_accuracy: 0.7257\n",
      "Epoch 4184/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0702 - accuracy: 0.7550 - val_loss: 0.0792 - val_accuracy: 0.7256\n",
      "Epoch 4185/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0701 - accuracy: 0.7550 - val_loss: 0.0790 - val_accuracy: 0.7253\n",
      "Epoch 4186/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0703 - accuracy: 0.7541 - val_loss: 0.0790 - val_accuracy: 0.7245\n",
      "Epoch 4187/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0704 - accuracy: 0.7539 - val_loss: 0.0797 - val_accuracy: 0.7249\n",
      "Epoch 4188/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0702 - accuracy: 0.7553 - val_loss: 0.0790 - val_accuracy: 0.7230\n",
      "Epoch 4189/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0701 - accuracy: 0.7554 - val_loss: 0.0791 - val_accuracy: 0.7267\n",
      "Epoch 4190/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0703 - accuracy: 0.7543 - val_loss: 0.0793 - val_accuracy: 0.7262\n",
      "Epoch 4191/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0704 - accuracy: 0.7533 - val_loss: 0.0794 - val_accuracy: 0.7230\n",
      "Epoch 4192/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0702 - accuracy: 0.7544 - val_loss: 0.0792 - val_accuracy: 0.7243\n",
      "Epoch 4193/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0703 - accuracy: 0.7544 - val_loss: 0.0795 - val_accuracy: 0.7207\n",
      "Epoch 4194/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0699 - accuracy: 0.7552 - val_loss: 0.0791 - val_accuracy: 0.7230\n",
      "Epoch 4195/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0698 - accuracy: 0.7555 - val_loss: 0.0788 - val_accuracy: 0.7215\n",
      "Epoch 4196/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0701 - accuracy: 0.7546 - val_loss: 0.0782 - val_accuracy: 0.7245\n",
      "Epoch 4197/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0703 - accuracy: 0.7547 - val_loss: 0.0796 - val_accuracy: 0.7227\n",
      "Epoch 4198/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0700 - accuracy: 0.7557 - val_loss: 0.0790 - val_accuracy: 0.7239\n",
      "Epoch 4199/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0699 - accuracy: 0.7561 - val_loss: 0.0787 - val_accuracy: 0.7234\n",
      "Epoch 4200/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0700 - accuracy: 0.7554 - val_loss: 0.0783 - val_accuracy: 0.7275\n",
      "Epoch 4201/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0702 - accuracy: 0.7547 - val_loss: 0.0794 - val_accuracy: 0.7226\n",
      "Epoch 4202/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0699 - accuracy: 0.7558 - val_loss: 0.0788 - val_accuracy: 0.7238\n",
      "Epoch 4203/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0700 - accuracy: 0.7554 - val_loss: 0.0787 - val_accuracy: 0.7269\n",
      "Epoch 4204/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0699 - accuracy: 0.7562 - val_loss: 0.0787 - val_accuracy: 0.7234\n",
      "Epoch 4205/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0700 - accuracy: 0.7556 - val_loss: 0.0790 - val_accuracy: 0.7265\n",
      "Epoch 4206/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0699 - accuracy: 0.7559 - val_loss: 0.0781 - val_accuracy: 0.7262\n",
      "Epoch 4207/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0699 - accuracy: 0.7559 - val_loss: 0.0787 - val_accuracy: 0.7246\n",
      "Epoch 4208/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0699 - accuracy: 0.7562 - val_loss: 0.0824 - val_accuracy: 0.7143\n",
      "Epoch 4209/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0700 - accuracy: 0.7551 - val_loss: 0.0794 - val_accuracy: 0.7243\n",
      "Epoch 4210/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0700 - accuracy: 0.7552 - val_loss: 0.0784 - val_accuracy: 0.7265\n",
      "Epoch 4211/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0700 - accuracy: 0.7558 - val_loss: 0.0788 - val_accuracy: 0.7264\n",
      "Epoch 4212/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0698 - accuracy: 0.7554 - val_loss: 0.0787 - val_accuracy: 0.7243\n",
      "Epoch 4213/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0700 - accuracy: 0.7553 - val_loss: 0.0777 - val_accuracy: 0.7268\n",
      "Epoch 4214/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0698 - accuracy: 0.7556 - val_loss: 0.0784 - val_accuracy: 0.7259\n",
      "Epoch 4215/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0699 - accuracy: 0.7556 - val_loss: 0.0790 - val_accuracy: 0.7238\n",
      "Epoch 4216/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0703 - accuracy: 0.7551 - val_loss: 0.0786 - val_accuracy: 0.7234\n",
      "Epoch 4217/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0703 - accuracy: 0.7545 - val_loss: 0.0789 - val_accuracy: 0.7258\n",
      "Epoch 4218/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0703 - accuracy: 0.7552 - val_loss: 0.0789 - val_accuracy: 0.7246\n",
      "Epoch 4219/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0702 - accuracy: 0.7546 - val_loss: 0.0799 - val_accuracy: 0.7202\n",
      "Epoch 4220/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0702 - accuracy: 0.7546 - val_loss: 0.0789 - val_accuracy: 0.7242\n",
      "Epoch 4221/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0704 - accuracy: 0.7545 - val_loss: 0.0788 - val_accuracy: 0.7230\n",
      "Epoch 4222/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0701 - accuracy: 0.7545 - val_loss: 0.0789 - val_accuracy: 0.7235\n",
      "Epoch 4223/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0701 - accuracy: 0.7556 - val_loss: 0.0791 - val_accuracy: 0.7251\n",
      "Epoch 4224/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0704 - accuracy: 0.7541 - val_loss: 0.0795 - val_accuracy: 0.7225\n",
      "Epoch 4225/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0704 - accuracy: 0.7535 - val_loss: 0.0784 - val_accuracy: 0.7264\n",
      "Epoch 4226/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0702 - accuracy: 0.7549 - val_loss: 0.0784 - val_accuracy: 0.7242\n",
      "Epoch 4227/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0702 - accuracy: 0.7545 - val_loss: 0.0802 - val_accuracy: 0.7193\n",
      "Epoch 4228/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0704 - accuracy: 0.7536 - val_loss: 0.0799 - val_accuracy: 0.7201\n",
      "Epoch 4229/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0702 - accuracy: 0.7549 - val_loss: 0.0794 - val_accuracy: 0.7230\n",
      "Epoch 4230/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0704 - accuracy: 0.7536 - val_loss: 0.0790 - val_accuracy: 0.7218\n",
      "Epoch 4231/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0704 - accuracy: 0.7537 - val_loss: 0.0788 - val_accuracy: 0.7259\n",
      "Epoch 4232/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0703 - accuracy: 0.7548 - val_loss: 0.0793 - val_accuracy: 0.7241\n",
      "Epoch 4233/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0704 - accuracy: 0.7534 - val_loss: 0.0788 - val_accuracy: 0.7247\n",
      "Epoch 4234/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0704 - accuracy: 0.7535 - val_loss: 0.0790 - val_accuracy: 0.7233\n",
      "Epoch 4235/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0702 - accuracy: 0.7546 - val_loss: 0.0793 - val_accuracy: 0.7211\n",
      "Epoch 4236/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0702 - accuracy: 0.7548 - val_loss: 0.0788 - val_accuracy: 0.7267\n",
      "Epoch 4237/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0705 - accuracy: 0.7542 - val_loss: 0.0787 - val_accuracy: 0.7249\n",
      "Epoch 4238/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0705 - accuracy: 0.7539 - val_loss: 0.0786 - val_accuracy: 0.7248\n",
      "Epoch 4239/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0702 - accuracy: 0.7546 - val_loss: 0.0788 - val_accuracy: 0.7252\n",
      "Epoch 4240/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0702 - accuracy: 0.7547 - val_loss: 0.0794 - val_accuracy: 0.7212\n",
      "Epoch 4241/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0705 - accuracy: 0.7527 - val_loss: 0.0791 - val_accuracy: 0.7246\n",
      "Epoch 4242/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0700 - accuracy: 0.7545 - val_loss: 0.0788 - val_accuracy: 0.7259\n",
      "Epoch 4243/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0702 - accuracy: 0.7545 - val_loss: 0.0792 - val_accuracy: 0.7244\n",
      "Epoch 4244/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0701 - accuracy: 0.7550 - val_loss: 0.0796 - val_accuracy: 0.7227\n",
      "Epoch 4245/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0702 - accuracy: 0.7545 - val_loss: 0.0782 - val_accuracy: 0.7269\n",
      "Epoch 4246/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0703 - accuracy: 0.7544 - val_loss: 0.0788 - val_accuracy: 0.7259\n",
      "Epoch 4247/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0705 - accuracy: 0.7535 - val_loss: 0.0788 - val_accuracy: 0.7224\n",
      "Epoch 4248/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0703 - accuracy: 0.7539 - val_loss: 0.0783 - val_accuracy: 0.7268\n",
      "Epoch 4249/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0701 - accuracy: 0.7545 - val_loss: 0.0791 - val_accuracy: 0.7245\n",
      "Epoch 4250/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0702 - accuracy: 0.7551 - val_loss: 0.0792 - val_accuracy: 0.7225\n",
      "Epoch 4251/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0700 - accuracy: 0.7549 - val_loss: 0.0786 - val_accuracy: 0.7246\n",
      "Epoch 4252/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0701 - accuracy: 0.7553 - val_loss: 0.0787 - val_accuracy: 0.7247\n",
      "Epoch 4253/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0704 - accuracy: 0.7544 - val_loss: 0.0783 - val_accuracy: 0.7255\n",
      "Epoch 4254/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0702 - accuracy: 0.7547 - val_loss: 0.0783 - val_accuracy: 0.7267\n",
      "Epoch 4255/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0701 - accuracy: 0.7554 - val_loss: 0.0793 - val_accuracy: 0.7225\n",
      "Epoch 4256/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0702 - accuracy: 0.7548 - val_loss: 0.0781 - val_accuracy: 0.7252\n",
      "Epoch 4257/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0704 - accuracy: 0.7540 - val_loss: 0.0799 - val_accuracy: 0.7218\n",
      "Epoch 4258/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0705 - accuracy: 0.7543 - val_loss: 0.0793 - val_accuracy: 0.7245\n",
      "Epoch 4259/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0706 - accuracy: 0.7538 - val_loss: 0.0787 - val_accuracy: 0.7265\n",
      "Epoch 4260/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0703 - accuracy: 0.7539 - val_loss: 0.0787 - val_accuracy: 0.7250\n",
      "Epoch 4261/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0703 - accuracy: 0.7543 - val_loss: 0.0796 - val_accuracy: 0.7245\n",
      "Epoch 4262/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0705 - accuracy: 0.7540 - val_loss: 0.0794 - val_accuracy: 0.7236\n",
      "Epoch 4263/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0704 - accuracy: 0.7543 - val_loss: 0.0800 - val_accuracy: 0.7233\n",
      "Epoch 4264/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0706 - accuracy: 0.7527 - val_loss: 0.0780 - val_accuracy: 0.7247\n",
      "Epoch 4265/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0702 - accuracy: 0.7550 - val_loss: 0.0799 - val_accuracy: 0.7224\n",
      "Epoch 4266/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0703 - accuracy: 0.7542 - val_loss: 0.0790 - val_accuracy: 0.7242\n",
      "Epoch 4267/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0704 - accuracy: 0.7548 - val_loss: 0.0791 - val_accuracy: 0.7223\n",
      "Epoch 4268/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0703 - accuracy: 0.7543 - val_loss: 0.0793 - val_accuracy: 0.7250\n",
      "Epoch 4269/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0704 - accuracy: 0.7546 - val_loss: 0.0787 - val_accuracy: 0.7259\n",
      "Epoch 4270/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0703 - accuracy: 0.7554 - val_loss: 0.0796 - val_accuracy: 0.7221\n",
      "Epoch 4271/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0702 - accuracy: 0.7546 - val_loss: 0.0787 - val_accuracy: 0.7242\n",
      "Epoch 4272/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0703 - accuracy: 0.7548 - val_loss: 0.0785 - val_accuracy: 0.7268\n",
      "Epoch 4273/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0702 - accuracy: 0.7546 - val_loss: 0.0784 - val_accuracy: 0.7247\n",
      "Epoch 4274/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0701 - accuracy: 0.7552 - val_loss: 0.0792 - val_accuracy: 0.7237\n",
      "Epoch 4275/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0704 - accuracy: 0.7544 - val_loss: 0.0797 - val_accuracy: 0.7235\n",
      "Epoch 4276/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0711 - accuracy: 0.7520 - val_loss: 0.0791 - val_accuracy: 0.7227\n",
      "Epoch 4277/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0707 - accuracy: 0.7524 - val_loss: 0.0789 - val_accuracy: 0.7225\n",
      "Epoch 4278/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0704 - accuracy: 0.7541 - val_loss: 0.0787 - val_accuracy: 0.7262\n",
      "Epoch 4279/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0702 - accuracy: 0.7551 - val_loss: 0.0788 - val_accuracy: 0.7255\n",
      "Epoch 4280/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0703 - accuracy: 0.7550 - val_loss: 0.0796 - val_accuracy: 0.7258\n",
      "Epoch 4281/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0705 - accuracy: 0.7544 - val_loss: 0.0793 - val_accuracy: 0.7242\n",
      "Epoch 4282/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0706 - accuracy: 0.7535 - val_loss: 0.0790 - val_accuracy: 0.7232\n",
      "Epoch 4283/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0705 - accuracy: 0.7534 - val_loss: 0.0798 - val_accuracy: 0.7218\n",
      "Epoch 4284/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0703 - accuracy: 0.7548 - val_loss: 0.0787 - val_accuracy: 0.7235\n",
      "Epoch 4285/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0701 - accuracy: 0.7556 - val_loss: 0.0786 - val_accuracy: 0.7236\n",
      "Epoch 4286/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0704 - accuracy: 0.7541 - val_loss: 0.0792 - val_accuracy: 0.7257\n",
      "Epoch 4287/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0704 - accuracy: 0.7542 - val_loss: 0.0798 - val_accuracy: 0.7208\n",
      "Epoch 4288/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0703 - accuracy: 0.7543 - val_loss: 0.0782 - val_accuracy: 0.7261\n",
      "Epoch 4289/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0707 - accuracy: 0.7532 - val_loss: 0.0809 - val_accuracy: 0.7187\n",
      "Epoch 4290/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0705 - accuracy: 0.7538 - val_loss: 0.0784 - val_accuracy: 0.7248\n",
      "Epoch 4291/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0706 - accuracy: 0.7533 - val_loss: 0.0793 - val_accuracy: 0.7223\n",
      "Epoch 4292/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0710 - accuracy: 0.7527 - val_loss: 0.0791 - val_accuracy: 0.7229\n",
      "Epoch 4293/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0704 - accuracy: 0.7540 - val_loss: 0.0789 - val_accuracy: 0.7238\n",
      "Epoch 4294/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0705 - accuracy: 0.7545 - val_loss: 0.0791 - val_accuracy: 0.7244\n",
      "Epoch 4295/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0707 - accuracy: 0.7527 - val_loss: 0.0792 - val_accuracy: 0.7207\n",
      "Epoch 4296/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0706 - accuracy: 0.7539 - val_loss: 0.0797 - val_accuracy: 0.7232\n",
      "Epoch 4297/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0703 - accuracy: 0.7547 - val_loss: 0.0781 - val_accuracy: 0.7268\n",
      "Epoch 4298/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0704 - accuracy: 0.7547 - val_loss: 0.0789 - val_accuracy: 0.7252\n",
      "Epoch 4299/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0704 - accuracy: 0.7537 - val_loss: 0.0791 - val_accuracy: 0.7216\n",
      "Epoch 4300/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0706 - accuracy: 0.7540 - val_loss: 0.0800 - val_accuracy: 0.7247\n",
      "Epoch 4301/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0708 - accuracy: 0.7524 - val_loss: 0.0788 - val_accuracy: 0.7249\n",
      "Epoch 4302/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0705 - accuracy: 0.7540 - val_loss: 0.0786 - val_accuracy: 0.7252\n",
      "Epoch 4303/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0705 - accuracy: 0.7542 - val_loss: 0.0790 - val_accuracy: 0.7245\n",
      "Epoch 4304/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0712 - accuracy: 0.7515 - val_loss: 0.0791 - val_accuracy: 0.7223\n",
      "Epoch 4305/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0705 - accuracy: 0.7537 - val_loss: 0.0800 - val_accuracy: 0.7220\n",
      "Epoch 4306/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0706 - accuracy: 0.7538 - val_loss: 0.0785 - val_accuracy: 0.7244\n",
      "Epoch 4307/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0706 - accuracy: 0.7535 - val_loss: 0.0782 - val_accuracy: 0.7274\n",
      "Epoch 4308/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0707 - accuracy: 0.7534 - val_loss: 0.0795 - val_accuracy: 0.7227\n",
      "Epoch 4309/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0707 - accuracy: 0.7532 - val_loss: 0.0789 - val_accuracy: 0.7230\n",
      "Epoch 4310/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0707 - accuracy: 0.7533 - val_loss: 0.0798 - val_accuracy: 0.7242\n",
      "Epoch 4311/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0707 - accuracy: 0.7527 - val_loss: 0.0783 - val_accuracy: 0.7232\n",
      "Epoch 4312/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0705 - accuracy: 0.7539 - val_loss: 0.0806 - val_accuracy: 0.7215\n",
      "Epoch 4313/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0705 - accuracy: 0.7539 - val_loss: 0.0784 - val_accuracy: 0.7264\n",
      "Epoch 4314/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0708 - accuracy: 0.7524 - val_loss: 0.0792 - val_accuracy: 0.7241\n",
      "Epoch 4315/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0705 - accuracy: 0.7538 - val_loss: 0.0797 - val_accuracy: 0.7257\n",
      "Epoch 4316/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0705 - accuracy: 0.7537 - val_loss: 0.0788 - val_accuracy: 0.7246\n",
      "Epoch 4317/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0705 - accuracy: 0.7543 - val_loss: 0.0798 - val_accuracy: 0.7215\n",
      "Epoch 4318/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0706 - accuracy: 0.7539 - val_loss: 0.0798 - val_accuracy: 0.7224\n",
      "Epoch 4319/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0706 - accuracy: 0.7536 - val_loss: 0.0801 - val_accuracy: 0.7216\n",
      "Epoch 4320/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0704 - accuracy: 0.7548 - val_loss: 0.0788 - val_accuracy: 0.7253\n",
      "Epoch 4321/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0704 - accuracy: 0.7537 - val_loss: 0.0785 - val_accuracy: 0.7251\n",
      "Epoch 4322/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0705 - accuracy: 0.7541 - val_loss: 0.0793 - val_accuracy: 0.7242\n",
      "Epoch 4323/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0707 - accuracy: 0.7534 - val_loss: 0.0779 - val_accuracy: 0.7278\n",
      "Epoch 4324/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0705 - accuracy: 0.7547 - val_loss: 0.0796 - val_accuracy: 0.7223\n",
      "Epoch 4325/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0704 - accuracy: 0.7547 - val_loss: 0.0789 - val_accuracy: 0.7262\n",
      "Epoch 4326/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0708 - accuracy: 0.7537 - val_loss: 0.0794 - val_accuracy: 0.7219\n",
      "Epoch 4327/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0707 - accuracy: 0.7528 - val_loss: 0.0788 - val_accuracy: 0.7229\n",
      "Epoch 4328/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0708 - accuracy: 0.7523 - val_loss: 0.0795 - val_accuracy: 0.7215\n",
      "Epoch 4329/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0708 - accuracy: 0.7533 - val_loss: 0.0783 - val_accuracy: 0.7269\n",
      "Epoch 4330/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0705 - accuracy: 0.7540 - val_loss: 0.0799 - val_accuracy: 0.7208\n",
      "Epoch 4331/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0710 - accuracy: 0.7521 - val_loss: 0.0798 - val_accuracy: 0.7229\n",
      "Epoch 4332/5000\n",
      "11786/11786 [==============================] - 8s 686us/step - loss: 0.0706 - accuracy: 0.7546 - val_loss: 0.0789 - val_accuracy: 0.7248\n",
      "Epoch 4333/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0708 - accuracy: 0.7528 - val_loss: 0.0800 - val_accuracy: 0.7216\n",
      "Epoch 4334/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0710 - accuracy: 0.7518 - val_loss: 0.0786 - val_accuracy: 0.7262\n",
      "Epoch 4335/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0710 - accuracy: 0.7522 - val_loss: 0.0798 - val_accuracy: 0.7189\n",
      "Epoch 4336/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0711 - accuracy: 0.7521 - val_loss: 0.0807 - val_accuracy: 0.7180\n",
      "Epoch 4337/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0710 - accuracy: 0.7519 - val_loss: 0.0791 - val_accuracy: 0.7252\n",
      "Epoch 4338/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0708 - accuracy: 0.7532 - val_loss: 0.0794 - val_accuracy: 0.7222\n",
      "Epoch 4339/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0708 - accuracy: 0.7532 - val_loss: 0.0792 - val_accuracy: 0.7225\n",
      "Epoch 4340/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0713 - accuracy: 0.7512 - val_loss: 0.0801 - val_accuracy: 0.7207\n",
      "Epoch 4341/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0710 - accuracy: 0.7524 - val_loss: 0.0813 - val_accuracy: 0.7171\n",
      "Epoch 4342/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0712 - accuracy: 0.7519 - val_loss: 0.0792 - val_accuracy: 0.7226\n",
      "Epoch 4343/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0711 - accuracy: 0.7522 - val_loss: 0.0797 - val_accuracy: 0.7199\n",
      "Epoch 4344/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0712 - accuracy: 0.7512 - val_loss: 0.0805 - val_accuracy: 0.7171\n",
      "Epoch 4345/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0715 - accuracy: 0.7500 - val_loss: 0.0807 - val_accuracy: 0.7205\n",
      "Epoch 4346/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0715 - accuracy: 0.7505 - val_loss: 0.0817 - val_accuracy: 0.7131\n",
      "Epoch 4347/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0716 - accuracy: 0.7504 - val_loss: 0.0808 - val_accuracy: 0.7177\n",
      "Epoch 4348/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0718 - accuracy: 0.7495 - val_loss: 0.0811 - val_accuracy: 0.7159\n",
      "Epoch 4349/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0724 - accuracy: 0.7469 - val_loss: 0.0810 - val_accuracy: 0.7205\n",
      "Epoch 4350/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0717 - accuracy: 0.7497 - val_loss: 0.0810 - val_accuracy: 0.7188\n",
      "Epoch 4351/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0718 - accuracy: 0.7501 - val_loss: 0.0800 - val_accuracy: 0.7231\n",
      "Epoch 4352/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0715 - accuracy: 0.7501 - val_loss: 0.0805 - val_accuracy: 0.7201\n",
      "Epoch 4353/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0711 - accuracy: 0.7519 - val_loss: 0.0798 - val_accuracy: 0.7189\n",
      "Epoch 4354/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0715 - accuracy: 0.7505 - val_loss: 0.0799 - val_accuracy: 0.7211\n",
      "Epoch 4355/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0712 - accuracy: 0.7513 - val_loss: 0.0797 - val_accuracy: 0.7202\n",
      "Epoch 4356/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0716 - accuracy: 0.7494 - val_loss: 0.0809 - val_accuracy: 0.7171\n",
      "Epoch 4357/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0713 - accuracy: 0.7518 - val_loss: 0.0797 - val_accuracy: 0.7227\n",
      "Epoch 4358/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0714 - accuracy: 0.7510 - val_loss: 0.0797 - val_accuracy: 0.7238\n",
      "Epoch 4359/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0715 - accuracy: 0.7507 - val_loss: 0.0794 - val_accuracy: 0.7229\n",
      "Epoch 4360/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0713 - accuracy: 0.7510 - val_loss: 0.0800 - val_accuracy: 0.7203\n",
      "Epoch 4361/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0712 - accuracy: 0.7509 - val_loss: 0.0792 - val_accuracy: 0.7202\n",
      "Epoch 4362/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0712 - accuracy: 0.7508 - val_loss: 0.0793 - val_accuracy: 0.7224\n",
      "Epoch 4363/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0713 - accuracy: 0.7506 - val_loss: 0.0794 - val_accuracy: 0.7226\n",
      "Epoch 4364/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0714 - accuracy: 0.7510 - val_loss: 0.0788 - val_accuracy: 0.7248\n",
      "Epoch 4365/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0710 - accuracy: 0.7519 - val_loss: 0.0801 - val_accuracy: 0.7200\n",
      "Epoch 4366/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0710 - accuracy: 0.7520 - val_loss: 0.0803 - val_accuracy: 0.7213\n",
      "Epoch 4367/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0711 - accuracy: 0.7519 - val_loss: 0.0785 - val_accuracy: 0.7229\n",
      "Epoch 4368/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0709 - accuracy: 0.7521 - val_loss: 0.0792 - val_accuracy: 0.7232\n",
      "Epoch 4369/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0712 - accuracy: 0.7515 - val_loss: 0.0792 - val_accuracy: 0.7222\n",
      "Epoch 4370/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0710 - accuracy: 0.7521 - val_loss: 0.0791 - val_accuracy: 0.7242\n",
      "Epoch 4371/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0711 - accuracy: 0.7520 - val_loss: 0.0795 - val_accuracy: 0.7227\n",
      "Epoch 4372/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0711 - accuracy: 0.7517 - val_loss: 0.0801 - val_accuracy: 0.7201\n",
      "Epoch 4373/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0712 - accuracy: 0.7514 - val_loss: 0.0798 - val_accuracy: 0.7223\n",
      "Epoch 4374/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0710 - accuracy: 0.7517 - val_loss: 0.0789 - val_accuracy: 0.7220\n",
      "Epoch 4375/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0708 - accuracy: 0.7530 - val_loss: 0.0789 - val_accuracy: 0.7241\n",
      "Epoch 4376/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0709 - accuracy: 0.7536 - val_loss: 0.0793 - val_accuracy: 0.7226\n",
      "Epoch 4377/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0715 - accuracy: 0.7513 - val_loss: 0.0796 - val_accuracy: 0.7221\n",
      "Epoch 4378/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0711 - accuracy: 0.7518 - val_loss: 0.0791 - val_accuracy: 0.7242\n",
      "Epoch 4379/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0711 - accuracy: 0.7516 - val_loss: 0.0798 - val_accuracy: 0.7214\n",
      "Epoch 4380/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0711 - accuracy: 0.7517 - val_loss: 0.0795 - val_accuracy: 0.7234\n",
      "Epoch 4381/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0708 - accuracy: 0.7531 - val_loss: 0.0791 - val_accuracy: 0.7238\n",
      "Epoch 4382/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0707 - accuracy: 0.7541 - val_loss: 0.0793 - val_accuracy: 0.7246\n",
      "Epoch 4383/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0707 - accuracy: 0.7539 - val_loss: 0.0798 - val_accuracy: 0.7223\n",
      "Epoch 4384/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0715 - accuracy: 0.7510 - val_loss: 0.0796 - val_accuracy: 0.7238\n",
      "Epoch 4385/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0709 - accuracy: 0.7524 - val_loss: 0.0796 - val_accuracy: 0.7245\n",
      "Epoch 4386/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0714 - accuracy: 0.7507 - val_loss: 0.0800 - val_accuracy: 0.7211\n",
      "Epoch 4387/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0713 - accuracy: 0.7514 - val_loss: 0.0788 - val_accuracy: 0.7241\n",
      "Epoch 4388/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0711 - accuracy: 0.7521 - val_loss: 0.0790 - val_accuracy: 0.7236\n",
      "Epoch 4389/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0711 - accuracy: 0.7517 - val_loss: 0.0802 - val_accuracy: 0.7215\n",
      "Epoch 4390/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0710 - accuracy: 0.7517 - val_loss: 0.0790 - val_accuracy: 0.7224\n",
      "Epoch 4391/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0711 - accuracy: 0.7507 - val_loss: 0.0787 - val_accuracy: 0.7257\n",
      "Epoch 4392/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0710 - accuracy: 0.7520 - val_loss: 0.0797 - val_accuracy: 0.7229\n",
      "Epoch 4393/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0713 - accuracy: 0.7510 - val_loss: 0.0789 - val_accuracy: 0.7245\n",
      "Epoch 4394/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0708 - accuracy: 0.7524 - val_loss: 0.0797 - val_accuracy: 0.7214\n",
      "Epoch 4395/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0708 - accuracy: 0.7527 - val_loss: 0.0791 - val_accuracy: 0.7220\n",
      "Epoch 4396/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0707 - accuracy: 0.7528 - val_loss: 0.0797 - val_accuracy: 0.7221\n",
      "Epoch 4397/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0709 - accuracy: 0.7520 - val_loss: 0.0792 - val_accuracy: 0.7241\n",
      "Epoch 4398/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0707 - accuracy: 0.7524 - val_loss: 0.0798 - val_accuracy: 0.7225\n",
      "Epoch 4399/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0709 - accuracy: 0.7519 - val_loss: 0.0789 - val_accuracy: 0.7225\n",
      "Epoch 4400/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0711 - accuracy: 0.7518 - val_loss: 0.0791 - val_accuracy: 0.7235\n",
      "Epoch 4401/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0710 - accuracy: 0.7521 - val_loss: 0.0799 - val_accuracy: 0.7214\n",
      "Epoch 4402/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0711 - accuracy: 0.7513 - val_loss: 0.0800 - val_accuracy: 0.7230\n",
      "Epoch 4403/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0710 - accuracy: 0.7518 - val_loss: 0.0787 - val_accuracy: 0.7244\n",
      "Epoch 4404/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0710 - accuracy: 0.7523 - val_loss: 0.0797 - val_accuracy: 0.7199\n",
      "Epoch 4405/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0706 - accuracy: 0.7532 - val_loss: 0.0793 - val_accuracy: 0.7267\n",
      "Epoch 4406/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0708 - accuracy: 0.7527 - val_loss: 0.0795 - val_accuracy: 0.7227\n",
      "Epoch 4407/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0712 - accuracy: 0.7513 - val_loss: 0.0796 - val_accuracy: 0.7216\n",
      "Epoch 4408/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0716 - accuracy: 0.7495 - val_loss: 0.0806 - val_accuracy: 0.7175\n",
      "Epoch 4409/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0712 - accuracy: 0.7513 - val_loss: 0.0792 - val_accuracy: 0.7227\n",
      "Epoch 4410/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0715 - accuracy: 0.7493 - val_loss: 0.0791 - val_accuracy: 0.7239\n",
      "Epoch 4411/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0712 - accuracy: 0.7516 - val_loss: 0.0793 - val_accuracy: 0.7222\n",
      "Epoch 4412/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0710 - accuracy: 0.7512 - val_loss: 0.0793 - val_accuracy: 0.7214\n",
      "Epoch 4413/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0708 - accuracy: 0.7526 - val_loss: 0.0787 - val_accuracy: 0.7264\n",
      "Epoch 4414/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0711 - accuracy: 0.7515 - val_loss: 0.0795 - val_accuracy: 0.7225\n",
      "Epoch 4415/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0715 - accuracy: 0.7505 - val_loss: 0.0811 - val_accuracy: 0.7176\n",
      "Epoch 4416/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0712 - accuracy: 0.7512 - val_loss: 0.0792 - val_accuracy: 0.7212\n",
      "Epoch 4417/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0712 - accuracy: 0.7512 - val_loss: 0.0816 - val_accuracy: 0.7173\n",
      "Epoch 4418/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0710 - accuracy: 0.7522 - val_loss: 0.0797 - val_accuracy: 0.7232\n",
      "Epoch 4419/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0711 - accuracy: 0.7517 - val_loss: 0.0792 - val_accuracy: 0.7235\n",
      "Epoch 4420/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0710 - accuracy: 0.7520 - val_loss: 0.0799 - val_accuracy: 0.7197\n",
      "Epoch 4421/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0711 - accuracy: 0.7515 - val_loss: 0.0804 - val_accuracy: 0.7184\n",
      "Epoch 4422/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0714 - accuracy: 0.7505 - val_loss: 0.0795 - val_accuracy: 0.7224\n",
      "Epoch 4423/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0712 - accuracy: 0.7515 - val_loss: 0.0806 - val_accuracy: 0.7177\n",
      "Epoch 4424/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0710 - accuracy: 0.7515 - val_loss: 0.0797 - val_accuracy: 0.7200\n",
      "Epoch 4425/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0709 - accuracy: 0.7521 - val_loss: 0.0789 - val_accuracy: 0.7248\n",
      "Epoch 4426/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0709 - accuracy: 0.7525 - val_loss: 0.0797 - val_accuracy: 0.7235\n",
      "Epoch 4427/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0711 - accuracy: 0.7518 - val_loss: 0.0793 - val_accuracy: 0.7225\n",
      "Epoch 4428/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0711 - accuracy: 0.7514 - val_loss: 0.0799 - val_accuracy: 0.7221\n",
      "Epoch 4429/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0708 - accuracy: 0.7524 - val_loss: 0.0790 - val_accuracy: 0.7229\n",
      "Epoch 4430/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0710 - accuracy: 0.7519 - val_loss: 0.0799 - val_accuracy: 0.7194\n",
      "Epoch 4431/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0712 - accuracy: 0.7508 - val_loss: 0.0806 - val_accuracy: 0.7184\n",
      "Epoch 4432/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0710 - accuracy: 0.7515 - val_loss: 0.0793 - val_accuracy: 0.7242\n",
      "Epoch 4433/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0712 - accuracy: 0.7514 - val_loss: 0.0789 - val_accuracy: 0.7250\n",
      "Epoch 4434/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0708 - accuracy: 0.7530 - val_loss: 0.0786 - val_accuracy: 0.7256\n",
      "Epoch 4435/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0709 - accuracy: 0.7517 - val_loss: 0.0787 - val_accuracy: 0.7236\n",
      "Epoch 4436/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0709 - accuracy: 0.7517 - val_loss: 0.0798 - val_accuracy: 0.7189\n",
      "Epoch 4437/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0709 - accuracy: 0.7525 - val_loss: 0.0792 - val_accuracy: 0.7226\n",
      "Epoch 4438/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0709 - accuracy: 0.7523 - val_loss: 0.0792 - val_accuracy: 0.7226\n",
      "Epoch 4439/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0710 - accuracy: 0.7521 - val_loss: 0.0795 - val_accuracy: 0.7246\n",
      "Epoch 4440/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0711 - accuracy: 0.7514 - val_loss: 0.0787 - val_accuracy: 0.7243\n",
      "Epoch 4441/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0709 - accuracy: 0.7526 - val_loss: 0.0802 - val_accuracy: 0.7199\n",
      "Epoch 4442/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0710 - accuracy: 0.7520 - val_loss: 0.0803 - val_accuracy: 0.7216\n",
      "Epoch 4443/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0712 - accuracy: 0.7515 - val_loss: 0.0796 - val_accuracy: 0.7229\n",
      "Epoch 4444/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0716 - accuracy: 0.7493 - val_loss: 0.0809 - val_accuracy: 0.7154\n",
      "Epoch 4445/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0711 - accuracy: 0.7512 - val_loss: 0.0800 - val_accuracy: 0.7202\n",
      "Epoch 4446/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0708 - accuracy: 0.7527 - val_loss: 0.0794 - val_accuracy: 0.7231\n",
      "Epoch 4447/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0710 - accuracy: 0.7519 - val_loss: 0.0794 - val_accuracy: 0.7243\n",
      "Epoch 4448/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0711 - accuracy: 0.7521 - val_loss: 0.0783 - val_accuracy: 0.7234\n",
      "Epoch 4449/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0710 - accuracy: 0.7522 - val_loss: 0.0808 - val_accuracy: 0.7175\n",
      "Epoch 4450/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0711 - accuracy: 0.7525 - val_loss: 0.0805 - val_accuracy: 0.7215\n",
      "Epoch 4451/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0712 - accuracy: 0.7521 - val_loss: 0.0789 - val_accuracy: 0.7240\n",
      "Epoch 4452/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0709 - accuracy: 0.7526 - val_loss: 0.0802 - val_accuracy: 0.7202\n",
      "Epoch 4453/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0711 - accuracy: 0.7528 - val_loss: 0.0793 - val_accuracy: 0.7232\n",
      "Epoch 4454/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0713 - accuracy: 0.7512 - val_loss: 0.0796 - val_accuracy: 0.7196\n",
      "Epoch 4455/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0714 - accuracy: 0.7511 - val_loss: 0.0793 - val_accuracy: 0.7229\n",
      "Epoch 4456/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0714 - accuracy: 0.7513 - val_loss: 0.0792 - val_accuracy: 0.7242\n",
      "Epoch 4457/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0713 - accuracy: 0.7510 - val_loss: 0.0793 - val_accuracy: 0.7231\n",
      "Epoch 4458/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0709 - accuracy: 0.7519 - val_loss: 0.0796 - val_accuracy: 0.7221\n",
      "Epoch 4459/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0710 - accuracy: 0.7516 - val_loss: 0.0797 - val_accuracy: 0.7193\n",
      "Epoch 4460/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0711 - accuracy: 0.7518 - val_loss: 0.0791 - val_accuracy: 0.7220\n",
      "Epoch 4461/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0714 - accuracy: 0.7501 - val_loss: 0.0791 - val_accuracy: 0.7215\n",
      "Epoch 4462/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0713 - accuracy: 0.7507 - val_loss: 0.0797 - val_accuracy: 0.7204\n",
      "Epoch 4463/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0710 - accuracy: 0.7525 - val_loss: 0.0796 - val_accuracy: 0.7213\n",
      "Epoch 4464/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0712 - accuracy: 0.7509 - val_loss: 0.0797 - val_accuracy: 0.7202\n",
      "Epoch 4465/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0712 - accuracy: 0.7504 - val_loss: 0.0805 - val_accuracy: 0.7198\n",
      "Epoch 4466/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0711 - accuracy: 0.7514 - val_loss: 0.0804 - val_accuracy: 0.7210\n",
      "Epoch 4467/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0712 - accuracy: 0.7521 - val_loss: 0.0803 - val_accuracy: 0.7211\n",
      "Epoch 4468/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0714 - accuracy: 0.7501 - val_loss: 0.0790 - val_accuracy: 0.7227\n",
      "Epoch 4469/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0711 - accuracy: 0.7514 - val_loss: 0.0798 - val_accuracy: 0.7203\n",
      "Epoch 4470/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0709 - accuracy: 0.7520 - val_loss: 0.0790 - val_accuracy: 0.7217\n",
      "Epoch 4471/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0710 - accuracy: 0.7516 - val_loss: 0.0792 - val_accuracy: 0.7239\n",
      "Epoch 4472/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0713 - accuracy: 0.7504 - val_loss: 0.0789 - val_accuracy: 0.7214\n",
      "Epoch 4473/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0711 - accuracy: 0.7517 - val_loss: 0.0815 - val_accuracy: 0.7161\n",
      "Epoch 4474/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0712 - accuracy: 0.7513 - val_loss: 0.0804 - val_accuracy: 0.7190\n",
      "Epoch 4475/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0716 - accuracy: 0.7498 - val_loss: 0.0801 - val_accuracy: 0.7229\n",
      "Epoch 4476/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0711 - accuracy: 0.7517 - val_loss: 0.0789 - val_accuracy: 0.7234\n",
      "Epoch 4477/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0713 - accuracy: 0.7511 - val_loss: 0.0793 - val_accuracy: 0.7230\n",
      "Epoch 4478/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0709 - accuracy: 0.7521 - val_loss: 0.0802 - val_accuracy: 0.7191\n",
      "Epoch 4479/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0713 - accuracy: 0.7512 - val_loss: 0.0798 - val_accuracy: 0.7200\n",
      "Epoch 4480/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0715 - accuracy: 0.7493 - val_loss: 0.0803 - val_accuracy: 0.7181\n",
      "Epoch 4481/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0709 - accuracy: 0.7523 - val_loss: 0.0790 - val_accuracy: 0.7224\n",
      "Epoch 4482/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0712 - accuracy: 0.7510 - val_loss: 0.0790 - val_accuracy: 0.7258\n",
      "Epoch 4483/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0709 - accuracy: 0.7518 - val_loss: 0.0796 - val_accuracy: 0.7212\n",
      "Epoch 4484/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0712 - accuracy: 0.7504 - val_loss: 0.0791 - val_accuracy: 0.7235\n",
      "Epoch 4485/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0710 - accuracy: 0.7517 - val_loss: 0.0798 - val_accuracy: 0.7210\n",
      "Epoch 4486/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0713 - accuracy: 0.7503 - val_loss: 0.0795 - val_accuracy: 0.7233\n",
      "Epoch 4487/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0714 - accuracy: 0.7507 - val_loss: 0.0792 - val_accuracy: 0.7219\n",
      "Epoch 4488/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0712 - accuracy: 0.7515 - val_loss: 0.0794 - val_accuracy: 0.7214\n",
      "Epoch 4489/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0719 - accuracy: 0.7492 - val_loss: 0.0844 - val_accuracy: 0.7037\n",
      "Epoch 4490/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0714 - accuracy: 0.7505 - val_loss: 0.0795 - val_accuracy: 0.7227\n",
      "Epoch 4491/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0711 - accuracy: 0.7513 - val_loss: 0.0801 - val_accuracy: 0.7196\n",
      "Epoch 4492/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0713 - accuracy: 0.7503 - val_loss: 0.0804 - val_accuracy: 0.7187\n",
      "Epoch 4493/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0711 - accuracy: 0.7512 - val_loss: 0.0792 - val_accuracy: 0.7215\n",
      "Epoch 4494/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0709 - accuracy: 0.7522 - val_loss: 0.0793 - val_accuracy: 0.7234\n",
      "Epoch 4495/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0711 - accuracy: 0.7516 - val_loss: 0.0793 - val_accuracy: 0.7239\n",
      "Epoch 4496/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0709 - accuracy: 0.7517 - val_loss: 0.0790 - val_accuracy: 0.7210\n",
      "Epoch 4497/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0712 - accuracy: 0.7510 - val_loss: 0.0795 - val_accuracy: 0.7214\n",
      "Epoch 4498/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0715 - accuracy: 0.7497 - val_loss: 0.0793 - val_accuracy: 0.7216\n",
      "Epoch 4499/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0711 - accuracy: 0.7510 - val_loss: 0.0794 - val_accuracy: 0.7217\n",
      "Epoch 4500/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0713 - accuracy: 0.7503 - val_loss: 0.0809 - val_accuracy: 0.7188\n",
      "Epoch 4501/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0715 - accuracy: 0.7499 - val_loss: 0.0792 - val_accuracy: 0.7222\n",
      "Epoch 4502/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0711 - accuracy: 0.7512 - val_loss: 0.0791 - val_accuracy: 0.7224\n",
      "Epoch 4503/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0711 - accuracy: 0.7510 - val_loss: 0.0802 - val_accuracy: 0.7208\n",
      "Epoch 4504/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0712 - accuracy: 0.7506 - val_loss: 0.0797 - val_accuracy: 0.7198\n",
      "Epoch 4505/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0708 - accuracy: 0.7516 - val_loss: 0.0792 - val_accuracy: 0.7229\n",
      "Epoch 4506/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0711 - accuracy: 0.7509 - val_loss: 0.0792 - val_accuracy: 0.7213\n",
      "Epoch 4507/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0712 - accuracy: 0.7512 - val_loss: 0.0792 - val_accuracy: 0.7243\n",
      "Epoch 4508/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0707 - accuracy: 0.7524 - val_loss: 0.0792 - val_accuracy: 0.7229\n",
      "Epoch 4509/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0709 - accuracy: 0.7523 - val_loss: 0.0788 - val_accuracy: 0.7245\n",
      "Epoch 4510/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0712 - accuracy: 0.7508 - val_loss: 0.0797 - val_accuracy: 0.7223\n",
      "Epoch 4511/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0712 - accuracy: 0.7506 - val_loss: 0.0787 - val_accuracy: 0.7224\n",
      "Epoch 4512/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0712 - accuracy: 0.7505 - val_loss: 0.0791 - val_accuracy: 0.7215\n",
      "Epoch 4513/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0711 - accuracy: 0.7506 - val_loss: 0.0790 - val_accuracy: 0.7204\n",
      "Epoch 4514/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0709 - accuracy: 0.7518 - val_loss: 0.0799 - val_accuracy: 0.7198\n",
      "Epoch 4515/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0711 - accuracy: 0.7504 - val_loss: 0.0793 - val_accuracy: 0.7238\n",
      "Epoch 4516/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0710 - accuracy: 0.7515 - val_loss: 0.0792 - val_accuracy: 0.7210\n",
      "Epoch 4517/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0711 - accuracy: 0.7505 - val_loss: 0.0801 - val_accuracy: 0.7205\n",
      "Epoch 4518/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0709 - accuracy: 0.7515 - val_loss: 0.0791 - val_accuracy: 0.7225\n",
      "Epoch 4519/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0709 - accuracy: 0.7528 - val_loss: 0.0800 - val_accuracy: 0.7213\n",
      "Epoch 4520/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0711 - accuracy: 0.7513 - val_loss: 0.0795 - val_accuracy: 0.7225\n",
      "Epoch 4521/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0711 - accuracy: 0.7517 - val_loss: 0.0794 - val_accuracy: 0.7236\n",
      "Epoch 4522/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0713 - accuracy: 0.7513 - val_loss: 0.0792 - val_accuracy: 0.7202\n",
      "Epoch 4523/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0713 - accuracy: 0.7511 - val_loss: 0.0797 - val_accuracy: 0.7215\n",
      "Epoch 4524/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0712 - accuracy: 0.7516 - val_loss: 0.0798 - val_accuracy: 0.7206\n",
      "Epoch 4525/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0713 - accuracy: 0.7511 - val_loss: 0.0789 - val_accuracy: 0.7219\n",
      "Epoch 4526/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0711 - accuracy: 0.7511 - val_loss: 0.0804 - val_accuracy: 0.7194\n",
      "Epoch 4527/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0712 - accuracy: 0.7512 - val_loss: 0.0794 - val_accuracy: 0.7228\n",
      "Epoch 4528/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0711 - accuracy: 0.7528 - val_loss: 0.0791 - val_accuracy: 0.7230\n",
      "Epoch 4529/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0712 - accuracy: 0.7516 - val_loss: 0.0794 - val_accuracy: 0.7229\n",
      "Epoch 4530/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0710 - accuracy: 0.7522 - val_loss: 0.0793 - val_accuracy: 0.7234\n",
      "Epoch 4531/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0718 - accuracy: 0.7487 - val_loss: 0.0807 - val_accuracy: 0.7170\n",
      "Epoch 4532/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0716 - accuracy: 0.7486 - val_loss: 0.0807 - val_accuracy: 0.7175\n",
      "Epoch 4533/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0713 - accuracy: 0.7501 - val_loss: 0.0796 - val_accuracy: 0.7245\n",
      "Epoch 4534/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0712 - accuracy: 0.7505 - val_loss: 0.0795 - val_accuracy: 0.7216\n",
      "Epoch 4535/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0716 - accuracy: 0.7494 - val_loss: 0.0794 - val_accuracy: 0.7215\n",
      "Epoch 4536/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0711 - accuracy: 0.7514 - val_loss: 0.0793 - val_accuracy: 0.7224\n",
      "Epoch 4537/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0713 - accuracy: 0.7501 - val_loss: 0.0803 - val_accuracy: 0.7192\n",
      "Epoch 4538/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0717 - accuracy: 0.7491 - val_loss: 0.0792 - val_accuracy: 0.7199\n",
      "Epoch 4539/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0713 - accuracy: 0.7498 - val_loss: 0.0796 - val_accuracy: 0.7225\n",
      "Epoch 4540/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0715 - accuracy: 0.7504 - val_loss: 0.0793 - val_accuracy: 0.7222\n",
      "Epoch 4541/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0712 - accuracy: 0.7511 - val_loss: 0.0786 - val_accuracy: 0.7241\n",
      "Epoch 4542/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0715 - accuracy: 0.7497 - val_loss: 0.0790 - val_accuracy: 0.7227\n",
      "Epoch 4543/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0714 - accuracy: 0.7497 - val_loss: 0.0797 - val_accuracy: 0.7188\n",
      "Epoch 4544/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0715 - accuracy: 0.7499 - val_loss: 0.0794 - val_accuracy: 0.7205\n",
      "Epoch 4545/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0714 - accuracy: 0.7511 - val_loss: 0.0787 - val_accuracy: 0.7220\n",
      "Epoch 4546/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0714 - accuracy: 0.7502 - val_loss: 0.0795 - val_accuracy: 0.7187\n",
      "Epoch 4547/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0717 - accuracy: 0.7492 - val_loss: 0.0798 - val_accuracy: 0.7184\n",
      "Epoch 4548/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0713 - accuracy: 0.7507 - val_loss: 0.0801 - val_accuracy: 0.7216\n",
      "Epoch 4549/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0715 - accuracy: 0.7502 - val_loss: 0.0797 - val_accuracy: 0.7203\n",
      "Epoch 4550/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0713 - accuracy: 0.7505 - val_loss: 0.0801 - val_accuracy: 0.7196\n",
      "Epoch 4551/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0713 - accuracy: 0.7508 - val_loss: 0.0805 - val_accuracy: 0.7221\n",
      "Epoch 4552/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0713 - accuracy: 0.7513 - val_loss: 0.0802 - val_accuracy: 0.7212\n",
      "Epoch 4553/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0716 - accuracy: 0.7491 - val_loss: 0.0806 - val_accuracy: 0.7210\n",
      "Epoch 4554/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0716 - accuracy: 0.7496 - val_loss: 0.0807 - val_accuracy: 0.7201\n",
      "Epoch 4555/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0716 - accuracy: 0.7491 - val_loss: 0.0797 - val_accuracy: 0.7219\n",
      "Epoch 4556/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0714 - accuracy: 0.7497 - val_loss: 0.0797 - val_accuracy: 0.7201\n",
      "Epoch 4557/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0715 - accuracy: 0.7504 - val_loss: 0.0791 - val_accuracy: 0.7223\n",
      "Epoch 4558/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0715 - accuracy: 0.7499 - val_loss: 0.0800 - val_accuracy: 0.7201\n",
      "Epoch 4559/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0716 - accuracy: 0.7500 - val_loss: 0.0803 - val_accuracy: 0.7178\n",
      "Epoch 4560/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0714 - accuracy: 0.7506 - val_loss: 0.0804 - val_accuracy: 0.7199\n",
      "Epoch 4561/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0714 - accuracy: 0.7503 - val_loss: 0.0800 - val_accuracy: 0.7169\n",
      "Epoch 4562/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0711 - accuracy: 0.7512 - val_loss: 0.0787 - val_accuracy: 0.7230\n",
      "Epoch 4563/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0715 - accuracy: 0.7501 - val_loss: 0.0806 - val_accuracy: 0.7219\n",
      "Epoch 4564/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0714 - accuracy: 0.7502 - val_loss: 0.0795 - val_accuracy: 0.7206\n",
      "Epoch 4565/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0713 - accuracy: 0.7514 - val_loss: 0.0794 - val_accuracy: 0.7232\n",
      "Epoch 4566/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0714 - accuracy: 0.7511 - val_loss: 0.0797 - val_accuracy: 0.7231\n",
      "Epoch 4567/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0713 - accuracy: 0.7505 - val_loss: 0.0800 - val_accuracy: 0.7202\n",
      "Epoch 4568/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0717 - accuracy: 0.7494 - val_loss: 0.0806 - val_accuracy: 0.7157\n",
      "Epoch 4569/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0719 - accuracy: 0.7482 - val_loss: 0.0796 - val_accuracy: 0.7219\n",
      "Epoch 4570/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0716 - accuracy: 0.7491 - val_loss: 0.0799 - val_accuracy: 0.7207\n",
      "Epoch 4571/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0713 - accuracy: 0.7506 - val_loss: 0.0795 - val_accuracy: 0.7201\n",
      "Epoch 4572/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0719 - accuracy: 0.7485 - val_loss: 0.0793 - val_accuracy: 0.7234\n",
      "Epoch 4573/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0716 - accuracy: 0.7496 - val_loss: 0.0802 - val_accuracy: 0.7202\n",
      "Epoch 4574/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0715 - accuracy: 0.7496 - val_loss: 0.0796 - val_accuracy: 0.7184\n",
      "Epoch 4575/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0719 - accuracy: 0.7479 - val_loss: 0.0796 - val_accuracy: 0.7214\n",
      "Epoch 4576/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0716 - accuracy: 0.7491 - val_loss: 0.0806 - val_accuracy: 0.7216\n",
      "Epoch 4577/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0716 - accuracy: 0.7487 - val_loss: 0.0799 - val_accuracy: 0.7225\n",
      "Epoch 4578/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0714 - accuracy: 0.7500 - val_loss: 0.0797 - val_accuracy: 0.7196\n",
      "Epoch 4579/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0716 - accuracy: 0.7491 - val_loss: 0.0796 - val_accuracy: 0.7205\n",
      "Epoch 4580/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0717 - accuracy: 0.7496 - val_loss: 0.0801 - val_accuracy: 0.7223\n",
      "Epoch 4581/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0714 - accuracy: 0.7511 - val_loss: 0.0804 - val_accuracy: 0.7175\n",
      "Epoch 4582/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0716 - accuracy: 0.7498 - val_loss: 0.0797 - val_accuracy: 0.7212\n",
      "Epoch 4583/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0716 - accuracy: 0.7507 - val_loss: 0.0816 - val_accuracy: 0.7137\n",
      "Epoch 4584/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0719 - accuracy: 0.7482 - val_loss: 0.0809 - val_accuracy: 0.7210\n",
      "Epoch 4585/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0719 - accuracy: 0.7487 - val_loss: 0.0800 - val_accuracy: 0.7208\n",
      "Epoch 4586/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0719 - accuracy: 0.7489 - val_loss: 0.0795 - val_accuracy: 0.7206\n",
      "Epoch 4587/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0720 - accuracy: 0.7483 - val_loss: 0.0792 - val_accuracy: 0.7222\n",
      "Epoch 4588/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0714 - accuracy: 0.7504 - val_loss: 0.0802 - val_accuracy: 0.7180\n",
      "Epoch 4589/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0716 - accuracy: 0.7501 - val_loss: 0.0791 - val_accuracy: 0.7231\n",
      "Epoch 4590/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0714 - accuracy: 0.7504 - val_loss: 0.0798 - val_accuracy: 0.7224\n",
      "Epoch 4591/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0716 - accuracy: 0.7498 - val_loss: 0.0791 - val_accuracy: 0.7226\n",
      "Epoch 4592/5000\n",
      "11786/11786 [==============================] - 8s 660us/step - loss: 0.0719 - accuracy: 0.7486 - val_loss: 0.0799 - val_accuracy: 0.7220\n",
      "Epoch 4593/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0718 - accuracy: 0.7486 - val_loss: 0.0798 - val_accuracy: 0.7186\n",
      "Epoch 4594/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0717 - accuracy: 0.7492 - val_loss: 0.0798 - val_accuracy: 0.7218\n",
      "Epoch 4595/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0717 - accuracy: 0.7492 - val_loss: 0.0799 - val_accuracy: 0.7224\n",
      "Epoch 4596/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0719 - accuracy: 0.7487 - val_loss: 0.0794 - val_accuracy: 0.7207\n",
      "Epoch 4597/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0717 - accuracy: 0.7495 - val_loss: 0.0806 - val_accuracy: 0.7167\n",
      "Epoch 4598/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0719 - accuracy: 0.7487 - val_loss: 0.0806 - val_accuracy: 0.7190\n",
      "Epoch 4599/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0720 - accuracy: 0.7494 - val_loss: 0.0799 - val_accuracy: 0.7206\n",
      "Epoch 4600/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0722 - accuracy: 0.7478 - val_loss: 0.0802 - val_accuracy: 0.7172\n",
      "Epoch 4601/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0720 - accuracy: 0.7489 - val_loss: 0.0797 - val_accuracy: 0.7234\n",
      "Epoch 4602/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0718 - accuracy: 0.7495 - val_loss: 0.0797 - val_accuracy: 0.7214\n",
      "Epoch 4603/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0720 - accuracy: 0.7487 - val_loss: 0.0805 - val_accuracy: 0.7195\n",
      "Epoch 4604/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0717 - accuracy: 0.7488 - val_loss: 0.0799 - val_accuracy: 0.7192\n",
      "Epoch 4605/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0717 - accuracy: 0.7487 - val_loss: 0.0793 - val_accuracy: 0.7218\n",
      "Epoch 4606/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0719 - accuracy: 0.7483 - val_loss: 0.0796 - val_accuracy: 0.7244\n",
      "Epoch 4607/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0715 - accuracy: 0.7503 - val_loss: 0.0795 - val_accuracy: 0.7214\n",
      "Epoch 4608/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0717 - accuracy: 0.7493 - val_loss: 0.0791 - val_accuracy: 0.7235\n",
      "Epoch 4609/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0718 - accuracy: 0.7489 - val_loss: 0.0800 - val_accuracy: 0.7187\n",
      "Epoch 4610/5000\n",
      "11786/11786 [==============================] - 8s 662us/step - loss: 0.0718 - accuracy: 0.7482 - val_loss: 0.0798 - val_accuracy: 0.7203\n",
      "Epoch 4611/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0718 - accuracy: 0.7485 - val_loss: 0.0796 - val_accuracy: 0.7210\n",
      "Epoch 4612/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0716 - accuracy: 0.7496 - val_loss: 0.0796 - val_accuracy: 0.7218\n",
      "Epoch 4613/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0718 - accuracy: 0.7479 - val_loss: 0.0795 - val_accuracy: 0.7204\n",
      "Epoch 4614/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0714 - accuracy: 0.7498 - val_loss: 0.0803 - val_accuracy: 0.7208\n",
      "Epoch 4615/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0717 - accuracy: 0.7495 - val_loss: 0.0811 - val_accuracy: 0.7164\n",
      "Epoch 4616/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0717 - accuracy: 0.7496 - val_loss: 0.0805 - val_accuracy: 0.7177\n",
      "Epoch 4617/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0717 - accuracy: 0.7494 - val_loss: 0.0793 - val_accuracy: 0.7215\n",
      "Epoch 4618/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0716 - accuracy: 0.7499 - val_loss: 0.0804 - val_accuracy: 0.7195\n",
      "Epoch 4619/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0718 - accuracy: 0.7490 - val_loss: 0.0801 - val_accuracy: 0.7185\n",
      "Epoch 4620/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0718 - accuracy: 0.7485 - val_loss: 0.0812 - val_accuracy: 0.7181\n",
      "Epoch 4621/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0718 - accuracy: 0.7490 - val_loss: 0.0812 - val_accuracy: 0.7183\n",
      "Epoch 4622/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0722 - accuracy: 0.7470 - val_loss: 0.0794 - val_accuracy: 0.7203\n",
      "Epoch 4623/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0719 - accuracy: 0.7485 - val_loss: 0.0803 - val_accuracy: 0.7196\n",
      "Epoch 4624/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0719 - accuracy: 0.7488 - val_loss: 0.0815 - val_accuracy: 0.7172\n",
      "Epoch 4625/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0718 - accuracy: 0.7489 - val_loss: 0.0800 - val_accuracy: 0.7195\n",
      "Epoch 4626/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0720 - accuracy: 0.7480 - val_loss: 0.0798 - val_accuracy: 0.7187\n",
      "Epoch 4627/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0718 - accuracy: 0.7487 - val_loss: 0.0795 - val_accuracy: 0.7211\n",
      "Epoch 4628/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0716 - accuracy: 0.7492 - val_loss: 0.0815 - val_accuracy: 0.7201\n",
      "Epoch 4629/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0717 - accuracy: 0.7501 - val_loss: 0.0812 - val_accuracy: 0.7178\n",
      "Epoch 4630/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0717 - accuracy: 0.7499 - val_loss: 0.0800 - val_accuracy: 0.7226\n",
      "Epoch 4631/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0719 - accuracy: 0.7482 - val_loss: 0.0803 - val_accuracy: 0.7187\n",
      "Epoch 4632/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0717 - accuracy: 0.7492 - val_loss: 0.0812 - val_accuracy: 0.7189\n",
      "Epoch 4633/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0716 - accuracy: 0.7505 - val_loss: 0.0800 - val_accuracy: 0.7210\n",
      "Epoch 4634/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0718 - accuracy: 0.7495 - val_loss: 0.0806 - val_accuracy: 0.7209\n",
      "Epoch 4635/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0720 - accuracy: 0.7480 - val_loss: 0.0803 - val_accuracy: 0.7201\n",
      "Epoch 4636/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0716 - accuracy: 0.7497 - val_loss: 0.0826 - val_accuracy: 0.7192\n",
      "Epoch 4637/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0718 - accuracy: 0.7499 - val_loss: 0.0801 - val_accuracy: 0.7193\n",
      "Epoch 4638/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0719 - accuracy: 0.7485 - val_loss: 0.0802 - val_accuracy: 0.7196\n",
      "Epoch 4639/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0720 - accuracy: 0.7481 - val_loss: 0.0795 - val_accuracy: 0.7191\n",
      "Epoch 4640/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0721 - accuracy: 0.7474 - val_loss: 0.0793 - val_accuracy: 0.7208\n",
      "Epoch 4641/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0720 - accuracy: 0.7479 - val_loss: 0.0804 - val_accuracy: 0.7179\n",
      "Epoch 4642/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0722 - accuracy: 0.7471 - val_loss: 0.0815 - val_accuracy: 0.7137\n",
      "Epoch 4643/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0723 - accuracy: 0.7472 - val_loss: 0.0797 - val_accuracy: 0.7208\n",
      "Epoch 4644/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0723 - accuracy: 0.7471 - val_loss: 0.0812 - val_accuracy: 0.7155\n",
      "Epoch 4645/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0720 - accuracy: 0.7474 - val_loss: 0.0805 - val_accuracy: 0.7157\n",
      "Epoch 4646/5000\n",
      "11786/11786 [==============================] - 8s 661us/step - loss: 0.0720 - accuracy: 0.7473 - val_loss: 0.0800 - val_accuracy: 0.7181\n",
      "Epoch 4647/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0717 - accuracy: 0.7485 - val_loss: 0.0806 - val_accuracy: 0.7213\n",
      "Epoch 4648/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0716 - accuracy: 0.7488 - val_loss: 0.0797 - val_accuracy: 0.7220\n",
      "Epoch 4649/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0718 - accuracy: 0.7485 - val_loss: 0.0814 - val_accuracy: 0.7146\n",
      "Epoch 4650/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0719 - accuracy: 0.7487 - val_loss: 0.0820 - val_accuracy: 0.7157\n",
      "Epoch 4651/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0716 - accuracy: 0.7498 - val_loss: 0.0807 - val_accuracy: 0.7167\n",
      "Epoch 4652/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0715 - accuracy: 0.7493 - val_loss: 0.0797 - val_accuracy: 0.7195\n",
      "Epoch 4653/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0715 - accuracy: 0.7499 - val_loss: 0.0803 - val_accuracy: 0.7165\n",
      "Epoch 4654/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0716 - accuracy: 0.7495 - val_loss: 0.0793 - val_accuracy: 0.7231\n",
      "Epoch 4655/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0717 - accuracy: 0.7487 - val_loss: 0.0815 - val_accuracy: 0.7130\n",
      "Epoch 4656/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0719 - accuracy: 0.7487 - val_loss: 0.0811 - val_accuracy: 0.7183\n",
      "Epoch 4657/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0716 - accuracy: 0.7495 - val_loss: 0.0804 - val_accuracy: 0.7194\n",
      "Epoch 4658/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0713 - accuracy: 0.7501 - val_loss: 0.0815 - val_accuracy: 0.7182\n",
      "Epoch 4659/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0717 - accuracy: 0.7491 - val_loss: 0.0801 - val_accuracy: 0.7186\n",
      "Epoch 4660/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0716 - accuracy: 0.7492 - val_loss: 0.0795 - val_accuracy: 0.7207\n",
      "Epoch 4661/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0717 - accuracy: 0.7490 - val_loss: 0.0802 - val_accuracy: 0.7171\n",
      "Epoch 4662/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0724 - accuracy: 0.7465 - val_loss: 0.0799 - val_accuracy: 0.7188\n",
      "Epoch 4663/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0720 - accuracy: 0.7482 - val_loss: 0.0799 - val_accuracy: 0.7188\n",
      "Epoch 4664/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0717 - accuracy: 0.7493 - val_loss: 0.0796 - val_accuracy: 0.7202\n",
      "Epoch 4665/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0716 - accuracy: 0.7496 - val_loss: 0.0803 - val_accuracy: 0.7213\n",
      "Epoch 4666/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0717 - accuracy: 0.7485 - val_loss: 0.0799 - val_accuracy: 0.7205\n",
      "Epoch 4667/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0717 - accuracy: 0.7499 - val_loss: 0.0795 - val_accuracy: 0.7210\n",
      "Epoch 4668/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0717 - accuracy: 0.7493 - val_loss: 0.0801 - val_accuracy: 0.7178\n",
      "Epoch 4669/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0716 - accuracy: 0.7496 - val_loss: 0.0794 - val_accuracy: 0.7220\n",
      "Epoch 4670/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0717 - accuracy: 0.7487 - val_loss: 0.0799 - val_accuracy: 0.7199\n",
      "Epoch 4671/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0722 - accuracy: 0.7467 - val_loss: 0.0807 - val_accuracy: 0.7147\n",
      "Epoch 4672/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0720 - accuracy: 0.7476 - val_loss: 0.0808 - val_accuracy: 0.7173\n",
      "Epoch 4673/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0718 - accuracy: 0.7491 - val_loss: 0.0798 - val_accuracy: 0.7195\n",
      "Epoch 4674/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0721 - accuracy: 0.7472 - val_loss: 0.0820 - val_accuracy: 0.7173\n",
      "Epoch 4675/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0720 - accuracy: 0.7480 - val_loss: 0.0813 - val_accuracy: 0.7175\n",
      "Epoch 4676/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0720 - accuracy: 0.7479 - val_loss: 0.0808 - val_accuracy: 0.7161\n",
      "Epoch 4677/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0725 - accuracy: 0.7452 - val_loss: 0.0827 - val_accuracy: 0.7101\n",
      "Epoch 4678/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0717 - accuracy: 0.7475 - val_loss: 0.0797 - val_accuracy: 0.7206\n",
      "Epoch 4679/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0720 - accuracy: 0.7478 - val_loss: 0.0801 - val_accuracy: 0.7179\n",
      "Epoch 4680/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0717 - accuracy: 0.7478 - val_loss: 0.0793 - val_accuracy: 0.7240\n",
      "Epoch 4681/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0716 - accuracy: 0.7496 - val_loss: 0.0800 - val_accuracy: 0.7187\n",
      "Epoch 4682/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0715 - accuracy: 0.7491 - val_loss: 0.0803 - val_accuracy: 0.7178\n",
      "Epoch 4683/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0716 - accuracy: 0.7488 - val_loss: 0.0810 - val_accuracy: 0.7208\n",
      "Epoch 4684/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0714 - accuracy: 0.7488 - val_loss: 0.0804 - val_accuracy: 0.7131\n",
      "Epoch 4685/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0716 - accuracy: 0.7490 - val_loss: 0.0802 - val_accuracy: 0.7200\n",
      "Epoch 4686/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0714 - accuracy: 0.7496 - val_loss: 0.0797 - val_accuracy: 0.7221\n",
      "Epoch 4687/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0716 - accuracy: 0.7491 - val_loss: 0.0802 - val_accuracy: 0.7194\n",
      "Epoch 4688/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0719 - accuracy: 0.7479 - val_loss: 0.0796 - val_accuracy: 0.7194\n",
      "Epoch 4689/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0721 - accuracy: 0.7469 - val_loss: 0.0794 - val_accuracy: 0.7194\n",
      "Epoch 4690/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0716 - accuracy: 0.7480 - val_loss: 0.0804 - val_accuracy: 0.7173\n",
      "Epoch 4691/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0718 - accuracy: 0.7481 - val_loss: 0.0807 - val_accuracy: 0.7183\n",
      "Epoch 4692/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0719 - accuracy: 0.7482 - val_loss: 0.0797 - val_accuracy: 0.7219\n",
      "Epoch 4693/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0719 - accuracy: 0.7479 - val_loss: 0.0804 - val_accuracy: 0.7164\n",
      "Epoch 4694/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0715 - accuracy: 0.7496 - val_loss: 0.0799 - val_accuracy: 0.7180\n",
      "Epoch 4695/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0716 - accuracy: 0.7484 - val_loss: 0.0800 - val_accuracy: 0.7187\n",
      "Epoch 4696/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0718 - accuracy: 0.7489 - val_loss: 0.0805 - val_accuracy: 0.7189\n",
      "Epoch 4697/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0716 - accuracy: 0.7487 - val_loss: 0.0796 - val_accuracy: 0.7205\n",
      "Epoch 4698/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0722 - accuracy: 0.7459 - val_loss: 0.0798 - val_accuracy: 0.7197\n",
      "Epoch 4699/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0721 - accuracy: 0.7465 - val_loss: 0.0818 - val_accuracy: 0.7116\n",
      "Epoch 4700/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0719 - accuracy: 0.7476 - val_loss: 0.0798 - val_accuracy: 0.7196\n",
      "Epoch 4701/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0719 - accuracy: 0.7481 - val_loss: 0.0799 - val_accuracy: 0.7177\n",
      "Epoch 4702/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0721 - accuracy: 0.7468 - val_loss: 0.0799 - val_accuracy: 0.7214\n",
      "Epoch 4703/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0721 - accuracy: 0.7464 - val_loss: 0.0809 - val_accuracy: 0.7151\n",
      "Epoch 4704/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0719 - accuracy: 0.7471 - val_loss: 0.0804 - val_accuracy: 0.7137\n",
      "Epoch 4705/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0723 - accuracy: 0.7454 - val_loss: 0.0810 - val_accuracy: 0.7165\n",
      "Epoch 4706/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0715 - accuracy: 0.7489 - val_loss: 0.0801 - val_accuracy: 0.7203\n",
      "Epoch 4707/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0720 - accuracy: 0.7473 - val_loss: 0.0795 - val_accuracy: 0.7181\n",
      "Epoch 4708/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0718 - accuracy: 0.7476 - val_loss: 0.0805 - val_accuracy: 0.7175\n",
      "Epoch 4709/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0718 - accuracy: 0.7478 - val_loss: 0.0805 - val_accuracy: 0.7192\n",
      "Epoch 4710/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0720 - accuracy: 0.7470 - val_loss: 0.0812 - val_accuracy: 0.7140\n",
      "Epoch 4711/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0720 - accuracy: 0.7466 - val_loss: 0.0801 - val_accuracy: 0.7201\n",
      "Epoch 4712/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0722 - accuracy: 0.7464 - val_loss: 0.0795 - val_accuracy: 0.7217\n",
      "Epoch 4713/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0715 - accuracy: 0.7496 - val_loss: 0.0801 - val_accuracy: 0.7219\n",
      "Epoch 4714/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0717 - accuracy: 0.7487 - val_loss: 0.0810 - val_accuracy: 0.7166\n",
      "Epoch 4715/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0718 - accuracy: 0.7472 - val_loss: 0.0796 - val_accuracy: 0.7199\n",
      "Epoch 4716/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0718 - accuracy: 0.7476 - val_loss: 0.0797 - val_accuracy: 0.7189\n",
      "Epoch 4717/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0718 - accuracy: 0.7474 - val_loss: 0.0791 - val_accuracy: 0.7215\n",
      "Epoch 4718/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0718 - accuracy: 0.7473 - val_loss: 0.0801 - val_accuracy: 0.7215\n",
      "Epoch 4719/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0719 - accuracy: 0.7473 - val_loss: 0.0807 - val_accuracy: 0.7172\n",
      "Epoch 4720/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0719 - accuracy: 0.7471 - val_loss: 0.0809 - val_accuracy: 0.7169\n",
      "Epoch 4721/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0719 - accuracy: 0.7470 - val_loss: 0.0812 - val_accuracy: 0.7157\n",
      "Epoch 4722/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0721 - accuracy: 0.7475 - val_loss: 0.0810 - val_accuracy: 0.7159\n",
      "Epoch 4723/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0721 - accuracy: 0.7474 - val_loss: 0.0799 - val_accuracy: 0.7209\n",
      "Epoch 4724/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0721 - accuracy: 0.7470 - val_loss: 0.0801 - val_accuracy: 0.7162\n",
      "Epoch 4725/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0717 - accuracy: 0.7490 - val_loss: 0.0799 - val_accuracy: 0.7151\n",
      "Epoch 4726/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0717 - accuracy: 0.7490 - val_loss: 0.0800 - val_accuracy: 0.7177\n",
      "Epoch 4727/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0718 - accuracy: 0.7488 - val_loss: 0.0798 - val_accuracy: 0.7200\n",
      "Epoch 4728/5000\n",
      "11786/11786 [==============================] - 8s 657us/step - loss: 0.0719 - accuracy: 0.7476 - val_loss: 0.0800 - val_accuracy: 0.7176\n",
      "Epoch 4729/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0725 - accuracy: 0.7453 - val_loss: 0.0803 - val_accuracy: 0.7179\n",
      "Epoch 4730/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0716 - accuracy: 0.7486 - val_loss: 0.0810 - val_accuracy: 0.7136\n",
      "Epoch 4731/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0717 - accuracy: 0.7489 - val_loss: 0.0801 - val_accuracy: 0.7201\n",
      "Epoch 4732/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0717 - accuracy: 0.7489 - val_loss: 0.0808 - val_accuracy: 0.7162\n",
      "Epoch 4733/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0716 - accuracy: 0.7490 - val_loss: 0.0803 - val_accuracy: 0.7179\n",
      "Epoch 4734/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0717 - accuracy: 0.7487 - val_loss: 0.0811 - val_accuracy: 0.7127\n",
      "Epoch 4735/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0722 - accuracy: 0.7462 - val_loss: 0.0804 - val_accuracy: 0.7194\n",
      "Epoch 4736/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0719 - accuracy: 0.7474 - val_loss: 0.0801 - val_accuracy: 0.7214\n",
      "Epoch 4737/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0718 - accuracy: 0.7480 - val_loss: 0.0799 - val_accuracy: 0.7191\n",
      "Epoch 4738/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0714 - accuracy: 0.7499 - val_loss: 0.0804 - val_accuracy: 0.7190\n",
      "Epoch 4739/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0720 - accuracy: 0.7468 - val_loss: 0.0797 - val_accuracy: 0.7187\n",
      "Epoch 4740/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0720 - accuracy: 0.7466 - val_loss: 0.0810 - val_accuracy: 0.7185\n",
      "Epoch 4741/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0718 - accuracy: 0.7479 - val_loss: 0.0800 - val_accuracy: 0.7189\n",
      "Epoch 4742/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0716 - accuracy: 0.7485 - val_loss: 0.0796 - val_accuracy: 0.7204\n",
      "Epoch 4743/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0715 - accuracy: 0.7489 - val_loss: 0.0801 - val_accuracy: 0.7176\n",
      "Epoch 4744/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0714 - accuracy: 0.7497 - val_loss: 0.0802 - val_accuracy: 0.7200\n",
      "Epoch 4745/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0717 - accuracy: 0.7486 - val_loss: 0.0809 - val_accuracy: 0.7160\n",
      "Epoch 4746/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0716 - accuracy: 0.7487 - val_loss: 0.0796 - val_accuracy: 0.7208\n",
      "Epoch 4747/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0719 - accuracy: 0.7476 - val_loss: 0.0796 - val_accuracy: 0.7187\n",
      "Epoch 4748/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0719 - accuracy: 0.7477 - val_loss: 0.0805 - val_accuracy: 0.7203\n",
      "Epoch 4749/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0715 - accuracy: 0.7490 - val_loss: 0.0800 - val_accuracy: 0.7195\n",
      "Epoch 4750/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0720 - accuracy: 0.7472 - val_loss: 0.0806 - val_accuracy: 0.7208\n",
      "Epoch 4751/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0716 - accuracy: 0.7493 - val_loss: 0.0804 - val_accuracy: 0.7173\n",
      "Epoch 4752/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0719 - accuracy: 0.7479 - val_loss: 0.0809 - val_accuracy: 0.7153\n",
      "Epoch 4753/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0720 - accuracy: 0.7466 - val_loss: 0.0804 - val_accuracy: 0.7187\n",
      "Epoch 4754/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0718 - accuracy: 0.7479 - val_loss: 0.0805 - val_accuracy: 0.7143\n",
      "Epoch 4755/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0720 - accuracy: 0.7478 - val_loss: 0.0799 - val_accuracy: 0.7183\n",
      "Epoch 4756/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0720 - accuracy: 0.7471 - val_loss: 0.0801 - val_accuracy: 0.7206\n",
      "Epoch 4757/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0721 - accuracy: 0.7467 - val_loss: 0.0800 - val_accuracy: 0.7216\n",
      "Epoch 4758/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0716 - accuracy: 0.7489 - val_loss: 0.0803 - val_accuracy: 0.7181\n",
      "Epoch 4759/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0718 - accuracy: 0.7475 - val_loss: 0.0804 - val_accuracy: 0.7196\n",
      "Epoch 4760/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0717 - accuracy: 0.7485 - val_loss: 0.0801 - val_accuracy: 0.7187\n",
      "Epoch 4761/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0716 - accuracy: 0.7487 - val_loss: 0.0813 - val_accuracy: 0.7186\n",
      "Epoch 4762/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0719 - accuracy: 0.7476 - val_loss: 0.0801 - val_accuracy: 0.7201\n",
      "Epoch 4763/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0715 - accuracy: 0.7485 - val_loss: 0.0800 - val_accuracy: 0.7147\n",
      "Epoch 4764/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0718 - accuracy: 0.7481 - val_loss: 0.0799 - val_accuracy: 0.7215\n",
      "Epoch 4765/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0717 - accuracy: 0.7484 - val_loss: 0.0807 - val_accuracy: 0.7178\n",
      "Epoch 4766/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0715 - accuracy: 0.7493 - val_loss: 0.0798 - val_accuracy: 0.7214\n",
      "Epoch 4767/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0716 - accuracy: 0.7493 - val_loss: 0.0804 - val_accuracy: 0.7187\n",
      "Epoch 4768/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0719 - accuracy: 0.7475 - val_loss: 0.0795 - val_accuracy: 0.7194\n",
      "Epoch 4769/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0714 - accuracy: 0.7490 - val_loss: 0.0800 - val_accuracy: 0.7194\n",
      "Epoch 4770/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0716 - accuracy: 0.7484 - val_loss: 0.0798 - val_accuracy: 0.7186\n",
      "Epoch 4771/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0720 - accuracy: 0.7466 - val_loss: 0.0800 - val_accuracy: 0.7198\n",
      "Epoch 4772/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0715 - accuracy: 0.7485 - val_loss: 0.0809 - val_accuracy: 0.7192\n",
      "Epoch 4773/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0717 - accuracy: 0.7492 - val_loss: 0.0798 - val_accuracy: 0.7217\n",
      "Epoch 4774/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0716 - accuracy: 0.7489 - val_loss: 0.0799 - val_accuracy: 0.7209\n",
      "Epoch 4775/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0715 - accuracy: 0.7493 - val_loss: 0.0808 - val_accuracy: 0.7164\n",
      "Epoch 4776/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0715 - accuracy: 0.7486 - val_loss: 0.0802 - val_accuracy: 0.7194\n",
      "Epoch 4777/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0718 - accuracy: 0.7477 - val_loss: 0.0801 - val_accuracy: 0.7184\n",
      "Epoch 4778/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0715 - accuracy: 0.7488 - val_loss: 0.0815 - val_accuracy: 0.7140\n",
      "Epoch 4779/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0722 - accuracy: 0.7462 - val_loss: 0.0794 - val_accuracy: 0.7194\n",
      "Epoch 4780/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0715 - accuracy: 0.7487 - val_loss: 0.0803 - val_accuracy: 0.7195\n",
      "Epoch 4781/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0716 - accuracy: 0.7487 - val_loss: 0.0816 - val_accuracy: 0.7171\n",
      "Epoch 4782/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0720 - accuracy: 0.7461 - val_loss: 0.0797 - val_accuracy: 0.7185\n",
      "Epoch 4783/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0717 - accuracy: 0.7477 - val_loss: 0.0806 - val_accuracy: 0.7181\n",
      "Epoch 4784/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0718 - accuracy: 0.7480 - val_loss: 0.0811 - val_accuracy: 0.7166\n",
      "Epoch 4785/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0718 - accuracy: 0.7477 - val_loss: 0.0809 - val_accuracy: 0.7168\n",
      "Epoch 4786/5000\n",
      "11786/11786 [==============================] - 8s 684us/step - loss: 0.0717 - accuracy: 0.7486 - val_loss: 0.0797 - val_accuracy: 0.7215\n",
      "Epoch 4787/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0715 - accuracy: 0.7498 - val_loss: 0.0795 - val_accuracy: 0.7203\n",
      "Epoch 4788/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0717 - accuracy: 0.7489 - val_loss: 0.0805 - val_accuracy: 0.7177\n",
      "Epoch 4789/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0715 - accuracy: 0.7489 - val_loss: 0.0797 - val_accuracy: 0.7208\n",
      "Epoch 4790/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0716 - accuracy: 0.7487 - val_loss: 0.0804 - val_accuracy: 0.7170\n",
      "Epoch 4791/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0716 - accuracy: 0.7492 - val_loss: 0.0798 - val_accuracy: 0.7188\n",
      "Epoch 4792/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0718 - accuracy: 0.7485 - val_loss: 0.0807 - val_accuracy: 0.7168\n",
      "Epoch 4793/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0715 - accuracy: 0.7490 - val_loss: 0.0803 - val_accuracy: 0.7197\n",
      "Epoch 4794/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0718 - accuracy: 0.7470 - val_loss: 0.0800 - val_accuracy: 0.7200\n",
      "Epoch 4795/5000\n",
      "11786/11786 [==============================] - 8s 658us/step - loss: 0.0717 - accuracy: 0.7478 - val_loss: 0.0803 - val_accuracy: 0.7186\n",
      "Epoch 4796/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0717 - accuracy: 0.7476 - val_loss: 0.0822 - val_accuracy: 0.7109\n",
      "Epoch 4797/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0717 - accuracy: 0.7475 - val_loss: 0.0793 - val_accuracy: 0.7216\n",
      "Epoch 4798/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0717 - accuracy: 0.7479 - val_loss: 0.0798 - val_accuracy: 0.7202\n",
      "Epoch 4799/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0718 - accuracy: 0.7478 - val_loss: 0.0804 - val_accuracy: 0.7175\n",
      "Epoch 4800/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0717 - accuracy: 0.7486 - val_loss: 0.0802 - val_accuracy: 0.7194\n",
      "Epoch 4801/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0715 - accuracy: 0.7493 - val_loss: 0.0801 - val_accuracy: 0.7178\n",
      "Epoch 4802/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0715 - accuracy: 0.7496 - val_loss: 0.0800 - val_accuracy: 0.7196\n",
      "Epoch 4803/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0717 - accuracy: 0.7484 - val_loss: 0.0804 - val_accuracy: 0.7185\n",
      "Epoch 4804/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0715 - accuracy: 0.7489 - val_loss: 0.0797 - val_accuracy: 0.7203\n",
      "Epoch 4805/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0714 - accuracy: 0.7490 - val_loss: 0.0794 - val_accuracy: 0.7192\n",
      "Epoch 4806/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0716 - accuracy: 0.7487 - val_loss: 0.0805 - val_accuracy: 0.7169\n",
      "Epoch 4807/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0718 - accuracy: 0.7474 - val_loss: 0.0801 - val_accuracy: 0.7173\n",
      "Epoch 4808/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0716 - accuracy: 0.7478 - val_loss: 0.0796 - val_accuracy: 0.7172\n",
      "Epoch 4809/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0718 - accuracy: 0.7467 - val_loss: 0.0800 - val_accuracy: 0.7167\n",
      "Epoch 4810/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0718 - accuracy: 0.7467 - val_loss: 0.0810 - val_accuracy: 0.7157\n",
      "Epoch 4811/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0721 - accuracy: 0.7463 - val_loss: 0.0801 - val_accuracy: 0.7200\n",
      "Epoch 4812/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0716 - accuracy: 0.7483 - val_loss: 0.0813 - val_accuracy: 0.7149\n",
      "Epoch 4813/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0715 - accuracy: 0.7488 - val_loss: 0.0800 - val_accuracy: 0.7187\n",
      "Epoch 4814/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0718 - accuracy: 0.7475 - val_loss: 0.0844 - val_accuracy: 0.7035\n",
      "Epoch 4815/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0715 - accuracy: 0.7488 - val_loss: 0.0802 - val_accuracy: 0.7223\n",
      "Epoch 4816/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0714 - accuracy: 0.7491 - val_loss: 0.0797 - val_accuracy: 0.7200\n",
      "Epoch 4817/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0718 - accuracy: 0.7479 - val_loss: 0.0807 - val_accuracy: 0.7172\n",
      "Epoch 4818/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0716 - accuracy: 0.7480 - val_loss: 0.0802 - val_accuracy: 0.7189\n",
      "Epoch 4819/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0714 - accuracy: 0.7490 - val_loss: 0.0795 - val_accuracy: 0.7203\n",
      "Epoch 4820/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0714 - accuracy: 0.7488 - val_loss: 0.0795 - val_accuracy: 0.7203\n",
      "Epoch 4821/5000\n",
      "11786/11786 [==============================] - 8s 682us/step - loss: 0.0716 - accuracy: 0.7484 - val_loss: 0.0799 - val_accuracy: 0.7198\n",
      "Epoch 4822/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0720 - accuracy: 0.7465 - val_loss: 0.0815 - val_accuracy: 0.7167\n",
      "Epoch 4823/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0714 - accuracy: 0.7485 - val_loss: 0.0801 - val_accuracy: 0.7193\n",
      "Epoch 4824/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0714 - accuracy: 0.7489 - val_loss: 0.0816 - val_accuracy: 0.7138\n",
      "Epoch 4825/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0717 - accuracy: 0.7478 - val_loss: 0.0814 - val_accuracy: 0.7173\n",
      "Epoch 4826/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0715 - accuracy: 0.7489 - val_loss: 0.0797 - val_accuracy: 0.7208\n",
      "Epoch 4827/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0714 - accuracy: 0.7496 - val_loss: 0.0797 - val_accuracy: 0.7188\n",
      "Epoch 4828/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0713 - accuracy: 0.7493 - val_loss: 0.0788 - val_accuracy: 0.7224\n",
      "Epoch 4829/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0712 - accuracy: 0.7493 - val_loss: 0.0801 - val_accuracy: 0.7210\n",
      "Epoch 4830/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0713 - accuracy: 0.7504 - val_loss: 0.0804 - val_accuracy: 0.7211\n",
      "Epoch 4831/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0718 - accuracy: 0.7476 - val_loss: 0.0816 - val_accuracy: 0.7168\n",
      "Epoch 4832/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0715 - accuracy: 0.7487 - val_loss: 0.0795 - val_accuracy: 0.7210\n",
      "Epoch 4833/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0716 - accuracy: 0.7479 - val_loss: 0.0798 - val_accuracy: 0.7187\n",
      "Epoch 4834/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0712 - accuracy: 0.7493 - val_loss: 0.0801 - val_accuracy: 0.7163\n",
      "Epoch 4835/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0713 - accuracy: 0.7496 - val_loss: 0.0811 - val_accuracy: 0.7168\n",
      "Epoch 4836/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0716 - accuracy: 0.7480 - val_loss: 0.0799 - val_accuracy: 0.7198\n",
      "Epoch 4837/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0714 - accuracy: 0.7494 - val_loss: 0.0810 - val_accuracy: 0.7186\n",
      "Epoch 4838/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0716 - accuracy: 0.7494 - val_loss: 0.0799 - val_accuracy: 0.7210\n",
      "Epoch 4839/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0715 - accuracy: 0.7493 - val_loss: 0.0803 - val_accuracy: 0.7216\n",
      "Epoch 4840/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0716 - accuracy: 0.7479 - val_loss: 0.0800 - val_accuracy: 0.7192\n",
      "Epoch 4841/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0714 - accuracy: 0.7494 - val_loss: 0.0794 - val_accuracy: 0.7206\n",
      "Epoch 4842/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0719 - accuracy: 0.7482 - val_loss: 0.0805 - val_accuracy: 0.7190\n",
      "Epoch 4843/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0717 - accuracy: 0.7483 - val_loss: 0.0797 - val_accuracy: 0.7186\n",
      "Epoch 4844/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0717 - accuracy: 0.7472 - val_loss: 0.0801 - val_accuracy: 0.7204\n",
      "Epoch 4845/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0721 - accuracy: 0.7461 - val_loss: 0.0807 - val_accuracy: 0.7171\n",
      "Epoch 4846/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0718 - accuracy: 0.7467 - val_loss: 0.0806 - val_accuracy: 0.7173\n",
      "Epoch 4847/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0715 - accuracy: 0.7481 - val_loss: 0.0804 - val_accuracy: 0.7159\n",
      "Epoch 4848/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0716 - accuracy: 0.7477 - val_loss: 0.0825 - val_accuracy: 0.7108\n",
      "Epoch 4849/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0714 - accuracy: 0.7483 - val_loss: 0.0806 - val_accuracy: 0.7143\n",
      "Epoch 4850/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0713 - accuracy: 0.7497 - val_loss: 0.0799 - val_accuracy: 0.7187\n",
      "Epoch 4851/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0716 - accuracy: 0.7488 - val_loss: 0.0795 - val_accuracy: 0.7214\n",
      "Epoch 4852/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0715 - accuracy: 0.7490 - val_loss: 0.0804 - val_accuracy: 0.7171\n",
      "Epoch 4853/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0713 - accuracy: 0.7493 - val_loss: 0.0800 - val_accuracy: 0.7177\n",
      "Epoch 4854/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0719 - accuracy: 0.7466 - val_loss: 0.0809 - val_accuracy: 0.7168\n",
      "Epoch 4855/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0715 - accuracy: 0.7480 - val_loss: 0.0794 - val_accuracy: 0.7206\n",
      "Epoch 4856/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0713 - accuracy: 0.7491 - val_loss: 0.0799 - val_accuracy: 0.7203\n",
      "Epoch 4857/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0714 - accuracy: 0.7494 - val_loss: 0.0800 - val_accuracy: 0.7240\n",
      "Epoch 4858/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0715 - accuracy: 0.7484 - val_loss: 0.0791 - val_accuracy: 0.7207\n",
      "Epoch 4859/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0715 - accuracy: 0.7485 - val_loss: 0.0802 - val_accuracy: 0.7196\n",
      "Epoch 4860/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0716 - accuracy: 0.7483 - val_loss: 0.0805 - val_accuracy: 0.7160\n",
      "Epoch 4861/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0717 - accuracy: 0.7479 - val_loss: 0.0806 - val_accuracy: 0.7173\n",
      "Epoch 4862/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0717 - accuracy: 0.7478 - val_loss: 0.0799 - val_accuracy: 0.7185\n",
      "Epoch 4863/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0719 - accuracy: 0.7477 - val_loss: 0.0822 - val_accuracy: 0.7107\n",
      "Epoch 4864/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0719 - accuracy: 0.7470 - val_loss: 0.0802 - val_accuracy: 0.7155\n",
      "Epoch 4865/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0719 - accuracy: 0.7466 - val_loss: 0.0822 - val_accuracy: 0.7131\n",
      "Epoch 4866/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0714 - accuracy: 0.7493 - val_loss: 0.0804 - val_accuracy: 0.7191\n",
      "Epoch 4867/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0717 - accuracy: 0.7478 - val_loss: 0.0811 - val_accuracy: 0.7190\n",
      "Epoch 4868/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0720 - accuracy: 0.7462 - val_loss: 0.0810 - val_accuracy: 0.7164\n",
      "Epoch 4869/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0716 - accuracy: 0.7479 - val_loss: 0.0811 - val_accuracy: 0.7144\n",
      "Epoch 4870/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0712 - accuracy: 0.7497 - val_loss: 0.0794 - val_accuracy: 0.7211\n",
      "Epoch 4871/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0712 - accuracy: 0.7497 - val_loss: 0.0789 - val_accuracy: 0.7216\n",
      "Epoch 4872/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0715 - accuracy: 0.7483 - val_loss: 0.0812 - val_accuracy: 0.7115\n",
      "Epoch 4873/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0713 - accuracy: 0.7492 - val_loss: 0.0798 - val_accuracy: 0.7224\n",
      "Epoch 4874/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0714 - accuracy: 0.7490 - val_loss: 0.0801 - val_accuracy: 0.7173\n",
      "Epoch 4875/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0717 - accuracy: 0.7478 - val_loss: 0.0805 - val_accuracy: 0.7173\n",
      "Epoch 4876/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0717 - accuracy: 0.7477 - val_loss: 0.0804 - val_accuracy: 0.7189\n",
      "Epoch 4877/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0716 - accuracy: 0.7485 - val_loss: 0.0802 - val_accuracy: 0.7175\n",
      "Epoch 4878/5000\n",
      "11786/11786 [==============================] - 8s 679us/step - loss: 0.0714 - accuracy: 0.7493 - val_loss: 0.0802 - val_accuracy: 0.7172\n",
      "Epoch 4879/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0715 - accuracy: 0.7476 - val_loss: 0.0798 - val_accuracy: 0.7221\n",
      "Epoch 4880/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0716 - accuracy: 0.7483 - val_loss: 0.0818 - val_accuracy: 0.7137\n",
      "Epoch 4881/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0714 - accuracy: 0.7485 - val_loss: 0.0797 - val_accuracy: 0.7226\n",
      "Epoch 4882/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0715 - accuracy: 0.7485 - val_loss: 0.0800 - val_accuracy: 0.7214\n",
      "Epoch 4883/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0716 - accuracy: 0.7483 - val_loss: 0.0807 - val_accuracy: 0.7166\n",
      "Epoch 4884/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0714 - accuracy: 0.7487 - val_loss: 0.0805 - val_accuracy: 0.7149\n",
      "Epoch 4885/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0715 - accuracy: 0.7484 - val_loss: 0.0800 - val_accuracy: 0.7168\n",
      "Epoch 4886/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0717 - accuracy: 0.7476 - val_loss: 0.0791 - val_accuracy: 0.7213\n",
      "Epoch 4887/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0715 - accuracy: 0.7481 - val_loss: 0.0803 - val_accuracy: 0.7193\n",
      "Epoch 4888/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0715 - accuracy: 0.7488 - val_loss: 0.0799 - val_accuracy: 0.7211\n",
      "Epoch 4889/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0714 - accuracy: 0.7480 - val_loss: 0.0799 - val_accuracy: 0.7189\n",
      "Epoch 4890/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0716 - accuracy: 0.7485 - val_loss: 0.0812 - val_accuracy: 0.7173\n",
      "Epoch 4891/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0715 - accuracy: 0.7484 - val_loss: 0.0798 - val_accuracy: 0.7175\n",
      "Epoch 4892/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0716 - accuracy: 0.7486 - val_loss: 0.0814 - val_accuracy: 0.7183\n",
      "Epoch 4893/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0714 - accuracy: 0.7499 - val_loss: 0.0801 - val_accuracy: 0.7205\n",
      "Epoch 4894/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0714 - accuracy: 0.7500 - val_loss: 0.0813 - val_accuracy: 0.7172\n",
      "Epoch 4895/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0716 - accuracy: 0.7472 - val_loss: 0.0814 - val_accuracy: 0.7158\n",
      "Epoch 4896/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0719 - accuracy: 0.7468 - val_loss: 0.0806 - val_accuracy: 0.7166\n",
      "Epoch 4897/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0720 - accuracy: 0.7467 - val_loss: 0.0800 - val_accuracy: 0.7210\n",
      "Epoch 4898/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0716 - accuracy: 0.7484 - val_loss: 0.0797 - val_accuracy: 0.7213\n",
      "Epoch 4899/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0716 - accuracy: 0.7479 - val_loss: 0.0801 - val_accuracy: 0.7177\n",
      "Epoch 4900/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0714 - accuracy: 0.7493 - val_loss: 0.0797 - val_accuracy: 0.7229\n",
      "Epoch 4901/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0714 - accuracy: 0.7491 - val_loss: 0.0797 - val_accuracy: 0.7217\n",
      "Epoch 4902/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0715 - accuracy: 0.7483 - val_loss: 0.0800 - val_accuracy: 0.7175\n",
      "Epoch 4903/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0716 - accuracy: 0.7482 - val_loss: 0.0795 - val_accuracy: 0.7215\n",
      "Epoch 4904/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0716 - accuracy: 0.7482 - val_loss: 0.0806 - val_accuracy: 0.7171\n",
      "Epoch 4905/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0717 - accuracy: 0.7474 - val_loss: 0.0815 - val_accuracy: 0.7172\n",
      "Epoch 4906/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0716 - accuracy: 0.7475 - val_loss: 0.0800 - val_accuracy: 0.7156\n",
      "Epoch 4907/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0719 - accuracy: 0.7466 - val_loss: 0.0803 - val_accuracy: 0.7183\n",
      "Epoch 4908/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0718 - accuracy: 0.7472 - val_loss: 0.0794 - val_accuracy: 0.7219\n",
      "Epoch 4909/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0713 - accuracy: 0.7488 - val_loss: 0.0799 - val_accuracy: 0.7208\n",
      "Epoch 4910/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0713 - accuracy: 0.7502 - val_loss: 0.0790 - val_accuracy: 0.7216\n",
      "Epoch 4911/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0715 - accuracy: 0.7488 - val_loss: 0.0799 - val_accuracy: 0.7182\n",
      "Epoch 4912/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0719 - accuracy: 0.7470 - val_loss: 0.0809 - val_accuracy: 0.7149\n",
      "Epoch 4913/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0717 - accuracy: 0.7478 - val_loss: 0.0796 - val_accuracy: 0.7211\n",
      "Epoch 4914/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0715 - accuracy: 0.7487 - val_loss: 0.0799 - val_accuracy: 0.7182\n",
      "Epoch 4915/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0714 - accuracy: 0.7491 - val_loss: 0.0795 - val_accuracy: 0.7200\n",
      "Epoch 4916/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0713 - accuracy: 0.7489 - val_loss: 0.0820 - val_accuracy: 0.7088\n",
      "Epoch 4917/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0714 - accuracy: 0.7492 - val_loss: 0.0793 - val_accuracy: 0.7218\n",
      "Epoch 4918/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0713 - accuracy: 0.7486 - val_loss: 0.0795 - val_accuracy: 0.7216\n",
      "Epoch 4919/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0714 - accuracy: 0.7489 - val_loss: 0.0797 - val_accuracy: 0.7195\n",
      "Epoch 4920/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0712 - accuracy: 0.7494 - val_loss: 0.0805 - val_accuracy: 0.7170\n",
      "Epoch 4921/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0713 - accuracy: 0.7486 - val_loss: 0.0799 - val_accuracy: 0.7189\n",
      "Epoch 4922/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0715 - accuracy: 0.7481 - val_loss: 0.0808 - val_accuracy: 0.7167\n",
      "Epoch 4923/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0719 - accuracy: 0.7473 - val_loss: 0.0816 - val_accuracy: 0.7148\n",
      "Epoch 4924/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0716 - accuracy: 0.7486 - val_loss: 0.0804 - val_accuracy: 0.7172\n",
      "Epoch 4925/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0717 - accuracy: 0.7472 - val_loss: 0.0809 - val_accuracy: 0.7155\n",
      "Epoch 4926/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0716 - accuracy: 0.7488 - val_loss: 0.0795 - val_accuracy: 0.7229\n",
      "Epoch 4927/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0715 - accuracy: 0.7482 - val_loss: 0.0806 - val_accuracy: 0.7167\n",
      "Epoch 4928/5000\n",
      "11786/11786 [==============================] - 8s 663us/step - loss: 0.0714 - accuracy: 0.7479 - val_loss: 0.0796 - val_accuracy: 0.7201\n",
      "Epoch 4929/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0714 - accuracy: 0.7493 - val_loss: 0.0800 - val_accuracy: 0.7177\n",
      "Epoch 4930/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0714 - accuracy: 0.7489 - val_loss: 0.0794 - val_accuracy: 0.7201\n",
      "Epoch 4931/5000\n",
      "11786/11786 [==============================] - 8s 683us/step - loss: 0.0714 - accuracy: 0.7491 - val_loss: 0.0804 - val_accuracy: 0.7218\n",
      "Epoch 4932/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0717 - accuracy: 0.7476 - val_loss: 0.0808 - val_accuracy: 0.7163\n",
      "Epoch 4933/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0713 - accuracy: 0.7491 - val_loss: 0.0802 - val_accuracy: 0.7177\n",
      "Epoch 4934/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0716 - accuracy: 0.7477 - val_loss: 0.0801 - val_accuracy: 0.7197\n",
      "Epoch 4935/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0714 - accuracy: 0.7485 - val_loss: 0.0789 - val_accuracy: 0.7217\n",
      "Epoch 4936/5000\n",
      "11786/11786 [==============================] - 8s 665us/step - loss: 0.0714 - accuracy: 0.7482 - val_loss: 0.0807 - val_accuracy: 0.7188\n",
      "Epoch 4937/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0715 - accuracy: 0.7479 - val_loss: 0.0794 - val_accuracy: 0.7177\n",
      "Epoch 4938/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0714 - accuracy: 0.7487 - val_loss: 0.0792 - val_accuracy: 0.7211\n",
      "Epoch 4939/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0713 - accuracy: 0.7490 - val_loss: 0.0795 - val_accuracy: 0.7206\n",
      "Epoch 4940/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0713 - accuracy: 0.7490 - val_loss: 0.0792 - val_accuracy: 0.7210\n",
      "Epoch 4941/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0713 - accuracy: 0.7503 - val_loss: 0.0799 - val_accuracy: 0.7211\n",
      "Epoch 4942/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0713 - accuracy: 0.7494 - val_loss: 0.0799 - val_accuracy: 0.7205\n",
      "Epoch 4943/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0713 - accuracy: 0.7488 - val_loss: 0.0798 - val_accuracy: 0.7199\n",
      "Epoch 4944/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0713 - accuracy: 0.7495 - val_loss: 0.0799 - val_accuracy: 0.7183\n",
      "Epoch 4945/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0714 - accuracy: 0.7486 - val_loss: 0.0800 - val_accuracy: 0.7195\n",
      "Epoch 4946/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0714 - accuracy: 0.7484 - val_loss: 0.0814 - val_accuracy: 0.7152\n",
      "Epoch 4947/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0713 - accuracy: 0.7488 - val_loss: 0.0796 - val_accuracy: 0.7211\n",
      "Epoch 4948/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0715 - accuracy: 0.7485 - val_loss: 0.0793 - val_accuracy: 0.7200\n",
      "Epoch 4949/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0716 - accuracy: 0.7477 - val_loss: 0.0800 - val_accuracy: 0.7177\n",
      "Epoch 4950/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0718 - accuracy: 0.7471 - val_loss: 0.0798 - val_accuracy: 0.7214\n",
      "Epoch 4951/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0716 - accuracy: 0.7481 - val_loss: 0.0793 - val_accuracy: 0.7213\n",
      "Epoch 4952/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0715 - accuracy: 0.7480 - val_loss: 0.0805 - val_accuracy: 0.7151\n",
      "Epoch 4953/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0719 - accuracy: 0.7465 - val_loss: 0.0800 - val_accuracy: 0.7205\n",
      "Epoch 4954/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0712 - accuracy: 0.7488 - val_loss: 0.0794 - val_accuracy: 0.7187\n",
      "Epoch 4955/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0716 - accuracy: 0.7482 - val_loss: 0.0798 - val_accuracy: 0.7203\n",
      "Epoch 4956/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0721 - accuracy: 0.7452 - val_loss: 0.0796 - val_accuracy: 0.7189\n",
      "Epoch 4957/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0719 - accuracy: 0.7472 - val_loss: 0.0805 - val_accuracy: 0.7162\n",
      "Epoch 4958/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0721 - accuracy: 0.7458 - val_loss: 0.0793 - val_accuracy: 0.7182\n",
      "Epoch 4959/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0716 - accuracy: 0.7476 - val_loss: 0.0793 - val_accuracy: 0.7198\n",
      "Epoch 4960/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0719 - accuracy: 0.7458 - val_loss: 0.0795 - val_accuracy: 0.7201\n",
      "Epoch 4961/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0720 - accuracy: 0.7464 - val_loss: 0.0808 - val_accuracy: 0.7172\n",
      "Epoch 4962/5000\n",
      "11786/11786 [==============================] - 8s 664us/step - loss: 0.0716 - accuracy: 0.7475 - val_loss: 0.0789 - val_accuracy: 0.7194\n",
      "Epoch 4963/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0715 - accuracy: 0.7479 - val_loss: 0.0787 - val_accuracy: 0.7217\n",
      "Epoch 4964/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0714 - accuracy: 0.7490 - val_loss: 0.0798 - val_accuracy: 0.7190\n",
      "Epoch 4965/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0716 - accuracy: 0.7487 - val_loss: 0.0800 - val_accuracy: 0.7189\n",
      "Epoch 4966/5000\n",
      "11786/11786 [==============================] - 8s 680us/step - loss: 0.0715 - accuracy: 0.7486 - val_loss: 0.0793 - val_accuracy: 0.7213\n",
      "Epoch 4967/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0714 - accuracy: 0.7489 - val_loss: 0.0812 - val_accuracy: 0.7180\n",
      "Epoch 4968/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0715 - accuracy: 0.7498 - val_loss: 0.0797 - val_accuracy: 0.7183\n",
      "Epoch 4969/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0717 - accuracy: 0.7483 - val_loss: 0.0812 - val_accuracy: 0.7184\n",
      "Epoch 4970/5000\n",
      "11786/11786 [==============================] - 8s 666us/step - loss: 0.0716 - accuracy: 0.7485 - val_loss: 0.0795 - val_accuracy: 0.7207\n",
      "Epoch 4971/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0717 - accuracy: 0.7480 - val_loss: 0.0792 - val_accuracy: 0.7218\n",
      "Epoch 4972/5000\n",
      "11786/11786 [==============================] - 8s 669us/step - loss: 0.0716 - accuracy: 0.7484 - val_loss: 0.0798 - val_accuracy: 0.7198\n",
      "Epoch 4973/5000\n",
      "11786/11786 [==============================] - 8s 676us/step - loss: 0.0716 - accuracy: 0.7483 - val_loss: 0.0802 - val_accuracy: 0.7199\n",
      "Epoch 4974/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0718 - accuracy: 0.7479 - val_loss: 0.0805 - val_accuracy: 0.7184\n",
      "Epoch 4975/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0720 - accuracy: 0.7471 - val_loss: 0.0805 - val_accuracy: 0.7174\n",
      "Epoch 4976/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0719 - accuracy: 0.7473 - val_loss: 0.0802 - val_accuracy: 0.7190\n",
      "Epoch 4977/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0719 - accuracy: 0.7465 - val_loss: 0.0800 - val_accuracy: 0.7204\n",
      "Epoch 4978/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0718 - accuracy: 0.7476 - val_loss: 0.0801 - val_accuracy: 0.7170\n",
      "Epoch 4979/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0716 - accuracy: 0.7479 - val_loss: 0.0803 - val_accuracy: 0.7183\n",
      "Epoch 4980/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0719 - accuracy: 0.7470 - val_loss: 0.0797 - val_accuracy: 0.7180\n",
      "Epoch 4981/5000\n",
      "11786/11786 [==============================] - 8s 668us/step - loss: 0.0719 - accuracy: 0.7463 - val_loss: 0.0800 - val_accuracy: 0.7209\n",
      "Epoch 4982/5000\n",
      "11786/11786 [==============================] - 8s 659us/step - loss: 0.0719 - accuracy: 0.7460 - val_loss: 0.0802 - val_accuracy: 0.7154\n",
      "Epoch 4983/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0715 - accuracy: 0.7477 - val_loss: 0.0792 - val_accuracy: 0.7212\n",
      "Epoch 4984/5000\n",
      "11786/11786 [==============================] - 8s 675us/step - loss: 0.0714 - accuracy: 0.7487 - val_loss: 0.0794 - val_accuracy: 0.7180\n",
      "Epoch 4985/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0714 - accuracy: 0.7485 - val_loss: 0.0798 - val_accuracy: 0.7148\n",
      "Epoch 4986/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0715 - accuracy: 0.7487 - val_loss: 0.0816 - val_accuracy: 0.7160\n",
      "Epoch 4987/5000\n",
      "11786/11786 [==============================] - 8s 674us/step - loss: 0.0715 - accuracy: 0.7485 - val_loss: 0.0787 - val_accuracy: 0.7228\n",
      "Epoch 4988/5000\n",
      "11786/11786 [==============================] - 8s 670us/step - loss: 0.0714 - accuracy: 0.7488 - val_loss: 0.0807 - val_accuracy: 0.7153\n",
      "Epoch 4989/5000\n",
      "11786/11786 [==============================] - 8s 667us/step - loss: 0.0714 - accuracy: 0.7487 - val_loss: 0.0792 - val_accuracy: 0.7207\n",
      "Epoch 4990/5000\n",
      "11786/11786 [==============================] - 8s 671us/step - loss: 0.0712 - accuracy: 0.7497 - val_loss: 0.0785 - val_accuracy: 0.7249\n",
      "Epoch 4991/5000\n",
      "11786/11786 [==============================] - 8s 672us/step - loss: 0.0716 - accuracy: 0.7480 - val_loss: 0.0793 - val_accuracy: 0.7201\n",
      "Epoch 4992/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0718 - accuracy: 0.7470 - val_loss: 0.0791 - val_accuracy: 0.7199\n",
      "Epoch 4993/5000\n",
      "11786/11786 [==============================] - 8s 687us/step - loss: 0.0716 - accuracy: 0.7477 - val_loss: 0.0800 - val_accuracy: 0.7172\n",
      "Epoch 4994/5000\n",
      "11786/11786 [==============================] - 8s 689us/step - loss: 0.0718 - accuracy: 0.7474 - val_loss: 0.0813 - val_accuracy: 0.7155\n",
      "Epoch 4995/5000\n",
      "11786/11786 [==============================] - 8s 678us/step - loss: 0.0716 - accuracy: 0.7481 - val_loss: 0.0795 - val_accuracy: 0.7211\n",
      "Epoch 4996/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0713 - accuracy: 0.7501 - val_loss: 0.0787 - val_accuracy: 0.7223\n",
      "Epoch 4997/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0713 - accuracy: 0.7491 - val_loss: 0.0796 - val_accuracy: 0.7212\n",
      "Epoch 4998/5000\n",
      "11786/11786 [==============================] - 8s 673us/step - loss: 0.0716 - accuracy: 0.7481 - val_loss: 0.0795 - val_accuracy: 0.7231\n",
      "Epoch 4999/5000\n",
      "11786/11786 [==============================] - 8s 677us/step - loss: 0.0715 - accuracy: 0.7485 - val_loss: 0.0794 - val_accuracy: 0.7193\n",
      "Epoch 5000/5000\n",
      "11786/11786 [==============================] - 8s 681us/step - loss: 0.0714 - accuracy: 0.7481 - val_loss: 0.0802 - val_accuracy: 0.7174\n"
     ]
    }
   ],
   "source": [
    "history = (model.fit(X_train, y_train, epochs=5000, validation_data=(X_val, y_val), callbacks=[model_checkpoint_callback]))\n",
    "#history = (model.fit(X_train, y_train, epochs=5000, validation_data=(X_val, y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICT AND PLOT\n",
    "\n",
    "##### For 5000 epochs, from data saved in history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/csuser/DATA/ARTEMIS/yale\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig('/media/csuser/DATA/ARTEMIS/yale/figs/NN_ACCURACYvsEPOCHS.png', dpi=500)\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig('/media/csuser/DATA/ARTEMIS/yale/figs/NN_LOSSvsEPOCHS.png', dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f9f3175db50>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model.load_weights('/media/csuser/DATA/ARTEMIS/models/yale_smote')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(117852, 207)\n",
      "3683/3683 [==============================] - 2s 334us/step\n",
      "(117852, 5)\n",
      "(117852, 5)\n",
      "[4 4 0 ... 1 4 1]\n",
      "[4 3 0 ... 1 3 1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CONFUSION MATRIX\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, classification_report, recall_score, ConfusionMatrixDisplay\n",
    "from numpy import argmax\n",
    "\n",
    "print(X_test.shape)\n",
    "y_pred = model.predict(X_test)\n",
    "print(y_test.shape)\n",
    "print(y_pred.shape)\n",
    "y_test = argmax(a=y_test, axis=1)\n",
    "y_pred = argmax(a=y_pred, axis=1)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "ConfusionMatrixDisplay.from_predictions(y_test+1, y_pred+1)\n",
    "plt.savefig('/media/csuser/DATA/ARTEMIS/yale/figs/NN_confusion_yale_smote.png', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 3, 0, ..., 1, 3, 1])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23865. 16605. 12966. 16351. 17592.] [  113.  6709. 10483.  7244.  5924.] [  469.  5258.  7984. 10527.  6235.]\n",
      "[0.98072656 0.75950236 0.61890215 0.60834139 0.73832207] [0.99528735 0.71223299 0.55294469 0.6929858  0.74808641] [0.99528735 0.71223299 0.55294469 0.6929858  0.74808641]\n"
     ]
    }
   ],
   "source": [
    "TP = np.zeros(5)\n",
    "FP = np.zeros(5)\n",
    "FN = np.zeros(5)\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(len(y_test)):\n",
    "        if y_test[j] == i and y_pred[j] == i:\n",
    "            TP[i] += 1\n",
    "        elif y_test[j] == i and y_pred[j] != i:\n",
    "            FN[i] += 1\n",
    "        elif y_test[j] != i and y_pred[j] == i:\n",
    "            FP[i] += 1\n",
    "print(TP, FN, FP)\n",
    "\n",
    "# Precision or positive predictive value\n",
    "PPV = TP/(TP+FP)\n",
    "\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "\n",
    "# Overall accuracy\n",
    "ACC = np.zeros(5)\n",
    "class_totals = np.zeros(5)\n",
    "for i in range(5):\n",
    "    for j in range(len(y_test)):\n",
    "        class_totals[y_test[j]] += 1\n",
    "        if y_test[j] == y_pred[j]:\n",
    "            ACC[y_test[j]] += 1\n",
    "ACC /= class_totals\n",
    "\n",
    "# F1\n",
    "F1 = 2 * (PPV * TPR) / (PPV + TPR)\n",
    "\n",
    "print(PPV, TPR, F1, ACC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc:  0.7414299290635713\n",
      "Prec:  0.7420470825250738\n",
      "Recall:  0.7414299290635713\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_test, y_pred)\n",
    "print('Acc: ', acc)\n",
    "\n",
    "prec = precision_score(y_test, y_pred, average='weighted')\n",
    "print('Prec: ', prec)\n",
    "\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "print('Recall: ', recall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
