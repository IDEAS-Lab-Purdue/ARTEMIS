{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data, Clean and Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import string\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(425087, 7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing data and keeping only wanted cols\n",
    "df = pd.read_csv('triage_original.csv')\n",
    "df = df.drop(columns=['subject_id', 'stay_id', 'chiefcomplaint', 'pain'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>heartrate</th>\n",
       "      <th>resprate</th>\n",
       "      <th>o2sat</th>\n",
       "      <th>sbp</th>\n",
       "      <th>dbp</th>\n",
       "      <th>acuity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97.8</td>\n",
       "      <td>87.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98.4</td>\n",
       "      <td>70.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99.4</td>\n",
       "      <td>105.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98.9</td>\n",
       "      <td>88.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>98.7</td>\n",
       "      <td>77.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425082</th>\n",
       "      <td>98.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425083</th>\n",
       "      <td>98.1</td>\n",
       "      <td>83.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425084</th>\n",
       "      <td>96.6</td>\n",
       "      <td>112.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425085</th>\n",
       "      <td>99.5</td>\n",
       "      <td>81.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425086</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>425087 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        temperature  heartrate  resprate  o2sat    sbp   dbp  acuity\n",
       "0              97.8       87.0      14.0   97.0   71.0  43.0     2.0\n",
       "1              98.4       70.0      16.0   97.0  106.0  63.0     3.0\n",
       "2              99.4      105.0      18.0   96.0  106.0  57.0     3.0\n",
       "3              98.9       88.0      18.0   97.0  116.0  88.0     3.0\n",
       "4              98.7       77.0      16.0   98.0   96.0  50.0     2.0\n",
       "...             ...        ...       ...    ...    ...   ...     ...\n",
       "425082         98.0       91.0      16.0   99.0  148.0  90.0     2.0\n",
       "425083         98.1       83.0      18.0  100.0  107.0  75.0     2.0\n",
       "425084         96.6      112.0      18.0  100.0  110.0  82.0     2.0\n",
       "425085         99.5       81.0      10.0  100.0   93.0  55.0     2.0\n",
       "425086          NaN        NaN       NaN    NaN    NaN   NaN     NaN\n",
       "\n",
       "[425087 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392462, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Because of excessive amount of data, removing all null valued rows\n",
    "df = df.dropna()\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df[\"temperature\"] >= 51.8) & (df[\"temperature\"] <= 108.14) & (df[\"heartrate\"] > 0) & (df[\"heartrate\"] < 140) & (df[\"o2sat\"] > 0) & (df[\"o2sat\"] < 100)]\n",
    "df = df.drop(df.loc[df['sbp'] > 400].index) # impossible\n",
    "df = df.drop(df.loc[df['dbp'] > 400].index) # impossible\n",
    "df = df.drop(df.loc[df['resprate'] > 200].index) # impossible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>heartrate</th>\n",
       "      <th>resprate</th>\n",
       "      <th>o2sat</th>\n",
       "      <th>sbp</th>\n",
       "      <th>dbp</th>\n",
       "      <th>acuity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97.8</td>\n",
       "      <td>87.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98.4</td>\n",
       "      <td>70.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99.4</td>\n",
       "      <td>105.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98.9</td>\n",
       "      <td>88.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>98.7</td>\n",
       "      <td>77.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392447</th>\n",
       "      <td>97.5</td>\n",
       "      <td>75.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392448</th>\n",
       "      <td>98.4</td>\n",
       "      <td>80.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392449</th>\n",
       "      <td>97.6</td>\n",
       "      <td>112.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392450</th>\n",
       "      <td>96.6</td>\n",
       "      <td>60.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392458</th>\n",
       "      <td>98.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>224736 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        temperature  heartrate  resprate  o2sat    sbp   dbp  acuity\n",
       "0              97.8       87.0      14.0   97.0   71.0  43.0     2.0\n",
       "1              98.4       70.0      16.0   97.0  106.0  63.0     3.0\n",
       "2              99.4      105.0      18.0   96.0  106.0  57.0     3.0\n",
       "3              98.9       88.0      18.0   97.0  116.0  88.0     3.0\n",
       "4              98.7       77.0      16.0   98.0   96.0  50.0     2.0\n",
       "...             ...        ...       ...    ...    ...   ...     ...\n",
       "392447         97.5       75.0      18.0   99.0  104.0  70.0     3.0\n",
       "392448         98.4       80.0      18.0   98.0  177.0  98.0     3.0\n",
       "392449         97.6      112.0      16.0   96.0  158.0  93.0     2.0\n",
       "392450         96.6       60.0      16.0   99.0  129.0  74.0     2.0\n",
       "392458         98.0       91.0      16.0   99.0  148.0  90.0     2.0\n",
       "\n",
       "[224736 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0    118634\n",
       "2.0     84362\n",
       "4.0     12792\n",
       "1.0      8486\n",
       "5.0       462\n",
       "Name: acuity, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"acuity\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-10 19:14:41.811203: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-10 19:14:41.937553: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-10 19:14:42.489284: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the data\n",
    "numerical_cols = ['temperature', 'heartrate', 'o2sat', 'sbp', 'dbp', 'resprate']\n",
    "for col in numerical_cols:\n",
    "    df[col] = (df[col] - df[col].mean()) / df[col].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversample and plot imbalanced dataset with SMOTE\n",
    "# Oversample with SMOTE and random undersample for imbalanced dataset\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from matplotlib import pyplot\n",
    "from numpy import where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>heartrate</th>\n",
       "      <th>resprate</th>\n",
       "      <th>o2sat</th>\n",
       "      <th>sbp</th>\n",
       "      <th>dbp</th>\n",
       "      <th>acuity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.300801</td>\n",
       "      <td>0.100170</td>\n",
       "      <td>-1.399974</td>\n",
       "      <td>-0.092946</td>\n",
       "      <td>-2.835714</td>\n",
       "      <td>-2.249201</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.287210</td>\n",
       "      <td>-0.901347</td>\n",
       "      <td>-0.620431</td>\n",
       "      <td>-0.092946</td>\n",
       "      <td>-1.288232</td>\n",
       "      <td>-0.927733</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.267228</td>\n",
       "      <td>1.160599</td>\n",
       "      <td>0.159111</td>\n",
       "      <td>-0.497609</td>\n",
       "      <td>-1.288232</td>\n",
       "      <td>-1.324174</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.777219</td>\n",
       "      <td>0.159082</td>\n",
       "      <td>0.159111</td>\n",
       "      <td>-0.092946</td>\n",
       "      <td>-0.846095</td>\n",
       "      <td>0.724101</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.581215</td>\n",
       "      <td>-0.488958</td>\n",
       "      <td>-0.620431</td>\n",
       "      <td>0.311717</td>\n",
       "      <td>-1.730370</td>\n",
       "      <td>-1.786687</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392447</th>\n",
       "      <td>-0.594806</td>\n",
       "      <td>-0.606783</td>\n",
       "      <td>0.159111</td>\n",
       "      <td>0.716380</td>\n",
       "      <td>-1.376660</td>\n",
       "      <td>-0.465220</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392448</th>\n",
       "      <td>0.287210</td>\n",
       "      <td>-0.312219</td>\n",
       "      <td>0.159111</td>\n",
       "      <td>0.311717</td>\n",
       "      <td>1.850944</td>\n",
       "      <td>1.384835</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392449</th>\n",
       "      <td>-0.496805</td>\n",
       "      <td>1.572988</td>\n",
       "      <td>-0.620431</td>\n",
       "      <td>-0.497609</td>\n",
       "      <td>1.010883</td>\n",
       "      <td>1.054468</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392450</th>\n",
       "      <td>-1.476823</td>\n",
       "      <td>-1.490474</td>\n",
       "      <td>-0.620431</td>\n",
       "      <td>0.716380</td>\n",
       "      <td>-0.271316</td>\n",
       "      <td>-0.200926</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392458</th>\n",
       "      <td>-0.104797</td>\n",
       "      <td>0.335820</td>\n",
       "      <td>-0.620431</td>\n",
       "      <td>0.716380</td>\n",
       "      <td>0.568745</td>\n",
       "      <td>0.856248</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>224736 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        temperature  heartrate  resprate     o2sat       sbp       dbp  acuity\n",
       "0         -0.300801   0.100170 -1.399974 -0.092946 -2.835714 -2.249201     2.0\n",
       "1          0.287210  -0.901347 -0.620431 -0.092946 -1.288232 -0.927733     3.0\n",
       "2          1.267228   1.160599  0.159111 -0.497609 -1.288232 -1.324174     3.0\n",
       "3          0.777219   0.159082  0.159111 -0.092946 -0.846095  0.724101     3.0\n",
       "4          0.581215  -0.488958 -0.620431  0.311717 -1.730370 -1.786687     2.0\n",
       "...             ...        ...       ...       ...       ...       ...     ...\n",
       "392447    -0.594806  -0.606783  0.159111  0.716380 -1.376660 -0.465220     3.0\n",
       "392448     0.287210  -0.312219  0.159111  0.311717  1.850944  1.384835     3.0\n",
       "392449    -0.496805   1.572988 -0.620431 -0.497609  1.010883  1.054468     2.0\n",
       "392450    -1.476823  -1.490474 -0.620431  0.716380 -0.271316 -0.200926     2.0\n",
       "392458    -0.104797   0.335820 -0.620431  0.716380  0.568745  0.856248     2.0\n",
       "\n",
       "[224736 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({3.0: 118634, 2.0: 84362, 4.0: 12792, 1.0: 8486, 5.0: 462})\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['acuity'], axis=1).to_numpy()\n",
    "y = df['acuity'].to_numpy()\n",
    "counter = Counter(y)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for label, _ in counter.items():\n",
    "    row_ix = where(y == label)[0]\n",
    "    plt.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "over = SMOTE(sampling_strategy={1: 118634, 2: 118634, 3: 118634, 4: 118634, 5: 118634})\n",
    "# under = RandomUnderSampler(sampling_strategy={1: 117852, 2: 117852, 3: 117852, 4: 117852, 5: 117852})\n",
    "steps = [('o', over),]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "X, y = pipeline.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({2.0: 118634, 3.0: 118634, 4.0: 118634, 1.0: 118634, 5.0: 118634})\n"
     ]
    }
   ],
   "source": [
    "counter = Counter(y)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiIAAAGdCAYAAAAvwBgXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACXGUlEQVR4nO3deXxTVfo/8M+9Sbe0TbonLRQsi2ABgQLFoo4gUKoI4ow646jg8vU78sOvII6yuGDdABcEHQd0ZlTUQXRcwaWAoLhQKFAqS8URRMDSpi1d0jZt2tx7f3+kSbPnJs3N0jzvefWFuTm59zTt9D455znPYQRBEEAIIYQQEgRssDtACCGEkMhFgQghhBBCgoYCEUIIIYQEDQUihBBCCAkaCkQIIYQQEjQUiBBCCCEkaCgQIYQQQkjQUCBCCCGEkKCRB7sD7vA8j3PnziExMREMwwS7O4QQQggRQRAEtLS0ICsrCyzrfswjpAORc+fOITs7O9jdIIQQQogPzp49i/79+7ttE9KBSGJiIgDTN6JUKoPcG0IIIYSIodPpkJ2dbbmPuxPSgYh5OkapVFIgQgghhIQZMWkVlKxKCCGEkKChQIQQQgghQUOBCCGEEEKCJqRzRMQQBAFGoxEcxwW7KyFDJpNBLpfTkmdCCCEhL6wDkc7OTlRXV0Ov1we7KyFHoVAgMzMT0dHRwe4KIYQQ4lLYBiI8z+PUqVOQyWTIyspCdHQ0jQDANELU2dmJuro6nDp1CkOHDvVYTIYQQggJlrANRDo7O8HzPLKzs6FQKILdnZASFxeHqKgonD59Gp2dnYiNjQ12lwghhBCnwv6jMn3ad47eF0IIIeEgbEdECCGEBB/HCyg71YDalg5kJMZi3MBkHDzdaHk8vl8CdJs3w3DqFAz//S8QHQ1ZfDzip07Fz8ZY/Lh7PwYf/g7RfBdkSUlobGlHVt0ZmCfaBQAcGLAQIIABK2Mhi4oC4uMBngc6OgCDwfTf1qKigIQEsPEKoMsIWUICYseORXxeHroaG/Hb6Rrou3jEjJ+AkYWX4cdXN6Lj1K+Ib2lAsiIasoQEKGfPggCg6aOPYPjhMBi5HHGXXALN0iWQxcWB7+xE46Z30Hn6NAQIYOMTwMrlUEyciPj8CeAZFnt/OY/Sk+cBCCgYlIZLBqdCxlIagTVGEAQh2J1wRafTQaVSobm52aGyakdHB06dOoWcnByaenCC3h9CiNRKjlajeGslqps7LMdYBuC77yp3HP0Uvz/xNWRB6p9YAgBvQ4OoAdnoOnPW5fNcghLrxl6PHam5NseTFFFY9ftRKBqZ6X1Hw4i7+7c9Gr8nhBDitZKj1Zj/drlNEALYBiHXn/i6z95k3AUhAMC26nDft69h0rkjNseb9F24++1ylBytlrJ7YYWmZoJg5cqV+PDDD3H8+HHExcVh0qRJWL16NYYNG+b2df/5z3/wyCOP4Ndff8XQoUOxevVqXH311QHqNSGEAFx7O6pXrQa//Xts6GyHTq6AgY0CwwBJXa1gBAZdgoAhbbUAvB9pCAYp+sjANNLyUNlGtEbF4i9TF6MpNsXy/GNbjmF6rsbpNI3AcdAfOAhjXR3k6elQjB8HRhbq40q+o0AEjnOc+Tkpks7h7d69GwsWLMCECRNgNBqxfPlyFBYWorKyEvHx8U5fs2fPHtx0001YuXIlrrnmGmzatAlz5sxBeXk5Ro4cKVlfCSHE7OyCBWjduQsAkGM5ej5Y3Ql5TPeXsqsD75Q8BQMrw5zZzwAAanQGlJ1qQMHgVEt7geNQv2EDzm98E4JOZzkuU6uheWg5lIWFAf4OAiPic0SczXFmqmKxYlZuwObw6urqkJGRgd27d+N3v/ud0zZ//OMf0dbWhk8//dRy7JJLLsGYMWOwYcMGh/aUI0II8SfrIIT4wnSr5cCgIm0IqhLSMfzx5bg2fwgAoGnbdlQ9/AjYFp3LM2StfQGqoqKA9La3KEdEJFdznDXNHZgfwDm85uZmAEBKSorLNqWlpZg2bZrNsRkzZqC0tFTSvhFCCNfeTkFIr5nGR2QAxtWfwOxfSzF07iycXbAAu1/5N84tXAjGTRACAOfuWwxdSUlAehtIERuIcLyA4q2VcDYcZD5WvLUSHC/tgBHP81i0aBEuvfRSt1MsNTU1UKvVNsfUajVqamok7R8hhNQ+82ywu9AnMQBadu5C+gtPWqZx3BIEVC26D7rt26XvXABJGoisX78eF198MZRKJZRKJQoKCvDFF19IeUnRyk41OIyEWBMAVDd3oOxUg6T9WLBgAY4ePYrNmzdLeh1CCPFV55kzwe5CnyUqALGjfXolhD600aukgUj//v2xatUqHDx4EAcOHMCVV16Ja6+9FseOHZPysqLUtrgOQnxp54t77rkHn376Kb766iv079/fbVuNRgOtVmtzTKvVQqPRSNY/QggBgOgBA4LdBWLFWFODmiefAt/ZGeyu+IWkgcisWbNw9dVXY+jQobjwwgvx1FNPISEhAXv37pXysqJkJIpL4BTbzhuCIOCee+7BRx99hF27diEnJ8fjawoKCrBz506bYzt27EBBQYHf+0cIIdYyHnwg2F0gdpreeQc/jRkL7bPhP20WsBwRjuOwefNmtLW1ubx5GgwG6HQ6my+p5OekIFMV63JIjIFp9Ux+jusEUl8tWLAAb7/9NjZt2oTExETU1NSgpqYG7e3tljZz587FsmXLLI8XLlyIkpISPP/88zh+/Dgee+wxHDhwAPfcc4/f+0cIIdZkcXFImHplsLtB7PE8Gv71WtgHI5IHIkeOHEFCQgJiYmJw991346OPPkJubq7TtitXroRKpbJ8ZWdnS9YvGctgxSxTP+yDEfPjFbNyJaknsn79ejQ3N2Py5MnIzMy0fL377ruWNmfOnEF1dc+qnUmTJmHTpk149dVXMXr0aLz//vv4+OOPqYYIISQgsl9+GTEjnP/tJsHV8PobYT1NI3kdkc7OTpw5cwbNzc14//338c9//hO7d+92GowYDAYYDAbLY51Oh+zs7D5fR0QKVEeEEOJvraV7cfb224PdDeKEcvZsJP3hDyFThdWbOiKSV1aNjo7GkCGmgi3jxo3D/v37sW7dOrzyyisObWNiYhATEyN1l2wUjczE9FxNQCurEkJIeArZ+pcRT7dlC3RbtkCu0UC9fFlYVWENeIl3nudtRj1CgYxlbMrsEkIIccSdl7acAek9o1aLqoWLgHVrwyYYkTQQWbZsGa666ioMGDAALS0t2LRpE77++mts27ZNyssSQgiRgDw9PdhdIJ50Z1ton16JxKlTQ2KaxhNJk1Vra2sxd+5cDBs2DFOnTsX+/fuxbds2TJ8+XcrLEkIIkYBi/DgwLjbmJKHFWFODeif7kIUiSUdE/vWvf0l5ekIIIYHG88HuQUQyZ+d4k71Y/9LfEDN4MJQhvlFexO41QwghxDv6AwchWNU7IoHVqUhE+oMPIt5uA1R3qhbfj+YQ3yiPAhFCCCGiGOvqgt2FiMUAiNG34IhCg+x1ayEXu70Hz+NciG+UR4EIIYQQUShZNfg+2XkYPMNCedVVXr0ulDfKo0CEEEKIKIrx4wB5wKs+ECsn+ViUnahD88cfe/U6Y00N9AcOStOpXqJAJAjWr1+Piy++GEqlEkqlEgUFBfjiiy/cvuY///kPhg8fjtjYWIwaNQqff/55gHpLCCEmjEyG2IsvDnY3IhYPQNnZhpb9+8E1Nnr9+lCdWqNABAB4Djj1LXDkfdO/vLTDV/3798eqVatw8OBBHDhwAFdeeSWuvfZaHDt2zGn7PXv24KabbsKdd96JQ4cOYc6cOZgzZw6OHj0qaT8JIcRe/IQJwe5CRHto/1tIP1zm02tDdWpN8r1mesNdrXq/7aVSuQUoWQLozvUcU2YBRauB3Nm+n9dLKSkpePbZZ3HnnXc6PPfHP/4RbW1t+PTTTy3HLrnkEowZMwYbXKwTp71mCCFSoP1mgosHIE9OBu/NiAjDQK5WY8jOLwNW4MybvWYie0Skcgvw3lzbIAQAdNWm45VbJO8Cx3HYvHkz2traUFBQ4LRNaWkpptkt15oxYwZKS0sl7x8hhFj7TtEfXUxk3zqCiQXANzZClpws7gWMqfKIevmykK2yGrm/TTxnGglxuolT97GSpZJN0xw5cgQJCQmIiYnB3XffjY8++sjpjsQAUFNTA7VabXNMrVajpqZGkr4RQiIbxwsoPXken1RUofTkeXC86W9iydFqLHjnEM5ekBbkHhJe5J5tcrUa/UJ835nITX8+vcdxJMSGAOiqTO1yLvf75YcNG4aKigo0Nzfj/fffx7x587B7926XwQghhARCydFqFG+tRHVzh+VYpioWj8y8CN9seR3fxfwTHM+hBVTqPZgEvd7pcTYhAcnz5iEmJwfy9HRTWf4QHQkxi9xApFXr33Zeio6OxpAhQwAA48aNw/79+7Fu3Tq88sorDm01Gg20Wtt+aLVaaMQWtCGEEBFKjlZj/tvlDuPENc0d+GTzK1gftRbggf/+Rn97QhUTH4/0/zc/5IMPa5E7NZOg9tzGm3a9xPM8DC6G2goKCrBz506bYzt27HCZU0IIId7ieAHFWyudTlYz4PFY1JtgALTXR0PgIvfWEeo4rTZk64W4ErkjIgMnmVbH6KrhPE+EMT0/cJLfL71s2TJcddVVGDBgAFpaWrBp0yZ8/fXX2LZtGwBg7ty56NevH1auXAkAWLhwIa644go8//zzmDlzJjZv3owDBw7g1Vdf9XvfCCGRqexUg810jLUFso+QyTQAAIwd4fNJO1KFar0QVyI3rGVlpiW6ABz3M+x+XLTK1M7PamtrMXfuXAwbNgxTp07F/v37sW3bNkyfPh0AcObMGVRXV1vaT5o0CZs2bcKrr76K0aNH4/3338fHH3+MkSNH+r1vhJDIVNviPAiZwZbhPvkHlsc/JEXu59dwEar1QlyhOiJO64j0MwUhAawj4m9UR4QQ4o3Sk+dx0z/22hxjweNAzN1IRisYBuAAXNo/C/94HpCH7J2jb+IBIDUd0XIWxtpawNmtOwj1Qlzxpo4Ihba5s4HhM02rY1q1ppyQgZMkGQkhhJBQlZ+TgkxVLGqaOyyT1QtkHyGFabW0KYuNQVuUHPWJRmh0welnJBJgGqfPevRhsAxQtXCRqT6IdTASBvVCXIncqRlrrMy0RHfU9aZ/KQghhEQYGctgxSxT+QAGptGQO+QlNm22JJiW7P6UFejeRTYGQFvBFUiaUQhlYSH6rVsLuV1tqXCoF+IKjYgQQggBABSNzMT6W/JQvLUSA1vKkcy02Tzf1l1RtV4VjN5FtoTS3dA++yzUDzwAZWEhEqdOhf7AQRjr6sKmXogrFIgQQgixKBqZiem5GrzxykHAroxSOmcEAIz9JQgdI2j412uIHTUKqqIiMDIZ4ifmB7tLfkFTM4QQQmzsqKzBjrP2qwmB0YZO3LyLQ054rQ7tU8498CAETtod4gONAhFCCCEWHC9g6YdHUMYPxzkhBbxVPmSmgcOsfbRcJqi6ulD78svB7oVfUSBCCCHEYu8v59Gk7wIPFsVdcwHAEowMPCIHC8fKSySwGv71Wp8aFaFAhBBCiEXpyfOW/97G52N+1yI0IBEAoK+KCVa3iDWDIezKuLtDgQghhBArtlMv2/h8XGJ4GeeFRAgCjYWEinAr4+4OBSKEEEIsCgalORwzQo7lXXcivp/zMvAk8Mpb+87tu+98J2Fq1apVYBgGixYtctvuP//5D4YPH47Y2FiMGjUKn3/+eWA6SAiJKJcMToUi2rYeBQsezUjA1sGXwvkmoSRQeAC1cUn4n0NGlByt9tg+HFAgAoDjOeyv2Y/Pf/kc+2v2g+MDkwS0f/9+vPLKK7j44ovdttuzZw9uuukm3HnnnTh06BDmzJmDOXPm4OjRowHpJyEkskTLe24NM9gyfBdzLzZHP4k7Y7YjPpNGRYKFhylR+JVR14JnWBRvrQTHh39gGPGByJenv8SMD2bgjm13YMm3S3DHtjsw44MZ+PL0l5Jet7W1FTfffDP+8Y9/IDk52W3bdevWoaioCA888AAuuugiPPHEE8jLy8Pf/vY3SftICIk8Zaca0KTvAmAKQtZHrYUGDZbnU4e3uXopkVh9XBKezJ+HPVmjIACobu5A2akGj68LdREdiHx5+kss/noxtHrb8oG1+los/nqxpMHIggULMHPmTEybNs1j29LSUod2M2bMQGlpqVTdIyRicLyA0pPn8UlFFUpPnu8TnzCdEft91raYRjxY8FgRtdH031Y5qor0TnBM33yPQtX3mpF48NK7cXvhcuzJGmXznPnnFc4itsQ7x3NYVbYKgpP5TgECGDBYXbYaU7KnQObnTfA2b96M8vJy7N+/X1T7mpoaqO02OFKr1aipqfFrvwiJNCVHq1G8tRLVzT1/zDNVsVgxKxdFIzOD2DP/8ub7zEiMBQAskH2MLKbR4VwdLKBNZJBFu+8GzNbBl+JI+hCnz5l/XuFM0hGRlStXYsKECUhMTERGRgbmzJmDn376ScpLilZeW+4wEmJNgIAafQ3Ka8v9et2zZ89i4cKF+Pe//43Y2PD/BSIkXJUcrcb8t8ttbs4AUNPcgflvl/eZREBvv8/8nBT8PrYci+XvOz3fmqQkJOkl6y6xIgBok8XgWGqOw3MMTMFkfk5KwPvlb5IGIrt378aCBQuwd+9e7NixA11dXSgsLERbW/DnGOv04tZgi20n1sGDB1FbW4u8vDzI5XLI5XLs3r0bL774IuRyOTgn1fI0Gg20WtugSavVQqPR+LVvhEQKjhdQvLXS6foP87G+kAjo0/fJc3gQr7s+Z10UFEa/dpO4wACI5wx4bftKTDp3xOH5FbNyIWPDv7aLpIFISUkJbrvtNowYMQKjR4/GG2+8gTNnzuDgweBXhEtXpPu1nVhTp07FkSNHUFFRYfkaP348br75ZlRUVEDmZBvngoIC7Ny50+bYjh07UFBQ4Ne+ERIpyk41OIwQWOsriYC+fJ/H922DBufBuLi/DdTxfu4l8SS1oxkPl220CUb+93c5fWb6MKA5Is3NzQCAlJTgDyXlZeRBrVCjVl/rNE+EAQO1Qo28jDy/XjcxMREjR460ORYfH4/U1FTL8blz56Jfv35YuXIlAGDhwoW44oor8Pzzz2PmzJnYvHkzDhw4gFdffdWvfSMkUohN8Av3REBfvs/2xiq3bWcZW6CFf0q91yMNhy9/FGAYQBBw8bePIw31fjl3+BJgv5sP23307iMfY2/mCAgMiy0/VOPBoosgYxlwvICyUw2obelARqJpuiacRkoCFojwPI9Fixbh0ksvdbgRmxkMBhgMBstjnU66bCgZK8PS/KVY/PViMGBsghGm+5dgSf4SvyeqinHmzBmwbM9g1aRJk7Bp0yY8/PDDWL58OYYOHYqPP/7Y5ftICHFPbIJfuCcC+vJ9xiX3c9lO4IFoAeiSCYjienej23X5iwDLwnro5fAVjwE8jyu/vbdX5w5vzt9XBkB6ezP++NNOvDN8umUkq7m9M+wTrhlBEAIyCTp//nx88cUX+O6779C/f3+nbR577DEUFxc7HG9uboZSqbQ51tHRgVOnTiEnJ6dXSZ9fnv4Sq8pW2SSuahQaLMlfgmkDPS+tDVX+en8I6Ys4XsBlq3ehprnDaf4EA0CjisV3S64Mq0+W9nz5PjmjEbonBiIJrTbTM7qzsdCWq2Bs7/2HM0sQAtgEIjDfjgQB8q5WDPvxbWQ0VYKhaq4WAmCpJTJ1eDp2Ha9zeHfM7+j6W/KCFozodDqoVCqn9297AQlE7rnnHnzyySf45ptvkJPjmP1r5mxEJDs7W9JABDAt5S2vLUedvg7pinTkZeQFZSTEnygQIcQ982oSwLZoeSj8Efcnr79PnoP+8SzECR2WGEF3NhZV3yfbvdI39UgzjXwAcJmIYo3ncGHlW+hfL67cQV/Hw1TY7PbC5RAY1mWIFuxg2ptARNJkVUEQcM899+Cjjz7Crl273AYhABATEwOlUmnzFQgyVoYJmgm4etDVmKCZEPZBCCHEs6KRmVh/02hc0X4GV/x2CKPqToAVeGhUsX0mCAG6v89b8qBR2X4gcfl9fvMcFOgJQgQe0Jarup90f0MTwKAxaShqMsahMWkoBCftLTkhYoIQAGBl+O+Iedg16Rlx7fs4FkBGexNG1P/idpwonBKuJc0RWbBgATZt2oRPPvkEiYmJlgJcKpUKcXFxUl6aEELc0m3fjsFPr8QSq8KAfFo6+j3yMJL6SBBiVjQyE9NzNZ4TGnkO2Lfe5pC+LlrUdExt2mgcHXIDEGu1ZQXPI7blNPIPrYUc3Wt+xQYg1hgGiFJg1+UvYsq3C2mqBkCKoUVUu3BIuJZ0RGT9+vVobm7G5MmTkZmZafl69913pbwsIYS4pdu+HVULF8FoV52YPV+P6kWLoNu+PUg9k46MZVAwOBXXjumHgsGpzofrT+8B2m2rqRo7RAYhI+4CYpJsn2BZdKhy8M0Va/FNwdPoQpRvgQhgep1Mhq8uX4dzaeN8O0cf0hCTKKpdOCRcSzoiEqA8WEIIEU3gOGifXtmTGGnzpAAwDLRPr0Ti1KlgnNT1CXk8ZwooWrVAghoYOAkQO93c6lhtWh7rfjdyAQyOXnSn6YGrIINhYIxR4dsrXvA9EDGTyXB8xO04qb8Gl+93XNwQCdrZKCRkdGA2swe1SEIZPxy8k3EFlgHGDXS/qWooiNi9ZgghkUl/4KDDSIgNQYCxpgb6AwcRPzE/cB3zh8otQMkSQHeu55gyCyhaDeTO9vz6BLXDIUV6J+RxHIztLJzliGiTRgBiA7beBiFW5+lSpGPX5S9G5FLf+CQD3ol52vL4nJCC4q652Mbb/r7yAnDwdCMKBqcGuoteiejddwkhkcdYJ27bBrHtQkblFuC9ubZBCADoqk3HK7d4PsfASTgvS4N1xXeGBdR5zd2PHEeRjl90s+997g2GAVgWuy59PjjXD6J4ZbvNYw0asD5qLWawZQ5tIz5HhBBCQo08Xdy2DWLbhQSeM42EuNtVpmSpqZ07rAwl/ReZXmV1KmV2B/pd2gh5nGN5dz4qwacu+wXDAPIYdCD08yD8R0Drb7EQrH4U5nSfFVFvgYXtzygcckQoECGERBTF+HFgk5LctmGTkqAYH0YJkaf3OI6E2BAAXZWpnQf9J/0RLxivd5hFUWZ3YMgsLbrSuuzCnSDnAjIM9hU8Etw+BBQDwShDfaVtAMgyQBZzHvns8e5W4bM7LwUihBBiJ+xqqTpJMvW1XYO+C6cF5zt7687GIqpeHnLvDxclbgVJX3L+eLzNqIhZBposP59w2Z2XApEg+OabbzBr1ixkZWWBYRh8/PHHHl/z9ddfIy8vDzExMRgyZAjeeOMNyftJSF+kP3AQfFOT2zZcUxP0B4K/S7hoTpJMfW1X39KBWiQ5HBd44FyZCvZhGsOFQg5C6N9s/U0wytBWG+1wvBZJYVeUjwIRmJbzte0rQ/Onn6FtXxkEzsM8ai+1tbVh9OjRePnll0W1P3XqFGbOnIkpU6agoqICixYtwv/8z/9g27ZtkvaTkL6oTyarDpxkWh3j8obMAMp+pnYeNOm7kAQdBME2T6StNhrgHFfHpNce8K3PpNf0tT27IAtgoI/TYOHt8/DdkivDJggBaPkudNu3Q/v0SpvlfHKNBurly6AsLJTkmldddRWuuuoq0e03bNiAnJwcPP+8KTv8oosuwnfffYcXXngBM2bMkKSPhPRVfTJZlZWZlui+NxemYMTJrjJFq0TVE2HB49GotyGgJwlSdzYW1WVJTttn1v2A2n5X9KLzxHemnzMP009ZMetZFAzNCGqPfBHRIyKuqisatVpULQyd6oqlpaWYNs12J+AZM2agtLQ0SD0iJHwpxo+DXKNxW9Mi7JJVAVOdkBvfBJR2n4SVWabjYuqIAChM+AVZTINNEFL1fTL4LufvV1d0EFfNRDhFRicAoEZIxfzOhSjhJwS5R76J2BGRcKquWFNTA7Xadm5XrVZDp9Ohvb2d9u0hxAuMTAb18mWounehyzZ8UxNadu6UbFRUMrmzgeEzfa+sCuCiBL3lv3kjUHPA/YZ30Z3i9jwh7gjwJs9FAKCPjsFDyXdB25mMMn44BLD4YWslpudqwiJB1VrEjoh4U12RENK3JE6d6n4Jb/cHEanzxSTByoCcy4FR15v+9XI38R9bFQCAptOx+OlDNTiDDO5uks522A04hsGuy18Mdi96ybtl0C+MvhGfCJdiL58LHmxY7bZrL2IDkXBKWNNoNNBqbZfdabVaKJVKGg0hxAceV85E8AeRba05+PnbDFSXJgO85yCmIenCAPRKBJYN42CEgTcjIgwAXXS80+fCoZKqvYgNRMIpYa2goAA7d+60ObZjxw4UFBQEqUeEhLdw+iASSCVHq2H8+9/QVSV+1r4+fYx0HRLLnO/DstBBGdy+9ELyMB3EjoykGJxPiYVDJVV7ERuIeExYYxjINRpJEtZaW1tRUVGBiooKAKbluRUVFThz5gwAYNmyZZg7d66l/d13341ffvkFDz74II4fP46///3veO+993Dffff5vW+ERIJw+iASKCVHq/F/b5Zh1n93d382F/cJnWdCZIdihgEYBgcufyLYPfEZb3S+saAzDTG2RdzCqZKqvYgNRMwJa6YHdj/47sfq5cskSVQ9cOAAxo4di7FjxwIAFi9ejLFjx+LRRx8FAFRXV1uCEgDIycnBZ599hh07dmD06NF4/vnn8c9//pOW7hLio2B+EAlFHC+geGslrv7l++5sA/EUbVUS9cpHTDje1gTIFUbRkzN6WTSOpQ2yPA63Sqr2InbVDABTRvy6tY51RNRqSeuITJ48GYKz1TrdnFVNnTx5Mg4dOiRJfwiJJALHQX/gIBJnzEDjxo2mYMT6/48SfxAJRWWnGlDd3IHMNu8THZOaT6IxFKZnzBgGAhgwwd4DRzRTP9VjdWitcayU6szJjBzwVgGXRhWLFbNyw6qImbWIDkQAUzCSOHWqaRVNXR3k6elQjB8XMX+ACIkkzgoY2gciUn8QCUU1zaZt5avjvR/W74xN9Xd3eodh0JQ0BMlNPwe7J04xLA+B7wki5AoO6rE6KLM7oD8fJeoco5rO4P1cA6ounoiMRNN0TDiOhJhFfCACmKZp4ifmB7sbhBAJmQsYOtQO4k07hyXPm4vEK6dG3AeRkqPVeOKzHwEAX+QU4C9Ht3aPJoi7scV11EvYO9+0RycjOdidcCEmpRPK/gbIYnlExXFQpHdaZpNYVuQoTns74lc+jCnr1kI5JvwD5nCcTCP+wnPAqW+BI++b/uXDsGYCISK4LWAIAAyDlm3bIzIImf92ORraTBU6b23a7lWiKgD0/203nG4DG0R16aOD3QWXOupjUVuhQt0PSnCdrE1Ki7lSqlhhW+vGDo2IRKrKLUDJEkB3rueYMsu0X4XIUtCEhAtvChhGyuioOUHVHJqx4HFr13a0Q1yeguU8cF/wLBjaY5KC3QWPjO0sqr5PBi5thDLbVPsjLr0TbDQHrlPm+R3tQ7+zNCISiSq3mDbHsg5CAEBXbTpeuSU4/SJEIlQ3xJE5QdUsnz2O9Did1+fZP36J2317gsEQEw5LWE3vmbZcidaaaDSfjkNVfRo+GXMZAPF1Vlt27fTcKMRRIBJpeM40EuL017z7WMlSmqYhfYrouiFpKREzXWlfgTMDTd35CuKnWQQw6IjX+LtrvcZFJWDX5S+iGSrPjYOKgbFdjrNfp+FcaTLavorGJYcrUaoZIfoMzVu2hv30DE3NRJrTexxHQmwIgK7K1C7n8oB1ixApmeuGGLVa53kiDAN5ihKK7+4AWiNjutK+AmctktBSFQuBFz+68cvAq0JuNAQAwJo+Yx+84imA53Hlt/cGuUPipXU0I62mWXR7vrEx7KdnaEQk0rRqPbfxpp0YlBRLgsxjAUNBgHr4r2BaI2e6Mj8nBZmqWEsuwgHuQpwrF7/WRACD0wOvkqZz/hRme9AwVl9ihfuUIgUikSZB7d92nlRuAdaOBDZeA3xwp+nftSP75B92EtqUhYXot24t5Grb3225Wo1+0wFldruTV/Xd6UoZy2DFrFwAppveRfW/QmgXfwusSxpuGXkIWVZ70IT+NI3vwn0rghD/LSJ+N3CSabjZ5R8bBlD2M7XrLUqKJSFGWViIITu/xICNG5H13HMYsHEjhvzzMShTRU5X9jFFIzOx/pY8aFSxLjdRc+XoqLsl6pWfde9BczCM96BxhQfAp2WE/VYEFIgEwWOPPQaGYWy+hg8f7vY1//nPfzB8+HDExsZi1KhR+Pzzz327OCszzXkDcAxGuh8XrTK16w1KiiUhRuA4tO0rg+6LEgCA8qoixE/MB9Mucljbn9OVQcbxAkpPnscnFVVQxUVj9wNTcM8fJop+fSeie/83ItBCMZelF8wl52rmzg/72jeUrAqA5wVU/9yENp0B8coYZA5NAitxudwRI0bgyy+/tDyWy13/KPbs2YObbroJK1euxDXXXINNmzZhzpw5KC8vx8iRI72/eO5s4MY3XdQRWeWfxDxKiiUhxFlpd7lGYyrlPjTA05VBVnK0GsVbK22W7maqYrEqtR4JgKiaqvvH/zX8buxu9vcKPZ5/CgyAN4fPwOyp0wPSIylFfCBy8lAtvn33Z7Q1GSzH4pNicPkfh2Lw2AzJriuXy6HRiFv2tm7dOhQVFeGBBx4AADzxxBPYsWMH/va3v2HDhg2+dSB3NjB8pikQaNWa/sgOnOS/TznBSIolQcHxAspONaC2pSMk971wVdrdWFODqnsXAutegFKZZZoydDqCx5iCdH9MVwaZuZKq/XdZ26RH7DvPiS7sblCE4eZqTLgEIuL72Z6eifyccKiZ4l5ET82cPFSLkleO2gQhANDWZEDJK0dx8lCtZNf++eefkZWVhUGDBuHmm2/GmTNnXLYtLS3FtGnTbI7NmDEDpaWlvesEKzONRoy63vSvP4daA50US4Ki5Gg1Llu9Czf9Yy8Wbq7ATf/Yi8tW70LJ0epgdw2AiNLuAKpXFEOYvrL7kYTTlUFmX0nV2sj6k1B26kOsPqqfCaH63dn+RORxHPZcJG6k+9opI0Mq6PdVxAYiPC/g23fd78743Xs/g+f9H0VPnDgRb7zxBkpKSrB+/XqcOnUKl19+OVpanCeL1dTUQG2X6a9Wq1HjrmR1sAUyKZYEhfnTtfUQPwDUNHdg/tvlIRGMeCztDoBvakL9N+dM05VKu0/6yizT8T5QR8S+kqq1i+tOeHcyo7MVRqEuVEdEGCjU7Uga2or4MQasmfFHPHXhPNTHqTxOf/V/5Vnotm8PUD+lI2kg8s0332DWrFnIysoCwzD4+OOPpbycV6p/bnIYCbHX2mhA9c9Nfr/2VVddhRtuuAEXX3wxZsyYgc8//xxNTU147733/H6toAlUUiwJCnefrs3HirdWgpMgkPeG2PoKDW+9BWHYTGDRUWDep8Af/mX6d9GRPhGEAI6VVG1596l6eOXbvesMsaHXxqHp5wS0VcTgppIvcUn1MfAL7jM96SYYMWq1qLp3YdgHI5IGIm1tbRg9ejRefvllKS/jkzad+yDE23a9kZSUhAsvvBAnTjj/VKLRaKDV2uZSaLVa0TkmQWNOiu3DnzIjlbtP14ApGKlu7kDZqYbAdcoJsfUV+KYm6A8clHa6MsjsK6la+yFtkFfnalCP6m13Ao8JjwmA1I5mPFy2EWMHJKPfurVglUqPr6l5dEVYl3mX9Cdz1VVX4cknn8R1110n5WV8Eq+M8Wu73mhtbcXJkyeRmek8AaygoAA7d9pubLRjxw4UFBRI3rdey53dpz9lRir3n669bycVxfhxYFXiClmFe3VKT+wrqVo7mj4EnSJv1AIY1GaEbznx0OI4YsgCYBjGlNvE8+CbPZd755qa0FZWJkH/AiOkQkSDwQCdTmfzJZXMoUmIT3IfZCQkm5by+ttf//pX7N69G7/++iv27NmD6667DjKZDDfddBMAYO7cuVi2bJml/cKFC1FSUoLnn38ex48fx2OPPYYDBw7gnnvu8XvfJNGHP2VGKnefrn1pJxVGJkPK3FtFtQ336pSe2FdStXlO4CETeFFZFI1JQwFZxC+49BMX0y6CAGNNDaoffkT0mfT7KBDxi5UrV0KlUlm+srOzJbsWyzK4/I9D3ba57MahktQT+e2333DTTTdh2LBhuPHGG5Gamoq9e/civfsP4ZkzZ1Bd3ZPoN2nSJGzatAmvvvoqRo8ejffffx8ff/yxbzVECPEDd5+uAdOf10xVbEgsLUy7+26wSUmuGzAM5BpN2FendMpun6ei3AxLJVVrf6ougwziMkUaky6UpKvEEd/aGuwuBERIhbXLli3D4sWLLY91Op2kwcjgsRko+stIhzoiCckxuOxG6eqIbN682e3zX3/9tcOxG264ATfccIMk/SHEW+ZP1/PfLgcD2wFm881sxazckFhayMhkyHy82GktEXMioHr5srCvTumgcovTooVFRasxfcksm9ovA946AN1+cadtjw1+cOmTsCpo5j3FRPGVcUNNSAUiMTExiImRPifD2uCxGcgZnR7wyqqEhDvzPiX2VTo1qlismJWLopGhU/RKWVgIrFvrWF1VrTZVVy0sDGLvJGDe58l+sqV7nyfZjW+iwCpPq9qLKqn6aM/Jk6GIMXq3l04wCQDaZDFI4MQtlmDi4xGfP0HaTkkopAKRYGFZBv2Gid/+mhBiUjQyE9NzNSFdWVXgOOgPHITQ2YXMlSsBCODON0Ceng7F+HF9byTE4z5PjGmfp+Eze/K1ZOJn6VsTpBullhQTLrc708/ok0GX4eafd3psDQBJ1/8BPMOi7OT5kP3/oTuS/mRaW1ttlqSeOnUKFRUVSElJwYABA6S8NCEkQGQsg4LBqcHuhlPu9piJn9hHV354uc+TwHHQfebFJpqy6F53MRgEWXATp8VjwABojY4DH6cA2673+Ipf2llct3qXw/5BoTYy6YqkyaoHDhzA2LFjMXbsWADA4sWLMXbsWDz66KNSXpYQQix7zNhXVjXvMRPuRaBc8nKfJ/2Bg+AbG0WfnuGNvvQqBITH6IDZYGMTsp5+ymM7AUDSe28g50fbJJ9QqnDsiaSByOTJkyEIgsPXG2+8IeVlCSERTtQeM2FeBMolL/d58rZ+itzY5m2PQkOY7Rb8+4TdSJZ9j5SLAXfl6c3J4n858glYgbccD6UKx56E1PJdXwh9PBPaV/S+kEgmeo+ZDa8EqEcB5OU+T97WT+mSK3rXv2ARQmkkR4Dr4EIAGAHqHC2EPS9CnXsOaSPcJ9qyADLamzCi/heHq4RChWNPwjYQiYqKAgDo9Z7nzyKR+X0xv0+ERBKv9piRYFSE4wWUnjyPTw6dwbHvPwN/+D+meh58AEZgvNznSTF+HLpS0sDDMx4sEKaBiLzTc4XS4DMFJynDWiG3yuDkusTdqlMMzgOWYFc49iRc0ogdyGQyJCUloba2FgCgUCjAhNnQmxQEQYBer0dtbS2SkpIg62srAggRwds9ZvyZuFpytBrFWytxccs3WBH1JrIYq0+jyixTkCD1FgfmfZ6c1BFB0Sqb6zMyGaKvnwzh1f+Yj7g87dn+V4TdFIcZE4gg0Csu3kdWQLzGAIE3bY8j8IDudJyoMzbEJDo9HuwKx56EbSACwLLpmzkYIT2SkpJCf1M8QiRi3mNGzD4d/txjpuRoNea/XY5Ctgzro9Y6PC/oqsG8N9dx00eeM61iadWacjcGTnK5FQLHC+KWS+fONi3R9XTeyi0YpnsJTQUxqCl1X8agWTXE01sQsriQGslxM23GMzj7dRrkcRzUec2QRfPgDJ4/UHIAfky9wOEqmhCpcOxOWAciDMMgMzMTGRkZ6OrqCnZ3QkZUVBSNhJCIZt5jpv6lv3ls6689ZjheQPHWSjDgsSLqTQCAfXzAQIAABox1HQ8XFVCdjZyYR1tEL9M07/PkSnfNkZazMag9qIKnlSWdYbp0FwB4Jrz+JhrbWVR9n4zkC8UlB8sAXHT+VxxJNwWLoVbh2J2wDkTMZDIZ3XgJITbS7r4bDW+9Db6pyXkDhoFcrfbbHjNlpxpQ3dyBS9jjttMx9pe1ruPR3ui2Aqr1yIl5tMU+xdG8THP9LXne14w4vQe6Yw2o+l5cQcewTVQFgLCpI2JmWg/T9Iu4aRkASO3oGQEMxQrHrvSJQIQQQuxZ9pi5d6HzBoLg1z1mzAmBGWgS94KWauDLFRBTAZUDi+Ktle5aonhrJabnakR9+jVP70QdO4bE/aruo55fZ4wKz/LuAMI0t4WBYJSBYXkIvOeE1Xvz0nDd1DFUWZUQQiKROSGwFkniXtBWJ7oCahmfazMd46SlZZmmpyq31tM7f6o/jnmd4gOxKE6PLoR2voFLIVfSwBxCimspxuCh2cgb08/nHgVL2C7fJYQQdyxFzdzQPr3Sb8t383NSkKmKxX5+OM4JKXBVQ0ow1/GIF5mb0qoVvfzSUzvz9I45qInRepdbF9te71X7kMKHzhJWRs5BHidmwXQ3EaMhACBLT/OxR8FFgQghpE8SU9TMWFMD/YGDfrmejGWwYlYueLB4vGsuADgEI0L3PiIoWiW+Amp8uujll+7amZNprbuU1t4krg/dog3etQ8pQugs300a1I4hs7TInlwPRuZFQOJReEzF2KNAhBDSJ3Vpxe25sq/sR5SePO+XMthFIzOx/pY8/JD4O8zvWoQau2kMRpnVk4AqdqpAECyjLQwAFjwuYSsxm92DS9hKsODBwLR6Jj8npaeYWkWVzfdlTqa1VhuX5NX316Ic5FX7UMIgdBY0JPbrAMMCCZpOpF7U6rfzcufP++1cgUQ5IoSQPolrEFfW+pPdx/BJVZrfdistGpmJ6bkalJ0ag/26OzFEfwQXJerBJmps63joRU5z6Ostoy0fb9qAR+2KpJ0TUvB411zMmXU3dlTWuFze297pOCLAuahV4gwPFm2J/UW3DzWCLBSqTJuCQmNHzxhAWm4rGv4bD76ThbMRDR5Ac3Q8kjs9L+P111L0QKNAhBDSJ8lTxCVV6mISAPRyGawdGct0J42mAhjgvJGXm9MVsfsxI3odBLvURQ3TgPXR61BRNQi//yrN5fLeP+TZJjGyAo+iU3tFp0yaqqqG8SA6Ewq3O9M7XVOugjLbNCrCsEDmhGZUfZ/s8LPgux//ffTv8b9HtiC1o9npNAYPAGkZfluKHmih8JMhhBC/k4n8dFgfa1q+ar6BL/3gCBJjo3DJoFRplz+aN6fTVcP5ugjG9PzASZbCY4wp1dUG2/3qzNJiMFgHAYBMcQqMvBmMrA0CpwAr02PbmUREJbdA4BRgZHqMqGpFeqf7zdSsNYRxVdVQwxtk0NdFI17dCQBQZncAlzbip/IsJLT3jGY1KpKgv+tefHdaiQsbz+L6E187PR8DQKu5AMMZNoQmoMSjQIQQ0ufotm+H9qmn3bYRAJxPZPDTBXrAatS7qb0LN/9zn9+malwyb0733lz0bOZuZrs5HffVSpR3nkddvALpHIe8DoPNDYeBAA3OY7hyG05nVICNcl7a3jqVVXPeuyTJ1gQXIzvEJ+ePx1sCEcAUjKzJ+BNaa2ORYmhBQ0wiFtz7B6gS4jCp+B8ugxAz9dEyrL3h/zCi+KGwKGJmLYzH2QghxJFu+3ZULVwEo5tkVfMt+PVpDKKzN0GeeNShjXlKo+RotUQ9Rc/mdEq7G4dVUuuX363EjF/exB2ZaizJSMMdmWrMyM7ClwrbiptfKuJwNms3GLm4XWYbE7zsawitOukL2qpjoa0wbVInCMA5IRX7hFwcSR+C3f3HYsKcaSga3R8TBqiw4OgnANzuUAMAmHFsF/7vzTJpf2clQCMihJA+w1I7xMOKlIYE4I1CFvuHsYAAxGS+B2NLLqw/m/lSsdQnbjan+/LX7Vh84t8Q7Kq/1spkWJyRhjW19ZimbwcHYFWqqUy72AKix/uZNkpzniLpSM53gnb08q+GnxKQOrIFrAwo7roVvNXv3/Rc06alhvJypOibPJ6LASCDgJm/fI/irQnS/s76GY2IEEL6DDG1QwBg52gGZcNMf/4YBmBlnYhO3enQzrpiqaTMm9ONut70LysDx3NYVfqEacLGLroQGAYCgNWpyeAAHIyNgVYu96qMxPAq00ZpYl+iCOdiZgCYLv8tk/UPBhAYnD2Rjvldi7CNzzcftSzFBrzfHTqv9r+B+Z31IxoRIaSPE71tfB8g9o/2jd8LOKvmLcEIAESlfo3O81Ph7POZ2Mqm/lReWw5tZ5PrIQ6GQY1cjvLYGNT7sF9Ospf3ZRkXOpVJfaHSnQp2F5z6T/Pl2MGPxyVsJTLQhFok4bZrbrL8f9TbJbkj6n8BK/BB+Z31FQUihPRhXm8bH+bE/tEWANy2g8f+oQyE7j/4rIxDdOoudJ6f5tBebGVTf9K2iSvIppXJ0NX/WqDze6/Or2n0roCbotXdvjihL1RD72zU4buYe213bN7xGiBbDeTOhmL8OMg1GlEjfQCg4Lswov4XZCROkqjH/kdTM4T0Ufb7ipgFJAkzSMx/tD1hAaS1ABedtb0ZR6XsQU8qq+MweSA1GhpFtauNUeGvP1wFvkvlNDWG4QXknuZx6TEeuad5MLwAhhcw9ZB9RRJb9s+dzb5SdN9DkS5xYLC74NSM9APQwHYaRdBVm1ZTVW4BI5NBvXyZV+cczHYE5XfWVxSIENIHOdtXxMx8rHhrpV/KmocSb/9o209PsHI9ZArTEL75E/SKWblBmcpKjkkW1W6X8XJwkMOgnQXANk934nEOr77I4bFNPBZu4fHYJh4v/53D7/fwSGt1P0pgW1iLBRet9P6bCCFcVGKwu+BUVBwH+18vxly2rmQpwHNQFhai39oXRGciXzv14rCafqVAhJA+huMFvPH9KdHbxvc1ysJCpP3f/4lq62wJqzyhEgCgUcX6pcqqr9Tx4iqvlraOAgAYW0aio+oWCEZTgbabd3FY/JEAVbtt+5QW4MZvvQtATVVVw+fG5hTL2qxKCRUuU4AgALoq02oqAMqiImQ9/5zbc/EAjKnpmHxDoZ97KS3KESGkD3GWE+JOOCW0eWKdlNsvPgPxbtryABoSgR+zHe8CyRlH8fzsx3HJoHTIWAYcz6G8thx1+jqkK9KRl5EHmRd7tPgqLyMPaoUaWr3rXBFVVDpa9DmWx8aWkeB1w/Hn069jdsVPTl/Doqd0uFjVaWO9aB2iGAZn+0/GwN92BbsnNrra3f8u8S01lvBJdfXV6Dh2DA3/es2hnQCAZRhkr3gYjA/Jy8FEgQghfYQ5J8Sbz7rBSMKUgnUAxgo83tj2HBRwfrM11wfZOK0nUdVaG9cMmeIXlNeexldnvsKnv3xqk6+hVqixNH8ppg10TGr1Jxkrw9L8pVj89WKH/WUAgAGDmwb/H5493PMpf9K5I7j7h4+QbtC5Pbf5FWL3mdGHaH6Ft+rSLg65QKSjPgrIaXf5/I8tCoyweqx+4AHEjhqFmuLHwTf2/F5GaTRQL18GZWF4jYYAFIgQ0ie4ywlxhoFp6iGcEtqc4jmUfb0Vn3+5HwORBC2GY0T9L0jvcF1d1HzjbYlzfQu+f/f90HU6v5nX6mux+OvFWDN5jeTByLSB07Bm8hqsKltlMzKiUWiwJH8JpmRPxdu7dqGmuQMF547g4bKN0nQknDe7sxF600uu/j/LC0ANUnFCMcomEAEAVVERlNOnm+rm1NVBnp4OxfhxYTcSYkaBCCF9QNmpBtHTMcFOwvSbyi0QSpYgX3cO+dGmQ+eEFGzunCzq5e7qaLgKQgBAgAAGDFaXrcaU7CmST9NMGzgNU7KnuJweWjErFwveOoC7D38MwLtbbRj/9H2SVF8R7C44iE7kwAuwSVg155AXd92K25TOJxkZmQzxE/MD0EPp9ZUwl5CI5k2uR7CTMP2icotpeaPOtraFBg24S/GpqFM0uUsi8UCAgBp9Dcpry30/iRdkrAwTNBNw9aCrMUEzwSb4KRqZiX+OlSO9o1nCwKJvrK5qCLFcFwHAowNvRw1sRyZrkIr/17UIhxN/F/6jliLQiAghfYDYXI9HZl6E2y7NCe+REJ4DSpYAEBxuvCwD8R/zPexH4wrDC7jorIDkVqBFVQphVp40Q+I853T/GWfyEniILTcmNi/Eti9dLq8dTloTs4PdBRsMgLP1Gbgs/UXks8ctlVXL+OEQwGJ9uI9aikSBCCF9QH5OCjJVsahp7nD62dWcExL2QQhgujnrXN92eYO4G2aS3vv3If8nHrft4JHW0n1gy3qcWPuR/5MEK7eYgi3r71OZBRSZqm3a87YMuLeSGo+jKX2MpNcICCb0gqnUjmbwYLGXz7UcS4mPwtPXjQrvUUsvBGRq5uWXX8YFF1yA2NhYTJw4EWVlZYG4bJ/E8QJKT57HJxVVKD15vs8VpCK+kbEMVswy/SGzv732mZwQs1b3pc/lseK2q3dWQ8Sd/J943P8hj9QW2+NGrRZVCxdBt327dyd0xcW0E6yqbdozV5T19NdAH+1bly4+9rrPI0ihJfR+/5MNtslKKfHR2LtsWsQEIUAAApF3330XixcvxooVK1BeXo7Ro0djxowZqK2tlfrSfU7J0WpctnoXbvrHXizcXIGb/rEXl63e1SdLdRPvFY3MxPpb8qBR2U7T9ImcEGsJ7gt9KdI7IY/jXK9GAFDvooaIKwwv4LYdptLvDq/qvkFrn14JgRMXBLlkNe3kqPtYd7VNm/5ZVZTl7V7Fd7/y3UsZCIJvt2I5jIBgf+YwxHcFuwcOEgxtNo+fvm4kouWRlb4p+Xe7Zs0a3HXXXbj99tuRm5uLDRs2QKFQ4LXXHAuyENcicd8Q4r2ikZn4bsmVeOeuS7DuT2Pwzl2X4LslV/adIAQw5Uoos+DqliowQHSe6aZpf+sUuvNK3pjOOq0h4spFZwWktbi5iQsCjDU10B84KPqcTnmYdoJdtU1rysJCZK17Ac1K2142JALP/54FWCC+V/fh0BtNEE0QAEHAxO8eCXZPHHUvjU5WRGFDX/rA4AVJc0Q6Oztx8OBBLFvWs/cDy7KYNm0aSktLHdobDAYYDAbLY53OfVGeSOFp3xAGpn1Dpudq+sbQO+kVGcugYHBqsLshHVZmypV4by5Mv/09/88QwIBhBDytvhkt+XG4+/DHNjVFBAWPNUVRKBvm3Wcwd0t9rRnr6rw6rwMP006e2iVNnw79TwJebGSR1CagMYHBj9kMGF7A//u0t1MrYT41w3OIR5vndgEWk5eHf98yEZcMSo3Yv9+SBiL19fXgOA5qte1QqlqtxvHjxx3ar1y5EsXFxVJ2KSx5qhFhvW9In74BEWKWOxu48U2HhE5GmQVuxkoc3pKAumEHcOQyGXJrWCS3mnJCajMZdMkEMIIAwYu9U8Tmk/Q6adTDtJPHdqf3YFrDOUARh1X9k6GVy5D/E4+7vuCh6Oxd10xTM6GX7CkKz+PKbxcGuxdOLZoxHAlD0oLdjaAKqVUzy5Ytw+LFiy2PdTodsrNDa7lVMIitEdGX9g0hfZ/13jAZiaYqr159IsydDQyf2bPENT4dEATI9PWYO2ovXq7fDAFA5cCe0Q+3ORLmZEwnAcqP2QzqE00bxjkbSxEAcOlJUIwfJ77/zpinnXTVcD4CwZieHzjJ+eu7R0qm6dsxRd+OH7SJiP0qoee1vcF3ArKo3p0jSNLr9ge7Cy5x5/vexpPekjQQSUtLg0wmg1ZrO4yo1Wqh0Wgc2sfExCAmJkbKLoUlsTUi+sq+IST8eBtUONucL1MVixWzcr2bI2dlQM7lppUkH98N6M6BA/BBdpaptoddUMEw3ekCnAIQ5GCjeqZ/NRyHB843IpnnUSeToU7G4rlUUzEpgWXwxnQW93/Ig4dtMGLeQG7d5S34029f9a7su5tpJ0sgUbTKdU0Pq5ESlgcS9ypgtH5tbzDhGYQAAB/C+S2yVBrFljQQiY6Oxrhx47Bz507MmTMHAMDzPHbu3Il77rlHykv3KWJrRERCBT4SerwNKlxtzmdOvPZ6hY95uWv3GctjY1DLypB7RkByq4DGBNOIhjk5lWEARq6H/vSduFX2JfKjDyKd45DXYbCZeOAA/CNJhWaWBRgGZcNYPP972NYRgSkZ9I3pLPYPY3HaH2XfXUw7meqIrHJaR8TCakRFXxcFo4edXb0SuvdyjzoUIqe8gmDPyTokZpz3fkTQH7womiclyadmFi9ejHnz5mH8+PHIz8/H2rVr0dbWhttvv13qS/cZ5hoR898ud/UZqe/UiCBhxdugwu+J106Wu7adjcXL/+GQZpWXWB8PvDGDtUlSZeWtuMdQgbQuvdNTywA8Vt+A+zJ65u/LhrHYP5SxVFa1DXJ6yr5P0Ezw3Hd37KedxN4krEZUjB1+vqGE8fJdTha6o8XvfHEIXx1lfRsR7A0vi+ZJSfLlu3/84x/x3HPP4dFHH8WYMWNQUVGBkpIShwRW4l7E1IggYcNTUAGYggrronveJF6LYrfcVXc2Fhk7FUi1WxyR2gbc/yGP/J96bqbDuUakMXbVyexM07fjheZOZMRl9PSRZVA5kMX3I1hUDnRcBlyn7+XKGTPztNOo603/iv2k2j2iIk9N9k8/zPpEQbPQ87+Ht2DSuSOBLcXgQ9E8KQWkaso999yD06dPw2AwYN++fZg4cWIgLtvnRESNCBI2fAkq/J54bbWMVeCBc/tUcLbdjPnx/9vKg+EE8F0qXNAuLh9t2rA/YPv12/HghAdFtU9XiFw5w3PAqW+BI++b/uV7WQzNWu5sKFb+AHma62BEANDOepH3wYRvICIIfnxv/UzV1YaHyzbi0nM/AHAM3v3Ox6J5Uoqs8m19gLlGxLVj+qFgcOSuOyfB50tQ4ffEa6vkzFZtNASjDK6SGRgAii4g9xQHg3YW6iByxGDY1ZCxMvx5+J+hVqjBuDw/A41Cg7yMPM/nrNwCrB0JbLwG+OBO079rR/rlk6jAcWjbVwbdth1IuukWgGEcbjnmcaGzaRn2L3eND9+pmWhje7C74JIpcBbw8JE3MYPZ692IoC96UTRPKiG1fJcQEj58CSo8J17zSEuvwnkA+2sykJeR5z7x0yo5U/erQlR/Lt8/CHvHjEQZeJwTUqBBA1zG88p+pmvwHGSn92Cp+gosPvUeGDCmKq2WnXgZNCUI+J9bHrDtr7NkwOOf2STXWpiHxW980+c5et327dA+9TSMVisVWZUKRl4A09KzQkgAAxYCLqytEn1uhpGFbUmz9PqKYHfBAwZCO/Bc0wYIySxqW8ZId6leFs2TAgUihBCf+LKay13itTzxKGLUW9ER1Yxl35mOqRVqLM1f6npJbHdypvDeXHBGcf2O6YgDAPBg8XjXXPw9aq2pIqurpbLHP7Mk9U0DsEYRh1VpaRh4QsBt23ibpFj2y6ege9hUbt1lMmBXO1wPizOmYfHhM71evaDbvh2/3bvQuvcAAGNzMxgAH42+GmhtwZyT34L1JaTwogBcSBEEDPhtd7B7IYqxXYYVGW/hdPwC6S7S26J5EqCpGUKIT3zd8ddZ4rU88Sji+r0NNqrZpm2tvhaLv16ML09/6bIfJfwELOi4Bx2CuJyPY2mDLP/9Q+Lv8MOkF8Eo7fKslFmmkQnAIalvmr4d739fj/s/5BySYvnaWlTduxC61552kQx4DmhvdNM734bFBY7D6eInATj+LFjTWTHj1724rOqw0zZiRBuafHhVCDB2gHXYdSg0RcVxyGLOI1/mWHncbzzs1WQqmtfPddE8CdCICCHEZ+agwr6OiMbDUsSikZmYnqtB2akG1Oja8MLx59HopAS50D1WsdpFfQ6OF3BsxVP4f8d2gRNTfpxhcOMT92GygUdGfBTyZccha4sHhm4wrQrR1/dMoQCmvA270QOBB2r2Kd3ezM+teQuJvxfM+5l5z8th8db9ByA/73q1DgtA0dwAcZNXzg39+QMcHSPhJ3WJxHSJ3CgoyGQxHBTppv8TyNok3J2+t0XzJECBCCGkV6yDCm/KtZsTr/fX/ILGw65vooKb+hyHH34SVx3b6bGP5holKXfcjosuyjRNm2x1UUMh53LT41PfOk3q60mKdXM9o6ldYqaPG7x4OSz+07FTiPftSqKlN/1oSlhlw2sgPaajPthdEEU5sL0ncJV6WqQ3RfMkQIEICZwQqeJH/K83O/6Krbth347v7ETMR5sBiJtqYBQKpC66Dz999W9cuHsBTCmbVnTngPduBW58y/SH2MWohNik2KZfFF4HIrwA1CAVh1tzUOTF6xpiEyUPRBgIAG8E2GiJr+RfjmuGQlNivw543EvIn3wtmicBCkRIYIRQFT8SWsTW3bBv17jpHTAiq30yAAS9Hv97/yt4Mvk5CBBcr5TZutD0B9rFp1JeZFJs69k4aCs4qMc4L5rGC7Dpg7l0xONdt+KHT3/C9BH9RC/PT5wwAXWxKqR2NDtN/OMBNCQAYFxv3CdKGOaryrjebjscCAKMBhmArsBOi5iL5gVZeI2xkfAUYlX8SGjJy8jzqT5H59mzXl9rUOMRZDFulusCQHsD8M1zLpP64tK6RF+v4XgCtBWJNscEMGgQElBjV8ekBqmY37UIJXy+17Uk8oek491LbgADOKRlmjfle6OQxRvTWadtRAvD6qrh0uNze5KgG/BgRH4wo0CESCsEq/iR0CJjZViavxQAHIIR8+Ml+UscElWjs7O9vpY8VuQteN8G079FqwEAAs+gTRuN5tNxiFV1wfS76+kWZ+p7w08JVqMopmPLuv4Hlxlewp86H8a9nffgT50P4zLDOmzj8y2vFl1dFqapsVn3/BlP5c/D+ViVzXMNicDzvzfts2PauI9FQ6KLE3nChN8gujEqIdhdEMH0e1GzcTsELvL+FobfbxUJL95U8QuBIUISHNMGTsOayWuwqmwVtPqe3Ay1Qo0l+Uuc1hFJ/vNNqH3mGVEVP3kA9XFJ+CFtsLgOtTeYfidzZ0M34EFoX34LRqulukwUIIgaGGEAAWg8EY/U4W2AMgv/HfsQtm1LAgDs5XNdvlJ0ddluRSMzcehPs3Fb5giMqP8FacIJ6C/YZbPzMGC7cd/svTzyfvHiIuFaSyQsMOC0WugPHET8xHzPzfsQCkSItEKwil9YiaAE32kDp2FK9hSU15ajTl+HdEW628qqbHQ0Um6/Def/9RoA1+kL5hUzr4y6FvuEXDQK8Uhm2ly0ttJSDd327ah65i3Hcxrtlz2616kpBObdCQychCFgkbl3l1eF4MTgeAFbfqgGz7A4kj4EcmUr4vo5H/QWWAYJHQLGehOEAN078IbXQHpim/jqsaHAWOenTRPDCAUiRFohWMUvbERggq+MlTks0XXnyI1jceAoi1n7eNeBSFoGnhp0FfZkjQIAvGYswv1RH3g8d+vHD6B6S5qLkwoAw4CJj4fQ6rlORfSYKZYRPxngsrqsu0JwgKlwmf7AQRjr6sCmpeB4Nos6w3mkK9LR2TrQppaLYHQ9JcHwAm7b4UOmiM+FUYJH1Xwq2F3wijxd5KaJfQgFIkRaVnuBOP8EGcDlagHA8YLX9TScMif4SrAfSV/B8RxWla3CwH49ZZms32nzO5e5bAkqD8oBvWku5WXuOtwu34ZktLqdadAfNoJv1btuIAimIIRh3CdxsiyS/3yTzSFfCsHptm+H9umVMNbUWI51JAIfTDflfiij0iBPLIKxZaTdO+DoorMC0pwv5ulzOqN9TYgJPJlaDcX4ccHuRsBRIEKkFYJV/KRScrTa4caS6aHCqFMeE3x9348kkDieEz3NIob1aIA8PR2V/QXUttZgRfcne2dl5nkA1aueAjP1EctxHiyWdf0P1kethWC3hNZyLR5o/K+4JMf4K65A29dfu3w+5fbbwEY71t7wphCcbvt2VC1c5BDwpLQA93/I4/nfA2XD6hHb7210VN0CY8tIjI46jJ9d9CnZ12KjYbhqRpfQP9hdEMH0/2vNQ8vByEL3/9NSoUCESC/Eqvj5k3kE5MvKGvzr+18dnq9p7sD8t8ux/pY88cFIH0jw/fL0l04TT91uYOeGs9GA2DQVfn8R7/aTPQsAdQ3of/YnNKYPsRzfxudjftciPB31L6TC8QT6umjwneKmIVJvvx0xgweh4fU3bBNnWRYpt98G9QMPuHytmEJwAsdB+/RKp0EAC1OwddsOHvuHMgDDIEa9FVe2teFOfIr/Qc+UZ89OwYCqzbeAQnNqK2qGzPHptcGij/Wt0F5AyWTo98ILps0SIxAFIiQw/F3FLwSSOJ2NgNgzTxcUb63E9FyNuGmaME/w/fL0l1j89WIIdiM65g3s1kxe41Uw4mo0QFbfjBu/FXeOFINjsLGNz0dsVyfWRf/d4Tljh7jfJValgmL8OMRPzEf6woVo3PQOOs+eRXR2NpL/fJPTkRBv6Q8ctAnAHPoAIK3FNN1SOZABG9WM6xI3Ia/DALXRiFqZDBP+a8oJsQ7aOAZgBe9qlA3/bSdqBl9rehAmK2g6Y7xL+g04lsWwQ4f88rsSrigQIYHjryp+IZDEWXK0GvPfLhe1bkIALAWqRJVBD+MEX3Pehn0QAnjewM4Zd6MB3qxbaYpxPs2iheNNSuABY7u40ZCUubdahtLZ6Gik3jbP9lx200mK8eO8HnoXu4rCerpFkLdBLgCPHm1BWZ0SVx9w8v51H3KWW+MqxGDBI/vsDpzNni6qT6GAFYJRl8Pdu2iH53FuyVL0f2GNpD0KZRSIkPASAkmcHC+geGul1xUbRReoCuME3/LacpvpGHvuNrBzxtNogNjP5CnxUU4DlzJ+uM1yXt3ZWGjLVTC2ew4WZElJSLv7bpfPO5tOkms0UC9f5tUQvNhVFI1WsZbmFxlO7FUjvV2GmS5+U83TOgIDyLz4ZR76yyc4239a2IyIJAR0+a7pjWSieAhd4gPOli++QPOMQqiKvNlhqO8Iv7VYJHKFSJXWslMNbqdjXBFdoMqc4AvAeQomQjbB19cN7FzxV02F24cnOv2t4cHiNaPpj7/uTCyqvk92Mhri/C6tebzYYXRD4Di07StDzcqVqLp3oUMQZdRqUbVwEXTbt4vuu2L8OMg1Gpc3fh5AfSLwY7apDm3hjxzivkoQNarDwhSEvDklCjW/a0NXlOtl0LbCJGlVEDDi2OsBvWRCvw4Mu06LAVPqIY8Xvx1A9WPFEVlVFaBAhIQTb5I4JeRN6W3AFDpkelugypzgq7RLcFVmhfTSXbEb2J3SivvT46+aCrLmZiQpohyOK6JleJm7DlVnklC1Jxmmn5aL4M/cJwWHfpc2Qtnf9vdAt307TkydhjPz5qFx45vOO9I9xaR9eqXomw4jk0G9fFn3A9u+WPaRmc4CLAOG43HbdvN5xY9YNCZy2NA/EVFd4n4uiU2u1uOEGEGAHCJ3Kez9xZA8rBXZlzeCYYF4dScGz6wDWHH1WoSmJugPHJS4j6GJpmZI+JAoidPb2h/elN72VKDKrRDaplss8wZ2tfpa53kiAiAYVXjuky4MTqzuWUnkIvnYPBpg1Gp7tXT0n0cb0ZTt+OlU38lhhaoOzR8rRN22M8Y0I+XCNjCs7RJqVwm1TgkCjDU1XpXyVhYWAuvWOkz1NCSagpCyYSw0nIBHjjRDrve+bkZjgndLenPObMfhlOFeX6fvMP2cY1IMYBgGCf07kDq0DazctgXDAglZHWj9TSHqrJFYVRWgQISEEwmSOH2p/ZGfk4JMVazLEt3W3BWoEiVEtukWy7yB3eKvFzvk65nv0QbtLABsz0qi41tdJh8zubOhXr7MdJO3LxzmqZCYlXq7jeDMWIHH4HdfFf39yeP47uKiPaNvwoBJLhNq3fH2pqMsLETi1Kk2lVVbs1n8wXAedzdXI++Txag7qUSjF+fkYQpmfsw27T0jVmrTf01ZvWFYadWfUofrEZNtRBfkDvVomoRE7E++CsMG7wJ+E3e+SKyqClAgQsKJn5I4e1v7Q8Yybkt0CwDuuPQCTM/V+F5ZNYxNGzgNfxlejL8feR5sVLPluGBUwaCdZan8Wd3cgRO7N2HY7gVwl3ysLJztdDRArlZDvXQJtKtWu0xoFQDUxSXhWNogp8+PqP8F6R3NTp9zRh5rN53SqvWYUOvyXD7cdBiZzGYUxZLue+R96M7GovG/8aLPZT2tI7AMfswG6hOA1FbPkzoMBMi62sCFUdVS/+reLfegCkP7aRHNGrGm6w+QgwMYoJTPxT4+F3wNC3nSNXg3egXiOg1u39dIraoKUCBCwokfqrT6q/aHLyW6I0n/mHy0nVgCmeIUGHkLBGMiOH0OrNPSWPAYsK8YYirI2o8G2CyFZVm30yIlAye67Kez+iKusNE8FOmdtgcT1DCe9nI4nWEg9/NNR4hLh7bc+aiPK9bTOoBpI7w3Clnc/6G4nAbNue9RdUFkrvIw4w0ytNdHIy6jE3+Sf43LDOvA26VeGhk5nh/zJzxcttHpol7zsUitqgpQINL3eVn4y297pUjFRZVWoXt79eOd45Bx8rzTfvu79oc3Jbr7IusS7imxaeD0F6C+tQsZibFIS4gBwILTD3b5+nz2OOI63OXz2FaQtR8NMHOVPwGY/sDPPb4NV/26FxsunmPZ+A4wTcskdehEf78pF7ZazUT0jL7Ja71IMOxONlUvX+bXm46+PlrUkmMBwGfjGRy4kMGP2QwEJ7+rnTIgRkQebVrTT6hCqAci0q/uMXbIwDJAFs5jkex97BFGoowfbhOQ7MkahSfz52Hhof9A2WW7f5EsKQmZjxdHbFVVgAKRvs3Lwl9+2ytFanZJnGV1cty3V4GqbV0AKgA49luq2h9iSnT3Rc5KuPNdPVMvGmUMkhRRaNZ3udzq/kJFG0QtaBCRfGweManf8ArqX3rJ4fnUjmY8XLYRT+bPw56sUZh07gjuPvyxyGkZAWw0j7Rcczan7eibNwm1crXa6zoiYhjrG0S1Kx0GnMxyHijn/8SLHg0BvKvIGjQBWGVsPV13b9THuBcf45yQguKuudjG9wTOe7JGYW/mCDzcX4+x9aeQmRyHhIkTEZ8/IWJHQswoEOmrvCz85Wq0wKe9UgKhO4mz5Gg15m8vhwDbFRH2/Za89kcEcVXCnZE3WzZd0+pGWp51tdX9NZPGAN+IuKCH5GNz9dIurRaNb7/ttI25eNdfjnwCRuDx0P63HM8DVzdXBpkTmntGQ+z2SDIvr3WXUJs8bx4Sr7zSp8qqYojNN5n0EzDpJ1OwUW81NcPwphLwgPgAozNa6UtXA0vSaEmAXME5TtcB0KAB66PWYn7XIptghGdYpF5+GcaO+aOUHQs7FIj0RV7u3uputMCnvVICRGy/E2OisK3Su2RCBqZ8D69qf0QAdyXczffgGPVWtLXkggELlSIKsXIZanSOeTT5uRlARe+Sj51VL3WFBZDR3oR7Kj40n93+ao6vSUpCZvEKKC+Mdzu96Wp6SKoREGsCx0HgOTAKBQS93nmb7n+tv0frnXtbY+F280BnOsMiUVWqv1emd1Q5oN3pwiGWAXgBWBH1FnYYxttM09CHG0cUiPRFXu7e6mm0wOu9UgJEbL9v/tc+r87bq9offZynEu4MAzBRzZApToHTD0aTvgv/vjMPLMs4z6PpRfKxV7U7rCR1tXlso5w1C6rf/96rYXO3CbUS8SYQs/9Ntt65d9Nk73/PZZ2e38e+y/T7qjsTh4yLW1wGI1k4j3z2OPbyufThxg3JApGnnnoKn332GSoqKhAdHY2mpiapLkXseVn4S2ylUG8rikpNqv7QyhfXxJZmZ+Q9H69LfzmP+6Zf6DSo43Kmo7bpOnQe2Yvo2FZkjNFBFgWH6Q977jbD84eEK65AQsElXr/OOqFWzIZ3XHs7ap95Fp1nziB6wABkPPgAZHFxTs9tn0h+0YmDqF60SNR74HoTO9NIiNL5QIpbLaoLvH9Rn8LAqJdDXxeNeLXj9IxZBpos/+3zh5sQ2G1cSpIFIp2dnbjhhhtQUFCAf/3rX1JdhjjjZeEvsUOFoTak6K/+UO0P8cSWcBeMPcP2f/vqBD4o/80huDu7YAFad+6yPNYjAU0nExCbOxgXvPshmCjX26L7WrujJSoWiV2eA9jeFpYSs+Gdw/f//fdoeucdJEy9Etkvv2xzPvtEclbg8daOp5EsCH6ZfGhWAC1xQEK7F5MZ4bDdjESBqjVjh/uAYCBTDQBQOdliQJQQ2G1capKVxSsuLsZ9992HUaNGeW5M/Mtc+MvlnxQGUPazzL2bK4W6ae39XikB4KnfYmlUsdhwSx4enTUCBYNTKQhxw1zCnXHxrguCafWMqWZID3PycMlR0x9l+5uwtY7Kkzg+dhzqXn7Z5X4svpbC/jFpIJqi4+FybQjDQK7R9KrGh3nKyN2Gd+6+/9adu3B2wQLLY3MiufU05Ij6X5Cib/JbBoSmyRSEeEMfFzrTtA4EARAEjPv2Eckv5VDkzq4b98k/wAy2DM36Lpv/D4hiXnRgP9VuXnRQucXHXoeWyK7P21d5uXuruVKom9YhmS/hrt9izC0YiHfuugTfLbmSpmFEMpdwB+AQjNiXcLd5rvvf4q2V6GzTu7wJWxiNqH/pb/jvpZc57FQrcByM9fU+9T+/7ickdbY5ZKQA8EuND7dTRt3Hap56yuP337pzF7j2dpcJ2d4UYnPHvHPv1EPd29eLfJ0ABs1K1zViQgLPQwXxVXO9J0CuMDpdNWNm3qNwRdRbYLrD3+KtleB4ESM1IbLbeCCEVCBiMBig0+lsvoiPvNy91VwpVKOyne7QqGJDb+muFVf9FuOqkZk0AuIBx3PYX7Mfn//yOfbX7AfHc5g2cBrWTF6DDEWGTVvBqEJH1S2WEu72zMnDlY8+Kfr6fFMTqu5diLqX/w6B4yw73NauWtWbb8vpn3a5Wo1+69b2aoWLxykjQQCnrRV1rtpnnnWZkN0Q4/2KFfvv2VzifecYBmkiyrpba0oaAiHKeS5LSBAEXPntvdKdvvtf9Vidx+12WAbIYkxJq9aJ/x6FyG7jgeBVjsjSpUuxevVqt21+/PFHDB/u266MK1euRHFxsU+vJU54uXtruFYKte93WkIM7n+vAlqdwWUxLcpe98xZ0TK1Qo2l+UsxbeA0TMmeYlNZ9ZvD8fj7iV89nrfr7BnEeNmX+pdewvk334TQ7J9PuCxMNxM2ORmaZcsgz0iDIq0TTHsdcOpbn5MB/bl7auevv7pMyD6WNgh1sSqkdjR7/jTJskiZNw+6zz83FV3rxsfzWFcoh5wDvE34MIRDDRGJCWDwH+PvMISrxhWyIx7bWyetikq0l2i38VDkVSBy//3347bbbnPbZtAg55tLibFs2TIsXrzY8lin0yE7O9vn8xF4vXtruFYKte/3Y7NHuNyUDgjNqaZQ4qpoWa2+Fou/Xow1k9dg2sBpmKCxbLsGof08/v71rx7PHZU9ADjsRVl08/n9FISYMQD4xkbIO04gfs+DfkkG9OfuqVxLi8uEbJ5hseHiOXi4bKPnE/E8EiZPRurixXhy4TLc1/4W5LGmQlxD0pJwqCnB677JI3rpbs/fkTGHfsZzWTeJCkRqkWT5b1GJ9hLsNh6qvJqaSU9Px/Dhw91+RUe7znT3JCYmBkql0uaLEF+E61RToDibcrF+zlXRMvOx1WWrbV4DiE96zn38YX99G35h/GK135IBzeXeLckBziSKm1YxnD6NCQNULt/TPVmj8NFgcR8yjHV12H+mGW8qf4e2AXGIy+gEwwJT9e34MZuBLta7MZH69Iu9aN13KToNGFn3C84JKXCV9sELwDkhFWX8cO8S/71cdBDOJMsROXPmDCoqKnDmzBlwHIeKigpUVFSgtbXV84sJ8YOikZn4bsmVeOeuS7DuT2MoMbXbl6e/xIwPZuCObXdgybdLcMe2OzDjgxn48vSXADwXLRMgoEZfg/LacpvjYpOeo+MVSJh6pb++nV6TOV314FsyoLncu+mB8xsIy4vcz6WlBYbycrcJ2Xs1I0SdSp6ejtqWDvBgUdw1F4DpBpnXYcBduzgkdniXI9Ie67+RH0kEYNmu2e/37ca/f50CAA7BiPlxcdetluqqokdjvVx0EM4kC0QeffRRjB07FitWrEBrayvGjh2LsWPH4sCBA1JdkhAH5imba8f0o8RU9Ey52AcaWr0W9319HzZUbIC2Tdycs7PiZmJHorJffjkkghE2hkO8y1UPviUDKgsL0W/dWrAqldPn+Tbx0xrGujqX72lKfJQlV8RVaMMD4NMyoBg/zjIdsI3Px/yuRahBClrPxGLqfu9v2rEd/suFkQQTwCInXcDMfaWo+S0J9n9empBg2W9Go4zxfjTWy0UH4YoRhACGjl7S6XRQqVRobm6maRpCeonjOcz4YIbb0Q4ASI5JRqOh0eP5Xpvxmk2OiO21BI9JzwLH4ecpV4KrFbeKxN8EAP0mNUA1wEPi4B/+BYy63rtzcxxOXDnVJjnUFwM2brRUarV/T8cNTMYVz36FQT/ux0NlG03Jt1avNa+KyVq3DkkzCsHxAi5bvQs1zR0QAMgFI97/4mHEdIrZAtnWsaE3Qtvvil59b1Jiu9ow+fsHA3hFAfI4DkNm1VpW0ZhHQ+Z3LcJFU27G/00d6vsHoTCsrOrN/Zv2miEkQniacjHzFIQwYKBWqJGXkeeyjZikZ/2Bg14HIa53yPWOAKB0SC7uHPCl58bx3k9D6A8c7HUQAoZB3NgxlofO3tMVs3Ixv7kDT+XPw18Of4z0jp6E3vq4JGDBIuTOKLS8fsWsXNz9tmlKbUT9KZ+CEADQJQ3z6XWBkmY3bSg9BsZ223Lv5o3vnknYBNXUR+EwXOINLxcdhBsKRAiJEGL3iXHHXMRsSf4SyHr5iczbpa7mT/jOOdtf1nXL9wdfgR8vzsGd8ByIlJ06j3wvFwP6ZRmvIKD9UIVlRMQZ87RN8dZY3JY5wlRx1dACJjUVf7pjFopG93f52gmdx33uGiOEdhGt2PbgLGm1L/fOMoCqs9aywShxjgIRQiKE2H1irNlP06gVaizJX4JpA6f1uj/eLnXtiGWQNuFSyFPT0LZ7N7hGz9NHzmzvPx6vjZqF2RCX+/Fp6WGMm3KdV8Pq/lrGKyagsa2jk+dyKsxcpdXSx1iRSbNOqGtKcWqId9NVgVSjKcCQ374K+HVdlnvvA7U+pESBCCERwrxPTK2+1unSXGcenPAg1PFq1OnrkK5IR15GXq9HQszMS12NWq3TVQ48TBuxncgCxp4EFB0C9N9+Z3qSYZB49VWQR3eiaesOCJznvHsBAA8Gf8sz3UCt6zq48199PMpONXhVXydu7BiAZQGxK2RcEBvQiJkKs6/S+kPaYPwh7msY21l4O+GV0Or9hoOB1KnQBPiKAuQKznW59z5Q60NKIVXinRDiH87qhJj3iREbhACAOl6NCZoJuHrQ1ZigmeC3IARwv9TVPA3zU38g76ST26QgoOXzL9D48U4InPib6IdDroCRNX3+KuOHi67/IKoSppX2QxW9C0L8sPmePfvvYZ+Qi+g88yd479YsnB0Q/BVP7gV+dZyzcu9CH6r1ISUKRAjpYzzVCRGDAQONQuM2IdUfzEtd5Wq7T4wZKahdcjMmnDRlpbi/rYi76VQpUvHayGssj+1ralizr/8gqhKmFa9yROzrjfhh8z1n7L8HHiyeVt+CrEsbwUZ5F4gYZQq/9UsSgm9JuL5SXqCHMts20LP8TvWRWh9SoqkZQvoQd6XZ7/v6PqhinNe2sObPhFQxlIWFSJw61bTSpK4O8vR0KMaPQ8Nbb6NWzC6lIn0+yPFTqbmmxoqoN5GFno3IapCK4q5bsZ3PF18J04o3OSKsSgW+qanntWo11MuX9WrzPWfMlW/Ny3cB0/cPNbB80tvQ7xZfFTuh9TRaVRf4tX/+NODUZwG6kumdVI9vBiewkDE9o2A1SMVv+Y8iv4/U+pASBSKE9BFiSrM3Gzzv15Icm4xHLnnELwmpYjEymcPqkM6zZ/1ybgGmIfKtgy41XQu2a2y28fnYYRiPfPY4MtCEWiShjB8OwdtKmFY85b9YY2JikP36a+DON1iCMH+OhJiZl+/a78G0jc/HzqQ8vBv1KBRdrre0t5ZedwQ1oVpHRBAw6LddgbgQACBleCtkMuBV41X4Shhr8zv072E0JSMGTc0Q0keIrRPiyQPjHwhoEOJKtB83vPzAKjdEo4rFhlvysMGqWikPFnv5XGzhJ2EvnwsebK/2JbLkv4ioF8lptWBYGVTXzET8xHxJghAzV1VajYwc7w+eIvo8tS4K2YWC+JazYF3WmvWvlOGtUI9pAQDcJf8MKrRafofUKgXt8C1SZI6IhGGVumASUyWTBJ8/6oQApgTVUJD855tQ+8wzvV550jX+Ekxd8QRGtxkcfn97lr12IC0hBhCAeiftnBE4zmE6yTqIUBYWQj9vHho3et4ht6201OV5xFzLG0UjM3HlcDXeKv0Vpxv06JcUBwbAb/n9oXvsWyR26j1m3XCyGJ+uLTlBwPjy5wJ2uc4W0y2U6R5ieibqVcR1GVCDVNx2zU30d1KkyAtEKrcAJUv8suV3JCg5Wo3irZU2y/4yVbFYMSs34jePCzW+1AmxJqZiaiCx0dFIuf02NPzrtV6dZ8j/zUf80DSnz4lZ9uqMbvt2aJ9eCWNNzzJWuUbjkNuRMHmyqEDk/IYNPX1Sq6F5aLnlPGKvJZaz/09bzjsgH9ef+NpjBVtV8wnUp4/x+tqSEgSk1h+GDIErttZaFYvm07FQDewAwwAq6LE2ej0AoP3zfwKyZ+m+IkJkTc1UbjFt7e2nLb/7upKj1Zj/drnDH6ya5g7Mf7scJUerg9Qz4oy5Tgjj4hbCgEFSdBKY7v/ZPwcELkFVLPUDDyDlzjtc7mTrib+XwAKmwKBq4SKbwAAAjFotqhYugm77dquj3ifbclotqu5dCN327V5ey7OSH37D3194DxceK8WouhNghZ7RJlbgMfm3QwA8r0OK7WgyTTuF0FZl0R0NGH3s1QBe0bSeq7osCYKTQbtYfQ0Euq+IEjmBCM+ZRkKc/mHwbcvvvsxchdHNu4XirZXg/LiqgfSOuU4IAJeBxopJK7Bm8hpkKDJsnlcr1FgzeU1I5IbYUz/wAC4sPwjIvRzAZRi/L4EVOA7ap1c6vwF3H9M+vRICZ/o7wp1vcGwnUvWjK1Dz1NOir+VJ07btSLz9Bqz+fgOWHvg3nvl+A97Y9hQmnTsCABhR/wvSO5o9BiECGPx04Z9MD3wMEP1OEDBp32PevaT7i2N4tMVzPoSM3efhWLTVOq44YhhTkrhA9xWPImdq5vQex5EQG1ZbftOeAA5VGO0JAKqbO7yuOEmkNW3gNKyZvAarylbZJK7al2afkj0F5bXlklRM9RfrvAjDqV8Ao/jaEL2ZunBHf+Cgw+iEDUGAsaYG+gMHET8xv1el3q2X9Iq5lju67dtxbuFCJNsdT+1oxsNlG/Fk/jxE8eLe38akoTBGJ4hqGzCC4HWCqjmEMrIsFG1Cr0qg6WujkaBxXHHEAnRfESFyAhGxtf5pTwAAjlUYe9uOBM60gdM8BhoyVoYJIbzywVlehBgxoy+GevH9ki2BFVuozNzOm2W8UvVJ4DjTyAocp1xYmKrY/uXIJ1iT90dR12tMutD7ToawaA7ofSVWD69voWlsdyInEBFb65/2BADgWIWxt+1IYIV6oOGOOS/Clxt36q1zPY4O9IbYEQ5zO/My3qqFi7rH6v0fjHjqU/2GV0xLhF08zwLIaG/CiPpfRO5h3LemY/0xuaTIMLhvULIUkMdS4qoLkZMjMnCSaXWMy1872hPAmrkKo5t3y6eKk4S44zYHQwR/7XrrinmEw20f7BJkXZaxF4FJcDMFImI/Gt327ah/6SVR1/rDid2m03pol9R0QtT5IoMANppDfIaHQnD687Qgwo3ICURYmWmJLgDH/6t1P6Y9ASzMVRgBl++WTxUnCXHHYw6GOzExfl8hY4+RyaCcebXbNsqZVztMCykLCzFk55cYsHEjsp57DtmvvwZG5bncvtDa6qIjnvejsQR1Iim4TlGjA0wfGxHxlfld0ExodtjsziVKXHUqcgIRwDQsduObgNKu/oUyy3Schs1suKrC2JuKk4S449VmcXaiBw6UtCopYLq5N33wods2zR986HQli7mMveqamUgoKEDWE4/73A+5Wo1+69a6TcYVG9TxADoY8e+bIVopum1f1hSlwNaJl6Ktv9gNAK0WRBAbkZMjYpY7Gxg+kyqrilQ0MtOm+iRVViVS6s3USlT//j0PJKqe3FZW5nE1C9fUhLayMiQUFLhtpywsBF5cB+1TT5uSWd1hGMiSk5GxdCmi1GpRybhigzoGQIwg/lN6JwUiAIB/XHwtvsochw2GOchnj+Mqdh/myXd4fiEtiHAQeYEIYPqDREupRPO1+iQh3lKMH2fajbbZ8+Z8jq8db/oPCasn6/eViW7nKRABenYebnjrbdSuWuW6oSCAa2hAlFotOhlXbFDXJo9BvNFDsqWVloT+nhtFgPpY09SaeZ8iAJgHEYEILYhwEFlTM4SQkMbIZEiZO9eHFzJIueXmsKyezMhkkKc5L0FvT8xS3bZ9ZWj+9DMIPG9KkHVTdMyoVCHBaPBq5Uho7jMTuLwVHkBtXBKOpQ2yOV7GD8c5IcVNNRNaEOEKBSKEkJCSdvdfgFjvloWn3HE7WLlM8urJiokT/drOzNtlwc7otm/HianTcGbePJz7619x9vbbwRsMphVI9sEIwwAMA+OUGV71E0CA9rX1llRTxXa/S4ypRvGro66FYJehKoDF411zwcDxPeLNZ6IFEU5RIEIICSmMTIbYC8UXzUq+/XaoH3jAu+rJ7lpZjSq07SuzSTyNz58ANinJ7evZpCTE53tXw8WyLNjV6IWHpbqu9qQxT3Gxdit0zMmuQ65zvwLIaVe8fkUgOB8REVw+4xtjShr6v7gON/91HpLjbcu6a1SxGHjZHzG/cxFqBNuyBjVCKuZ3LkQJH561faQWmTkihJCQFj1wIDoOH/bYLiYvD5olD5oe+KF6sqedbhmZDJmPF6Pq3oUuz5H5eLGo1TvWJezl6elQL12CqvsWOxY+87BUV8z+N4iORvbrr4E73wB5erol2VXgOBhT0yE7Xyc6wIjixOeTBI7z3n8/DLj0JzjsJixAcLk5JCAg6cI2KPt1IC61E/rz0ahvV2GR7B7UDhqBhzUj8MRnlWho66kdkhIfhYeuGo6nvjiOaj4f2w3jkc8eRwaaUIsklPHDIYDFD1srMT1XQ8n+digQIYSEHOWcOdBt3eqxXfqCBT0Pelk92VVFV/NOt+heLmte7VLz1NPgrFa7yNRqaB5aLmp/G1cBT8odt0P32ee2x9Vqt/vmiFmmy9fWor38ENIX/D+H5zTTx6B+s3kXX883SE3NPmg13k09Sc8xCBMAXHzaeWvG0sL599v033jEp3eClQMJ6k4koA6xnV0419KJ/7fpkEP7xrYu3LO5wvLYOoHVGu3P5RwFIoSQkJNwyUQwCgUEvd5lG0ahQMIlVjdEc/VkXTWcD8gzpuedJAt6HFVgGGifXonEqVNNRc26V7tYj2iI3d/GXcDT8NrryHphDeTJKaLPK3aZbv1LLyFm6BBLQKPbvt1q6XDf+4TOAFB2uAo33H2/DAAB2kNKJPYz7aWlr4vGpNYjaIuOxrG0QeAd8kPEo/25HFEgQggJOYxMhqxVK91OgWStWml7gzZXT35vLsw3E6szmv5xkSzo7a665j56u6+NmICndtVqDNn5pejibN7UXjEHUy07d7rYz8f1KIFZU9JQ0dcLHNd99i3EYmDUy1FfmYCmk/EwtsswHfsxHftRF6vChovnYE/WKJ/OTPtzOaJkVUJISFIWFqLfi+vAZmTYHGczMtDvxXXOpyp8rJ7s7a66vhIb8LSViatXAojb/8bMdO790D71tIv9fDzftiOpwHv90UQY221vk6kdzXi4bCMmnTvi1blofy7XaESEEBKyfJoC8aF6sj+Wz4ohNpCpWnQfMp94XFS+iWWHXzejR9ZqnnzScyVXN+RG19NlQSPBrsY9bIMzFqbluH858gn2Zo5wmKYxv8LJeBztz+UCBSKEkJDmyxSIt9WTzaMKRq3W+U2NYSDvLq3eG2IDGb652TR18sIayETkiygLC2H4v3tQ/9LfPJ676+RJb7ttoz7VtykJSXT/rAZ8+6LrJvBlesb8KuevZAFktDdhRP0vOJI+BOhuqVHF4pGZuXjis0pUN/fkgmhUsVgxK5f253JBskDk119/xRNPPIFdu3ahpqYGWVlZuOWWW/DQQw8hOjra8wkIISRALKMKCxd5vXzWG8bGBvGNBQFVi+8H+J7yWNZLie2l3X03mt77T69GO+w6APsbsQAGrcoL/HT+XjL/jHgeQ3DCzycXF7qkGFpsWpuDjRkjaX8ub0iWI3L8+HHwPI9XXnkFx44dwwsvvIANGzZg+fLlUl2SEEJ8piwsRL91a01l0a2I2elWDIHjULtqtXcv4m1rdJqXEuu2b3covAYA6oeWW6qm9qKncDWO0JQ0BLwshD5I8jyu/PZet01+S5Lu8g0xiQCAlPhomx3JzftzXTumHwoGp1IQ4gEjCJJOrtl49tlnsX79evzyyy+i2ut0OqhUKjQ3N0OppB0fCSHSsy80JnZZridt+8pwZt48P/TQVL2VjYmxGf0wj5YAcKhR4i81GeNRmXu738/rNZ7HgG/WiRoJ2Z0LXFHp/SWaouKh7Gpz+mldAKCLVuDPVz0GnmHxwo2jcV2e42aAHC9E7MiIN/fvgOaINDc3IyXFdcawwWCAwdBTtU+n0wWiW4QQYuFTTooIvV1xY41vanLYz8Q8WtJv3VoM2fmlJZgynDiB8xs2+OW6HdGJfjlPb405/BJSRAQhAoBvvAxEeAD1cUl4deQsPLT/LadjQwwEKDv1uKT6GPZkjYJGFedwnpKj1Sjeapsrkkm5Ik4FbPnuiRMn8NJLL+Evf/mLyzYrV66ESqWyfGVnZweqe4QQIqnerrjxqHtwW/v0SgBA/MR8qK6ZifiCAl9PCPvFuq0Jjp/6A47nkNz0s6imDAA+ikV9orjN+sxBR8nAidiXOQKdcjkYF8XxGAj4a8U7yEqMdliSW3K0GvPfLrcJQgCgprkD898uR8nRalH9jxReByJLly4FwzBuv44fP27zmqqqKhQVFeGGG27AXXfd5fLcy5YtQ3Nzs+Xr7Nmz3n9HhBASgjxubOcPVoXXfL+udQBi+5oOWfCLcSmbT7oIDpxLbhHwxnTW6a649oGWeZ3M3OPb8NYXjyPGaITrxFUGcZ2deOqCdpvpFo4XULy10t0e0CjeWgmOj6SKLO55HYjcf//9+PHHH91+DRo0yNL+3LlzmDJlCiZNmoRXX33V7bljYmKgVCptvgghpC8wr8wxPZA2T8B6Gsi761oHII5tW5OGedcRXsw4hHdyTn/hVfsLzwkoG8bi+d+zaLCbWZLFcUjM1sPZ6I+qS1y9lBEndts8LjvV4DASYk1Az54zxMTrHJH09HSkixxirKqqwpQpUzBu3Di8/vrrYFkq5EoIiVzKwkJg3VrJkknN7KeB/HVd3k1ROAdSrIMQeKSInJax70bZMBb7hzJYe6QZ4xq7II/lEJfaiZ+3mFdJ2QZeokPFzjabh2L3kqE9Z3pIlqxaVVWFyZMnY+DAgXjuuedQZxWha0SWIyaEkL7GXC32/JtvoW61l8t5PXFTeM1ZldrYi0dh79p/4uze3ZgetwfRyi789k2ay9NHGfXoErN8VxAgM+jA+Tm5NaHphFfTMgCgTekJKQSWQWKGASqlaVFEa000+M7erYhSjM+zeSx2Lxnac6aHZEMUO3bswIkTJ7Bz5070798fmZmZli9CCIlkjEyG1Lm3glWp/HhSz4XXzCuCVNfMRPzEfOw42YRbmgdh+UXzYBgWA32d+yBjQukTpiEGd6MdggDwPK7Y6/+aUYNPl3jVXgCwbYzpvxlBgMZoRF5Hz8pMfW1ML3ojgI0B4q+5zeZofk4KMlWxbjJLaM8Ze5IFIrfddhsEQXD6RQghkY6RyZD5xOO+v16hsHnsbeE166RKHiyKu+ais8396EAsOsAau2/krnYQFlFkzCc8h5Sm/3r1EgbAsGoGTHdfl5xvhO13KPZ+5GyXYiBz4a1gomyDNxnLYMWsXMv17fsD0J4z9ihpgxBCgiRx6lSwSUlevy7ptnkYtr8MAzZuRNZzz2HAxo0YsvNLr6q/2idVbuPz8WOL55IJk7+/vycYsSYIgNEgTRACQNbV6vW0DAAktwJqjsOa2npM07fbPik2Foiy64uCQb8H50J5h/NRn6KRmVh/Sx40KtvpF40q1qYCKzGhTe8IISRI9AcOgm9q8uo1yfPmQbN0KQD0qvCafbLkpHNH0F/kXjiTv78fHYjF/oJHYJQrIDfqMaH0CcRCugTMgWd3+vS6u8+0YpSiCfZjPQIPNJ2Mh7tt8cwVVOcWPYw/t+zBolGxiOo3EIqr5zqMhNgrGpmJ6bm054wYFIgQQgImkkteO+NLtVXFuDzPjUSwTpZkBR53H/7Yq9fHogOXlz7kl754JAgY8NtXvrwQip+iwV4Ih/F/fV00uA73U1EMgE8GXYZONhrJf7gLSdMu9Orq5j1niHsUiBBCAoJKXjvypdqq9umVSJw6tdf735iTKqubOzCi/hekdzT36nyS4jmwomqj2mPAtcvRVheNBHWnzTNGD0GI2bmEdCQronDPlUN9uD4Rg3JECCGSo5LXzlmqnnrBvnKqr8xJlQyAS2qO9fp8UoruqO/V641OknDlsZyo1zbGJGLl70dF9Mid1CgQIYRIikpeu2apeuplpVV/baBXNDIT628ajWm/HfLL+aQy7Of3e/X69vNRDscU6Z2Qx3FwtXKGB1CvSML/u/cPETtiFygUiBBCJEUlr91TFhYi5Y7bvXqNPzfQu7zjHJSGVr+dz5YfgktBQFrTcc/t3J3CSZzHsIA6zzwdZdtPc/rq5gl/wPRR/Xp1beIZBSKEEElRyWv3BI5D0wcfin8ByyJu7Bi/Xd9foyvORBl6H1wqdGd8WrZrLSbB+TSMMrsD/S5tBBttm3/CANBFKdDYbozYADmQKBAhhEiKSl6711a237slvDyP9kMVfru+P0dX7OXvWymuEqur44KA8YfW9LIXApIGt7ltwXeysB8VSezS4+GyjdDv3GFznOMFlJ48j08qqlB68nxETin6G62aIYRIyrw6o6a5w+nnWgamQk+RWvJav2+f168x1tVB4DibfWMU48f5tJKGE1k7xBcxMEDWpQcXpTAFFva5MOYgxP657uMJul8hh7GXvWCgPx+NRE2nwzMCD2jLVZZ21liY8kQ0b66HcOcNYGQyWvklERoRIYRIikpe+1/n6dM4MXUazsybh3N//SvOzJuHE1OnQbd9u1fnETgO1Y8VS9RLkyv2PAhZl97l81EG58uGE3S/Iv/Qc37pQ90JpdPj+rpoGNtlcFXQjAXA1tdCf+AgrfySECOE8OYvOp0OKpUKzc3NUCqd/yIRQsIDfZp0rrW0FGdvv0P8CxjG+XRG94iCN/vNeH3tXjAgBvsnLkNntAoMb8SA09uR89tOsOBhhBzHRtyOjtg0xHbUY8Sx1/0wEtKjTRYDfu3DyD//EXD8U8vx5tNxOFea7PH1mmefxdVH41wmXZtH9b5bciUF1N28uX/T1AwhJCCo5LVz8fn5YOPjwbe5z2OwcJdTwTBeFTxr2rzZi572TgwMuGzfY06fk8OI0cf+Idm14zkDBigHAEPutglExNYSOWGMEb3yiyqpeo+mZgghkjMn+H16+BwA4JqLs1AwODXigxCgexfep570z8kEQXTBM4Hj0Prd9/65bhgw1tUBAycByiyYp2I81RIBw0Cu0eDcwGGirhGpK796i0ZECCGSoikZz5RFRWi/8wga/vWaX84nZkmu/sBBCGJHYfoAeXo6wMqAotXAe3MBMGBYAeq8ZlR9nwyHze+6p7rUy5ehXhUv6hqRuvKrt2hEhBAiGUrwEy9j8WIgLs4v5xKzJLdl165eXYPv/gp1PAA+LQOK8eNMB3JnAze+CShNQbC5log83nZ0Tq5WW/JtzCu/XI3fMTAF15G68qu3aESEECIJjhfw2BbXpd0ZmEq7T8/V0BQNTPVE0N7usR0bHw9er3eZsCpXq3tuui4IHAfdli2+dhUAUKa+CBO1P9qPI4QUHqa+Vc+djxHWOTO5s4HhM4HTe4BWLZQJaiT2nwh9eYXT5dDmlV/z3y4HA9uJHFr51Xs0IkIIkcTfdv2MGh2VdherrbRUVDvFpEmm/7CvyWE1leApUVV/4CC4xkav+2jtwyFXoFQzolfnkFqbPBZP5s+DYup0xydZGZBzOTDqeiDncjBR0YifmA/VNTMRPzHf4T0sGpmJ9bfkQaOynX7RqGKx/pY8mmbsBRoRIYT4XcnRarzw5c+i2lKCn4mxWtw0FdfUiH7r1kL79EoYa2osx+VqNdTLl4lautuya6fP/QSAFnkskgwtKAjxXXu/7j8Gpy6a4LcpE1r5JQ0KRAghfmXebVcsSvAzkWeJ+0TdUfkjEqdOReLUqT5VVhU4Ds1btvrcTwHAS6Ovw70V74fslIyZuq3B71MmMpahJbp+RoEIIcSvPO22ay1cE/z8VV7dWvwll6DhlVc9X7utDfoDBxE/MR/xE/O9vo7+wEHwvZiWaZXHojVagQSjwedzBMqEuv+i/7kjAE2bhDQKRAghfuXNVEs4Jvjptm93nBbRaERPi7gSn58PRqGAoHddDt2sNzvmdmm1Pr8WAFqjYvFU6b96dY5AYQCvCryR4KBkVUKIX4mdarlv2oVhl+Cn274dVQsX2QQhAGDUalG1cJHXe71YY2QypN55p6i2vdkxt/X73hUx07Q39er1gSa2wBsJHgpECCF+5anmAgBolDG458ohAeuTPwgcB+3TK50vm+0+pn16JQROXNlwZ9Lu/gvYpCTXDborfXpanuuKwHFoKSnx7bXoWbYaXmNYvR8FItKiQIQQ4leedttlADw2e0TYTcnoDxx0GAmx4UV5dVcYmQyZj7vYDdeL5bmu6A8cBAy+53aYf37hhmugJeKhjAIRQojf9cWaC2LzMnzJ3+A7O3H+jY2ofuJJdJ2rRuaa5yHXaGzaWFf69JXPuSVRUYjOucDn6wbbqe1fBbsLxA1KViWESKKv1VwQm5fhbf6G9tln0fD6GwBvVTCdZZEybx4SJk/268ocX3JLEoqK0P/55/DLnOt6de1gUpTvQ/UzzyLzwQeC3RXiBAUihBDJ9KWaC4rx4yDXaGDUantVXt2a9tlnnW90x/NoeP11gGWgfsB/N0/F+HGQqdXgRORMKOfMQebjxWCjowEAMcOGofNncUXqQlHj669DvWih5fshoYOmZgghRARGJoN6+bLuB76XVzfjOztNIyFuNLz+BvjOTm+76hIjk0Hz0HKP7bLWvoB+q1ba3LRV14XviAgDgBEENPz738HuCnGCAhFCCBFJWViIfuvWQq5W2xz3JX+jcdM7ttMxzvC8qZ0fKQsL0e/FdU5X5zBKJfq9uA6qoiKH5+InjPdrP4KhnZbxhiRJp2Zmz56NiooK1NbWIjk5GdOmTcPq1auRlZUl5WUJIUQyysJCn8urW+s8e9av7bxh/h7ayvZDv28fAEAxMd9UVM3F99F+qMLv/Qg0VqEIdheIE5IGIlOmTMHy5cuRmZmJqqoq/PWvf8X111+PPXv2SHlZQgiRFCOT+VRe3Vp0drZf23mLkcmQUHAJEgouEdW+N9VcQ0XCtdcGuwvECUYQnGVdSWPLli2YM2cODAYDoqKiPLbX6XRQqVRobm6GUqkMQA8JISQw+M5O/DRmrPvpGZbFsIpDIZFg2bavDGfmzQt2N3wiANDLo9H14Q4UXJgR7O5EBG/u3wHLEWloaMC///1vTJo0yWUQYjAYoNPpbL4IIaQvYqOjkXL7bW7bpNx+W0gEIUDPqqFwtSbvJtTqu4LdDeKE5IHIkiVLEB8fj9TUVJw5cwaffPKJy7YrV66ESqWyfGVLNCRJCCGhQP3AA0i58w6AtftTzLJIufMOvy7d7S1GJoNy5tXB7oZP3ho+A3uyRoneB4kEltdTM0uXLsXq1avdtvnxxx8xfPhwAEB9fT0aGhpw+vRpFBcXQ6VS4dNPPwVjv/wNphERg1X5YZ1Oh+zsbJqaIYT0aXxnJxo3vYPOs2cRnZ2N5D/fFDIjIWa67dtRde9CCAivMu9N0fG45aoVyEhS4LslV4ZtQb1w483UjNeBSF1dHc6fP++2zaBBgxDt5P9Ev/32G7Kzs7Fnzx4UFBR4vBbliBBCSPAJHIdjEyeBbdWFVRAiAHh6wq34vt/osN1aIFx5c//2etVMeno60n3cgprvTsoy9GLTJUIIIYH19bsl0LSGV86eAOD9wVfgZO5ErJ+VS0FICJNs+e6+ffuwf/9+XHbZZUhOTsbJkyfxyCOPYPDgwaJGQwghhAQfxwso+2gHZge7I14QADRecz2mz1+Eh8J4f6NIIVkgolAo8OGHH2LFihVoa2tDZmYmioqK8PDDDyMmJkaqyxJCCPGjslMNaDUYg90Nr/Rf+wJynVSHJaFJskBk1KhR2LVrl1SnJ4QQEgC1LR04nD4Ef/7vzmB3RZSsZ56BkoKQsEJ7zRBCCHEpIzEWx1JzwINBwKpf9oL9PkAk9FEgQgghxKX8nBRcZjgHFkJIr5gRAMg1aijGjwt2V4iXKBAhhBDikoxlcMdFicHuhlvmkZr0Zcu93nyQBB8FIoQQQtwaN/bCYHfBrXZ5DJ7Mn4cfh9BoSDiSdPddQggh4U8xfhwQFQV0idurRerqqxyAfRnDoY9WYOeAcTicPhQ8w+KPLR0SXpVIhQIRQgghbrXs2CE6CAGA0/HpuKCtTrL+fDZwItaPvcHhOO0lE55oaoYQQohLAsfh3PKHRLfvYKOw44KJ0vUHwL8uvtbmGAMgUxWL/JwUya5LpEMjIoQQQlxqKyuDoNeLaisAeH7cnxDNdUrWn+rYZHTKHPcyWzErlyqohikaESGEEOKSfl+Z6LZVilR81280EjvFBS6++CZ7jM1jjTKGNrQLczQiQgghxC9Sb/oT1k0fg377m4GjWyW5Bs/0fH6+b9qFuOfKITQSEuZoRIQQQohLioki8z0YBmMW/i+uHdMPF108RLL+HE4fgkxVLDbckoeF04ZSENIH0IgIIYQQl+LzJ4BNSgLf1OS2Xcptt4GNNuVuKMaPg1yjgbGmxm/9EABw8QlYuuTPyB+STgFIH0IjIoQQQlxiZDJkPl7stk3C1CuhXvKgzWvUy5cBjP+CBQZAyvRpKLgwg4KQPoYCEUIIIW4pCwvR78V1kNlvKBcfj8w1zyP75Zedv2bdWsg1Gr/1g29p8du5SOigqRlCCCEeKQsLkTh1KvQHDsJYVwd5ejoU48e53dvF/JrTt85Fe3l5r/vAKhS9PgcJPRSIEEIIEYWRyRA/Md/r10QNyPZLIKKcM6fX5yChh6ZmCCGESEbgOLTuKe31eRiFAgmXSFexlQQPBSKEEEIkoz9wEHxtba/Pk7VqpdtpIBK+KBAhhBAiGWOdt5vfCTaP2ORE9HtxHZSFhf7rFAkplCNCCCFEMvL0dC9am4KQtJE6RCdykMdyUNy/AcyQK6TpHAkJFIgQQgiRjKW4mVYLCILbtnIFB/VYHZTZHQAYQJkFDLosMB0lQUNTM4QQQiRjKW4GuChwJiD5wlYMmFKPIdfU9gQhAFC0CmApL6Svo0CEEEKIpCzFzewKosk1GvR7cC40kxMQr+6EZT87ZRZw45tA7uzAd5YEHE3NEEIIkZx1QbTO2lqcMMbg3MBhqFfFI3/gg5CdLQXfUoMfWxQ4oRiFjJh4jDPyOHi6EbUtHchIjEV+TgqVd++DKBAhhBASEIxMhm/js1F8tAXVzR3AviMAgExVLGaPzsSWHzpNx2E6zjIAb5VWkqmKxYpZuSgamRmE3hOpMILgIXsoiHQ6HVQqFZqbm6FUKoPdHUIIIb1QcrQa898uh683HfNYyPpb8igYCXHe3L8pR4QQQojkOF5A8dZKn4MQoKfCSPHWSnB8yH6GJl6iQIQQQojkyk41dE+79I4AoLq5A2WnGnrfKRISKEeEEEKIzzheQNmpBo8JpbUtvQ9CpDwfCR4KRAghhPik5Gg1irdW2ox0uEoozUiM9eu1/X0+EjwBmZoxGAwYM2YMGIZBRUVFIC5JCCFEQubEU/vplprmDsx/uxwlR6ttjufnpCBTFYveLr5lYAp28nNSenkmEioCEog8+OCDyMrKCsSlCCGESMxd4qmrhFIZy2DFrFwA6HUwsmJWLtUT6UMkD0S++OILbN++Hc8995zUlyKEEBIAnhJPXSWUFo3MxPpb8qBR2U6rpMRHibpuSnwULd3tgyTNEdFqtbjrrrvw8ccfQ6FQSHkpQgghASI2UfT7E3UOSaxFIzMxPVfTk+AaHwXjr9/jP18dQC2SUMYPB+/iM/Ij14ygIKQPkiwQEQQBt912G+6++26MHz8ev/76q8fXGAwGGAwGy2OdTidV9wghhPhIbKLo3746aflv6yRWGcugYHAqULkF2LoE0J3D5dGmdueEFBR3zcU2Pt/hfBolJaj2RV5PzSxduhQMw7j9On78OF566SW0tLRg2bJlos+9cuVKqFQqy1d2dra33SOEECIxXxJPHZJYK7cA780FdOds2mnQgPVRazGDLbMcowTVvs3rEu91dXU4f/682zaDBg3CjTfeiK1bt4Kx2vaZ4zjIZDLcfPPN2Lhxo8PrnI2IZGdnU4l3QggJMeZVMwBEV0tlAGhUsfjugSsge3GUQxBixgtADVJxmWEdhO7Py5QbEl68KfEu2V4zZ86csZlaOXfuHGbMmIH3338fEydORP/+/T2eg/aaIYSQ0OWsjogYn80CRuz4s8d2f+p8GKcT82ijuzDkzf1bshyRAQMG2DxOSEgAAAwePFhUEEIIISS02See/qxtxd++OuHxde2NVaLO//iVaRh85ZW0VLePo71mCCGE+MyceHrtmH64dEiaqNfEJfcT1e7CwUMoCIkAASvxfsEFF0CiWSBCCCEhwJzEWtPc4TRvxJwjMnziFcC+LEBXDecZJgygzAKyJwKnvgVatUCCGhg4CWBl0n4TJOBoRIQQQohfuKuean68YlYuZHI5ULTa7hm7liP/ALw4Gth4DfDBnaZ/1440rbYhfQoFIoQQQvzGVfVUjSrWduVL7mzgxjcBpV0SqjILmPR/wJ6XHFfV6KpNS34pGOlTJFs14w+0aoYQQsITxws91VOtKqs64Dng9J6e6ZfsiaaREBdLey3TNouO0DRNCAuJVTOEEEIil6V6qiesDMi5vOfx16vdBCEAIAC6KlPwYv06ErYoECGEEBIaKrcAXz8trm2rtue/7UdVKKk1rFAgQgghJPh4DihZIr59gtr0b+UW0+usR1GUWaZk2NzZ/u0jkQQlqxJCCAm+03s8TMlYUfYzjXq42K+GklrDCwUihBBCgs96qsWTolWmf0uWwHkdku5jJUtNIy0kpFEgQgghJPjMUy0e/Jz7f6YpF48jKFZJrSSkUSBCCCEk+AZOMuV2OBQ4M+EF4JyQghnlE7Huy5/BH/9M3Hm9GWkhQUGBCCGEkOBjZUDRaggAeLun+O6ZluKuueDBYt2Xx9G879/izitypIUEDwUihBBCQkPubPz3ipdRI6TYHK5BKuZ3LcI2Ph8AkM8eRzJ0ns+nSDONtJCQRst3CSGEhIzjyZNxn+FF5LPHkYEm1CIJZfxw8FafmzPQJO5kF99I9UTCAAUihBBCQkZGYix4sNjL57psU4skcScbdrV/OkUkRVMzhBBCQkZ+TgoyVbEuUlZNDvAXghMYuN0pjZGZ9q0hIY8CEUIIISFDxjJYMcv1aAgAjGf/CxkjgHEXrQgccHaffztHJEGBCCGEkJBSNDIT62/Jg0YZ6/R50TkitHQ3LFAgQgghJOQUjczE90uvxH3Thjo8JzpHhJbuhgUKRAghhIQkGctg4bQLseGWPGSqekZHyvjh0CIVgstMEqZnPxoS8mjVDCGEkJBWNDIT03M1KDvVgNqWDmQkxiKt4wUw/5kHUyVW66zV7uCkaBUt3Q0TFIgQQggJeTKWQcHgVKsj1wLMm6aN76z3nFFmmYKQ3NkB7yPxDQUihBBCwlPubGD4TNPGdq1aU07IwEk0EhJmKBAhhBASvlgZkHN5sHtBeoGSVQkhhBASNBSIEEIIISRoKBAhhBBCSNBQIEIIIYSQoKFAhBBCCCFBQ6tmCCGEkF7geMGm2Fp+TgpkrLsd+Yg1CkQIIYQQH5UcrUbx1kpUN3dYjmWqYrFiVi6KRmYGsWfhg6ZmCCGEEB+UHK3G/LfLbYIQAKhp7sD8t8tRcrQ6SD0LL5IGIhdccAEYhrH5WrVqlZSXJIQQQiTH8QKKt1ba7HJjZj5WvLUSHO+sBbEm+dTM448/jrvuusvyODExUepLEkIIIZIqO9XgMBJiTQBQ3dyBslMNdnvkEHuSByKJiYnQaDRSX4YQQggJmNoW10GIL+0imeQ5IqtWrUJqairGjh2LZ599Fkaj0WVbg8EAnU5n80UIIYSEmozEWL+2i2SSjojce++9yMvLQ0pKCvbs2YNly5ahuroaa9ascdp+5cqVKC4ulrJLhBBCSK/l56QgUxWLmuYOp3kiDACNyrSUl7jHCILgVSbN0qVLsXr1ardtfvzxRwwfPtzh+GuvvYa//OUvaG1tRUxMjMPzBoMBBoPB8lin0yE7OxvNzc1QKpXedJMQQgiRlHnVDACbYMRcQWT9LXkRu4RXp9NBpVKJun97HYjU1dXh/PnzbtsMGjQI0dHRDsePHTuGkSNH4vjx4xg2bJjHa3nzjRBCCCGBRnVEnPPm/u311Ex6ejrS09N96lhFRQVYlkVGRoZPryeEEEJCSdHITEzP1VBl1V6QLEektLQU+/btw5QpU5CYmIjS0lLcd999uOWWW5CcnCzVZQkhhJCAkrEMLdHtBckCkZiYGGzevBmPPfYYDAYDcnJycN9992Hx4sVSXZIQQgghYUayQCQvLw979+6V6vSEEEII6QNorxlCCCGEBA0FIoQQQggJGgpECCGEEBI0FIgQQgghJGgoECGEEEJI0FAgQgghhJCgoUCEEEIIIUEj6e67vWXeBken0wW5J4QQQggRy3zfFrOdXUgHIi0tLQCA7OzsIPeEEEIIId5qaWmBSqVy28br3XcDied5nDt3DomJiWAY2kAoUHQ6HbKzs3H27Fna9TgI6P0PPvoZBBe9/8Hlj/dfEAS0tLQgKysLLOs+CySkR0RYlkX//v2D3Y2IpVQq6Y9AENH7H3z0Mwguev+Dq7fvv6eREDNKViWEEEJI0FAgQgghhJCgoUCEOIiJicGKFSsQExMT7K5EJHr/g49+BsFF739wBfr9D+lkVUIIIYT0bTQiQgghhJCgoUCEEEIIIUFDgQghhBBCgoYCEUIIIYQEDQUixMbs2bMxYMAAxMbGIjMzE7feeivOnTtn0+bw4cO4/PLLERsbi+zsbDzzzDNB6m3f8uuvv+LOO+9ETk4O4uLiMHjwYKxYsQKdnZ027ej9l85TTz2FSZMmQaFQICkpyWmbM2fOYObMmVAoFMjIyMADDzwAo9EY2I72YS+//DIuuOACxMbGYuLEiSgrKwt2l/qsb775BrNmzUJWVhYYhsHHH39s87wgCHj00UeRmZmJuLg4TJs2DT///LPf+0GBCLExZcoUvPfee/jpp5/wwQcf4OTJk7j++ustz+t0OhQWFmLgwIE4ePAgnn32WTz22GN49dVXg9jrvuH48ePgeR6vvPIKjh07hhdeeAEbNmzA8uXLLW3o/ZdWZ2cnbrjhBsyfP9/p8xzHYebMmejs7MSePXuwceNGvPHGG3j00UcD3NO+6d1338XixYuxYsUKlJeXY/To0ZgxYwZqa2uD3bU+qa2tDaNHj8bLL7/s9PlnnnkGL774IjZs2IB9+/YhPj4eM2bMQEdHh387IhDixieffCIwDCN0dnYKgiAIf//734Xk5GTBYDBY2ixZskQYNmxYsLrYpz3zzDNCTk6O5TG9/4Hx+uuvCyqVyuH4559/LrAsK9TU1FiOrV+/XlAqlTY/E+Kb/Px8YcGCBZbHHMcJWVlZwsqVK4PYq8gAQPjoo48sj3meFzQajfDss89ajjU1NQkxMTHCO++849dr04gIcamhoQH//ve/MWnSJERFRQEASktL8bvf/Q7R0dGWdjNmzMBPP/2ExsbGYHW1z2pubkZKSorlMb3/wVVaWopRo0ZBrVZbjs2YMQM6nQ7Hjh0LYs/CX2dnJw4ePIhp06ZZjrEsi2nTpqG0tDSIPYtMp06dQk1Njc3PQ6VSYeLEiX7/eVAgQhwsWbIE8fHxSE1NxZkzZ/DJJ59YnqupqbH5IwzA8rimpiag/ezrTpw4gZdeegl/+ctfLMfo/Q8uev+lU19fD47jnL6/9N4Gnvk9D8TPgwKRCLB06VIwDOP26/jx45b2DzzwAA4dOoTt27dDJpNh7ty5EKgAr8+8ff8BoKqqCkVFRbjhhhtw1113BannfYMv7z8hJHDkwe4Akd7999+P2267zW2bQYMGWf47LS0NaWlpuPDCC3HRRRchOzsbe/fuRUFBATQaDbRarc1rzY81Go3f+94XePv+nzt3DlOmTMGkSZMcklDp/feet++/OxqNxmEVB73//pGWlgaZTOb095ve28Azv+darRaZmZmW41qtFmPGjPHrtSgQiQDp6elIT0/36bU8zwMADAYDAKCgoAAPPfQQurq6LHkjO3bswLBhw5CcnOyfDvcx3rz/VVVVmDJlCsaNG4fXX38dLGs7aEnvv/d68/tvr6CgAE899RRqa2uRkZEBwPT+K5VK5Obm+uUakSo6Ohrjxo3Dzp07MWfOHACmvz87d+7EPffcE9zORaCcnBxoNBrs3LnTEnjodDrs27fP5aoyn/k19ZWEtb179wovvfSScOjQIeHXX38Vdu7cKUyaNEkYPHiw0NHRIQiCKWtarVYLt956q3D06FFh8+bNgkKhEF555ZUg9z78/fbbb8KQIUOEqVOnCr/99ptQXV1t+TKj919ap0+fFg4dOiQUFxcLCQkJwqFDh4RDhw4JLS0tgiAIgtFoFEaOHCkUFhYKFRUVQklJiZCeni4sW7YsyD3vGzZv3izExMQIb7zxhlBZWSn87//+r5CUlGSzSon4T0tLi+V3HICwZs0a4dChQ8Lp06cFQRCEVatWCUlJScInn3wiHD58WLj22muFnJwcob293a/9oECEWBw+fFiYMmWKkJKSIsTExAgXXHCBcPfddwu//fabTbsffvhBuOyyy4SYmBihX79+wqpVq4LU477l9ddfFwA4/bJG77905s2b5/T9/+qrryxtfv31V+Gqq64S4uLihLS0NOH+++8Xurq6gtfpPuall14SBgwYIERHRwv5+fnC3r17g92lPuurr75y+vs+b948QRBMS3gfeeQRQa1WCzExMcLUqVOFn376ye/9YASBshAJIYQQEhy0aoYQQgghQUOBCCGEEEKChgIRQgghhAQNBSKEEEIICRoKRAghhBASNBSIEEIIISRoKBAhhBBCSNBQIEIIIYSQoKFAhBBCCCFBQ4EIIYQQQoKGAhFCCCGEBA0FIoQQQggJmv8PkKs7DjHqeOgAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for label, _ in counter.items():\n",
    "    row_ix = where(y == label)[0]\n",
    "    plt.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(593170, 6)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Concatenate X and y numpy arrays\n",
    "Xy = np.concatenate((X, y.reshape(-1, 1)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/csuser/DATA/ARTEMIS/mimic\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 593170 entries, 0 to 593169\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   temperature  593170 non-null  float64\n",
      " 1   heartrate    593170 non-null  float64\n",
      " 2   resprate     593170 non-null  float64\n",
      " 3   o2sat        593170 non-null  float64\n",
      " 4   sbp          593170 non-null  float64\n",
      " 5   dbp          593170 non-null  float64\n",
      " 6   acuity       593170 non-null  float64\n",
      "dtypes: float64(7)\n",
      "memory usage: 31.7 MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a pandas DataFrame from the concatenated array\n",
    "#new_keys.remove('esi')\n",
    "#new_keys.append('esi')\n",
    "new_keys = ['temperature', 'heartrate', 'resprate',\t'o2sat', 'sbp',\t'dbp', 'acuity']\n",
    "df = pd.DataFrame(data=Xy, columns=new_keys)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/media/csuser/DATA/ARTEMIS/mimic/triage_smote7.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(593170, 7)\n",
      "[[-0.30080092  0.10016959 -1.3999738  -0.09294572 -2.8357136  -2.2492008 ]\n",
      " [ 0.28720993 -0.90134674 -0.6204313  -0.09294572 -1.2882322  -0.9277333 ]\n",
      " [ 1.267228    1.1605986   0.15911114 -0.4976085  -1.2882322  -1.3241736 ]\n",
      " ...\n",
      " [-0.37229583 -0.6545861  -1.3999738   0.3482006  -0.1426608  -0.08069345]\n",
      " [-0.34623998 -0.5435881  -1.3999738   0.09467843 -0.11496077  0.2501634 ]\n",
      " [ 0.1212853  -1.2446153  -0.6204313  -0.97238696 -0.7517578  -0.24050672]]\n",
      "(593170, 6)\n",
      "[array([1, 2, 3, 4, 5])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(593170, 5)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/media/csuser/DATA/ARTEMIS/mimic/triage_smote7.csv')\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "print(df.shape)\n",
    "x = df.drop(['acuity'], axis=1)\n",
    "y = df['acuity']\n",
    "\n",
    "x = x.to_numpy().astype(np.float32)\n",
    "y = y.to_numpy().reshape(-1,1).astype(np.int_)\n",
    "\n",
    "print(np.asarray(x))\n",
    "\n",
    "# x = tf.constant(np.asarray(x), dtype=tf.float64)\n",
    "# y = tf.constant(np.asarray(y).reshape(-1, 1), dtype=tf.float64)\n",
    "\n",
    "print(x.shape)\n",
    "\n",
    "# convert to one hot vector\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(handle_unknown='ignore', sparse=False).fit(y)\n",
    "print(ohe.categories_)\n",
    "\n",
    "y = ohe.transform(y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>heartrate</th>\n",
       "      <th>resprate</th>\n",
       "      <th>o2sat</th>\n",
       "      <th>sbp</th>\n",
       "      <th>dbp</th>\n",
       "      <th>acuity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.300801</td>\n",
       "      <td>0.100170</td>\n",
       "      <td>-1.399974</td>\n",
       "      <td>-0.092946</td>\n",
       "      <td>-2.835714</td>\n",
       "      <td>-2.249201</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.287210</td>\n",
       "      <td>-0.901347</td>\n",
       "      <td>-0.620431</td>\n",
       "      <td>-0.092946</td>\n",
       "      <td>-1.288232</td>\n",
       "      <td>-0.927733</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.267228</td>\n",
       "      <td>1.160599</td>\n",
       "      <td>0.159111</td>\n",
       "      <td>-0.497609</td>\n",
       "      <td>-1.288232</td>\n",
       "      <td>-1.324174</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.777219</td>\n",
       "      <td>0.159082</td>\n",
       "      <td>0.159111</td>\n",
       "      <td>-0.092946</td>\n",
       "      <td>-0.846095</td>\n",
       "      <td>0.724101</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.581215</td>\n",
       "      <td>-0.488958</td>\n",
       "      <td>-0.620431</td>\n",
       "      <td>0.311717</td>\n",
       "      <td>-1.730370</td>\n",
       "      <td>-1.786687</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   temperature  heartrate  resprate     o2sat       sbp       dbp  acuity\n",
       "0    -0.300801   0.100170 -1.399974 -0.092946 -2.835714 -2.249201     2.0\n",
       "1     0.287210  -0.901347 -0.620431 -0.092946 -1.288232 -0.927733     3.0\n",
       "2     1.267228   1.160599  0.159111 -0.497609 -1.288232 -1.324174     3.0\n",
       "3     0.777219   0.159082  0.159111 -0.092946 -0.846095  0.724101     3.0\n",
       "4     0.581215  -0.488958 -0.620431  0.311717 -1.730370 -1.786687     2.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a basic model\n",
    "# def make_model(input_shape, num_classes):\n",
    "#     inputs = keras.Input(shape=input_shape)\n",
    "#     dense1 = layers.Dense(units=128, activation='LeakyReLU', use_bias=True,)(inputs)\n",
    "#     dense2 = layers.Dense(units=64, activation='LeakyReLU', use_bias=True,)(dense1)\n",
    "#     dense3 = layers.Dense(units=32, activation='LeakyReLU', use_bias=True,)(dense2)\n",
    "#     dense4 = layers.Dense(units=128, activation='LeakyReLU', use_bias=True,)(dense3)\n",
    "#     dense5 = layers.Dense(units=64, activation='LeakyReLU', use_bias=True,)(dense4)\n",
    "#     dense6 = layers.Dense(units=32, activation='LeakyReLU', use_bias=True,)(dense5)\n",
    "#     dense7 = layers.Dense(units=32, activation='LeakyReLU', use_bias=True,)(dense6)\n",
    "#     output = layers.Dense(units=num_classes, activation='softmax')(dense7)\n",
    "#     return keras.Model(inputs, output)\n",
    "def make_model(input_shape, num_classes):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    dense1 = layers.Dense(units=50, activation='ReLU', use_bias=True,)(inputs)\n",
    "    dense2 = layers.Dense(units=50, activation='ReLU', use_bias=True,)(dense1)\n",
    "    dense3 = layers.Dense(units=50, activation='ReLU', use_bias=True,)(dense2)\n",
    "    dense4 = layers.Dense(units=50, activation='ReLU', use_bias=True,)(dense3)\n",
    "    output = layers.Dense(units=num_classes, activation='softmax')(dense4)\n",
    "    return keras.Model(inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=1)\n",
    "X_train, X_val, y_train, y_val =  train_test_split(X_train, y_train, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 6)]               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 50)                350       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 5)                 255       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,255\n",
      "Trainable params: 8,255\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-10 19:47:26.990562: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_COMPAT_NOT_SUPPORTED_ON_DEVICE: forward compatibility was attempted on non supported HW\n",
      "2024-03-10 19:47:26.990589: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: IDEAS8\n",
      "2024-03-10 19:47:26.990592: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: IDEAS8\n",
      "2024-03-10 19:47:26.990720: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: 535.161.7\n",
      "2024-03-10 19:47:26.990738: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 535.154.5\n",
      "2024-03-10 19:47:26.990741: E tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:312] kernel version 535.154.5 does not match DSO version 535.161.7 -- cannot find working devices in this configuration\n"
     ]
    }
   ],
   "source": [
    "model = make_model(input_shape=(6), num_classes=y[0].shape[0])\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adamax(learning_rate=0.01, weight_decay=1e-6),\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "# make the save callback\n",
    "best_model_path = '/media/csuser/DATA/ARTEMIS/models/mimic_smote'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=best_model_path,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "# load the saved model by:\n",
    "# model.load_weights(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.1278 - accuracy: 0.4578 - val_loss: 0.1210 - val_accuracy: 0.4948\n",
      "Epoch 2/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.1173 - accuracy: 0.5096 - val_loss: 0.1151 - val_accuracy: 0.5189\n",
      "Epoch 3/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.1138 - accuracy: 0.5244 - val_loss: 0.1137 - val_accuracy: 0.5246\n",
      "Epoch 4/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.1119 - accuracy: 0.5312 - val_loss: 0.1116 - val_accuracy: 0.5315\n",
      "Epoch 5/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.1106 - accuracy: 0.5376 - val_loss: 0.1116 - val_accuracy: 0.5347\n",
      "Epoch 6/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.1096 - accuracy: 0.5417 - val_loss: 0.1101 - val_accuracy: 0.5386\n",
      "Epoch 7/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.1089 - accuracy: 0.5444 - val_loss: 0.1085 - val_accuracy: 0.5445\n",
      "Epoch 8/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.1082 - accuracy: 0.5482 - val_loss: 0.1095 - val_accuracy: 0.5415\n",
      "Epoch 9/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.1076 - accuracy: 0.5500 - val_loss: 0.1090 - val_accuracy: 0.5447\n",
      "Epoch 10/5000\n",
      "11864/11864 [==============================] - 7s 565us/step - loss: 0.1072 - accuracy: 0.5524 - val_loss: 0.1082 - val_accuracy: 0.5477\n",
      "Epoch 11/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.1069 - accuracy: 0.5544 - val_loss: 0.1085 - val_accuracy: 0.5451\n",
      "Epoch 12/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.1064 - accuracy: 0.5560 - val_loss: 0.1085 - val_accuracy: 0.5471\n",
      "Epoch 13/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.1063 - accuracy: 0.5575 - val_loss: 0.1068 - val_accuracy: 0.5535\n",
      "Epoch 14/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.1060 - accuracy: 0.5588 - val_loss: 0.1076 - val_accuracy: 0.5502\n",
      "Epoch 15/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.1057 - accuracy: 0.5599 - val_loss: 0.1069 - val_accuracy: 0.5548\n",
      "Epoch 16/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.1055 - accuracy: 0.5608 - val_loss: 0.1070 - val_accuracy: 0.5528\n",
      "Epoch 17/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.1053 - accuracy: 0.5623 - val_loss: 0.1068 - val_accuracy: 0.5553\n",
      "Epoch 18/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.1052 - accuracy: 0.5633 - val_loss: 0.1066 - val_accuracy: 0.5539\n",
      "Epoch 19/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.1049 - accuracy: 0.5640 - val_loss: 0.1069 - val_accuracy: 0.5556\n",
      "Epoch 20/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.1048 - accuracy: 0.5648 - val_loss: 0.1079 - val_accuracy: 0.5507\n",
      "Epoch 21/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.1046 - accuracy: 0.5654 - val_loss: 0.1062 - val_accuracy: 0.5576\n",
      "Epoch 22/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.1044 - accuracy: 0.5667 - val_loss: 0.1066 - val_accuracy: 0.5557\n",
      "Epoch 23/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.1043 - accuracy: 0.5676 - val_loss: 0.1061 - val_accuracy: 0.5564\n",
      "Epoch 24/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.1042 - accuracy: 0.5674 - val_loss: 0.1059 - val_accuracy: 0.5589\n",
      "Epoch 25/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.1041 - accuracy: 0.5688 - val_loss: 0.1060 - val_accuracy: 0.5584\n",
      "Epoch 26/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.1040 - accuracy: 0.5689 - val_loss: 0.1057 - val_accuracy: 0.5594\n",
      "Epoch 27/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.1039 - accuracy: 0.5686 - val_loss: 0.1054 - val_accuracy: 0.5607\n",
      "Epoch 28/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.1038 - accuracy: 0.5702 - val_loss: 0.1056 - val_accuracy: 0.5620\n",
      "Epoch 29/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.1037 - accuracy: 0.5701 - val_loss: 0.1050 - val_accuracy: 0.5608\n",
      "Epoch 30/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.1036 - accuracy: 0.5707 - val_loss: 0.1056 - val_accuracy: 0.5604\n",
      "Epoch 31/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.1035 - accuracy: 0.5713 - val_loss: 0.1051 - val_accuracy: 0.5640\n",
      "Epoch 32/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.1033 - accuracy: 0.5721 - val_loss: 0.1055 - val_accuracy: 0.5607\n",
      "Epoch 33/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.1032 - accuracy: 0.5723 - val_loss: 0.1050 - val_accuracy: 0.5635\n",
      "Epoch 34/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.1032 - accuracy: 0.5718 - val_loss: 0.1044 - val_accuracy: 0.5656\n",
      "Epoch 35/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.1030 - accuracy: 0.5723 - val_loss: 0.1052 - val_accuracy: 0.5606\n",
      "Epoch 36/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.1030 - accuracy: 0.5732 - val_loss: 0.1048 - val_accuracy: 0.5633\n",
      "Epoch 37/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.1030 - accuracy: 0.5730 - val_loss: 0.1041 - val_accuracy: 0.5670\n",
      "Epoch 38/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.1029 - accuracy: 0.5737 - val_loss: 0.1051 - val_accuracy: 0.5654\n",
      "Epoch 39/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.1029 - accuracy: 0.5730 - val_loss: 0.1041 - val_accuracy: 0.5658\n",
      "Epoch 40/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.1029 - accuracy: 0.5736 - val_loss: 0.1051 - val_accuracy: 0.5625\n",
      "Epoch 41/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.1027 - accuracy: 0.5737 - val_loss: 0.1049 - val_accuracy: 0.5644\n",
      "Epoch 42/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.1026 - accuracy: 0.5749 - val_loss: 0.1058 - val_accuracy: 0.5628\n",
      "Epoch 43/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.1026 - accuracy: 0.5748 - val_loss: 0.1045 - val_accuracy: 0.5641\n",
      "Epoch 44/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.1025 - accuracy: 0.5748 - val_loss: 0.1044 - val_accuracy: 0.5662\n",
      "Epoch 45/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.1026 - accuracy: 0.5753 - val_loss: 0.1039 - val_accuracy: 0.5669\n",
      "Epoch 46/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.1025 - accuracy: 0.5751 - val_loss: 0.1056 - val_accuracy: 0.5631\n",
      "Epoch 47/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.1025 - accuracy: 0.5753 - val_loss: 0.1046 - val_accuracy: 0.5650\n",
      "Epoch 48/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.1024 - accuracy: 0.5761 - val_loss: 0.1051 - val_accuracy: 0.5640\n",
      "Epoch 49/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.1023 - accuracy: 0.5760 - val_loss: 0.1043 - val_accuracy: 0.5674\n",
      "Epoch 50/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.1023 - accuracy: 0.5770 - val_loss: 0.1046 - val_accuracy: 0.5651\n",
      "Epoch 51/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.1022 - accuracy: 0.5769 - val_loss: 0.1042 - val_accuracy: 0.5668\n",
      "Epoch 52/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.1021 - accuracy: 0.5770 - val_loss: 0.1046 - val_accuracy: 0.5650\n",
      "Epoch 53/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.1021 - accuracy: 0.5779 - val_loss: 0.1042 - val_accuracy: 0.5677\n",
      "Epoch 54/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.1020 - accuracy: 0.5778 - val_loss: 0.1045 - val_accuracy: 0.5661\n",
      "Epoch 55/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.1020 - accuracy: 0.5778 - val_loss: 0.1046 - val_accuracy: 0.5655\n",
      "Epoch 56/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.1020 - accuracy: 0.5777 - val_loss: 0.1038 - val_accuracy: 0.5686\n",
      "Epoch 57/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.1020 - accuracy: 0.5788 - val_loss: 0.1046 - val_accuracy: 0.5657\n",
      "Epoch 58/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.1019 - accuracy: 0.5784 - val_loss: 0.1043 - val_accuracy: 0.5678\n",
      "Epoch 59/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.1019 - accuracy: 0.5786 - val_loss: 0.1048 - val_accuracy: 0.5679\n",
      "Epoch 60/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.1019 - accuracy: 0.5782 - val_loss: 0.1036 - val_accuracy: 0.5682\n",
      "Epoch 61/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.1018 - accuracy: 0.5789 - val_loss: 0.1045 - val_accuracy: 0.5665\n",
      "Epoch 62/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.1018 - accuracy: 0.5781 - val_loss: 0.1037 - val_accuracy: 0.5685\n",
      "Epoch 63/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.1018 - accuracy: 0.5782 - val_loss: 0.1043 - val_accuracy: 0.5667\n",
      "Epoch 64/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.1018 - accuracy: 0.5792 - val_loss: 0.1041 - val_accuracy: 0.5673\n",
      "Epoch 65/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.1018 - accuracy: 0.5791 - val_loss: 0.1038 - val_accuracy: 0.5707\n",
      "Epoch 66/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.1018 - accuracy: 0.5793 - val_loss: 0.1040 - val_accuracy: 0.5696\n",
      "Epoch 67/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.1017 - accuracy: 0.5805 - val_loss: 0.1037 - val_accuracy: 0.5686\n",
      "Epoch 68/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.1017 - accuracy: 0.5799 - val_loss: 0.1042 - val_accuracy: 0.5671\n",
      "Epoch 69/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.1016 - accuracy: 0.5809 - val_loss: 0.1036 - val_accuracy: 0.5689\n",
      "Epoch 70/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.1016 - accuracy: 0.5811 - val_loss: 0.1044 - val_accuracy: 0.5664\n",
      "Epoch 71/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.1017 - accuracy: 0.5797 - val_loss: 0.1043 - val_accuracy: 0.5698\n",
      "Epoch 72/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.1016 - accuracy: 0.5800 - val_loss: 0.1042 - val_accuracy: 0.5681\n",
      "Epoch 73/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.1015 - accuracy: 0.5806 - val_loss: 0.1036 - val_accuracy: 0.5681\n",
      "Epoch 74/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.1015 - accuracy: 0.5810 - val_loss: 0.1039 - val_accuracy: 0.5680\n",
      "Epoch 75/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.1015 - accuracy: 0.5803 - val_loss: 0.1036 - val_accuracy: 0.5704\n",
      "Epoch 76/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.1015 - accuracy: 0.5809 - val_loss: 0.1040 - val_accuracy: 0.5693\n",
      "Epoch 77/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.1015 - accuracy: 0.5802 - val_loss: 0.1037 - val_accuracy: 0.5706\n",
      "Epoch 78/5000\n",
      "11864/11864 [==============================] - 7s 565us/step - loss: 0.1014 - accuracy: 0.5812 - val_loss: 0.1042 - val_accuracy: 0.5670\n",
      "Epoch 79/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.1014 - accuracy: 0.5814 - val_loss: 0.1038 - val_accuracy: 0.5689\n",
      "Epoch 80/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.1013 - accuracy: 0.5813 - val_loss: 0.1040 - val_accuracy: 0.5703\n",
      "Epoch 81/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.1013 - accuracy: 0.5819 - val_loss: 0.1035 - val_accuracy: 0.5712\n",
      "Epoch 82/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.1014 - accuracy: 0.5806 - val_loss: 0.1036 - val_accuracy: 0.5689\n",
      "Epoch 83/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.1013 - accuracy: 0.5821 - val_loss: 0.1035 - val_accuracy: 0.5694\n",
      "Epoch 84/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.1013 - accuracy: 0.5821 - val_loss: 0.1040 - val_accuracy: 0.5696\n",
      "Epoch 85/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.1013 - accuracy: 0.5819 - val_loss: 0.1038 - val_accuracy: 0.5721\n",
      "Epoch 86/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.1012 - accuracy: 0.5826 - val_loss: 0.1036 - val_accuracy: 0.5723\n",
      "Epoch 87/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.1013 - accuracy: 0.5826 - val_loss: 0.1036 - val_accuracy: 0.5698\n",
      "Epoch 88/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.1012 - accuracy: 0.5824 - val_loss: 0.1030 - val_accuracy: 0.5730\n",
      "Epoch 89/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.1012 - accuracy: 0.5822 - val_loss: 0.1036 - val_accuracy: 0.5706\n",
      "Epoch 90/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.1012 - accuracy: 0.5826 - val_loss: 0.1032 - val_accuracy: 0.5730\n",
      "Epoch 91/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.1012 - accuracy: 0.5826 - val_loss: 0.1039 - val_accuracy: 0.5685\n",
      "Epoch 92/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.1012 - accuracy: 0.5828 - val_loss: 0.1035 - val_accuracy: 0.5725\n",
      "Epoch 93/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.1011 - accuracy: 0.5836 - val_loss: 0.1033 - val_accuracy: 0.5722\n",
      "Epoch 94/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.1011 - accuracy: 0.5828 - val_loss: 0.1040 - val_accuracy: 0.5730\n",
      "Epoch 95/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.1011 - accuracy: 0.5824 - val_loss: 0.1034 - val_accuracy: 0.5710\n",
      "Epoch 96/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.1011 - accuracy: 0.5831 - val_loss: 0.1036 - val_accuracy: 0.5705\n",
      "Epoch 97/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.1011 - accuracy: 0.5839 - val_loss: 0.1042 - val_accuracy: 0.5658\n",
      "Epoch 98/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.1011 - accuracy: 0.5838 - val_loss: 0.1040 - val_accuracy: 0.5703\n",
      "Epoch 99/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.1011 - accuracy: 0.5839 - val_loss: 0.1032 - val_accuracy: 0.5734\n",
      "Epoch 100/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.1011 - accuracy: 0.5831 - val_loss: 0.1035 - val_accuracy: 0.5714\n",
      "Epoch 101/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.1011 - accuracy: 0.5834 - val_loss: 0.1032 - val_accuracy: 0.5723\n",
      "Epoch 102/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.1010 - accuracy: 0.5843 - val_loss: 0.1031 - val_accuracy: 0.5757\n",
      "Epoch 103/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.1010 - accuracy: 0.5841 - val_loss: 0.1027 - val_accuracy: 0.5737\n",
      "Epoch 104/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.1009 - accuracy: 0.5846 - val_loss: 0.1032 - val_accuracy: 0.5718\n",
      "Epoch 105/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.1008 - accuracy: 0.5848 - val_loss: 0.1036 - val_accuracy: 0.5705\n",
      "Epoch 106/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.1010 - accuracy: 0.5836 - val_loss: 0.1033 - val_accuracy: 0.5712\n",
      "Epoch 107/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.1009 - accuracy: 0.5843 - val_loss: 0.1031 - val_accuracy: 0.5725\n",
      "Epoch 108/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.1009 - accuracy: 0.5838 - val_loss: 0.1048 - val_accuracy: 0.5661\n",
      "Epoch 109/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.1010 - accuracy: 0.5844 - val_loss: 0.1034 - val_accuracy: 0.5705\n",
      "Epoch 110/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.1010 - accuracy: 0.5841 - val_loss: 0.1039 - val_accuracy: 0.5721\n",
      "Epoch 111/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.1009 - accuracy: 0.5844 - val_loss: 0.1040 - val_accuracy: 0.5701\n",
      "Epoch 112/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.1008 - accuracy: 0.5847 - val_loss: 0.1032 - val_accuracy: 0.5733\n",
      "Epoch 113/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.1009 - accuracy: 0.5842 - val_loss: 0.1034 - val_accuracy: 0.5727\n",
      "Epoch 114/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.1009 - accuracy: 0.5839 - val_loss: 0.1033 - val_accuracy: 0.5724\n",
      "Epoch 115/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.1009 - accuracy: 0.5844 - val_loss: 0.1031 - val_accuracy: 0.5730\n",
      "Epoch 116/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.1008 - accuracy: 0.5840 - val_loss: 0.1036 - val_accuracy: 0.5723\n",
      "Epoch 117/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.1008 - accuracy: 0.5845 - val_loss: 0.1040 - val_accuracy: 0.5694\n",
      "Epoch 118/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.1008 - accuracy: 0.5850 - val_loss: 0.1032 - val_accuracy: 0.5719\n",
      "Epoch 119/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.1008 - accuracy: 0.5848 - val_loss: 0.1034 - val_accuracy: 0.5712\n",
      "Epoch 120/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.1007 - accuracy: 0.5858 - val_loss: 0.1041 - val_accuracy: 0.5685\n",
      "Epoch 121/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.1007 - accuracy: 0.5852 - val_loss: 0.1031 - val_accuracy: 0.5732\n",
      "Epoch 122/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.1007 - accuracy: 0.5854 - val_loss: 0.1038 - val_accuracy: 0.5697\n",
      "Epoch 123/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.1008 - accuracy: 0.5850 - val_loss: 0.1033 - val_accuracy: 0.5738\n",
      "Epoch 124/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.1008 - accuracy: 0.5842 - val_loss: 0.1040 - val_accuracy: 0.5687\n",
      "Epoch 125/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.1007 - accuracy: 0.5842 - val_loss: 0.1031 - val_accuracy: 0.5742\n",
      "Epoch 126/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.1007 - accuracy: 0.5854 - val_loss: 0.1025 - val_accuracy: 0.5739\n",
      "Epoch 127/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.1008 - accuracy: 0.5850 - val_loss: 0.1032 - val_accuracy: 0.5737\n",
      "Epoch 128/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.1007 - accuracy: 0.5857 - val_loss: 0.1029 - val_accuracy: 0.5744\n",
      "Epoch 129/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.1008 - accuracy: 0.5854 - val_loss: 0.1038 - val_accuracy: 0.5710\n",
      "Epoch 130/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.1007 - accuracy: 0.5845 - val_loss: 0.1036 - val_accuracy: 0.5724\n",
      "Epoch 131/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.1007 - accuracy: 0.5853 - val_loss: 0.1033 - val_accuracy: 0.5719\n",
      "Epoch 132/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.1006 - accuracy: 0.5861 - val_loss: 0.1032 - val_accuracy: 0.5742\n",
      "Epoch 133/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.1008 - accuracy: 0.5852 - val_loss: 0.1034 - val_accuracy: 0.5731\n",
      "Epoch 134/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.1007 - accuracy: 0.5858 - val_loss: 0.1032 - val_accuracy: 0.5738\n",
      "Epoch 135/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.1006 - accuracy: 0.5855 - val_loss: 0.1032 - val_accuracy: 0.5722\n",
      "Epoch 136/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.1007 - accuracy: 0.5860 - val_loss: 0.1037 - val_accuracy: 0.5680\n",
      "Epoch 137/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.1006 - accuracy: 0.5861 - val_loss: 0.1033 - val_accuracy: 0.5723\n",
      "Epoch 138/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.1007 - accuracy: 0.5860 - val_loss: 0.1032 - val_accuracy: 0.5753\n",
      "Epoch 139/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.1006 - accuracy: 0.5862 - val_loss: 0.1034 - val_accuracy: 0.5738\n",
      "Epoch 140/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.1006 - accuracy: 0.5858 - val_loss: 0.1041 - val_accuracy: 0.5694\n",
      "Epoch 141/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.1007 - accuracy: 0.5864 - val_loss: 0.1030 - val_accuracy: 0.5747\n",
      "Epoch 142/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.1006 - accuracy: 0.5859 - val_loss: 0.1032 - val_accuracy: 0.5724\n",
      "Epoch 143/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.1006 - accuracy: 0.5869 - val_loss: 0.1034 - val_accuracy: 0.5703\n",
      "Epoch 144/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.1005 - accuracy: 0.5864 - val_loss: 0.1032 - val_accuracy: 0.5736\n",
      "Epoch 145/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.1005 - accuracy: 0.5869 - val_loss: 0.1037 - val_accuracy: 0.5695\n",
      "Epoch 146/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.1006 - accuracy: 0.5863 - val_loss: 0.1032 - val_accuracy: 0.5742\n",
      "Epoch 147/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.1005 - accuracy: 0.5860 - val_loss: 0.1031 - val_accuracy: 0.5727\n",
      "Epoch 148/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.1005 - accuracy: 0.5863 - val_loss: 0.1036 - val_accuracy: 0.5712\n",
      "Epoch 149/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.1006 - accuracy: 0.5864 - val_loss: 0.1030 - val_accuracy: 0.5732\n",
      "Epoch 150/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.1005 - accuracy: 0.5869 - val_loss: 0.1026 - val_accuracy: 0.5752\n",
      "Epoch 151/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.1005 - accuracy: 0.5871 - val_loss: 0.1032 - val_accuracy: 0.5742\n",
      "Epoch 152/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.1004 - accuracy: 0.5873 - val_loss: 0.1035 - val_accuracy: 0.5733\n",
      "Epoch 153/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.1005 - accuracy: 0.5873 - val_loss: 0.1032 - val_accuracy: 0.5737\n",
      "Epoch 154/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.1004 - accuracy: 0.5864 - val_loss: 0.1030 - val_accuracy: 0.5747\n",
      "Epoch 155/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.1005 - accuracy: 0.5867 - val_loss: 0.1026 - val_accuracy: 0.5769\n",
      "Epoch 156/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.1004 - accuracy: 0.5869 - val_loss: 0.1033 - val_accuracy: 0.5738\n",
      "Epoch 157/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.1005 - accuracy: 0.5862 - val_loss: 0.1039 - val_accuracy: 0.5694\n",
      "Epoch 158/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.1005 - accuracy: 0.5857 - val_loss: 0.1036 - val_accuracy: 0.5731\n",
      "Epoch 159/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.1004 - accuracy: 0.5880 - val_loss: 0.1034 - val_accuracy: 0.5739\n",
      "Epoch 160/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.1004 - accuracy: 0.5871 - val_loss: 0.1031 - val_accuracy: 0.5740\n",
      "Epoch 161/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.1005 - accuracy: 0.5874 - val_loss: 0.1034 - val_accuracy: 0.5734\n",
      "Epoch 162/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.1004 - accuracy: 0.5873 - val_loss: 0.1032 - val_accuracy: 0.5744\n",
      "Epoch 163/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.1003 - accuracy: 0.5878 - val_loss: 0.1027 - val_accuracy: 0.5748\n",
      "Epoch 164/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.1003 - accuracy: 0.5876 - val_loss: 0.1037 - val_accuracy: 0.5753\n",
      "Epoch 165/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.1003 - accuracy: 0.5875 - val_loss: 0.1031 - val_accuracy: 0.5752\n",
      "Epoch 166/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.1003 - accuracy: 0.5884 - val_loss: 0.1025 - val_accuracy: 0.5759\n",
      "Epoch 167/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.1003 - accuracy: 0.5874 - val_loss: 0.1027 - val_accuracy: 0.5751\n",
      "Epoch 168/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.1003 - accuracy: 0.5873 - val_loss: 0.1034 - val_accuracy: 0.5741\n",
      "Epoch 169/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.1003 - accuracy: 0.5874 - val_loss: 0.1031 - val_accuracy: 0.5752\n",
      "Epoch 170/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.1003 - accuracy: 0.5882 - val_loss: 0.1024 - val_accuracy: 0.5764\n",
      "Epoch 171/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.1003 - accuracy: 0.5885 - val_loss: 0.1029 - val_accuracy: 0.5765\n",
      "Epoch 172/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.1003 - accuracy: 0.5876 - val_loss: 0.1023 - val_accuracy: 0.5755\n",
      "Epoch 173/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.1003 - accuracy: 0.5873 - val_loss: 0.1039 - val_accuracy: 0.5675\n",
      "Epoch 174/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.1002 - accuracy: 0.5881 - val_loss: 0.1030 - val_accuracy: 0.5741\n",
      "Epoch 175/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.1002 - accuracy: 0.5878 - val_loss: 0.1028 - val_accuracy: 0.5773\n",
      "Epoch 176/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.1002 - accuracy: 0.5887 - val_loss: 0.1028 - val_accuracy: 0.5734\n",
      "Epoch 177/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.1002 - accuracy: 0.5882 - val_loss: 0.1029 - val_accuracy: 0.5725\n",
      "Epoch 178/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.1001 - accuracy: 0.5886 - val_loss: 0.1031 - val_accuracy: 0.5737\n",
      "Epoch 179/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.1003 - accuracy: 0.5882 - val_loss: 0.1037 - val_accuracy: 0.5718\n",
      "Epoch 180/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.1002 - accuracy: 0.5886 - val_loss: 0.1029 - val_accuracy: 0.5775\n",
      "Epoch 181/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.1001 - accuracy: 0.5882 - val_loss: 0.1033 - val_accuracy: 0.5737\n",
      "Epoch 182/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.1002 - accuracy: 0.5882 - val_loss: 0.1029 - val_accuracy: 0.5759\n",
      "Epoch 183/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.1003 - accuracy: 0.5879 - val_loss: 0.1025 - val_accuracy: 0.5778\n",
      "Epoch 184/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.1002 - accuracy: 0.5888 - val_loss: 0.1029 - val_accuracy: 0.5763\n",
      "Epoch 185/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.1002 - accuracy: 0.5883 - val_loss: 0.1030 - val_accuracy: 0.5747\n",
      "Epoch 186/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.1001 - accuracy: 0.5890 - val_loss: 0.1030 - val_accuracy: 0.5741\n",
      "Epoch 187/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.1002 - accuracy: 0.5883 - val_loss: 0.1026 - val_accuracy: 0.5766\n",
      "Epoch 188/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.1001 - accuracy: 0.5885 - val_loss: 0.1037 - val_accuracy: 0.5735\n",
      "Epoch 189/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.1002 - accuracy: 0.5877 - val_loss: 0.1027 - val_accuracy: 0.5740\n",
      "Epoch 190/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.1001 - accuracy: 0.5890 - val_loss: 0.1031 - val_accuracy: 0.5749\n",
      "Epoch 191/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.1001 - accuracy: 0.5893 - val_loss: 0.1028 - val_accuracy: 0.5759\n",
      "Epoch 192/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.1002 - accuracy: 0.5875 - val_loss: 0.1031 - val_accuracy: 0.5750\n",
      "Epoch 193/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.1001 - accuracy: 0.5880 - val_loss: 0.1029 - val_accuracy: 0.5773\n",
      "Epoch 194/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.1001 - accuracy: 0.5893 - val_loss: 0.1030 - val_accuracy: 0.5756\n",
      "Epoch 195/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.1002 - accuracy: 0.5882 - val_loss: 0.1034 - val_accuracy: 0.5704\n",
      "Epoch 196/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.1000 - accuracy: 0.5890 - val_loss: 0.1030 - val_accuracy: 0.5751\n",
      "Epoch 197/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.1001 - accuracy: 0.5890 - val_loss: 0.1033 - val_accuracy: 0.5726\n",
      "Epoch 198/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.1000 - accuracy: 0.5897 - val_loss: 0.1028 - val_accuracy: 0.5773\n",
      "Epoch 199/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.1000 - accuracy: 0.5896 - val_loss: 0.1032 - val_accuracy: 0.5771\n",
      "Epoch 200/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.1001 - accuracy: 0.5883 - val_loss: 0.1029 - val_accuracy: 0.5761\n",
      "Epoch 201/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.1000 - accuracy: 0.5890 - val_loss: 0.1038 - val_accuracy: 0.5714\n",
      "Epoch 202/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.1000 - accuracy: 0.5891 - val_loss: 0.1033 - val_accuracy: 0.5735\n",
      "Epoch 203/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0999 - accuracy: 0.5895 - val_loss: 0.1037 - val_accuracy: 0.5751\n",
      "Epoch 204/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.1001 - accuracy: 0.5888 - val_loss: 0.1029 - val_accuracy: 0.5737\n",
      "Epoch 205/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.1002 - accuracy: 0.5887 - val_loss: 0.1026 - val_accuracy: 0.5786\n",
      "Epoch 206/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.1000 - accuracy: 0.5899 - val_loss: 0.1037 - val_accuracy: 0.5729\n",
      "Epoch 207/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.1000 - accuracy: 0.5895 - val_loss: 0.1033 - val_accuracy: 0.5750\n",
      "Epoch 208/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.1000 - accuracy: 0.5890 - val_loss: 0.1031 - val_accuracy: 0.5737\n",
      "Epoch 209/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.1000 - accuracy: 0.5894 - val_loss: 0.1025 - val_accuracy: 0.5766\n",
      "Epoch 210/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.1000 - accuracy: 0.5890 - val_loss: 0.1030 - val_accuracy: 0.5769\n",
      "Epoch 211/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.1001 - accuracy: 0.5891 - val_loss: 0.1032 - val_accuracy: 0.5733\n",
      "Epoch 212/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.1000 - accuracy: 0.5894 - val_loss: 0.1031 - val_accuracy: 0.5741\n",
      "Epoch 213/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.1000 - accuracy: 0.5898 - val_loss: 0.1029 - val_accuracy: 0.5785\n",
      "Epoch 214/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.1000 - accuracy: 0.5902 - val_loss: 0.1030 - val_accuracy: 0.5758\n",
      "Epoch 215/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.1000 - accuracy: 0.5891 - val_loss: 0.1029 - val_accuracy: 0.5751\n",
      "Epoch 216/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0999 - accuracy: 0.5894 - val_loss: 0.1034 - val_accuracy: 0.5732\n",
      "Epoch 217/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.1000 - accuracy: 0.5890 - val_loss: 0.1029 - val_accuracy: 0.5767\n",
      "Epoch 218/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.1000 - accuracy: 0.5896 - val_loss: 0.1030 - val_accuracy: 0.5757\n",
      "Epoch 219/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.1000 - accuracy: 0.5890 - val_loss: 0.1028 - val_accuracy: 0.5779\n",
      "Epoch 220/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0999 - accuracy: 0.5896 - val_loss: 0.1033 - val_accuracy: 0.5755\n",
      "Epoch 221/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.1000 - accuracy: 0.5891 - val_loss: 0.1028 - val_accuracy: 0.5755\n",
      "Epoch 222/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0999 - accuracy: 0.5896 - val_loss: 0.1024 - val_accuracy: 0.5766\n",
      "Epoch 223/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.1000 - accuracy: 0.5897 - val_loss: 0.1031 - val_accuracy: 0.5721\n",
      "Epoch 224/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.1000 - accuracy: 0.5895 - val_loss: 0.1023 - val_accuracy: 0.5787\n",
      "Epoch 225/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.1000 - accuracy: 0.5892 - val_loss: 0.1027 - val_accuracy: 0.5770\n",
      "Epoch 226/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.1000 - accuracy: 0.5893 - val_loss: 0.1024 - val_accuracy: 0.5792\n",
      "Epoch 227/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0999 - accuracy: 0.5897 - val_loss: 0.1024 - val_accuracy: 0.5763\n",
      "Epoch 228/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.1000 - accuracy: 0.5898 - val_loss: 0.1033 - val_accuracy: 0.5743\n",
      "Epoch 229/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.1000 - accuracy: 0.5895 - val_loss: 0.1030 - val_accuracy: 0.5751\n",
      "Epoch 230/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.1000 - accuracy: 0.5886 - val_loss: 0.1028 - val_accuracy: 0.5769\n",
      "Epoch 231/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0999 - accuracy: 0.5897 - val_loss: 0.1027 - val_accuracy: 0.5765\n",
      "Epoch 232/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0999 - accuracy: 0.5900 - val_loss: 0.1026 - val_accuracy: 0.5783\n",
      "Epoch 233/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0998 - accuracy: 0.5896 - val_loss: 0.1036 - val_accuracy: 0.5733\n",
      "Epoch 234/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0998 - accuracy: 0.5901 - val_loss: 0.1032 - val_accuracy: 0.5742\n",
      "Epoch 235/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0999 - accuracy: 0.5896 - val_loss: 0.1029 - val_accuracy: 0.5767\n",
      "Epoch 236/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0999 - accuracy: 0.5898 - val_loss: 0.1036 - val_accuracy: 0.5740\n",
      "Epoch 237/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.1000 - accuracy: 0.5893 - val_loss: 0.1024 - val_accuracy: 0.5773\n",
      "Epoch 238/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.1000 - accuracy: 0.5889 - val_loss: 0.1028 - val_accuracy: 0.5772\n",
      "Epoch 239/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0998 - accuracy: 0.5896 - val_loss: 0.1027 - val_accuracy: 0.5766\n",
      "Epoch 240/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0999 - accuracy: 0.5902 - val_loss: 0.1029 - val_accuracy: 0.5760\n",
      "Epoch 241/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0999 - accuracy: 0.5896 - val_loss: 0.1034 - val_accuracy: 0.5742\n",
      "Epoch 242/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0999 - accuracy: 0.5893 - val_loss: 0.1028 - val_accuracy: 0.5785\n",
      "Epoch 243/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0999 - accuracy: 0.5892 - val_loss: 0.1031 - val_accuracy: 0.5765\n",
      "Epoch 244/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0999 - accuracy: 0.5900 - val_loss: 0.1032 - val_accuracy: 0.5737\n",
      "Epoch 245/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0998 - accuracy: 0.5895 - val_loss: 0.1031 - val_accuracy: 0.5751\n",
      "Epoch 246/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0999 - accuracy: 0.5896 - val_loss: 0.1029 - val_accuracy: 0.5755\n",
      "Epoch 247/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0998 - accuracy: 0.5898 - val_loss: 0.1027 - val_accuracy: 0.5790\n",
      "Epoch 248/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0999 - accuracy: 0.5898 - val_loss: 0.1028 - val_accuracy: 0.5775\n",
      "Epoch 249/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0999 - accuracy: 0.5899 - val_loss: 0.1023 - val_accuracy: 0.5784\n",
      "Epoch 250/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0998 - accuracy: 0.5911 - val_loss: 0.1027 - val_accuracy: 0.5760\n",
      "Epoch 251/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0998 - accuracy: 0.5901 - val_loss: 0.1030 - val_accuracy: 0.5728\n",
      "Epoch 252/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0999 - accuracy: 0.5898 - val_loss: 0.1031 - val_accuracy: 0.5756\n",
      "Epoch 253/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0998 - accuracy: 0.5891 - val_loss: 0.1032 - val_accuracy: 0.5761\n",
      "Epoch 254/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0998 - accuracy: 0.5903 - val_loss: 0.1031 - val_accuracy: 0.5757\n",
      "Epoch 255/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0999 - accuracy: 0.5899 - val_loss: 0.1029 - val_accuracy: 0.5737\n",
      "Epoch 256/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0998 - accuracy: 0.5902 - val_loss: 0.1027 - val_accuracy: 0.5785\n",
      "Epoch 257/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0997 - accuracy: 0.5905 - val_loss: 0.1028 - val_accuracy: 0.5728\n",
      "Epoch 258/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0998 - accuracy: 0.5905 - val_loss: 0.1024 - val_accuracy: 0.5772\n",
      "Epoch 259/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0998 - accuracy: 0.5900 - val_loss: 0.1030 - val_accuracy: 0.5730\n",
      "Epoch 260/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0998 - accuracy: 0.5903 - val_loss: 0.1031 - val_accuracy: 0.5760\n",
      "Epoch 261/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0998 - accuracy: 0.5900 - val_loss: 0.1030 - val_accuracy: 0.5776\n",
      "Epoch 262/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0997 - accuracy: 0.5901 - val_loss: 0.1026 - val_accuracy: 0.5758\n",
      "Epoch 263/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0997 - accuracy: 0.5909 - val_loss: 0.1026 - val_accuracy: 0.5744\n",
      "Epoch 264/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0998 - accuracy: 0.5907 - val_loss: 0.1021 - val_accuracy: 0.5784\n",
      "Epoch 265/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0998 - accuracy: 0.5904 - val_loss: 0.1024 - val_accuracy: 0.5797\n",
      "Epoch 266/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0997 - accuracy: 0.5907 - val_loss: 0.1027 - val_accuracy: 0.5797\n",
      "Epoch 267/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0997 - accuracy: 0.5908 - val_loss: 0.1027 - val_accuracy: 0.5765\n",
      "Epoch 268/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0998 - accuracy: 0.5902 - val_loss: 0.1026 - val_accuracy: 0.5765\n",
      "Epoch 269/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0997 - accuracy: 0.5908 - val_loss: 0.1032 - val_accuracy: 0.5751\n",
      "Epoch 270/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0997 - accuracy: 0.5905 - val_loss: 0.1032 - val_accuracy: 0.5739\n",
      "Epoch 271/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0998 - accuracy: 0.5914 - val_loss: 0.1028 - val_accuracy: 0.5768\n",
      "Epoch 272/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0997 - accuracy: 0.5909 - val_loss: 0.1030 - val_accuracy: 0.5774\n",
      "Epoch 273/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0998 - accuracy: 0.5901 - val_loss: 0.1026 - val_accuracy: 0.5753\n",
      "Epoch 274/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0997 - accuracy: 0.5902 - val_loss: 0.1027 - val_accuracy: 0.5758\n",
      "Epoch 275/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0997 - accuracy: 0.5904 - val_loss: 0.1028 - val_accuracy: 0.5784\n",
      "Epoch 276/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0998 - accuracy: 0.5906 - val_loss: 0.1022 - val_accuracy: 0.5785\n",
      "Epoch 277/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0998 - accuracy: 0.5896 - val_loss: 0.1032 - val_accuracy: 0.5759\n",
      "Epoch 278/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0996 - accuracy: 0.5909 - val_loss: 0.1032 - val_accuracy: 0.5742\n",
      "Epoch 279/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0997 - accuracy: 0.5902 - val_loss: 0.1032 - val_accuracy: 0.5744\n",
      "Epoch 280/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0997 - accuracy: 0.5912 - val_loss: 0.1026 - val_accuracy: 0.5762\n",
      "Epoch 281/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0996 - accuracy: 0.5906 - val_loss: 0.1028 - val_accuracy: 0.5762\n",
      "Epoch 282/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0997 - accuracy: 0.5908 - val_loss: 0.1035 - val_accuracy: 0.5743\n",
      "Epoch 283/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0997 - accuracy: 0.5904 - val_loss: 0.1027 - val_accuracy: 0.5760\n",
      "Epoch 284/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0997 - accuracy: 0.5903 - val_loss: 0.1027 - val_accuracy: 0.5752\n",
      "Epoch 285/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0997 - accuracy: 0.5902 - val_loss: 0.1030 - val_accuracy: 0.5745\n",
      "Epoch 286/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0996 - accuracy: 0.5909 - val_loss: 0.1032 - val_accuracy: 0.5756\n",
      "Epoch 287/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0997 - accuracy: 0.5908 - val_loss: 0.1028 - val_accuracy: 0.5776\n",
      "Epoch 288/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0996 - accuracy: 0.5910 - val_loss: 0.1031 - val_accuracy: 0.5754\n",
      "Epoch 289/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0996 - accuracy: 0.5922 - val_loss: 0.1025 - val_accuracy: 0.5774\n",
      "Epoch 290/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0995 - accuracy: 0.5921 - val_loss: 0.1026 - val_accuracy: 0.5788\n",
      "Epoch 291/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0997 - accuracy: 0.5910 - val_loss: 0.1030 - val_accuracy: 0.5769\n",
      "Epoch 292/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0996 - accuracy: 0.5917 - val_loss: 0.1026 - val_accuracy: 0.5757\n",
      "Epoch 293/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0996 - accuracy: 0.5909 - val_loss: 0.1029 - val_accuracy: 0.5753\n",
      "Epoch 294/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0997 - accuracy: 0.5904 - val_loss: 0.1023 - val_accuracy: 0.5771\n",
      "Epoch 295/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0996 - accuracy: 0.5915 - val_loss: 0.1035 - val_accuracy: 0.5740\n",
      "Epoch 296/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0996 - accuracy: 0.5910 - val_loss: 0.1026 - val_accuracy: 0.5782\n",
      "Epoch 297/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0996 - accuracy: 0.5916 - val_loss: 0.1030 - val_accuracy: 0.5784\n",
      "Epoch 298/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0997 - accuracy: 0.5910 - val_loss: 0.1028 - val_accuracy: 0.5770\n",
      "Epoch 299/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0996 - accuracy: 0.5906 - val_loss: 0.1026 - val_accuracy: 0.5759\n",
      "Epoch 300/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0996 - accuracy: 0.5907 - val_loss: 0.1029 - val_accuracy: 0.5775\n",
      "Epoch 301/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0996 - accuracy: 0.5911 - val_loss: 0.1035 - val_accuracy: 0.5714\n",
      "Epoch 302/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0996 - accuracy: 0.5919 - val_loss: 0.1030 - val_accuracy: 0.5742\n",
      "Epoch 303/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0996 - accuracy: 0.5912 - val_loss: 0.1026 - val_accuracy: 0.5783\n",
      "Epoch 304/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0996 - accuracy: 0.5913 - val_loss: 0.1032 - val_accuracy: 0.5768\n",
      "Epoch 305/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0996 - accuracy: 0.5918 - val_loss: 0.1033 - val_accuracy: 0.5756\n",
      "Epoch 306/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0995 - accuracy: 0.5914 - val_loss: 0.1032 - val_accuracy: 0.5747\n",
      "Epoch 307/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0995 - accuracy: 0.5916 - val_loss: 0.1029 - val_accuracy: 0.5769\n",
      "Epoch 308/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0995 - accuracy: 0.5921 - val_loss: 0.1032 - val_accuracy: 0.5726\n",
      "Epoch 309/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0995 - accuracy: 0.5910 - val_loss: 0.1030 - val_accuracy: 0.5763\n",
      "Epoch 310/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0995 - accuracy: 0.5913 - val_loss: 0.1028 - val_accuracy: 0.5755\n",
      "Epoch 311/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0996 - accuracy: 0.5905 - val_loss: 0.1032 - val_accuracy: 0.5758\n",
      "Epoch 312/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0996 - accuracy: 0.5914 - val_loss: 0.1030 - val_accuracy: 0.5767\n",
      "Epoch 313/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0995 - accuracy: 0.5913 - val_loss: 0.1025 - val_accuracy: 0.5763\n",
      "Epoch 314/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0995 - accuracy: 0.5915 - val_loss: 0.1027 - val_accuracy: 0.5753\n",
      "Epoch 315/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0995 - accuracy: 0.5921 - val_loss: 0.1027 - val_accuracy: 0.5774\n",
      "Epoch 316/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0995 - accuracy: 0.5912 - val_loss: 0.1026 - val_accuracy: 0.5772\n",
      "Epoch 317/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0995 - accuracy: 0.5926 - val_loss: 0.1030 - val_accuracy: 0.5766\n",
      "Epoch 318/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0996 - accuracy: 0.5909 - val_loss: 0.1026 - val_accuracy: 0.5793\n",
      "Epoch 319/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0995 - accuracy: 0.5923 - val_loss: 0.1028 - val_accuracy: 0.5783\n",
      "Epoch 320/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0994 - accuracy: 0.5916 - val_loss: 0.1036 - val_accuracy: 0.5758\n",
      "Epoch 321/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0995 - accuracy: 0.5916 - val_loss: 0.1025 - val_accuracy: 0.5757\n",
      "Epoch 322/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0995 - accuracy: 0.5921 - val_loss: 0.1030 - val_accuracy: 0.5785\n",
      "Epoch 323/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0994 - accuracy: 0.5916 - val_loss: 0.1025 - val_accuracy: 0.5776\n",
      "Epoch 324/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0996 - accuracy: 0.5912 - val_loss: 0.1025 - val_accuracy: 0.5788\n",
      "Epoch 325/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0995 - accuracy: 0.5918 - val_loss: 0.1033 - val_accuracy: 0.5735\n",
      "Epoch 326/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0995 - accuracy: 0.5921 - val_loss: 0.1025 - val_accuracy: 0.5772\n",
      "Epoch 327/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0995 - accuracy: 0.5920 - val_loss: 0.1023 - val_accuracy: 0.5775\n",
      "Epoch 328/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0994 - accuracy: 0.5910 - val_loss: 0.1032 - val_accuracy: 0.5760\n",
      "Epoch 329/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0995 - accuracy: 0.5913 - val_loss: 0.1030 - val_accuracy: 0.5746\n",
      "Epoch 330/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0995 - accuracy: 0.5917 - val_loss: 0.1027 - val_accuracy: 0.5772\n",
      "Epoch 331/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0995 - accuracy: 0.5917 - val_loss: 0.1032 - val_accuracy: 0.5755\n",
      "Epoch 332/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0995 - accuracy: 0.5919 - val_loss: 0.1027 - val_accuracy: 0.5791\n",
      "Epoch 333/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0994 - accuracy: 0.5922 - val_loss: 0.1035 - val_accuracy: 0.5753\n",
      "Epoch 334/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0995 - accuracy: 0.5913 - val_loss: 0.1033 - val_accuracy: 0.5748\n",
      "Epoch 335/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0994 - accuracy: 0.5920 - val_loss: 0.1026 - val_accuracy: 0.5793\n",
      "Epoch 336/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0993 - accuracy: 0.5931 - val_loss: 0.1028 - val_accuracy: 0.5769\n",
      "Epoch 337/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0994 - accuracy: 0.5921 - val_loss: 0.1026 - val_accuracy: 0.5787\n",
      "Epoch 338/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0994 - accuracy: 0.5922 - val_loss: 0.1027 - val_accuracy: 0.5789\n",
      "Epoch 339/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0994 - accuracy: 0.5925 - val_loss: 0.1024 - val_accuracy: 0.5770\n",
      "Epoch 340/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0994 - accuracy: 0.5929 - val_loss: 0.1024 - val_accuracy: 0.5770\n",
      "Epoch 341/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0994 - accuracy: 0.5926 - val_loss: 0.1030 - val_accuracy: 0.5741\n",
      "Epoch 342/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0994 - accuracy: 0.5921 - val_loss: 0.1026 - val_accuracy: 0.5766\n",
      "Epoch 343/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0994 - accuracy: 0.5927 - val_loss: 0.1028 - val_accuracy: 0.5781\n",
      "Epoch 344/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0993 - accuracy: 0.5925 - val_loss: 0.1022 - val_accuracy: 0.5790\n",
      "Epoch 345/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0994 - accuracy: 0.5921 - val_loss: 0.1030 - val_accuracy: 0.5735\n",
      "Epoch 346/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0994 - accuracy: 0.5918 - val_loss: 0.1029 - val_accuracy: 0.5764\n",
      "Epoch 347/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0994 - accuracy: 0.5920 - val_loss: 0.1025 - val_accuracy: 0.5784\n",
      "Epoch 348/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0993 - accuracy: 0.5927 - val_loss: 0.1033 - val_accuracy: 0.5762\n",
      "Epoch 349/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0993 - accuracy: 0.5927 - val_loss: 0.1024 - val_accuracy: 0.5769\n",
      "Epoch 350/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0995 - accuracy: 0.5919 - val_loss: 0.1025 - val_accuracy: 0.5792\n",
      "Epoch 351/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0993 - accuracy: 0.5924 - val_loss: 0.1025 - val_accuracy: 0.5767\n",
      "Epoch 352/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0993 - accuracy: 0.5923 - val_loss: 0.1031 - val_accuracy: 0.5777\n",
      "Epoch 353/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0994 - accuracy: 0.5923 - val_loss: 0.1029 - val_accuracy: 0.5753\n",
      "Epoch 354/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0994 - accuracy: 0.5919 - val_loss: 0.1023 - val_accuracy: 0.5783\n",
      "Epoch 355/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0994 - accuracy: 0.5923 - val_loss: 0.1032 - val_accuracy: 0.5775\n",
      "Epoch 356/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0993 - accuracy: 0.5925 - val_loss: 0.1028 - val_accuracy: 0.5781\n",
      "Epoch 357/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0994 - accuracy: 0.5920 - val_loss: 0.1025 - val_accuracy: 0.5804\n",
      "Epoch 358/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0993 - accuracy: 0.5921 - val_loss: 0.1028 - val_accuracy: 0.5773\n",
      "Epoch 359/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0994 - accuracy: 0.5926 - val_loss: 0.1029 - val_accuracy: 0.5769\n",
      "Epoch 360/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0994 - accuracy: 0.5922 - val_loss: 0.1026 - val_accuracy: 0.5793\n",
      "Epoch 361/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0994 - accuracy: 0.5920 - val_loss: 0.1027 - val_accuracy: 0.5751\n",
      "Epoch 362/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0993 - accuracy: 0.5920 - val_loss: 0.1030 - val_accuracy: 0.5781\n",
      "Epoch 363/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0993 - accuracy: 0.5932 - val_loss: 0.1027 - val_accuracy: 0.5764\n",
      "Epoch 364/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0993 - accuracy: 0.5921 - val_loss: 0.1029 - val_accuracy: 0.5763\n",
      "Epoch 365/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0993 - accuracy: 0.5925 - val_loss: 0.1021 - val_accuracy: 0.5798\n",
      "Epoch 366/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0993 - accuracy: 0.5919 - val_loss: 0.1024 - val_accuracy: 0.5786\n",
      "Epoch 367/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0994 - accuracy: 0.5930 - val_loss: 0.1024 - val_accuracy: 0.5762\n",
      "Epoch 368/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0993 - accuracy: 0.5933 - val_loss: 0.1024 - val_accuracy: 0.5775\n",
      "Epoch 369/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0993 - accuracy: 0.5934 - val_loss: 0.1024 - val_accuracy: 0.5788\n",
      "Epoch 370/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0993 - accuracy: 0.5922 - val_loss: 0.1031 - val_accuracy: 0.5742\n",
      "Epoch 371/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0994 - accuracy: 0.5921 - val_loss: 0.1023 - val_accuracy: 0.5781\n",
      "Epoch 372/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0993 - accuracy: 0.5922 - val_loss: 0.1035 - val_accuracy: 0.5766\n",
      "Epoch 373/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0994 - accuracy: 0.5919 - val_loss: 0.1025 - val_accuracy: 0.5779\n",
      "Epoch 374/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0993 - accuracy: 0.5925 - val_loss: 0.1030 - val_accuracy: 0.5760\n",
      "Epoch 375/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0993 - accuracy: 0.5932 - val_loss: 0.1033 - val_accuracy: 0.5763\n",
      "Epoch 376/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0994 - accuracy: 0.5923 - val_loss: 0.1033 - val_accuracy: 0.5743\n",
      "Epoch 377/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0993 - accuracy: 0.5929 - val_loss: 0.1026 - val_accuracy: 0.5776\n",
      "Epoch 378/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0993 - accuracy: 0.5928 - val_loss: 0.1025 - val_accuracy: 0.5788\n",
      "Epoch 379/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0993 - accuracy: 0.5931 - val_loss: 0.1028 - val_accuracy: 0.5798\n",
      "Epoch 380/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0993 - accuracy: 0.5928 - val_loss: 0.1029 - val_accuracy: 0.5790\n",
      "Epoch 381/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0993 - accuracy: 0.5923 - val_loss: 0.1027 - val_accuracy: 0.5777\n",
      "Epoch 382/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0993 - accuracy: 0.5932 - val_loss: 0.1024 - val_accuracy: 0.5779\n",
      "Epoch 383/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0994 - accuracy: 0.5929 - val_loss: 0.1026 - val_accuracy: 0.5779\n",
      "Epoch 384/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0993 - accuracy: 0.5929 - val_loss: 0.1029 - val_accuracy: 0.5792\n",
      "Epoch 385/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0993 - accuracy: 0.5923 - val_loss: 0.1023 - val_accuracy: 0.5773\n",
      "Epoch 386/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0993 - accuracy: 0.5929 - val_loss: 0.1029 - val_accuracy: 0.5777\n",
      "Epoch 387/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0992 - accuracy: 0.5931 - val_loss: 0.1031 - val_accuracy: 0.5757\n",
      "Epoch 388/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0993 - accuracy: 0.5935 - val_loss: 0.1028 - val_accuracy: 0.5773\n",
      "Epoch 389/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0992 - accuracy: 0.5936 - val_loss: 0.1023 - val_accuracy: 0.5810\n",
      "Epoch 390/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0993 - accuracy: 0.5925 - val_loss: 0.1027 - val_accuracy: 0.5787\n",
      "Epoch 391/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0992 - accuracy: 0.5933 - val_loss: 0.1029 - val_accuracy: 0.5760\n",
      "Epoch 392/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0992 - accuracy: 0.5936 - val_loss: 0.1020 - val_accuracy: 0.5806\n",
      "Epoch 393/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0993 - accuracy: 0.5928 - val_loss: 0.1047 - val_accuracy: 0.5731\n",
      "Epoch 394/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0993 - accuracy: 0.5926 - val_loss: 0.1022 - val_accuracy: 0.5795\n",
      "Epoch 395/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0993 - accuracy: 0.5932 - val_loss: 0.1027 - val_accuracy: 0.5773\n",
      "Epoch 396/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0992 - accuracy: 0.5932 - val_loss: 0.1025 - val_accuracy: 0.5791\n",
      "Epoch 397/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0992 - accuracy: 0.5933 - val_loss: 0.1029 - val_accuracy: 0.5774\n",
      "Epoch 398/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0993 - accuracy: 0.5922 - val_loss: 0.1028 - val_accuracy: 0.5799\n",
      "Epoch 399/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0993 - accuracy: 0.5924 - val_loss: 0.1032 - val_accuracy: 0.5769\n",
      "Epoch 400/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0992 - accuracy: 0.5937 - val_loss: 0.1024 - val_accuracy: 0.5780\n",
      "Epoch 401/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0993 - accuracy: 0.5934 - val_loss: 0.1022 - val_accuracy: 0.5804\n",
      "Epoch 402/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0992 - accuracy: 0.5935 - val_loss: 0.1027 - val_accuracy: 0.5798\n",
      "Epoch 403/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0993 - accuracy: 0.5930 - val_loss: 0.1025 - val_accuracy: 0.5781\n",
      "Epoch 404/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0992 - accuracy: 0.5922 - val_loss: 0.1030 - val_accuracy: 0.5769\n",
      "Epoch 405/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0992 - accuracy: 0.5937 - val_loss: 0.1025 - val_accuracy: 0.5779\n",
      "Epoch 406/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0992 - accuracy: 0.5932 - val_loss: 0.1026 - val_accuracy: 0.5796\n",
      "Epoch 407/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0993 - accuracy: 0.5931 - val_loss: 0.1028 - val_accuracy: 0.5766\n",
      "Epoch 408/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0993 - accuracy: 0.5924 - val_loss: 0.1027 - val_accuracy: 0.5776\n",
      "Epoch 409/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0992 - accuracy: 0.5936 - val_loss: 0.1022 - val_accuracy: 0.5786\n",
      "Epoch 410/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0992 - accuracy: 0.5933 - val_loss: 0.1025 - val_accuracy: 0.5800\n",
      "Epoch 411/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0992 - accuracy: 0.5932 - val_loss: 0.1033 - val_accuracy: 0.5781\n",
      "Epoch 412/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0993 - accuracy: 0.5927 - val_loss: 0.1027 - val_accuracy: 0.5798\n",
      "Epoch 413/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0992 - accuracy: 0.5934 - val_loss: 0.1021 - val_accuracy: 0.5813\n",
      "Epoch 414/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0992 - accuracy: 0.5929 - val_loss: 0.1023 - val_accuracy: 0.5811\n",
      "Epoch 415/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0992 - accuracy: 0.5931 - val_loss: 0.1027 - val_accuracy: 0.5773\n",
      "Epoch 416/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0993 - accuracy: 0.5924 - val_loss: 0.1027 - val_accuracy: 0.5774\n",
      "Epoch 417/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0992 - accuracy: 0.5934 - val_loss: 0.1026 - val_accuracy: 0.5772\n",
      "Epoch 418/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0993 - accuracy: 0.5933 - val_loss: 0.1025 - val_accuracy: 0.5795\n",
      "Epoch 419/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0992 - accuracy: 0.5937 - val_loss: 0.1027 - val_accuracy: 0.5797\n",
      "Epoch 420/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0992 - accuracy: 0.5930 - val_loss: 0.1022 - val_accuracy: 0.5787\n",
      "Epoch 421/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0992 - accuracy: 0.5936 - val_loss: 0.1021 - val_accuracy: 0.5807\n",
      "Epoch 422/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0993 - accuracy: 0.5929 - val_loss: 0.1029 - val_accuracy: 0.5774\n",
      "Epoch 423/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0991 - accuracy: 0.5938 - val_loss: 0.1023 - val_accuracy: 0.5782\n",
      "Epoch 424/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0991 - accuracy: 0.5941 - val_loss: 0.1032 - val_accuracy: 0.5753\n",
      "Epoch 425/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0992 - accuracy: 0.5934 - val_loss: 0.1034 - val_accuracy: 0.5748\n",
      "Epoch 426/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0991 - accuracy: 0.5943 - val_loss: 0.1030 - val_accuracy: 0.5771\n",
      "Epoch 427/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0992 - accuracy: 0.5940 - val_loss: 0.1027 - val_accuracy: 0.5793\n",
      "Epoch 428/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0993 - accuracy: 0.5928 - val_loss: 0.1021 - val_accuracy: 0.5811\n",
      "Epoch 429/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0992 - accuracy: 0.5944 - val_loss: 0.1022 - val_accuracy: 0.5792\n",
      "Epoch 430/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0992 - accuracy: 0.5946 - val_loss: 0.1026 - val_accuracy: 0.5774\n",
      "Epoch 431/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0992 - accuracy: 0.5934 - val_loss: 0.1033 - val_accuracy: 0.5760\n",
      "Epoch 432/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0992 - accuracy: 0.5940 - val_loss: 0.1029 - val_accuracy: 0.5743\n",
      "Epoch 433/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0991 - accuracy: 0.5935 - val_loss: 0.1024 - val_accuracy: 0.5754\n",
      "Epoch 434/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0992 - accuracy: 0.5931 - val_loss: 0.1024 - val_accuracy: 0.5784\n",
      "Epoch 435/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0991 - accuracy: 0.5936 - val_loss: 0.1025 - val_accuracy: 0.5787\n",
      "Epoch 436/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0992 - accuracy: 0.5943 - val_loss: 0.1035 - val_accuracy: 0.5782\n",
      "Epoch 437/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0992 - accuracy: 0.5933 - val_loss: 0.1023 - val_accuracy: 0.5793\n",
      "Epoch 438/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0993 - accuracy: 0.5935 - val_loss: 0.1030 - val_accuracy: 0.5776\n",
      "Epoch 439/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0990 - accuracy: 0.5943 - val_loss: 0.1020 - val_accuracy: 0.5798\n",
      "Epoch 440/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0992 - accuracy: 0.5938 - val_loss: 0.1024 - val_accuracy: 0.5802\n",
      "Epoch 441/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0992 - accuracy: 0.5942 - val_loss: 0.1028 - val_accuracy: 0.5777\n",
      "Epoch 442/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0991 - accuracy: 0.5940 - val_loss: 0.1024 - val_accuracy: 0.5800\n",
      "Epoch 443/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0992 - accuracy: 0.5944 - val_loss: 0.1026 - val_accuracy: 0.5783\n",
      "Epoch 444/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0991 - accuracy: 0.5933 - val_loss: 0.1026 - val_accuracy: 0.5780\n",
      "Epoch 445/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0992 - accuracy: 0.5943 - val_loss: 0.1024 - val_accuracy: 0.5804\n",
      "Epoch 446/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0992 - accuracy: 0.5930 - val_loss: 0.1025 - val_accuracy: 0.5803\n",
      "Epoch 447/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0991 - accuracy: 0.5934 - val_loss: 0.1026 - val_accuracy: 0.5814\n",
      "Epoch 448/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0991 - accuracy: 0.5942 - val_loss: 0.1021 - val_accuracy: 0.5759\n",
      "Epoch 449/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0992 - accuracy: 0.5941 - val_loss: 0.1026 - val_accuracy: 0.5792\n",
      "Epoch 450/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0992 - accuracy: 0.5935 - val_loss: 0.1031 - val_accuracy: 0.5765\n",
      "Epoch 451/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0991 - accuracy: 0.5934 - val_loss: 0.1023 - val_accuracy: 0.5766\n",
      "Epoch 452/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0991 - accuracy: 0.5935 - val_loss: 0.1021 - val_accuracy: 0.5814\n",
      "Epoch 453/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0991 - accuracy: 0.5939 - val_loss: 0.1027 - val_accuracy: 0.5779\n",
      "Epoch 454/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0992 - accuracy: 0.5937 - val_loss: 0.1023 - val_accuracy: 0.5809\n",
      "Epoch 455/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0991 - accuracy: 0.5937 - val_loss: 0.1024 - val_accuracy: 0.5787\n",
      "Epoch 456/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0992 - accuracy: 0.5936 - val_loss: 0.1026 - val_accuracy: 0.5777\n",
      "Epoch 457/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0991 - accuracy: 0.5941 - val_loss: 0.1028 - val_accuracy: 0.5802\n",
      "Epoch 458/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0991 - accuracy: 0.5944 - val_loss: 0.1030 - val_accuracy: 0.5767\n",
      "Epoch 459/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0991 - accuracy: 0.5936 - val_loss: 0.1031 - val_accuracy: 0.5726\n",
      "Epoch 460/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0992 - accuracy: 0.5929 - val_loss: 0.1024 - val_accuracy: 0.5793\n",
      "Epoch 461/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0991 - accuracy: 0.5935 - val_loss: 0.1025 - val_accuracy: 0.5791\n",
      "Epoch 462/5000\n",
      "11864/11864 [==============================] - 7s 563us/step - loss: 0.0992 - accuracy: 0.5941 - val_loss: 0.1028 - val_accuracy: 0.5757\n",
      "Epoch 463/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0992 - accuracy: 0.5937 - val_loss: 0.1026 - val_accuracy: 0.5795\n",
      "Epoch 464/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0990 - accuracy: 0.5946 - val_loss: 0.1032 - val_accuracy: 0.5768\n",
      "Epoch 465/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0991 - accuracy: 0.5946 - val_loss: 0.1021 - val_accuracy: 0.5821\n",
      "Epoch 466/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0991 - accuracy: 0.5949 - val_loss: 0.1032 - val_accuracy: 0.5782\n",
      "Epoch 467/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0991 - accuracy: 0.5944 - val_loss: 0.1028 - val_accuracy: 0.5770\n",
      "Epoch 468/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0991 - accuracy: 0.5947 - val_loss: 0.1025 - val_accuracy: 0.5783\n",
      "Epoch 469/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0991 - accuracy: 0.5942 - val_loss: 0.1028 - val_accuracy: 0.5787\n",
      "Epoch 470/5000\n",
      "11864/11864 [==============================] - 7s 558us/step - loss: 0.0991 - accuracy: 0.5941 - val_loss: 0.1028 - val_accuracy: 0.5776\n",
      "Epoch 471/5000\n",
      "11864/11864 [==============================] - 7s 561us/step - loss: 0.0990 - accuracy: 0.5949 - val_loss: 0.1027 - val_accuracy: 0.5764\n",
      "Epoch 472/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0990 - accuracy: 0.5943 - val_loss: 0.1031 - val_accuracy: 0.5744\n",
      "Epoch 473/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0991 - accuracy: 0.5943 - val_loss: 0.1029 - val_accuracy: 0.5779\n",
      "Epoch 474/5000\n",
      "11864/11864 [==============================] - 7s 562us/step - loss: 0.0990 - accuracy: 0.5945 - val_loss: 0.1023 - val_accuracy: 0.5778\n",
      "Epoch 475/5000\n",
      "11864/11864 [==============================] - 7s 564us/step - loss: 0.0991 - accuracy: 0.5942 - val_loss: 0.1027 - val_accuracy: 0.5784\n",
      "Epoch 476/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0991 - accuracy: 0.5951 - val_loss: 0.1024 - val_accuracy: 0.5807\n",
      "Epoch 477/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0991 - accuracy: 0.5947 - val_loss: 0.1026 - val_accuracy: 0.5812\n",
      "Epoch 478/5000\n",
      "11864/11864 [==============================] - 7s 559us/step - loss: 0.0991 - accuracy: 0.5943 - val_loss: 0.1025 - val_accuracy: 0.5797\n",
      "Epoch 479/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0992 - accuracy: 0.5940 - val_loss: 0.1031 - val_accuracy: 0.5761\n",
      "Epoch 480/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0990 - accuracy: 0.5949 - val_loss: 0.1019 - val_accuracy: 0.5820\n",
      "Epoch 481/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0990 - accuracy: 0.5950 - val_loss: 0.1019 - val_accuracy: 0.5818\n",
      "Epoch 482/5000\n",
      "11864/11864 [==============================] - 7s 565us/step - loss: 0.0990 - accuracy: 0.5943 - val_loss: 0.1025 - val_accuracy: 0.5800\n",
      "Epoch 483/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0990 - accuracy: 0.5948 - val_loss: 0.1023 - val_accuracy: 0.5795\n",
      "Epoch 484/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0991 - accuracy: 0.5940 - val_loss: 0.1032 - val_accuracy: 0.5795\n",
      "Epoch 485/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0989 - accuracy: 0.5947 - val_loss: 0.1025 - val_accuracy: 0.5792\n",
      "Epoch 486/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0990 - accuracy: 0.5942 - val_loss: 0.1024 - val_accuracy: 0.5782\n",
      "Epoch 487/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0991 - accuracy: 0.5932 - val_loss: 0.1030 - val_accuracy: 0.5758\n",
      "Epoch 488/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0990 - accuracy: 0.5948 - val_loss: 0.1026 - val_accuracy: 0.5780\n",
      "Epoch 489/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0991 - accuracy: 0.5943 - val_loss: 0.1024 - val_accuracy: 0.5771\n",
      "Epoch 490/5000\n",
      "11864/11864 [==============================] - 7s 559us/step - loss: 0.0990 - accuracy: 0.5941 - val_loss: 0.1023 - val_accuracy: 0.5787\n",
      "Epoch 491/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0989 - accuracy: 0.5948 - val_loss: 0.1024 - val_accuracy: 0.5787\n",
      "Epoch 492/5000\n",
      "11864/11864 [==============================] - 7s 563us/step - loss: 0.0990 - accuracy: 0.5940 - val_loss: 0.1024 - val_accuracy: 0.5797\n",
      "Epoch 493/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0990 - accuracy: 0.5944 - val_loss: 0.1026 - val_accuracy: 0.5791\n",
      "Epoch 494/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0991 - accuracy: 0.5934 - val_loss: 0.1029 - val_accuracy: 0.5815\n",
      "Epoch 495/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0989 - accuracy: 0.5952 - val_loss: 0.1029 - val_accuracy: 0.5766\n",
      "Epoch 496/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0990 - accuracy: 0.5949 - val_loss: 0.1029 - val_accuracy: 0.5794\n",
      "Epoch 497/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0990 - accuracy: 0.5946 - val_loss: 0.1023 - val_accuracy: 0.5806\n",
      "Epoch 498/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0991 - accuracy: 0.5940 - val_loss: 0.1020 - val_accuracy: 0.5828\n",
      "Epoch 499/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0990 - accuracy: 0.5943 - val_loss: 0.1028 - val_accuracy: 0.5771\n",
      "Epoch 500/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0991 - accuracy: 0.5945 - val_loss: 0.1024 - val_accuracy: 0.5795\n",
      "Epoch 501/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0990 - accuracy: 0.5955 - val_loss: 0.1021 - val_accuracy: 0.5818\n",
      "Epoch 502/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0991 - accuracy: 0.5946 - val_loss: 0.1032 - val_accuracy: 0.5786\n",
      "Epoch 503/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0990 - accuracy: 0.5952 - val_loss: 0.1021 - val_accuracy: 0.5804\n",
      "Epoch 504/5000\n",
      "11864/11864 [==============================] - 7s 566us/step - loss: 0.0989 - accuracy: 0.5952 - val_loss: 0.1025 - val_accuracy: 0.5777\n",
      "Epoch 505/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0991 - accuracy: 0.5945 - val_loss: 0.1022 - val_accuracy: 0.5796\n",
      "Epoch 506/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0989 - accuracy: 0.5950 - val_loss: 0.1028 - val_accuracy: 0.5780\n",
      "Epoch 507/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0990 - accuracy: 0.5950 - val_loss: 0.1027 - val_accuracy: 0.5777\n",
      "Epoch 508/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0991 - accuracy: 0.5939 - val_loss: 0.1027 - val_accuracy: 0.5814\n",
      "Epoch 509/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0989 - accuracy: 0.5949 - val_loss: 0.1031 - val_accuracy: 0.5773\n",
      "Epoch 510/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0990 - accuracy: 0.5943 - val_loss: 0.1025 - val_accuracy: 0.5812\n",
      "Epoch 511/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0990 - accuracy: 0.5952 - val_loss: 0.1026 - val_accuracy: 0.5804\n",
      "Epoch 512/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0990 - accuracy: 0.5942 - val_loss: 0.1025 - val_accuracy: 0.5791\n",
      "Epoch 513/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0991 - accuracy: 0.5942 - val_loss: 0.1028 - val_accuracy: 0.5758\n",
      "Epoch 514/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0990 - accuracy: 0.5944 - val_loss: 0.1026 - val_accuracy: 0.5777\n",
      "Epoch 515/5000\n",
      "11864/11864 [==============================] - 7s 566us/step - loss: 0.0990 - accuracy: 0.5955 - val_loss: 0.1029 - val_accuracy: 0.5764\n",
      "Epoch 516/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0989 - accuracy: 0.5951 - val_loss: 0.1033 - val_accuracy: 0.5789\n",
      "Epoch 517/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0990 - accuracy: 0.5947 - val_loss: 0.1021 - val_accuracy: 0.5796\n",
      "Epoch 518/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0989 - accuracy: 0.5945 - val_loss: 0.1029 - val_accuracy: 0.5759\n",
      "Epoch 519/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0990 - accuracy: 0.5950 - val_loss: 0.1025 - val_accuracy: 0.5810\n",
      "Epoch 520/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0991 - accuracy: 0.5947 - val_loss: 0.1033 - val_accuracy: 0.5795\n",
      "Epoch 521/5000\n",
      "11864/11864 [==============================] - 7s 566us/step - loss: 0.0990 - accuracy: 0.5949 - val_loss: 0.1035 - val_accuracy: 0.5769\n",
      "Epoch 522/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0990 - accuracy: 0.5948 - val_loss: 0.1019 - val_accuracy: 0.5817\n",
      "Epoch 523/5000\n",
      "11864/11864 [==============================] - 7s 566us/step - loss: 0.0990 - accuracy: 0.5947 - val_loss: 0.1024 - val_accuracy: 0.5787\n",
      "Epoch 524/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0989 - accuracy: 0.5952 - val_loss: 0.1027 - val_accuracy: 0.5805\n",
      "Epoch 525/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0989 - accuracy: 0.5951 - val_loss: 0.1035 - val_accuracy: 0.5724\n",
      "Epoch 526/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0991 - accuracy: 0.5939 - val_loss: 0.1025 - val_accuracy: 0.5786\n",
      "Epoch 527/5000\n",
      "11864/11864 [==============================] - 7s 566us/step - loss: 0.0990 - accuracy: 0.5939 - val_loss: 0.1023 - val_accuracy: 0.5809\n",
      "Epoch 528/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0990 - accuracy: 0.5934 - val_loss: 0.1023 - val_accuracy: 0.5782\n",
      "Epoch 529/5000\n",
      "11864/11864 [==============================] - 7s 566us/step - loss: 0.0990 - accuracy: 0.5948 - val_loss: 0.1025 - val_accuracy: 0.5793\n",
      "Epoch 530/5000\n",
      "11864/11864 [==============================] - 7s 566us/step - loss: 0.0990 - accuracy: 0.5947 - val_loss: 0.1036 - val_accuracy: 0.5712\n",
      "Epoch 531/5000\n",
      "11864/11864 [==============================] - 7s 565us/step - loss: 0.0990 - accuracy: 0.5948 - val_loss: 0.1029 - val_accuracy: 0.5767\n",
      "Epoch 532/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0990 - accuracy: 0.5942 - val_loss: 0.1027 - val_accuracy: 0.5787\n",
      "Epoch 533/5000\n",
      "11864/11864 [==============================] - 7s 564us/step - loss: 0.0990 - accuracy: 0.5943 - val_loss: 0.1029 - val_accuracy: 0.5756\n",
      "Epoch 534/5000\n",
      "11864/11864 [==============================] - 7s 565us/step - loss: 0.0990 - accuracy: 0.5947 - val_loss: 0.1024 - val_accuracy: 0.5801\n",
      "Epoch 535/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0989 - accuracy: 0.5944 - val_loss: 0.1027 - val_accuracy: 0.5803\n",
      "Epoch 536/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0990 - accuracy: 0.5943 - val_loss: 0.1022 - val_accuracy: 0.5804\n",
      "Epoch 537/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0989 - accuracy: 0.5947 - val_loss: 0.1022 - val_accuracy: 0.5788\n",
      "Epoch 538/5000\n",
      "11864/11864 [==============================] - 7s 566us/step - loss: 0.0989 - accuracy: 0.5947 - val_loss: 0.1023 - val_accuracy: 0.5781\n",
      "Epoch 539/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0989 - accuracy: 0.5946 - val_loss: 0.1034 - val_accuracy: 0.5748\n",
      "Epoch 540/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0989 - accuracy: 0.5948 - val_loss: 0.1020 - val_accuracy: 0.5813\n",
      "Epoch 541/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0989 - accuracy: 0.5951 - val_loss: 0.1036 - val_accuracy: 0.5763\n",
      "Epoch 542/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0990 - accuracy: 0.5951 - val_loss: 0.1024 - val_accuracy: 0.5790\n",
      "Epoch 543/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0990 - accuracy: 0.5956 - val_loss: 0.1028 - val_accuracy: 0.5753\n",
      "Epoch 544/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0991 - accuracy: 0.5944 - val_loss: 0.1038 - val_accuracy: 0.5778\n",
      "Epoch 545/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0990 - accuracy: 0.5952 - val_loss: 0.1022 - val_accuracy: 0.5809\n",
      "Epoch 546/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0989 - accuracy: 0.5945 - val_loss: 0.1029 - val_accuracy: 0.5772\n",
      "Epoch 547/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0990 - accuracy: 0.5948 - val_loss: 0.1023 - val_accuracy: 0.5821\n",
      "Epoch 548/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0990 - accuracy: 0.5947 - val_loss: 0.1023 - val_accuracy: 0.5799\n",
      "Epoch 549/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0990 - accuracy: 0.5950 - val_loss: 0.1023 - val_accuracy: 0.5791\n",
      "Epoch 550/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0990 - accuracy: 0.5948 - val_loss: 0.1024 - val_accuracy: 0.5792\n",
      "Epoch 551/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0990 - accuracy: 0.5943 - val_loss: 0.1020 - val_accuracy: 0.5801\n",
      "Epoch 552/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0989 - accuracy: 0.5946 - val_loss: 0.1024 - val_accuracy: 0.5791\n",
      "Epoch 553/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0990 - accuracy: 0.5945 - val_loss: 0.1024 - val_accuracy: 0.5797\n",
      "Epoch 554/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0990 - accuracy: 0.5948 - val_loss: 0.1025 - val_accuracy: 0.5777\n",
      "Epoch 555/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0989 - accuracy: 0.5951 - val_loss: 0.1031 - val_accuracy: 0.5781\n",
      "Epoch 556/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0990 - accuracy: 0.5946 - val_loss: 0.1024 - val_accuracy: 0.5781\n",
      "Epoch 557/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0989 - accuracy: 0.5959 - val_loss: 0.1027 - val_accuracy: 0.5786\n",
      "Epoch 558/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0990 - accuracy: 0.5947 - val_loss: 0.1027 - val_accuracy: 0.5786\n",
      "Epoch 559/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0990 - accuracy: 0.5954 - val_loss: 0.1023 - val_accuracy: 0.5783\n",
      "Epoch 560/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0990 - accuracy: 0.5943 - val_loss: 0.1027 - val_accuracy: 0.5770\n",
      "Epoch 561/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0990 - accuracy: 0.5952 - val_loss: 0.1029 - val_accuracy: 0.5774\n",
      "Epoch 562/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0990 - accuracy: 0.5949 - val_loss: 0.1024 - val_accuracy: 0.5812\n",
      "Epoch 563/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0989 - accuracy: 0.5953 - val_loss: 0.1021 - val_accuracy: 0.5805\n",
      "Epoch 564/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0990 - accuracy: 0.5950 - val_loss: 0.1028 - val_accuracy: 0.5755\n",
      "Epoch 565/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0990 - accuracy: 0.5947 - val_loss: 0.1024 - val_accuracy: 0.5777\n",
      "Epoch 566/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0989 - accuracy: 0.5943 - val_loss: 0.1024 - val_accuracy: 0.5806\n",
      "Epoch 567/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0989 - accuracy: 0.5953 - val_loss: 0.1024 - val_accuracy: 0.5800\n",
      "Epoch 568/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0990 - accuracy: 0.5947 - val_loss: 0.1027 - val_accuracy: 0.5783\n",
      "Epoch 569/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0989 - accuracy: 0.5955 - val_loss: 0.1029 - val_accuracy: 0.5789\n",
      "Epoch 570/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0988 - accuracy: 0.5960 - val_loss: 0.1024 - val_accuracy: 0.5778\n",
      "Epoch 571/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0990 - accuracy: 0.5950 - val_loss: 0.1029 - val_accuracy: 0.5775\n",
      "Epoch 572/5000\n",
      "11864/11864 [==============================] - 7s 565us/step - loss: 0.0990 - accuracy: 0.5957 - val_loss: 0.1023 - val_accuracy: 0.5805\n",
      "Epoch 573/5000\n",
      "11864/11864 [==============================] - 7s 565us/step - loss: 0.0990 - accuracy: 0.5952 - val_loss: 0.1032 - val_accuracy: 0.5796\n",
      "Epoch 574/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0989 - accuracy: 0.5947 - val_loss: 0.1028 - val_accuracy: 0.5788\n",
      "Epoch 575/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0989 - accuracy: 0.5947 - val_loss: 0.1033 - val_accuracy: 0.5763\n",
      "Epoch 576/5000\n",
      "11864/11864 [==============================] - 7s 563us/step - loss: 0.0990 - accuracy: 0.5948 - val_loss: 0.1025 - val_accuracy: 0.5815\n",
      "Epoch 577/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0989 - accuracy: 0.5951 - val_loss: 0.1030 - val_accuracy: 0.5786\n",
      "Epoch 578/5000\n",
      "11864/11864 [==============================] - 7s 565us/step - loss: 0.0989 - accuracy: 0.5949 - val_loss: 0.1023 - val_accuracy: 0.5808\n",
      "Epoch 579/5000\n",
      "11864/11864 [==============================] - 7s 565us/step - loss: 0.0989 - accuracy: 0.5945 - val_loss: 0.1029 - val_accuracy: 0.5786\n",
      "Epoch 580/5000\n",
      "11864/11864 [==============================] - 7s 563us/step - loss: 0.0990 - accuracy: 0.5948 - val_loss: 0.1026 - val_accuracy: 0.5796\n",
      "Epoch 581/5000\n",
      "11864/11864 [==============================] - 7s 558us/step - loss: 0.0989 - accuracy: 0.5955 - val_loss: 0.1029 - val_accuracy: 0.5773\n",
      "Epoch 582/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0989 - accuracy: 0.5949 - val_loss: 0.1026 - val_accuracy: 0.5772\n",
      "Epoch 583/5000\n",
      "11864/11864 [==============================] - 7s 564us/step - loss: 0.0989 - accuracy: 0.5942 - val_loss: 0.1024 - val_accuracy: 0.5837\n",
      "Epoch 584/5000\n",
      "11864/11864 [==============================] - 7s 563us/step - loss: 0.0989 - accuracy: 0.5948 - val_loss: 0.1018 - val_accuracy: 0.5809\n",
      "Epoch 585/5000\n",
      "11864/11864 [==============================] - 7s 566us/step - loss: 0.0989 - accuracy: 0.5945 - val_loss: 0.1027 - val_accuracy: 0.5794\n",
      "Epoch 586/5000\n",
      "11864/11864 [==============================] - 7s 565us/step - loss: 0.0989 - accuracy: 0.5944 - val_loss: 0.1025 - val_accuracy: 0.5771\n",
      "Epoch 587/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0988 - accuracy: 0.5962 - val_loss: 0.1022 - val_accuracy: 0.5811\n",
      "Epoch 588/5000\n",
      "11864/11864 [==============================] - 7s 566us/step - loss: 0.0989 - accuracy: 0.5959 - val_loss: 0.1033 - val_accuracy: 0.5787\n",
      "Epoch 589/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0990 - accuracy: 0.5938 - val_loss: 0.1027 - val_accuracy: 0.5766\n",
      "Epoch 590/5000\n",
      "11864/11864 [==============================] - 7s 565us/step - loss: 0.0989 - accuracy: 0.5955 - val_loss: 0.1024 - val_accuracy: 0.5784\n",
      "Epoch 591/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0990 - accuracy: 0.5947 - val_loss: 0.1023 - val_accuracy: 0.5794\n",
      "Epoch 592/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0990 - accuracy: 0.5949 - val_loss: 0.1021 - val_accuracy: 0.5816\n",
      "Epoch 593/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0988 - accuracy: 0.5955 - val_loss: 0.1023 - val_accuracy: 0.5792\n",
      "Epoch 594/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0990 - accuracy: 0.5950 - val_loss: 0.1021 - val_accuracy: 0.5820\n",
      "Epoch 595/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0989 - accuracy: 0.5948 - val_loss: 0.1030 - val_accuracy: 0.5797\n",
      "Epoch 596/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0989 - accuracy: 0.5943 - val_loss: 0.1027 - val_accuracy: 0.5766\n",
      "Epoch 597/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0990 - accuracy: 0.5948 - val_loss: 0.1031 - val_accuracy: 0.5768\n",
      "Epoch 598/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0988 - accuracy: 0.5948 - val_loss: 0.1029 - val_accuracy: 0.5780\n",
      "Epoch 599/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0989 - accuracy: 0.5948 - val_loss: 0.1039 - val_accuracy: 0.5769\n",
      "Epoch 600/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0990 - accuracy: 0.5947 - val_loss: 0.1029 - val_accuracy: 0.5741\n",
      "Epoch 601/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0988 - accuracy: 0.5955 - val_loss: 0.1023 - val_accuracy: 0.5826\n",
      "Epoch 602/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0989 - accuracy: 0.5950 - val_loss: 0.1026 - val_accuracy: 0.5787\n",
      "Epoch 603/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0989 - accuracy: 0.5956 - val_loss: 0.1022 - val_accuracy: 0.5804\n",
      "Epoch 604/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0988 - accuracy: 0.5958 - val_loss: 0.1027 - val_accuracy: 0.5768\n",
      "Epoch 605/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0989 - accuracy: 0.5948 - val_loss: 0.1022 - val_accuracy: 0.5795\n",
      "Epoch 606/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0989 - accuracy: 0.5948 - val_loss: 0.1028 - val_accuracy: 0.5804\n",
      "Epoch 607/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0989 - accuracy: 0.5950 - val_loss: 0.1025 - val_accuracy: 0.5792\n",
      "Epoch 608/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0990 - accuracy: 0.5950 - val_loss: 0.1029 - val_accuracy: 0.5767\n",
      "Epoch 609/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0988 - accuracy: 0.5954 - val_loss: 0.1026 - val_accuracy: 0.5785\n",
      "Epoch 610/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0989 - accuracy: 0.5947 - val_loss: 0.1020 - val_accuracy: 0.5812\n",
      "Epoch 611/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0989 - accuracy: 0.5950 - val_loss: 0.1029 - val_accuracy: 0.5761\n",
      "Epoch 612/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0988 - accuracy: 0.5955 - val_loss: 0.1023 - val_accuracy: 0.5818\n",
      "Epoch 613/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0989 - accuracy: 0.5955 - val_loss: 0.1027 - val_accuracy: 0.5802\n",
      "Epoch 614/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0988 - accuracy: 0.5956 - val_loss: 0.1026 - val_accuracy: 0.5796\n",
      "Epoch 615/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0988 - accuracy: 0.5952 - val_loss: 0.1022 - val_accuracy: 0.5797\n",
      "Epoch 616/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0988 - accuracy: 0.5952 - val_loss: 0.1021 - val_accuracy: 0.5788\n",
      "Epoch 617/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0989 - accuracy: 0.5949 - val_loss: 0.1023 - val_accuracy: 0.5806\n",
      "Epoch 618/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0989 - accuracy: 0.5955 - val_loss: 0.1025 - val_accuracy: 0.5793\n",
      "Epoch 619/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0990 - accuracy: 0.5952 - val_loss: 0.1026 - val_accuracy: 0.5803\n",
      "Epoch 620/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0988 - accuracy: 0.5959 - val_loss: 0.1025 - val_accuracy: 0.5794\n",
      "Epoch 621/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0988 - accuracy: 0.5955 - val_loss: 0.1027 - val_accuracy: 0.5783\n",
      "Epoch 622/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0989 - accuracy: 0.5953 - val_loss: 0.1027 - val_accuracy: 0.5785\n",
      "Epoch 623/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0989 - accuracy: 0.5952 - val_loss: 0.1021 - val_accuracy: 0.5785\n",
      "Epoch 624/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0988 - accuracy: 0.5949 - val_loss: 0.1025 - val_accuracy: 0.5803\n",
      "Epoch 625/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0989 - accuracy: 0.5952 - val_loss: 0.1023 - val_accuracy: 0.5808\n",
      "Epoch 626/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0988 - accuracy: 0.5944 - val_loss: 0.1025 - val_accuracy: 0.5798\n",
      "Epoch 627/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0988 - accuracy: 0.5954 - val_loss: 0.1024 - val_accuracy: 0.5788\n",
      "Epoch 628/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0989 - accuracy: 0.5951 - val_loss: 0.1028 - val_accuracy: 0.5783\n",
      "Epoch 629/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0989 - accuracy: 0.5946 - val_loss: 0.1027 - val_accuracy: 0.5784\n",
      "Epoch 630/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0988 - accuracy: 0.5958 - val_loss: 0.1037 - val_accuracy: 0.5734\n",
      "Epoch 631/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0989 - accuracy: 0.5952 - val_loss: 0.1024 - val_accuracy: 0.5806\n",
      "Epoch 632/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0989 - accuracy: 0.5942 - val_loss: 0.1023 - val_accuracy: 0.5811\n",
      "Epoch 633/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0988 - accuracy: 0.5950 - val_loss: 0.1019 - val_accuracy: 0.5796\n",
      "Epoch 634/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0988 - accuracy: 0.5952 - val_loss: 0.1021 - val_accuracy: 0.5783\n",
      "Epoch 635/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0987 - accuracy: 0.5963 - val_loss: 0.1029 - val_accuracy: 0.5780\n",
      "Epoch 636/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0988 - accuracy: 0.5957 - val_loss: 0.1022 - val_accuracy: 0.5812\n",
      "Epoch 637/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0988 - accuracy: 0.5955 - val_loss: 0.1026 - val_accuracy: 0.5789\n",
      "Epoch 638/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0988 - accuracy: 0.5960 - val_loss: 0.1026 - val_accuracy: 0.5793\n",
      "Epoch 639/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0989 - accuracy: 0.5952 - val_loss: 0.1028 - val_accuracy: 0.5819\n",
      "Epoch 640/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0988 - accuracy: 0.5956 - val_loss: 0.1025 - val_accuracy: 0.5792\n",
      "Epoch 641/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0987 - accuracy: 0.5963 - val_loss: 0.1024 - val_accuracy: 0.5794\n",
      "Epoch 642/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0988 - accuracy: 0.5957 - val_loss: 0.1027 - val_accuracy: 0.5798\n",
      "Epoch 643/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0988 - accuracy: 0.5952 - val_loss: 0.1028 - val_accuracy: 0.5790\n",
      "Epoch 644/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0987 - accuracy: 0.5956 - val_loss: 0.1023 - val_accuracy: 0.5809\n",
      "Epoch 645/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0988 - accuracy: 0.5963 - val_loss: 0.1025 - val_accuracy: 0.5787\n",
      "Epoch 646/5000\n",
      "11864/11864 [==============================] - 7s 565us/step - loss: 0.0988 - accuracy: 0.5952 - val_loss: 0.1026 - val_accuracy: 0.5773\n",
      "Epoch 647/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0988 - accuracy: 0.5951 - val_loss: 0.1021 - val_accuracy: 0.5821\n",
      "Epoch 648/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0988 - accuracy: 0.5953 - val_loss: 0.1024 - val_accuracy: 0.5799\n",
      "Epoch 649/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0989 - accuracy: 0.5958 - val_loss: 0.1025 - val_accuracy: 0.5783\n",
      "Epoch 650/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0989 - accuracy: 0.5945 - val_loss: 0.1023 - val_accuracy: 0.5808\n",
      "Epoch 651/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0988 - accuracy: 0.5956 - val_loss: 0.1031 - val_accuracy: 0.5784\n",
      "Epoch 652/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0988 - accuracy: 0.5957 - val_loss: 0.1026 - val_accuracy: 0.5772\n",
      "Epoch 653/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0987 - accuracy: 0.5961 - val_loss: 0.1020 - val_accuracy: 0.5796\n",
      "Epoch 654/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0988 - accuracy: 0.5946 - val_loss: 0.1024 - val_accuracy: 0.5816\n",
      "Epoch 655/5000\n",
      "11864/11864 [==============================] - 7s 565us/step - loss: 0.0988 - accuracy: 0.5956 - val_loss: 0.1023 - val_accuracy: 0.5791\n",
      "Epoch 656/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0988 - accuracy: 0.5959 - val_loss: 0.1023 - val_accuracy: 0.5807\n",
      "Epoch 657/5000\n",
      "11864/11864 [==============================] - 7s 566us/step - loss: 0.0988 - accuracy: 0.5947 - val_loss: 0.1026 - val_accuracy: 0.5785\n",
      "Epoch 658/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0988 - accuracy: 0.5959 - val_loss: 0.1021 - val_accuracy: 0.5797\n",
      "Epoch 659/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0988 - accuracy: 0.5962 - val_loss: 0.1023 - val_accuracy: 0.5807\n",
      "Epoch 660/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0988 - accuracy: 0.5967 - val_loss: 0.1024 - val_accuracy: 0.5792\n",
      "Epoch 661/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0988 - accuracy: 0.5954 - val_loss: 0.1024 - val_accuracy: 0.5805\n",
      "Epoch 662/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0988 - accuracy: 0.5959 - val_loss: 0.1026 - val_accuracy: 0.5803\n",
      "Epoch 663/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0988 - accuracy: 0.5955 - val_loss: 0.1023 - val_accuracy: 0.5804\n",
      "Epoch 664/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0988 - accuracy: 0.5953 - val_loss: 0.1033 - val_accuracy: 0.5763\n",
      "Epoch 665/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0987 - accuracy: 0.5960 - val_loss: 0.1027 - val_accuracy: 0.5820\n",
      "Epoch 666/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0988 - accuracy: 0.5959 - val_loss: 0.1029 - val_accuracy: 0.5777\n",
      "Epoch 667/5000\n",
      "11864/11864 [==============================] - 7s 564us/step - loss: 0.0988 - accuracy: 0.5957 - val_loss: 0.1019 - val_accuracy: 0.5791\n",
      "Epoch 668/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0987 - accuracy: 0.5965 - val_loss: 0.1021 - val_accuracy: 0.5814\n",
      "Epoch 669/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0988 - accuracy: 0.5959 - val_loss: 0.1020 - val_accuracy: 0.5803\n",
      "Epoch 670/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0988 - accuracy: 0.5959 - val_loss: 0.1032 - val_accuracy: 0.5767\n",
      "Epoch 671/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0988 - accuracy: 0.5956 - val_loss: 0.1034 - val_accuracy: 0.5773\n",
      "Epoch 672/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0988 - accuracy: 0.5961 - val_loss: 0.1024 - val_accuracy: 0.5787\n",
      "Epoch 673/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0989 - accuracy: 0.5953 - val_loss: 0.1023 - val_accuracy: 0.5803\n",
      "Epoch 674/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0986 - accuracy: 0.5960 - val_loss: 0.1031 - val_accuracy: 0.5781\n",
      "Epoch 675/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0988 - accuracy: 0.5950 - val_loss: 0.1017 - val_accuracy: 0.5822\n",
      "Epoch 676/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0988 - accuracy: 0.5951 - val_loss: 0.1028 - val_accuracy: 0.5791\n",
      "Epoch 677/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0987 - accuracy: 0.5955 - val_loss: 0.1024 - val_accuracy: 0.5795\n",
      "Epoch 678/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0988 - accuracy: 0.5953 - val_loss: 0.1017 - val_accuracy: 0.5812\n",
      "Epoch 679/5000\n",
      "11864/11864 [==============================] - 7s 564us/step - loss: 0.0987 - accuracy: 0.5962 - val_loss: 0.1023 - val_accuracy: 0.5801\n",
      "Epoch 680/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0988 - accuracy: 0.5958 - val_loss: 0.1027 - val_accuracy: 0.5797\n",
      "Epoch 681/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0987 - accuracy: 0.5955 - val_loss: 0.1025 - val_accuracy: 0.5795\n",
      "Epoch 682/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0988 - accuracy: 0.5959 - val_loss: 0.1023 - val_accuracy: 0.5793\n",
      "Epoch 683/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0989 - accuracy: 0.5957 - val_loss: 0.1031 - val_accuracy: 0.5786\n",
      "Epoch 684/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0989 - accuracy: 0.5960 - val_loss: 0.1022 - val_accuracy: 0.5786\n",
      "Epoch 685/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0988 - accuracy: 0.5952 - val_loss: 0.1021 - val_accuracy: 0.5781\n",
      "Epoch 686/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0988 - accuracy: 0.5957 - val_loss: 0.1031 - val_accuracy: 0.5759\n",
      "Epoch 687/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0988 - accuracy: 0.5958 - val_loss: 0.1024 - val_accuracy: 0.5803\n",
      "Epoch 688/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0988 - accuracy: 0.5963 - val_loss: 0.1028 - val_accuracy: 0.5780\n",
      "Epoch 689/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0987 - accuracy: 0.5969 - val_loss: 0.1025 - val_accuracy: 0.5805\n",
      "Epoch 690/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0988 - accuracy: 0.5963 - val_loss: 0.1024 - val_accuracy: 0.5785\n",
      "Epoch 691/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0987 - accuracy: 0.5965 - val_loss: 0.1023 - val_accuracy: 0.5805\n",
      "Epoch 692/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0988 - accuracy: 0.5960 - val_loss: 0.1026 - val_accuracy: 0.5784\n",
      "Epoch 693/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0988 - accuracy: 0.5958 - val_loss: 0.1024 - val_accuracy: 0.5787\n",
      "Epoch 694/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0988 - accuracy: 0.5962 - val_loss: 0.1028 - val_accuracy: 0.5773\n",
      "Epoch 695/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0988 - accuracy: 0.5960 - val_loss: 0.1026 - val_accuracy: 0.5784\n",
      "Epoch 696/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0987 - accuracy: 0.5960 - val_loss: 0.1018 - val_accuracy: 0.5807\n",
      "Epoch 697/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0987 - accuracy: 0.5952 - val_loss: 0.1025 - val_accuracy: 0.5795\n",
      "Epoch 698/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0987 - accuracy: 0.5962 - val_loss: 0.1021 - val_accuracy: 0.5810\n",
      "Epoch 699/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0987 - accuracy: 0.5965 - val_loss: 0.1031 - val_accuracy: 0.5766\n",
      "Epoch 700/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0987 - accuracy: 0.5959 - val_loss: 0.1027 - val_accuracy: 0.5776\n",
      "Epoch 701/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0988 - accuracy: 0.5958 - val_loss: 0.1024 - val_accuracy: 0.5798\n",
      "Epoch 702/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0988 - accuracy: 0.5955 - val_loss: 0.1028 - val_accuracy: 0.5780\n",
      "Epoch 703/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0988 - accuracy: 0.5951 - val_loss: 0.1024 - val_accuracy: 0.5804\n",
      "Epoch 704/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0987 - accuracy: 0.5956 - val_loss: 0.1023 - val_accuracy: 0.5806\n",
      "Epoch 705/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0987 - accuracy: 0.5962 - val_loss: 0.1029 - val_accuracy: 0.5787\n",
      "Epoch 706/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0988 - accuracy: 0.5964 - val_loss: 0.1022 - val_accuracy: 0.5802\n",
      "Epoch 707/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0987 - accuracy: 0.5961 - val_loss: 0.1021 - val_accuracy: 0.5795\n",
      "Epoch 708/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0988 - accuracy: 0.5956 - val_loss: 0.1024 - val_accuracy: 0.5780\n",
      "Epoch 709/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0987 - accuracy: 0.5963 - val_loss: 0.1021 - val_accuracy: 0.5803\n",
      "Epoch 710/5000\n",
      "11864/11864 [==============================] - 7s 566us/step - loss: 0.0988 - accuracy: 0.5958 - val_loss: 0.1025 - val_accuracy: 0.5792\n",
      "Epoch 711/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0988 - accuracy: 0.5956 - val_loss: 0.1022 - val_accuracy: 0.5816\n",
      "Epoch 712/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0987 - accuracy: 0.5961 - val_loss: 0.1021 - val_accuracy: 0.5813\n",
      "Epoch 713/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0987 - accuracy: 0.5963 - val_loss: 0.1031 - val_accuracy: 0.5746\n",
      "Epoch 714/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0987 - accuracy: 0.5959 - val_loss: 0.1026 - val_accuracy: 0.5808\n",
      "Epoch 715/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0988 - accuracy: 0.5958 - val_loss: 0.1025 - val_accuracy: 0.5783\n",
      "Epoch 716/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0986 - accuracy: 0.5963 - val_loss: 0.1023 - val_accuracy: 0.5805\n",
      "Epoch 717/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0988 - accuracy: 0.5960 - val_loss: 0.1026 - val_accuracy: 0.5772\n",
      "Epoch 718/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0987 - accuracy: 0.5960 - val_loss: 0.1024 - val_accuracy: 0.5811\n",
      "Epoch 719/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0988 - accuracy: 0.5956 - val_loss: 0.1020 - val_accuracy: 0.5786\n",
      "Epoch 720/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0988 - accuracy: 0.5956 - val_loss: 0.1028 - val_accuracy: 0.5795\n",
      "Epoch 721/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0987 - accuracy: 0.5961 - val_loss: 0.1030 - val_accuracy: 0.5792\n",
      "Epoch 722/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0988 - accuracy: 0.5959 - val_loss: 0.1021 - val_accuracy: 0.5790\n",
      "Epoch 723/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0988 - accuracy: 0.5955 - val_loss: 0.1032 - val_accuracy: 0.5780\n",
      "Epoch 724/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0987 - accuracy: 0.5959 - val_loss: 0.1025 - val_accuracy: 0.5792\n",
      "Epoch 725/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0987 - accuracy: 0.5959 - val_loss: 0.1022 - val_accuracy: 0.5810\n",
      "Epoch 726/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0988 - accuracy: 0.5962 - val_loss: 0.1026 - val_accuracy: 0.5804\n",
      "Epoch 727/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0987 - accuracy: 0.5967 - val_loss: 0.1023 - val_accuracy: 0.5796\n",
      "Epoch 728/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0988 - accuracy: 0.5963 - val_loss: 0.1021 - val_accuracy: 0.5798\n",
      "Epoch 729/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0987 - accuracy: 0.5960 - val_loss: 0.1023 - val_accuracy: 0.5802\n",
      "Epoch 730/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0987 - accuracy: 0.5960 - val_loss: 0.1021 - val_accuracy: 0.5814\n",
      "Epoch 731/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0987 - accuracy: 0.5959 - val_loss: 0.1025 - val_accuracy: 0.5790\n",
      "Epoch 732/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0988 - accuracy: 0.5959 - val_loss: 0.1029 - val_accuracy: 0.5793\n",
      "Epoch 733/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0988 - accuracy: 0.5960 - val_loss: 0.1022 - val_accuracy: 0.5819\n",
      "Epoch 734/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0987 - accuracy: 0.5957 - val_loss: 0.1023 - val_accuracy: 0.5782\n",
      "Epoch 735/5000\n",
      "11864/11864 [==============================] - 7s 564us/step - loss: 0.0987 - accuracy: 0.5959 - val_loss: 0.1025 - val_accuracy: 0.5806\n",
      "Epoch 736/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0987 - accuracy: 0.5969 - val_loss: 0.1037 - val_accuracy: 0.5722\n",
      "Epoch 737/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0988 - accuracy: 0.5963 - val_loss: 0.1019 - val_accuracy: 0.5822\n",
      "Epoch 738/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0987 - accuracy: 0.5961 - val_loss: 0.1028 - val_accuracy: 0.5765\n",
      "Epoch 739/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0987 - accuracy: 0.5960 - val_loss: 0.1025 - val_accuracy: 0.5781\n",
      "Epoch 740/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0987 - accuracy: 0.5962 - val_loss: 0.1030 - val_accuracy: 0.5740\n",
      "Epoch 741/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0988 - accuracy: 0.5966 - val_loss: 0.1027 - val_accuracy: 0.5789\n",
      "Epoch 742/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0987 - accuracy: 0.5955 - val_loss: 0.1026 - val_accuracy: 0.5809\n",
      "Epoch 743/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0988 - accuracy: 0.5959 - val_loss: 0.1024 - val_accuracy: 0.5791\n",
      "Epoch 744/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0987 - accuracy: 0.5962 - val_loss: 0.1027 - val_accuracy: 0.5784\n",
      "Epoch 745/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0987 - accuracy: 0.5963 - val_loss: 0.1020 - val_accuracy: 0.5813\n",
      "Epoch 746/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0987 - accuracy: 0.5959 - val_loss: 0.1031 - val_accuracy: 0.5767\n",
      "Epoch 747/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0988 - accuracy: 0.5957 - val_loss: 0.1020 - val_accuracy: 0.5833\n",
      "Epoch 748/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0987 - accuracy: 0.5962 - val_loss: 0.1028 - val_accuracy: 0.5789\n",
      "Epoch 749/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0987 - accuracy: 0.5967 - val_loss: 0.1029 - val_accuracy: 0.5788\n",
      "Epoch 750/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0988 - accuracy: 0.5955 - val_loss: 0.1033 - val_accuracy: 0.5778\n",
      "Epoch 751/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0987 - accuracy: 0.5950 - val_loss: 0.1027 - val_accuracy: 0.5797\n",
      "Epoch 752/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0988 - accuracy: 0.5960 - val_loss: 0.1026 - val_accuracy: 0.5783\n",
      "Epoch 753/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0989 - accuracy: 0.5955 - val_loss: 0.1020 - val_accuracy: 0.5809\n",
      "Epoch 754/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0987 - accuracy: 0.5964 - val_loss: 0.1030 - val_accuracy: 0.5765\n",
      "Epoch 755/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0987 - accuracy: 0.5959 - val_loss: 0.1027 - val_accuracy: 0.5782\n",
      "Epoch 756/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0987 - accuracy: 0.5963 - val_loss: 0.1022 - val_accuracy: 0.5818\n",
      "Epoch 757/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0987 - accuracy: 0.5957 - val_loss: 0.1031 - val_accuracy: 0.5787\n",
      "Epoch 758/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0988 - accuracy: 0.5962 - val_loss: 0.1031 - val_accuracy: 0.5770\n",
      "Epoch 759/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0987 - accuracy: 0.5958 - val_loss: 0.1021 - val_accuracy: 0.5817\n",
      "Epoch 760/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0987 - accuracy: 0.5952 - val_loss: 0.1018 - val_accuracy: 0.5809\n",
      "Epoch 761/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0987 - accuracy: 0.5964 - val_loss: 0.1018 - val_accuracy: 0.5825\n",
      "Epoch 762/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0988 - accuracy: 0.5963 - val_loss: 0.1030 - val_accuracy: 0.5785\n",
      "Epoch 763/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0986 - accuracy: 0.5969 - val_loss: 0.1018 - val_accuracy: 0.5827\n",
      "Epoch 764/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0986 - accuracy: 0.5961 - val_loss: 0.1023 - val_accuracy: 0.5796\n",
      "Epoch 765/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0987 - accuracy: 0.5957 - val_loss: 0.1017 - val_accuracy: 0.5826\n",
      "Epoch 766/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0986 - accuracy: 0.5969 - val_loss: 0.1029 - val_accuracy: 0.5793\n",
      "Epoch 767/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0988 - accuracy: 0.5956 - val_loss: 0.1021 - val_accuracy: 0.5808\n",
      "Epoch 768/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0987 - accuracy: 0.5966 - val_loss: 0.1023 - val_accuracy: 0.5817\n",
      "Epoch 769/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0987 - accuracy: 0.5965 - val_loss: 0.1022 - val_accuracy: 0.5805\n",
      "Epoch 770/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0986 - accuracy: 0.5967 - val_loss: 0.1022 - val_accuracy: 0.5812\n",
      "Epoch 771/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0987 - accuracy: 0.5963 - val_loss: 0.1025 - val_accuracy: 0.5825\n",
      "Epoch 772/5000\n",
      "11864/11864 [==============================] - 7s 564us/step - loss: 0.0987 - accuracy: 0.5964 - val_loss: 0.1032 - val_accuracy: 0.5756\n",
      "Epoch 773/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0987 - accuracy: 0.5964 - val_loss: 0.1021 - val_accuracy: 0.5799\n",
      "Epoch 774/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0987 - accuracy: 0.5965 - val_loss: 0.1020 - val_accuracy: 0.5806\n",
      "Epoch 775/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0987 - accuracy: 0.5959 - val_loss: 0.1030 - val_accuracy: 0.5757\n",
      "Epoch 776/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0987 - accuracy: 0.5963 - val_loss: 0.1025 - val_accuracy: 0.5791\n",
      "Epoch 777/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0987 - accuracy: 0.5967 - val_loss: 0.1027 - val_accuracy: 0.5773\n",
      "Epoch 778/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0987 - accuracy: 0.5961 - val_loss: 0.1024 - val_accuracy: 0.5813\n",
      "Epoch 779/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0986 - accuracy: 0.5968 - val_loss: 0.1026 - val_accuracy: 0.5779\n",
      "Epoch 780/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0987 - accuracy: 0.5967 - val_loss: 0.1024 - val_accuracy: 0.5806\n",
      "Epoch 781/5000\n",
      "11864/11864 [==============================] - 7s 566us/step - loss: 0.0988 - accuracy: 0.5960 - val_loss: 0.1022 - val_accuracy: 0.5805\n",
      "Epoch 782/5000\n",
      "11864/11864 [==============================] - 7s 564us/step - loss: 0.0987 - accuracy: 0.5960 - val_loss: 0.1021 - val_accuracy: 0.5811\n",
      "Epoch 783/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0987 - accuracy: 0.5962 - val_loss: 0.1023 - val_accuracy: 0.5786\n",
      "Epoch 784/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0987 - accuracy: 0.5965 - val_loss: 0.1022 - val_accuracy: 0.5793\n",
      "Epoch 785/5000\n",
      "11864/11864 [==============================] - 7s 564us/step - loss: 0.0988 - accuracy: 0.5961 - val_loss: 0.1029 - val_accuracy: 0.5761\n",
      "Epoch 786/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0987 - accuracy: 0.5965 - val_loss: 0.1020 - val_accuracy: 0.5811\n",
      "Epoch 787/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0986 - accuracy: 0.5964 - val_loss: 0.1030 - val_accuracy: 0.5803\n",
      "Epoch 788/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0988 - accuracy: 0.5963 - val_loss: 0.1021 - val_accuracy: 0.5816\n",
      "Epoch 789/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0986 - accuracy: 0.5963 - val_loss: 0.1024 - val_accuracy: 0.5797\n",
      "Epoch 790/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0988 - accuracy: 0.5957 - val_loss: 0.1025 - val_accuracy: 0.5809\n",
      "Epoch 791/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0987 - accuracy: 0.5958 - val_loss: 0.1022 - val_accuracy: 0.5835\n",
      "Epoch 792/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0987 - accuracy: 0.5961 - val_loss: 0.1024 - val_accuracy: 0.5788\n",
      "Epoch 793/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0987 - accuracy: 0.5965 - val_loss: 0.1026 - val_accuracy: 0.5806\n",
      "Epoch 794/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0987 - accuracy: 0.5957 - val_loss: 0.1024 - val_accuracy: 0.5811\n",
      "Epoch 795/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0988 - accuracy: 0.5960 - val_loss: 0.1024 - val_accuracy: 0.5804\n",
      "Epoch 796/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0987 - accuracy: 0.5966 - val_loss: 0.1031 - val_accuracy: 0.5762\n",
      "Epoch 797/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0988 - accuracy: 0.5956 - val_loss: 0.1027 - val_accuracy: 0.5803\n",
      "Epoch 798/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0987 - accuracy: 0.5957 - val_loss: 0.1034 - val_accuracy: 0.5771\n",
      "Epoch 799/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0986 - accuracy: 0.5971 - val_loss: 0.1022 - val_accuracy: 0.5816\n",
      "Epoch 800/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0987 - accuracy: 0.5962 - val_loss: 0.1026 - val_accuracy: 0.5782\n",
      "Epoch 801/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0986 - accuracy: 0.5958 - val_loss: 0.1026 - val_accuracy: 0.5808\n",
      "Epoch 802/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0987 - accuracy: 0.5952 - val_loss: 0.1030 - val_accuracy: 0.5780\n",
      "Epoch 803/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0986 - accuracy: 0.5962 - val_loss: 0.1027 - val_accuracy: 0.5766\n",
      "Epoch 804/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0987 - accuracy: 0.5956 - val_loss: 0.1025 - val_accuracy: 0.5798\n",
      "Epoch 805/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0987 - accuracy: 0.5957 - val_loss: 0.1020 - val_accuracy: 0.5800\n",
      "Epoch 806/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0986 - accuracy: 0.5974 - val_loss: 0.1026 - val_accuracy: 0.5783\n",
      "Epoch 807/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0986 - accuracy: 0.5964 - val_loss: 0.1021 - val_accuracy: 0.5805\n",
      "Epoch 808/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0987 - accuracy: 0.5968 - val_loss: 0.1028 - val_accuracy: 0.5788\n",
      "Epoch 809/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0987 - accuracy: 0.5963 - val_loss: 0.1032 - val_accuracy: 0.5758\n",
      "Epoch 810/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0987 - accuracy: 0.5970 - val_loss: 0.1023 - val_accuracy: 0.5790\n",
      "Epoch 811/5000\n",
      "11864/11864 [==============================] - 7s 566us/step - loss: 0.0987 - accuracy: 0.5969 - val_loss: 0.1026 - val_accuracy: 0.5789\n",
      "Epoch 812/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0986 - accuracy: 0.5976 - val_loss: 0.1018 - val_accuracy: 0.5826\n",
      "Epoch 813/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0987 - accuracy: 0.5968 - val_loss: 0.1029 - val_accuracy: 0.5782\n",
      "Epoch 814/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0987 - accuracy: 0.5967 - val_loss: 0.1026 - val_accuracy: 0.5812\n",
      "Epoch 815/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0987 - accuracy: 0.5966 - val_loss: 0.1019 - val_accuracy: 0.5839\n",
      "Epoch 816/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0987 - accuracy: 0.5962 - val_loss: 0.1022 - val_accuracy: 0.5798\n",
      "Epoch 817/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0986 - accuracy: 0.5959 - val_loss: 0.1025 - val_accuracy: 0.5794\n",
      "Epoch 818/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0987 - accuracy: 0.5965 - val_loss: 0.1025 - val_accuracy: 0.5814\n",
      "Epoch 819/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0987 - accuracy: 0.5962 - val_loss: 0.1023 - val_accuracy: 0.5814\n",
      "Epoch 820/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0986 - accuracy: 0.5968 - val_loss: 0.1034 - val_accuracy: 0.5765\n",
      "Epoch 821/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0986 - accuracy: 0.5966 - val_loss: 0.1023 - val_accuracy: 0.5781\n",
      "Epoch 822/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0987 - accuracy: 0.5966 - val_loss: 0.1030 - val_accuracy: 0.5730\n",
      "Epoch 823/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0986 - accuracy: 0.5963 - val_loss: 0.1024 - val_accuracy: 0.5794\n",
      "Epoch 824/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0986 - accuracy: 0.5971 - val_loss: 0.1020 - val_accuracy: 0.5802\n",
      "Epoch 825/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0986 - accuracy: 0.5969 - val_loss: 0.1030 - val_accuracy: 0.5806\n",
      "Epoch 826/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0987 - accuracy: 0.5966 - val_loss: 0.1022 - val_accuracy: 0.5800\n",
      "Epoch 827/5000\n",
      "11864/11864 [==============================] - 7s 566us/step - loss: 0.0986 - accuracy: 0.5961 - val_loss: 0.1020 - val_accuracy: 0.5804\n",
      "Epoch 828/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0986 - accuracy: 0.5967 - val_loss: 0.1033 - val_accuracy: 0.5778\n",
      "Epoch 829/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0986 - accuracy: 0.5963 - val_loss: 0.1027 - val_accuracy: 0.5778\n",
      "Epoch 830/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0986 - accuracy: 0.5970 - val_loss: 0.1026 - val_accuracy: 0.5778\n",
      "Epoch 831/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0987 - accuracy: 0.5968 - val_loss: 0.1023 - val_accuracy: 0.5794\n",
      "Epoch 832/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0986 - accuracy: 0.5966 - val_loss: 0.1024 - val_accuracy: 0.5799\n",
      "Epoch 833/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0986 - accuracy: 0.5971 - val_loss: 0.1019 - val_accuracy: 0.5820\n",
      "Epoch 834/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0987 - accuracy: 0.5970 - val_loss: 0.1026 - val_accuracy: 0.5794\n",
      "Epoch 835/5000\n",
      "11864/11864 [==============================] - 7s 566us/step - loss: 0.0987 - accuracy: 0.5971 - val_loss: 0.1022 - val_accuracy: 0.5806\n",
      "Epoch 836/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0986 - accuracy: 0.5971 - val_loss: 0.1024 - val_accuracy: 0.5789\n",
      "Epoch 837/5000\n",
      "11864/11864 [==============================] - 7s 563us/step - loss: 0.0986 - accuracy: 0.5973 - val_loss: 0.1020 - val_accuracy: 0.5808\n",
      "Epoch 838/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0987 - accuracy: 0.5965 - val_loss: 0.1029 - val_accuracy: 0.5756\n",
      "Epoch 839/5000\n",
      "11864/11864 [==============================] - 7s 564us/step - loss: 0.0986 - accuracy: 0.5968 - val_loss: 0.1021 - val_accuracy: 0.5791\n",
      "Epoch 840/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0987 - accuracy: 0.5963 - val_loss: 0.1022 - val_accuracy: 0.5818\n",
      "Epoch 841/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0986 - accuracy: 0.5968 - val_loss: 0.1022 - val_accuracy: 0.5804\n",
      "Epoch 842/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0987 - accuracy: 0.5955 - val_loss: 0.1032 - val_accuracy: 0.5754\n",
      "Epoch 843/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0987 - accuracy: 0.5968 - val_loss: 0.1025 - val_accuracy: 0.5779\n",
      "Epoch 844/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0986 - accuracy: 0.5971 - val_loss: 0.1028 - val_accuracy: 0.5790\n",
      "Epoch 845/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0986 - accuracy: 0.5959 - val_loss: 0.1021 - val_accuracy: 0.5811\n",
      "Epoch 846/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0987 - accuracy: 0.5959 - val_loss: 0.1018 - val_accuracy: 0.5846\n",
      "Epoch 847/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0986 - accuracy: 0.5961 - val_loss: 0.1020 - val_accuracy: 0.5785\n",
      "Epoch 848/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0987 - accuracy: 0.5960 - val_loss: 0.1021 - val_accuracy: 0.5815\n",
      "Epoch 849/5000\n",
      "11864/11864 [==============================] - 7s 564us/step - loss: 0.0986 - accuracy: 0.5969 - val_loss: 0.1028 - val_accuracy: 0.5765\n",
      "Epoch 850/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0987 - accuracy: 0.5972 - val_loss: 0.1025 - val_accuracy: 0.5786\n",
      "Epoch 851/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0987 - accuracy: 0.5961 - val_loss: 0.1020 - val_accuracy: 0.5815\n",
      "Epoch 852/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0988 - accuracy: 0.5965 - val_loss: 0.1019 - val_accuracy: 0.5821\n",
      "Epoch 853/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0987 - accuracy: 0.5967 - val_loss: 0.1029 - val_accuracy: 0.5774\n",
      "Epoch 854/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0986 - accuracy: 0.5964 - val_loss: 0.1020 - val_accuracy: 0.5815\n",
      "Epoch 855/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0987 - accuracy: 0.5961 - val_loss: 0.1021 - val_accuracy: 0.5806\n",
      "Epoch 856/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0986 - accuracy: 0.5966 - val_loss: 0.1027 - val_accuracy: 0.5802\n",
      "Epoch 857/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0987 - accuracy: 0.5959 - val_loss: 0.1022 - val_accuracy: 0.5799\n",
      "Epoch 858/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0987 - accuracy: 0.5965 - val_loss: 0.1026 - val_accuracy: 0.5820\n",
      "Epoch 859/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0987 - accuracy: 0.5959 - val_loss: 0.1020 - val_accuracy: 0.5823\n",
      "Epoch 860/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0987 - accuracy: 0.5963 - val_loss: 0.1019 - val_accuracy: 0.5820\n",
      "Epoch 861/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0986 - accuracy: 0.5968 - val_loss: 0.1026 - val_accuracy: 0.5774\n",
      "Epoch 862/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0987 - accuracy: 0.5960 - val_loss: 0.1020 - val_accuracy: 0.5805\n",
      "Epoch 863/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0986 - accuracy: 0.5970 - val_loss: 0.1021 - val_accuracy: 0.5821\n",
      "Epoch 864/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0986 - accuracy: 0.5966 - val_loss: 0.1027 - val_accuracy: 0.5794\n",
      "Epoch 865/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0986 - accuracy: 0.5969 - val_loss: 0.1031 - val_accuracy: 0.5763\n",
      "Epoch 866/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0986 - accuracy: 0.5966 - val_loss: 0.1026 - val_accuracy: 0.5802\n",
      "Epoch 867/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0986 - accuracy: 0.5966 - val_loss: 0.1029 - val_accuracy: 0.5768\n",
      "Epoch 868/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0987 - accuracy: 0.5964 - val_loss: 0.1023 - val_accuracy: 0.5820\n",
      "Epoch 869/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0987 - accuracy: 0.5975 - val_loss: 0.1029 - val_accuracy: 0.5790\n",
      "Epoch 870/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0986 - accuracy: 0.5965 - val_loss: 0.1019 - val_accuracy: 0.5835\n",
      "Epoch 871/5000\n",
      "11864/11864 [==============================] - 7s 563us/step - loss: 0.0985 - accuracy: 0.5965 - val_loss: 0.1022 - val_accuracy: 0.5832\n",
      "Epoch 872/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0986 - accuracy: 0.5968 - val_loss: 0.1023 - val_accuracy: 0.5810\n",
      "Epoch 873/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0986 - accuracy: 0.5968 - val_loss: 0.1023 - val_accuracy: 0.5819\n",
      "Epoch 874/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0987 - accuracy: 0.5965 - val_loss: 0.1020 - val_accuracy: 0.5812\n",
      "Epoch 875/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0986 - accuracy: 0.5964 - val_loss: 0.1021 - val_accuracy: 0.5810\n",
      "Epoch 876/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0987 - accuracy: 0.5957 - val_loss: 0.1018 - val_accuracy: 0.5793\n",
      "Epoch 877/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0987 - accuracy: 0.5951 - val_loss: 0.1021 - val_accuracy: 0.5822\n",
      "Epoch 878/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0987 - accuracy: 0.5962 - val_loss: 0.1021 - val_accuracy: 0.5802\n",
      "Epoch 879/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0986 - accuracy: 0.5962 - val_loss: 0.1026 - val_accuracy: 0.5708\n",
      "Epoch 880/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0987 - accuracy: 0.5963 - val_loss: 0.1024 - val_accuracy: 0.5788\n",
      "Epoch 881/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0986 - accuracy: 0.5968 - val_loss: 0.1025 - val_accuracy: 0.5800\n",
      "Epoch 882/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0987 - accuracy: 0.5961 - val_loss: 0.1026 - val_accuracy: 0.5757\n",
      "Epoch 883/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0987 - accuracy: 0.5962 - val_loss: 0.1027 - val_accuracy: 0.5791\n",
      "Epoch 884/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0987 - accuracy: 0.5959 - val_loss: 0.1021 - val_accuracy: 0.5782\n",
      "Epoch 885/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0988 - accuracy: 0.5961 - val_loss: 0.1019 - val_accuracy: 0.5816\n",
      "Epoch 886/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0987 - accuracy: 0.5959 - val_loss: 0.1027 - val_accuracy: 0.5788\n",
      "Epoch 887/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0987 - accuracy: 0.5964 - val_loss: 0.1017 - val_accuracy: 0.5812\n",
      "Epoch 888/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0986 - accuracy: 0.5968 - val_loss: 0.1022 - val_accuracy: 0.5822\n",
      "Epoch 889/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0987 - accuracy: 0.5958 - val_loss: 0.1024 - val_accuracy: 0.5793\n",
      "Epoch 890/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0986 - accuracy: 0.5964 - val_loss: 0.1024 - val_accuracy: 0.5794\n",
      "Epoch 891/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0987 - accuracy: 0.5957 - val_loss: 0.1030 - val_accuracy: 0.5785\n",
      "Epoch 892/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0986 - accuracy: 0.5967 - val_loss: 0.1024 - val_accuracy: 0.5814\n",
      "Epoch 893/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0987 - accuracy: 0.5956 - val_loss: 0.1024 - val_accuracy: 0.5799\n",
      "Epoch 894/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0985 - accuracy: 0.5968 - val_loss: 0.1029 - val_accuracy: 0.5802\n",
      "Epoch 895/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0986 - accuracy: 0.5969 - val_loss: 0.1026 - val_accuracy: 0.5798\n",
      "Epoch 896/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0987 - accuracy: 0.5964 - val_loss: 0.1021 - val_accuracy: 0.5794\n",
      "Epoch 897/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0987 - accuracy: 0.5962 - val_loss: 0.1021 - val_accuracy: 0.5799\n",
      "Epoch 898/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0986 - accuracy: 0.5967 - val_loss: 0.1018 - val_accuracy: 0.5808\n",
      "Epoch 899/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0986 - accuracy: 0.5970 - val_loss: 0.1020 - val_accuracy: 0.5785\n",
      "Epoch 900/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0986 - accuracy: 0.5967 - val_loss: 0.1022 - val_accuracy: 0.5804\n",
      "Epoch 901/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0987 - accuracy: 0.5960 - val_loss: 0.1021 - val_accuracy: 0.5776\n",
      "Epoch 902/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0986 - accuracy: 0.5966 - val_loss: 0.1025 - val_accuracy: 0.5785\n",
      "Epoch 903/5000\n",
      "11864/11864 [==============================] - 7s 566us/step - loss: 0.0987 - accuracy: 0.5963 - val_loss: 0.1029 - val_accuracy: 0.5799\n",
      "Epoch 904/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0986 - accuracy: 0.5963 - val_loss: 0.1019 - val_accuracy: 0.5802\n",
      "Epoch 905/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0986 - accuracy: 0.5970 - val_loss: 0.1030 - val_accuracy: 0.5767\n",
      "Epoch 906/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0985 - accuracy: 0.5973 - val_loss: 0.1018 - val_accuracy: 0.5812\n",
      "Epoch 907/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0986 - accuracy: 0.5968 - val_loss: 0.1022 - val_accuracy: 0.5796\n",
      "Epoch 908/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0985 - accuracy: 0.5971 - val_loss: 0.1027 - val_accuracy: 0.5800\n",
      "Epoch 909/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0987 - accuracy: 0.5973 - val_loss: 0.1026 - val_accuracy: 0.5789\n",
      "Epoch 910/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0986 - accuracy: 0.5969 - val_loss: 0.1023 - val_accuracy: 0.5793\n",
      "Epoch 911/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0986 - accuracy: 0.5966 - val_loss: 0.1020 - val_accuracy: 0.5821\n",
      "Epoch 912/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0986 - accuracy: 0.5966 - val_loss: 0.1018 - val_accuracy: 0.5829\n",
      "Epoch 913/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0986 - accuracy: 0.5970 - val_loss: 0.1019 - val_accuracy: 0.5811\n",
      "Epoch 914/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0986 - accuracy: 0.5966 - val_loss: 0.1027 - val_accuracy: 0.5795\n",
      "Epoch 915/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0986 - accuracy: 0.5966 - val_loss: 0.1024 - val_accuracy: 0.5757\n",
      "Epoch 916/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0986 - accuracy: 0.5973 - val_loss: 0.1022 - val_accuracy: 0.5813\n",
      "Epoch 917/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0987 - accuracy: 0.5970 - val_loss: 0.1022 - val_accuracy: 0.5808\n",
      "Epoch 918/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0986 - accuracy: 0.5969 - val_loss: 0.1026 - val_accuracy: 0.5784\n",
      "Epoch 919/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0986 - accuracy: 0.5969 - val_loss: 0.1025 - val_accuracy: 0.5772\n",
      "Epoch 920/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0987 - accuracy: 0.5969 - val_loss: 0.1020 - val_accuracy: 0.5803\n",
      "Epoch 921/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0986 - accuracy: 0.5964 - val_loss: 0.1022 - val_accuracy: 0.5825\n",
      "Epoch 922/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0986 - accuracy: 0.5970 - val_loss: 0.1019 - val_accuracy: 0.5813\n",
      "Epoch 923/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0985 - accuracy: 0.5973 - val_loss: 0.1022 - val_accuracy: 0.5799\n",
      "Epoch 924/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0986 - accuracy: 0.5967 - val_loss: 0.1020 - val_accuracy: 0.5831\n",
      "Epoch 925/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0986 - accuracy: 0.5963 - val_loss: 0.1022 - val_accuracy: 0.5807\n",
      "Epoch 926/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0986 - accuracy: 0.5965 - val_loss: 0.1027 - val_accuracy: 0.5816\n",
      "Epoch 927/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0985 - accuracy: 0.5971 - val_loss: 0.1020 - val_accuracy: 0.5819\n",
      "Epoch 928/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0985 - accuracy: 0.5969 - val_loss: 0.1024 - val_accuracy: 0.5814\n",
      "Epoch 929/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0986 - accuracy: 0.5973 - val_loss: 0.1025 - val_accuracy: 0.5785\n",
      "Epoch 930/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0985 - accuracy: 0.5967 - val_loss: 0.1026 - val_accuracy: 0.5788\n",
      "Epoch 931/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0985 - accuracy: 0.5971 - val_loss: 0.1027 - val_accuracy: 0.5759\n",
      "Epoch 932/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0986 - accuracy: 0.5964 - val_loss: 0.1027 - val_accuracy: 0.5776\n",
      "Epoch 933/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0986 - accuracy: 0.5963 - val_loss: 0.1023 - val_accuracy: 0.5775\n",
      "Epoch 934/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0985 - accuracy: 0.5973 - val_loss: 0.1025 - val_accuracy: 0.5770\n",
      "Epoch 935/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0986 - accuracy: 0.5970 - val_loss: 0.1022 - val_accuracy: 0.5817\n",
      "Epoch 936/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0986 - accuracy: 0.5968 - val_loss: 0.1025 - val_accuracy: 0.5793\n",
      "Epoch 937/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0984 - accuracy: 0.5969 - val_loss: 0.1028 - val_accuracy: 0.5817\n",
      "Epoch 938/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0985 - accuracy: 0.5965 - val_loss: 0.1025 - val_accuracy: 0.5793\n",
      "Epoch 939/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0986 - accuracy: 0.5971 - val_loss: 0.1024 - val_accuracy: 0.5802\n",
      "Epoch 940/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0985 - accuracy: 0.5972 - val_loss: 0.1019 - val_accuracy: 0.5810\n",
      "Epoch 941/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0984 - accuracy: 0.5972 - val_loss: 0.1026 - val_accuracy: 0.5810\n",
      "Epoch 942/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0986 - accuracy: 0.5970 - val_loss: 0.1027 - val_accuracy: 0.5816\n",
      "Epoch 943/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0986 - accuracy: 0.5969 - val_loss: 0.1029 - val_accuracy: 0.5786\n",
      "Epoch 944/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0984 - accuracy: 0.5966 - val_loss: 0.1026 - val_accuracy: 0.5796\n",
      "Epoch 945/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0985 - accuracy: 0.5963 - val_loss: 0.1020 - val_accuracy: 0.5794\n",
      "Epoch 946/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0985 - accuracy: 0.5965 - val_loss: 0.1018 - val_accuracy: 0.5817\n",
      "Epoch 947/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0986 - accuracy: 0.5969 - val_loss: 0.1022 - val_accuracy: 0.5800\n",
      "Epoch 948/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0986 - accuracy: 0.5963 - val_loss: 0.1029 - val_accuracy: 0.5768\n",
      "Epoch 949/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0986 - accuracy: 0.5972 - val_loss: 0.1028 - val_accuracy: 0.5777\n",
      "Epoch 950/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0985 - accuracy: 0.5967 - val_loss: 0.1023 - val_accuracy: 0.5791\n",
      "Epoch 951/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0985 - accuracy: 0.5966 - val_loss: 0.1024 - val_accuracy: 0.5788\n",
      "Epoch 952/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0985 - accuracy: 0.5969 - val_loss: 0.1026 - val_accuracy: 0.5806\n",
      "Epoch 953/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0985 - accuracy: 0.5975 - val_loss: 0.1023 - val_accuracy: 0.5789\n",
      "Epoch 954/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0985 - accuracy: 0.5976 - val_loss: 0.1018 - val_accuracy: 0.5828\n",
      "Epoch 955/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0985 - accuracy: 0.5969 - val_loss: 0.1025 - val_accuracy: 0.5819\n",
      "Epoch 956/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0985 - accuracy: 0.5971 - val_loss: 0.1022 - val_accuracy: 0.5809\n",
      "Epoch 957/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0985 - accuracy: 0.5963 - val_loss: 0.1025 - val_accuracy: 0.5791\n",
      "Epoch 958/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0986 - accuracy: 0.5966 - val_loss: 0.1022 - val_accuracy: 0.5797\n",
      "Epoch 959/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0985 - accuracy: 0.5977 - val_loss: 0.1020 - val_accuracy: 0.5831\n",
      "Epoch 960/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0986 - accuracy: 0.5963 - val_loss: 0.1034 - val_accuracy: 0.5739\n",
      "Epoch 961/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0985 - accuracy: 0.5965 - val_loss: 0.1027 - val_accuracy: 0.5738\n",
      "Epoch 962/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0985 - accuracy: 0.5968 - val_loss: 0.1020 - val_accuracy: 0.5816\n",
      "Epoch 963/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0985 - accuracy: 0.5974 - val_loss: 0.1025 - val_accuracy: 0.5779\n",
      "Epoch 964/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0985 - accuracy: 0.5979 - val_loss: 0.1029 - val_accuracy: 0.5790\n",
      "Epoch 965/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0985 - accuracy: 0.5970 - val_loss: 0.1023 - val_accuracy: 0.5782\n",
      "Epoch 966/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0983 - accuracy: 0.5980 - val_loss: 0.1019 - val_accuracy: 0.5803\n",
      "Epoch 967/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0986 - accuracy: 0.5962 - val_loss: 0.1024 - val_accuracy: 0.5813\n",
      "Epoch 968/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0986 - accuracy: 0.5963 - val_loss: 0.1022 - val_accuracy: 0.5790\n",
      "Epoch 969/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0986 - accuracy: 0.5966 - val_loss: 0.1021 - val_accuracy: 0.5825\n",
      "Epoch 970/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0985 - accuracy: 0.5965 - val_loss: 0.1028 - val_accuracy: 0.5782\n",
      "Epoch 971/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0985 - accuracy: 0.5976 - val_loss: 0.1026 - val_accuracy: 0.5821\n",
      "Epoch 972/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0985 - accuracy: 0.5976 - val_loss: 0.1028 - val_accuracy: 0.5789\n",
      "Epoch 973/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0985 - accuracy: 0.5978 - val_loss: 0.1021 - val_accuracy: 0.5802\n",
      "Epoch 974/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0984 - accuracy: 0.5978 - val_loss: 0.1028 - val_accuracy: 0.5781\n",
      "Epoch 975/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0984 - accuracy: 0.5975 - val_loss: 0.1023 - val_accuracy: 0.5826\n",
      "Epoch 976/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0984 - accuracy: 0.5973 - val_loss: 0.1020 - val_accuracy: 0.5799\n",
      "Epoch 977/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0985 - accuracy: 0.5971 - val_loss: 0.1019 - val_accuracy: 0.5805\n",
      "Epoch 978/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0985 - accuracy: 0.5975 - val_loss: 0.1025 - val_accuracy: 0.5791\n",
      "Epoch 979/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0985 - accuracy: 0.5976 - val_loss: 0.1020 - val_accuracy: 0.5831\n",
      "Epoch 980/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0985 - accuracy: 0.5973 - val_loss: 0.1027 - val_accuracy: 0.5766\n",
      "Epoch 981/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0985 - accuracy: 0.5966 - val_loss: 0.1032 - val_accuracy: 0.5769\n",
      "Epoch 982/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0986 - accuracy: 0.5972 - val_loss: 0.1024 - val_accuracy: 0.5809\n",
      "Epoch 983/5000\n",
      "11864/11864 [==============================] - 7s 565us/step - loss: 0.0985 - accuracy: 0.5970 - val_loss: 0.1023 - val_accuracy: 0.5829\n",
      "Epoch 984/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0985 - accuracy: 0.5966 - val_loss: 0.1024 - val_accuracy: 0.5826\n",
      "Epoch 985/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0985 - accuracy: 0.5970 - val_loss: 0.1022 - val_accuracy: 0.5813\n",
      "Epoch 986/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0985 - accuracy: 0.5977 - val_loss: 0.1020 - val_accuracy: 0.5795\n",
      "Epoch 987/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0985 - accuracy: 0.5966 - val_loss: 0.1027 - val_accuracy: 0.5785\n",
      "Epoch 988/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0985 - accuracy: 0.5968 - val_loss: 0.1027 - val_accuracy: 0.5786\n",
      "Epoch 989/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0985 - accuracy: 0.5962 - val_loss: 0.1028 - val_accuracy: 0.5789\n",
      "Epoch 990/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0985 - accuracy: 0.5975 - val_loss: 0.1022 - val_accuracy: 0.5816\n",
      "Epoch 991/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0985 - accuracy: 0.5976 - val_loss: 0.1028 - val_accuracy: 0.5806\n",
      "Epoch 992/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0985 - accuracy: 0.5974 - val_loss: 0.1023 - val_accuracy: 0.5810\n",
      "Epoch 993/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0985 - accuracy: 0.5971 - val_loss: 0.1022 - val_accuracy: 0.5795\n",
      "Epoch 994/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0985 - accuracy: 0.5974 - val_loss: 0.1026 - val_accuracy: 0.5782\n",
      "Epoch 995/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0985 - accuracy: 0.5966 - val_loss: 0.1020 - val_accuracy: 0.5829\n",
      "Epoch 996/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0985 - accuracy: 0.5968 - val_loss: 0.1024 - val_accuracy: 0.5822\n",
      "Epoch 997/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0986 - accuracy: 0.5972 - val_loss: 0.1023 - val_accuracy: 0.5797\n",
      "Epoch 998/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0985 - accuracy: 0.5964 - val_loss: 0.1026 - val_accuracy: 0.5766\n",
      "Epoch 999/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0985 - accuracy: 0.5972 - val_loss: 0.1028 - val_accuracy: 0.5757\n",
      "Epoch 1000/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0985 - accuracy: 0.5973 - val_loss: 0.1023 - val_accuracy: 0.5825\n",
      "Epoch 1001/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0984 - accuracy: 0.5977 - val_loss: 0.1024 - val_accuracy: 0.5786\n",
      "Epoch 1002/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0985 - accuracy: 0.5977 - val_loss: 0.1027 - val_accuracy: 0.5796\n",
      "Epoch 1003/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0986 - accuracy: 0.5963 - val_loss: 0.1025 - val_accuracy: 0.5792\n",
      "Epoch 1004/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0985 - accuracy: 0.5971 - val_loss: 0.1023 - val_accuracy: 0.5810\n",
      "Epoch 1005/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0984 - accuracy: 0.5972 - val_loss: 0.1030 - val_accuracy: 0.5741\n",
      "Epoch 1006/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0984 - accuracy: 0.5978 - val_loss: 0.1020 - val_accuracy: 0.5795\n",
      "Epoch 1007/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0985 - accuracy: 0.5970 - val_loss: 0.1021 - val_accuracy: 0.5806\n",
      "Epoch 1008/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0984 - accuracy: 0.5976 - val_loss: 0.1026 - val_accuracy: 0.5809\n",
      "Epoch 1009/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0985 - accuracy: 0.5971 - val_loss: 0.1028 - val_accuracy: 0.5806\n",
      "Epoch 1010/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0985 - accuracy: 0.5968 - val_loss: 0.1026 - val_accuracy: 0.5767\n",
      "Epoch 1011/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0985 - accuracy: 0.5970 - val_loss: 0.1025 - val_accuracy: 0.5796\n",
      "Epoch 1012/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0985 - accuracy: 0.5964 - val_loss: 0.1025 - val_accuracy: 0.5775\n",
      "Epoch 1013/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0985 - accuracy: 0.5974 - val_loss: 0.1024 - val_accuracy: 0.5802\n",
      "Epoch 1014/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0985 - accuracy: 0.5964 - val_loss: 0.1025 - val_accuracy: 0.5820\n",
      "Epoch 1015/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0984 - accuracy: 0.5969 - val_loss: 0.1024 - val_accuracy: 0.5803\n",
      "Epoch 1016/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0984 - accuracy: 0.5978 - val_loss: 0.1044 - val_accuracy: 0.5588\n",
      "Epoch 1017/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0985 - accuracy: 0.5975 - val_loss: 0.1024 - val_accuracy: 0.5806\n",
      "Epoch 1018/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0984 - accuracy: 0.5983 - val_loss: 0.1024 - val_accuracy: 0.5786\n",
      "Epoch 1019/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0985 - accuracy: 0.5973 - val_loss: 0.1024 - val_accuracy: 0.5787\n",
      "Epoch 1020/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0985 - accuracy: 0.5974 - val_loss: 0.1029 - val_accuracy: 0.5806\n",
      "Epoch 1021/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0985 - accuracy: 0.5980 - val_loss: 0.1024 - val_accuracy: 0.5823\n",
      "Epoch 1022/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0985 - accuracy: 0.5972 - val_loss: 0.1031 - val_accuracy: 0.5791\n",
      "Epoch 1023/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0985 - accuracy: 0.5974 - val_loss: 0.1026 - val_accuracy: 0.5787\n",
      "Epoch 1024/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0984 - accuracy: 0.5982 - val_loss: 0.1023 - val_accuracy: 0.5779\n",
      "Epoch 1025/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0985 - accuracy: 0.5967 - val_loss: 0.1027 - val_accuracy: 0.5818\n",
      "Epoch 1026/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0983 - accuracy: 0.5975 - val_loss: 0.1018 - val_accuracy: 0.5822\n",
      "Epoch 1027/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0984 - accuracy: 0.5976 - val_loss: 0.1023 - val_accuracy: 0.5798\n",
      "Epoch 1028/5000\n",
      "11864/11864 [==============================] - 7s 566us/step - loss: 0.0984 - accuracy: 0.5973 - val_loss: 0.1021 - val_accuracy: 0.5796\n",
      "Epoch 1029/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0985 - accuracy: 0.5968 - val_loss: 0.1025 - val_accuracy: 0.5782\n",
      "Epoch 1030/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0985 - accuracy: 0.5964 - val_loss: 0.1025 - val_accuracy: 0.5773\n",
      "Epoch 1031/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0984 - accuracy: 0.5972 - val_loss: 0.1024 - val_accuracy: 0.5803\n",
      "Epoch 1032/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0985 - accuracy: 0.5974 - val_loss: 0.1032 - val_accuracy: 0.5771\n",
      "Epoch 1033/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0986 - accuracy: 0.5966 - val_loss: 0.1023 - val_accuracy: 0.5817\n",
      "Epoch 1034/5000\n",
      "11864/11864 [==============================] - 7s 565us/step - loss: 0.0984 - accuracy: 0.5975 - val_loss: 0.1024 - val_accuracy: 0.5788\n",
      "Epoch 1035/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0985 - accuracy: 0.5976 - val_loss: 0.1027 - val_accuracy: 0.5811\n",
      "Epoch 1036/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0984 - accuracy: 0.5975 - val_loss: 0.1028 - val_accuracy: 0.5775\n",
      "Epoch 1037/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0984 - accuracy: 0.5972 - val_loss: 0.1023 - val_accuracy: 0.5780\n",
      "Epoch 1038/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0985 - accuracy: 0.5971 - val_loss: 0.1029 - val_accuracy: 0.5749\n",
      "Epoch 1039/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0984 - accuracy: 0.5970 - val_loss: 0.1030 - val_accuracy: 0.5797\n",
      "Epoch 1040/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0984 - accuracy: 0.5970 - val_loss: 0.1021 - val_accuracy: 0.5802\n",
      "Epoch 1041/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0985 - accuracy: 0.5973 - val_loss: 0.1027 - val_accuracy: 0.5798\n",
      "Epoch 1042/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0985 - accuracy: 0.5970 - val_loss: 0.1026 - val_accuracy: 0.5778\n",
      "Epoch 1043/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0984 - accuracy: 0.5974 - val_loss: 0.1026 - val_accuracy: 0.5775\n",
      "Epoch 1044/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0984 - accuracy: 0.5965 - val_loss: 0.1022 - val_accuracy: 0.5823\n",
      "Epoch 1045/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0985 - accuracy: 0.5968 - val_loss: 0.1025 - val_accuracy: 0.5789\n",
      "Epoch 1046/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0984 - accuracy: 0.5970 - val_loss: 0.1021 - val_accuracy: 0.5824\n",
      "Epoch 1047/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0984 - accuracy: 0.5974 - val_loss: 0.1030 - val_accuracy: 0.5780\n",
      "Epoch 1048/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0984 - accuracy: 0.5966 - val_loss: 0.1032 - val_accuracy: 0.5774\n",
      "Epoch 1049/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0986 - accuracy: 0.5963 - val_loss: 0.1026 - val_accuracy: 0.5793\n",
      "Epoch 1050/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0985 - accuracy: 0.5972 - val_loss: 0.1025 - val_accuracy: 0.5800\n",
      "Epoch 1051/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0985 - accuracy: 0.5968 - val_loss: 0.1024 - val_accuracy: 0.5804\n",
      "Epoch 1052/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0984 - accuracy: 0.5981 - val_loss: 0.1026 - val_accuracy: 0.5768\n",
      "Epoch 1053/5000\n",
      "11864/11864 [==============================] - 7s 566us/step - loss: 0.0984 - accuracy: 0.5970 - val_loss: 0.1024 - val_accuracy: 0.5789\n",
      "Epoch 1054/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0985 - accuracy: 0.5972 - val_loss: 0.1021 - val_accuracy: 0.5807\n",
      "Epoch 1055/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0985 - accuracy: 0.5977 - val_loss: 0.1023 - val_accuracy: 0.5802\n",
      "Epoch 1056/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0985 - accuracy: 0.5966 - val_loss: 0.1035 - val_accuracy: 0.5737\n",
      "Epoch 1057/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0984 - accuracy: 0.5971 - val_loss: 0.1022 - val_accuracy: 0.5790\n",
      "Epoch 1058/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0984 - accuracy: 0.5973 - val_loss: 0.1026 - val_accuracy: 0.5786\n",
      "Epoch 1059/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0985 - accuracy: 0.5965 - val_loss: 0.1028 - val_accuracy: 0.5799\n",
      "Epoch 1060/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0985 - accuracy: 0.5964 - val_loss: 0.1021 - val_accuracy: 0.5834\n",
      "Epoch 1061/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0984 - accuracy: 0.5967 - val_loss: 0.1026 - val_accuracy: 0.5815\n",
      "Epoch 1062/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0985 - accuracy: 0.5968 - val_loss: 0.1022 - val_accuracy: 0.5800\n",
      "Epoch 1063/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0984 - accuracy: 0.5970 - val_loss: 0.1029 - val_accuracy: 0.5786\n",
      "Epoch 1064/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0985 - accuracy: 0.5971 - val_loss: 0.1024 - val_accuracy: 0.5796\n",
      "Epoch 1065/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0985 - accuracy: 0.5975 - val_loss: 0.1020 - val_accuracy: 0.5818\n",
      "Epoch 1066/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0984 - accuracy: 0.5975 - val_loss: 0.1024 - val_accuracy: 0.5823\n",
      "Epoch 1067/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0984 - accuracy: 0.5968 - val_loss: 0.1022 - val_accuracy: 0.5799\n",
      "Epoch 1068/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0985 - accuracy: 0.5971 - val_loss: 0.1025 - val_accuracy: 0.5809\n",
      "Epoch 1069/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0984 - accuracy: 0.5965 - val_loss: 0.1030 - val_accuracy: 0.5777\n",
      "Epoch 1070/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0984 - accuracy: 0.5972 - val_loss: 0.1024 - val_accuracy: 0.5808\n",
      "Epoch 1071/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0984 - accuracy: 0.5971 - val_loss: 0.1026 - val_accuracy: 0.5818\n",
      "Epoch 1072/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0984 - accuracy: 0.5979 - val_loss: 0.1026 - val_accuracy: 0.5776\n",
      "Epoch 1073/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0985 - accuracy: 0.5961 - val_loss: 0.1024 - val_accuracy: 0.5794\n",
      "Epoch 1074/5000\n",
      "11864/11864 [==============================] - 7s 566us/step - loss: 0.0985 - accuracy: 0.5978 - val_loss: 0.1026 - val_accuracy: 0.5801\n",
      "Epoch 1075/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0985 - accuracy: 0.5970 - val_loss: 0.1022 - val_accuracy: 0.5814\n",
      "Epoch 1076/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0985 - accuracy: 0.5965 - val_loss: 0.1029 - val_accuracy: 0.5743\n",
      "Epoch 1077/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0985 - accuracy: 0.5967 - val_loss: 0.1023 - val_accuracy: 0.5818\n",
      "Epoch 1078/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0984 - accuracy: 0.5972 - val_loss: 0.1022 - val_accuracy: 0.5797\n",
      "Epoch 1079/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0984 - accuracy: 0.5969 - val_loss: 0.1027 - val_accuracy: 0.5835\n",
      "Epoch 1080/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0985 - accuracy: 0.5969 - val_loss: 0.1022 - val_accuracy: 0.5795\n",
      "Epoch 1081/5000\n",
      "11864/11864 [==============================] - 7s 565us/step - loss: 0.0984 - accuracy: 0.5970 - val_loss: 0.1026 - val_accuracy: 0.5798\n",
      "Epoch 1082/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0985 - accuracy: 0.5973 - val_loss: 0.1020 - val_accuracy: 0.5814\n",
      "Epoch 1083/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0985 - accuracy: 0.5971 - val_loss: 0.1019 - val_accuracy: 0.5818\n",
      "Epoch 1084/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0986 - accuracy: 0.5965 - val_loss: 0.1024 - val_accuracy: 0.5802\n",
      "Epoch 1085/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0985 - accuracy: 0.5973 - val_loss: 0.1025 - val_accuracy: 0.5803\n",
      "Epoch 1086/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0985 - accuracy: 0.5969 - val_loss: 0.1023 - val_accuracy: 0.5804\n",
      "Epoch 1087/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0985 - accuracy: 0.5978 - val_loss: 0.1025 - val_accuracy: 0.5819\n",
      "Epoch 1088/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0984 - accuracy: 0.5979 - val_loss: 0.1025 - val_accuracy: 0.5787\n",
      "Epoch 1089/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0984 - accuracy: 0.5966 - val_loss: 0.1024 - val_accuracy: 0.5780\n",
      "Epoch 1090/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0985 - accuracy: 0.5971 - val_loss: 0.1029 - val_accuracy: 0.5779\n",
      "Epoch 1091/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0985 - accuracy: 0.5964 - val_loss: 0.1029 - val_accuracy: 0.5790\n",
      "Epoch 1092/5000\n",
      "11864/11864 [==============================] - 7s 566us/step - loss: 0.0984 - accuracy: 0.5975 - val_loss: 0.1028 - val_accuracy: 0.5769\n",
      "Epoch 1093/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0986 - accuracy: 0.5973 - val_loss: 0.1023 - val_accuracy: 0.5803\n",
      "Epoch 1094/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0984 - accuracy: 0.5968 - val_loss: 0.1029 - val_accuracy: 0.5800\n",
      "Epoch 1095/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0984 - accuracy: 0.5975 - val_loss: 0.1025 - val_accuracy: 0.5800\n",
      "Epoch 1096/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0984 - accuracy: 0.5976 - val_loss: 0.1023 - val_accuracy: 0.5812\n",
      "Epoch 1097/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0984 - accuracy: 0.5974 - val_loss: 0.1025 - val_accuracy: 0.5812\n",
      "Epoch 1098/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0984 - accuracy: 0.5981 - val_loss: 0.1035 - val_accuracy: 0.5787\n",
      "Epoch 1099/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0985 - accuracy: 0.5968 - val_loss: 0.1024 - val_accuracy: 0.5789\n",
      "Epoch 1100/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0986 - accuracy: 0.5974 - val_loss: 0.1019 - val_accuracy: 0.5831\n",
      "Epoch 1101/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0985 - accuracy: 0.5966 - val_loss: 0.1024 - val_accuracy: 0.5785\n",
      "Epoch 1102/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0984 - accuracy: 0.5959 - val_loss: 0.1024 - val_accuracy: 0.5772\n",
      "Epoch 1103/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0984 - accuracy: 0.5971 - val_loss: 0.1020 - val_accuracy: 0.5830\n",
      "Epoch 1104/5000\n",
      "11864/11864 [==============================] - 7s 564us/step - loss: 0.0985 - accuracy: 0.5970 - val_loss: 0.1025 - val_accuracy: 0.5796\n",
      "Epoch 1105/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0984 - accuracy: 0.5969 - val_loss: 0.1024 - val_accuracy: 0.5775\n",
      "Epoch 1106/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0985 - accuracy: 0.5969 - val_loss: 0.1023 - val_accuracy: 0.5797\n",
      "Epoch 1107/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0985 - accuracy: 0.5966 - val_loss: 0.1019 - val_accuracy: 0.5798\n",
      "Epoch 1108/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0984 - accuracy: 0.5975 - val_loss: 0.1025 - val_accuracy: 0.5805\n",
      "Epoch 1109/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0984 - accuracy: 0.5969 - val_loss: 0.1028 - val_accuracy: 0.5778\n",
      "Epoch 1110/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0984 - accuracy: 0.5968 - val_loss: 0.1021 - val_accuracy: 0.5817\n",
      "Epoch 1111/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0984 - accuracy: 0.5971 - val_loss: 0.1025 - val_accuracy: 0.5802\n",
      "Epoch 1112/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0984 - accuracy: 0.5973 - val_loss: 0.1019 - val_accuracy: 0.5817\n",
      "Epoch 1113/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0984 - accuracy: 0.5977 - val_loss: 0.1024 - val_accuracy: 0.5771\n",
      "Epoch 1114/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0985 - accuracy: 0.5973 - val_loss: 0.1026 - val_accuracy: 0.5792\n",
      "Epoch 1115/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0984 - accuracy: 0.5979 - val_loss: 0.1024 - val_accuracy: 0.5797\n",
      "Epoch 1116/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0985 - accuracy: 0.5971 - val_loss: 0.1021 - val_accuracy: 0.5800\n",
      "Epoch 1117/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0984 - accuracy: 0.5976 - val_loss: 0.1022 - val_accuracy: 0.5792\n",
      "Epoch 1118/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0986 - accuracy: 0.5971 - val_loss: 0.1033 - val_accuracy: 0.5786\n",
      "Epoch 1119/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0985 - accuracy: 0.5978 - val_loss: 0.1024 - val_accuracy: 0.5799\n",
      "Epoch 1120/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0984 - accuracy: 0.5975 - val_loss: 0.1020 - val_accuracy: 0.5798\n",
      "Epoch 1121/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0984 - accuracy: 0.5970 - val_loss: 0.1022 - val_accuracy: 0.5794\n",
      "Epoch 1122/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0984 - accuracy: 0.5971 - val_loss: 0.1031 - val_accuracy: 0.5810\n",
      "Epoch 1123/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0985 - accuracy: 0.5972 - val_loss: 0.1023 - val_accuracy: 0.5812\n",
      "Epoch 1124/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0985 - accuracy: 0.5967 - val_loss: 0.1022 - val_accuracy: 0.5812\n",
      "Epoch 1125/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0985 - accuracy: 0.5966 - val_loss: 0.1022 - val_accuracy: 0.5804\n",
      "Epoch 1126/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0984 - accuracy: 0.5970 - val_loss: 0.1029 - val_accuracy: 0.5791\n",
      "Epoch 1127/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0985 - accuracy: 0.5969 - val_loss: 0.1023 - val_accuracy: 0.5796\n",
      "Epoch 1128/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0984 - accuracy: 0.5972 - val_loss: 0.1027 - val_accuracy: 0.5775\n",
      "Epoch 1129/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0985 - accuracy: 0.5965 - val_loss: 0.1020 - val_accuracy: 0.5832\n",
      "Epoch 1130/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0984 - accuracy: 0.5961 - val_loss: 0.1024 - val_accuracy: 0.5789\n",
      "Epoch 1131/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0985 - accuracy: 0.5968 - val_loss: 0.1022 - val_accuracy: 0.5807\n",
      "Epoch 1132/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0984 - accuracy: 0.5977 - val_loss: 0.1022 - val_accuracy: 0.5806\n",
      "Epoch 1133/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0985 - accuracy: 0.5967 - val_loss: 0.1018 - val_accuracy: 0.5807\n",
      "Epoch 1134/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0985 - accuracy: 0.5972 - val_loss: 0.1023 - val_accuracy: 0.5807\n",
      "Epoch 1135/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0984 - accuracy: 0.5972 - val_loss: 0.1025 - val_accuracy: 0.5785\n",
      "Epoch 1136/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0986 - accuracy: 0.5964 - val_loss: 0.1020 - val_accuracy: 0.5833\n",
      "Epoch 1137/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0984 - accuracy: 0.5976 - val_loss: 0.1024 - val_accuracy: 0.5805\n",
      "Epoch 1138/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0984 - accuracy: 0.5967 - val_loss: 0.1022 - val_accuracy: 0.5807\n",
      "Epoch 1139/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0984 - accuracy: 0.5969 - val_loss: 0.1020 - val_accuracy: 0.5805\n",
      "Epoch 1140/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0985 - accuracy: 0.5970 - val_loss: 0.1020 - val_accuracy: 0.5798\n",
      "Epoch 1141/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0984 - accuracy: 0.5975 - val_loss: 0.1021 - val_accuracy: 0.5782\n",
      "Epoch 1142/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0984 - accuracy: 0.5971 - val_loss: 0.1025 - val_accuracy: 0.5798\n",
      "Epoch 1143/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0985 - accuracy: 0.5968 - val_loss: 0.1020 - val_accuracy: 0.5816\n",
      "Epoch 1144/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0984 - accuracy: 0.5973 - val_loss: 0.1032 - val_accuracy: 0.5753\n",
      "Epoch 1145/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0984 - accuracy: 0.5972 - val_loss: 0.1022 - val_accuracy: 0.5796\n",
      "Epoch 1146/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0985 - accuracy: 0.5968 - val_loss: 0.1027 - val_accuracy: 0.5796\n",
      "Epoch 1147/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0985 - accuracy: 0.5965 - val_loss: 0.1023 - val_accuracy: 0.5790\n",
      "Epoch 1148/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0985 - accuracy: 0.5969 - val_loss: 0.1021 - val_accuracy: 0.5792\n",
      "Epoch 1149/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0985 - accuracy: 0.5971 - val_loss: 0.1019 - val_accuracy: 0.5797\n",
      "Epoch 1150/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0985 - accuracy: 0.5963 - val_loss: 0.1025 - val_accuracy: 0.5789\n",
      "Epoch 1151/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0984 - accuracy: 0.5970 - val_loss: 0.1021 - val_accuracy: 0.5810\n",
      "Epoch 1152/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0985 - accuracy: 0.5964 - val_loss: 0.1025 - val_accuracy: 0.5803\n",
      "Epoch 1153/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0984 - accuracy: 0.5966 - val_loss: 0.1028 - val_accuracy: 0.5779\n",
      "Epoch 1154/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0985 - accuracy: 0.5968 - val_loss: 0.1022 - val_accuracy: 0.5806\n",
      "Epoch 1155/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0985 - accuracy: 0.5971 - val_loss: 0.1025 - val_accuracy: 0.5796\n",
      "Epoch 1156/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0984 - accuracy: 0.5972 - val_loss: 0.1027 - val_accuracy: 0.5806\n",
      "Epoch 1157/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0985 - accuracy: 0.5965 - val_loss: 0.1025 - val_accuracy: 0.5805\n",
      "Epoch 1158/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0984 - accuracy: 0.5978 - val_loss: 0.1026 - val_accuracy: 0.5809\n",
      "Epoch 1159/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0985 - accuracy: 0.5970 - val_loss: 0.1024 - val_accuracy: 0.5828\n",
      "Epoch 1160/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0984 - accuracy: 0.5971 - val_loss: 0.1025 - val_accuracy: 0.5778\n",
      "Epoch 1161/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0984 - accuracy: 0.5974 - val_loss: 0.1029 - val_accuracy: 0.5781\n",
      "Epoch 1162/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0984 - accuracy: 0.5966 - val_loss: 0.1023 - val_accuracy: 0.5791\n",
      "Epoch 1163/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0984 - accuracy: 0.5972 - val_loss: 0.1016 - val_accuracy: 0.5810\n",
      "Epoch 1164/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0985 - accuracy: 0.5969 - val_loss: 0.1022 - val_accuracy: 0.5812\n",
      "Epoch 1165/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0985 - accuracy: 0.5969 - val_loss: 0.1026 - val_accuracy: 0.5806\n",
      "Epoch 1166/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0985 - accuracy: 0.5973 - val_loss: 0.1017 - val_accuracy: 0.5822\n",
      "Epoch 1167/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0985 - accuracy: 0.5974 - val_loss: 0.1026 - val_accuracy: 0.5783\n",
      "Epoch 1168/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0984 - accuracy: 0.5971 - val_loss: 0.1021 - val_accuracy: 0.5820\n",
      "Epoch 1169/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0985 - accuracy: 0.5968 - val_loss: 0.1025 - val_accuracy: 0.5794\n",
      "Epoch 1170/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0984 - accuracy: 0.5975 - val_loss: 0.1028 - val_accuracy: 0.5754\n",
      "Epoch 1171/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0985 - accuracy: 0.5961 - val_loss: 0.1025 - val_accuracy: 0.5787\n",
      "Epoch 1172/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0984 - accuracy: 0.5971 - val_loss: 0.1024 - val_accuracy: 0.5790\n",
      "Epoch 1173/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0984 - accuracy: 0.5971 - val_loss: 0.1019 - val_accuracy: 0.5840\n",
      "Epoch 1174/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0984 - accuracy: 0.5970 - val_loss: 0.1022 - val_accuracy: 0.5825\n",
      "Epoch 1175/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0985 - accuracy: 0.5963 - val_loss: 0.1016 - val_accuracy: 0.5823\n",
      "Epoch 1176/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0984 - accuracy: 0.5966 - val_loss: 0.1025 - val_accuracy: 0.5810\n",
      "Epoch 1177/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0985 - accuracy: 0.5976 - val_loss: 0.1017 - val_accuracy: 0.5822\n",
      "Epoch 1178/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0985 - accuracy: 0.5965 - val_loss: 0.1024 - val_accuracy: 0.5831\n",
      "Epoch 1179/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0985 - accuracy: 0.5963 - val_loss: 0.1025 - val_accuracy: 0.5789\n",
      "Epoch 1180/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0985 - accuracy: 0.5973 - val_loss: 0.1023 - val_accuracy: 0.5828\n",
      "Epoch 1181/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0984 - accuracy: 0.5971 - val_loss: 0.1025 - val_accuracy: 0.5789\n",
      "Epoch 1182/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0984 - accuracy: 0.5980 - val_loss: 0.1026 - val_accuracy: 0.5818\n",
      "Epoch 1183/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0983 - accuracy: 0.5979 - val_loss: 0.1028 - val_accuracy: 0.5785\n",
      "Epoch 1184/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0984 - accuracy: 0.5977 - val_loss: 0.1027 - val_accuracy: 0.5753\n",
      "Epoch 1185/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0984 - accuracy: 0.5974 - val_loss: 0.1017 - val_accuracy: 0.5826\n",
      "Epoch 1186/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0984 - accuracy: 0.5971 - val_loss: 0.1024 - val_accuracy: 0.5798\n",
      "Epoch 1187/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0985 - accuracy: 0.5964 - val_loss: 0.1031 - val_accuracy: 0.5761\n",
      "Epoch 1188/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0984 - accuracy: 0.5975 - val_loss: 0.1022 - val_accuracy: 0.5816\n",
      "Epoch 1189/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0984 - accuracy: 0.5973 - val_loss: 0.1021 - val_accuracy: 0.5800\n",
      "Epoch 1190/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0985 - accuracy: 0.5974 - val_loss: 0.1029 - val_accuracy: 0.5761\n",
      "Epoch 1191/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0984 - accuracy: 0.5979 - val_loss: 0.1024 - val_accuracy: 0.5800\n",
      "Epoch 1192/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0985 - accuracy: 0.5970 - val_loss: 0.1028 - val_accuracy: 0.5818\n",
      "Epoch 1193/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0984 - accuracy: 0.5969 - val_loss: 0.1030 - val_accuracy: 0.5774\n",
      "Epoch 1194/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0984 - accuracy: 0.5971 - val_loss: 0.1017 - val_accuracy: 0.5825\n",
      "Epoch 1195/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0983 - accuracy: 0.5977 - val_loss: 0.1022 - val_accuracy: 0.5816\n",
      "Epoch 1196/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0984 - accuracy: 0.5977 - val_loss: 0.1027 - val_accuracy: 0.5823\n",
      "Epoch 1197/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0984 - accuracy: 0.5981 - val_loss: 0.1022 - val_accuracy: 0.5821\n",
      "Epoch 1198/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0984 - accuracy: 0.5969 - val_loss: 0.1022 - val_accuracy: 0.5799\n",
      "Epoch 1199/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0984 - accuracy: 0.5969 - val_loss: 0.1026 - val_accuracy: 0.5813\n",
      "Epoch 1200/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0983 - accuracy: 0.5976 - val_loss: 0.1021 - val_accuracy: 0.5810\n",
      "Epoch 1201/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0984 - accuracy: 0.5974 - val_loss: 0.1022 - val_accuracy: 0.5823\n",
      "Epoch 1202/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0984 - accuracy: 0.5974 - val_loss: 0.1024 - val_accuracy: 0.5822\n",
      "Epoch 1203/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0984 - accuracy: 0.5975 - val_loss: 0.1024 - val_accuracy: 0.5793\n",
      "Epoch 1204/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0984 - accuracy: 0.5976 - val_loss: 0.1023 - val_accuracy: 0.5826\n",
      "Epoch 1205/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0984 - accuracy: 0.5971 - val_loss: 0.1030 - val_accuracy: 0.5756\n",
      "Epoch 1206/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0984 - accuracy: 0.5977 - val_loss: 0.1022 - val_accuracy: 0.5781\n",
      "Epoch 1207/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0984 - accuracy: 0.5970 - val_loss: 0.1023 - val_accuracy: 0.5807\n",
      "Epoch 1208/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0985 - accuracy: 0.5967 - val_loss: 0.1020 - val_accuracy: 0.5796\n",
      "Epoch 1209/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0984 - accuracy: 0.5973 - val_loss: 0.1024 - val_accuracy: 0.5809\n",
      "Epoch 1210/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0984 - accuracy: 0.5971 - val_loss: 0.1020 - val_accuracy: 0.5807\n",
      "Epoch 1211/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0984 - accuracy: 0.5973 - val_loss: 0.1023 - val_accuracy: 0.5804\n",
      "Epoch 1212/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0983 - accuracy: 0.5981 - val_loss: 0.1030 - val_accuracy: 0.5794\n",
      "Epoch 1213/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0985 - accuracy: 0.5972 - val_loss: 0.1026 - val_accuracy: 0.5797\n",
      "Epoch 1214/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0985 - accuracy: 0.5972 - val_loss: 0.1019 - val_accuracy: 0.5794\n",
      "Epoch 1215/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0985 - accuracy: 0.5973 - val_loss: 0.1028 - val_accuracy: 0.5781\n",
      "Epoch 1216/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0984 - accuracy: 0.5976 - val_loss: 0.1030 - val_accuracy: 0.5794\n",
      "Epoch 1217/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0984 - accuracy: 0.5972 - val_loss: 0.1025 - val_accuracy: 0.5787\n",
      "Epoch 1218/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0984 - accuracy: 0.5973 - val_loss: 0.1025 - val_accuracy: 0.5764\n",
      "Epoch 1219/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0984 - accuracy: 0.5971 - val_loss: 0.1027 - val_accuracy: 0.5804\n",
      "Epoch 1220/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0984 - accuracy: 0.5981 - val_loss: 0.1030 - val_accuracy: 0.5779\n",
      "Epoch 1221/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0984 - accuracy: 0.5975 - val_loss: 0.1027 - val_accuracy: 0.5789\n",
      "Epoch 1222/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0984 - accuracy: 0.5977 - val_loss: 0.1023 - val_accuracy: 0.5808\n",
      "Epoch 1223/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0984 - accuracy: 0.5972 - val_loss: 0.1026 - val_accuracy: 0.5799\n",
      "Epoch 1224/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0984 - accuracy: 0.5970 - val_loss: 0.1022 - val_accuracy: 0.5812\n",
      "Epoch 1225/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0984 - accuracy: 0.5976 - val_loss: 0.1022 - val_accuracy: 0.5795\n",
      "Epoch 1226/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0984 - accuracy: 0.5970 - val_loss: 0.1024 - val_accuracy: 0.5808\n",
      "Epoch 1227/5000\n",
      "11864/11864 [==============================] - 7s 566us/step - loss: 0.0984 - accuracy: 0.5970 - val_loss: 0.1018 - val_accuracy: 0.5821\n",
      "Epoch 1228/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0984 - accuracy: 0.5965 - val_loss: 0.1024 - val_accuracy: 0.5828\n",
      "Epoch 1229/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0984 - accuracy: 0.5974 - val_loss: 0.1024 - val_accuracy: 0.5807\n",
      "Epoch 1230/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0984 - accuracy: 0.5975 - val_loss: 0.1018 - val_accuracy: 0.5812\n",
      "Epoch 1231/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0984 - accuracy: 0.5969 - val_loss: 0.1020 - val_accuracy: 0.5825\n",
      "Epoch 1232/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0983 - accuracy: 0.5977 - val_loss: 0.1021 - val_accuracy: 0.5822\n",
      "Epoch 1233/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0984 - accuracy: 0.5966 - val_loss: 0.1021 - val_accuracy: 0.5807\n",
      "Epoch 1234/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0983 - accuracy: 0.5978 - val_loss: 0.1025 - val_accuracy: 0.5798\n",
      "Epoch 1235/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0984 - accuracy: 0.5974 - val_loss: 0.1023 - val_accuracy: 0.5808\n",
      "Epoch 1236/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0985 - accuracy: 0.5980 - val_loss: 0.1022 - val_accuracy: 0.5800\n",
      "Epoch 1237/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0984 - accuracy: 0.5977 - val_loss: 0.1020 - val_accuracy: 0.5809\n",
      "Epoch 1238/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0985 - accuracy: 0.5973 - val_loss: 0.1029 - val_accuracy: 0.5798\n",
      "Epoch 1239/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0983 - accuracy: 0.5980 - val_loss: 0.1021 - val_accuracy: 0.5830\n",
      "Epoch 1240/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0984 - accuracy: 0.5972 - val_loss: 0.1024 - val_accuracy: 0.5788\n",
      "Epoch 1241/5000\n",
      "11864/11864 [==============================] - 7s 566us/step - loss: 0.0984 - accuracy: 0.5969 - val_loss: 0.1024 - val_accuracy: 0.5798\n",
      "Epoch 1242/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0985 - accuracy: 0.5973 - val_loss: 0.1023 - val_accuracy: 0.5790\n",
      "Epoch 1243/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0984 - accuracy: 0.5973 - val_loss: 0.1024 - val_accuracy: 0.5792\n",
      "Epoch 1244/5000\n",
      "11864/11864 [==============================] - 7s 564us/step - loss: 0.0985 - accuracy: 0.5974 - val_loss: 0.1028 - val_accuracy: 0.5786\n",
      "Epoch 1245/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0984 - accuracy: 0.5972 - val_loss: 0.1019 - val_accuracy: 0.5793\n",
      "Epoch 1246/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0985 - accuracy: 0.5963 - val_loss: 0.1020 - val_accuracy: 0.5791\n",
      "Epoch 1247/5000\n",
      "11864/11864 [==============================] - 7s 564us/step - loss: 0.0985 - accuracy: 0.5977 - val_loss: 0.1023 - val_accuracy: 0.5798\n",
      "Epoch 1248/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0985 - accuracy: 0.5970 - val_loss: 0.1020 - val_accuracy: 0.5820\n",
      "Epoch 1249/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0985 - accuracy: 0.5972 - val_loss: 0.1020 - val_accuracy: 0.5805\n",
      "Epoch 1250/5000\n",
      "11864/11864 [==============================] - 7s 560us/step - loss: 0.0984 - accuracy: 0.5973 - val_loss: 0.1024 - val_accuracy: 0.5819\n",
      "Epoch 1251/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0984 - accuracy: 0.5978 - val_loss: 0.1025 - val_accuracy: 0.5774\n",
      "Epoch 1252/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0984 - accuracy: 0.5976 - val_loss: 0.1024 - val_accuracy: 0.5804\n",
      "Epoch 1253/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0984 - accuracy: 0.5982 - val_loss: 0.1021 - val_accuracy: 0.5814\n",
      "Epoch 1254/5000\n",
      "11864/11864 [==============================] - 7s 565us/step - loss: 0.0984 - accuracy: 0.5976 - val_loss: 0.1028 - val_accuracy: 0.5789\n",
      "Epoch 1255/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0985 - accuracy: 0.5976 - val_loss: 0.1029 - val_accuracy: 0.5762\n",
      "Epoch 1256/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0984 - accuracy: 0.5979 - val_loss: 0.1028 - val_accuracy: 0.5807\n",
      "Epoch 1257/5000\n",
      "11864/11864 [==============================] - 7s 566us/step - loss: 0.0985 - accuracy: 0.5981 - val_loss: 0.1026 - val_accuracy: 0.5798\n",
      "Epoch 1258/5000\n",
      "11864/11864 [==============================] - 7s 564us/step - loss: 0.0984 - accuracy: 0.5976 - val_loss: 0.1028 - val_accuracy: 0.5786\n",
      "Epoch 1259/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0985 - accuracy: 0.5979 - val_loss: 0.1028 - val_accuracy: 0.5807\n",
      "Epoch 1260/5000\n",
      "11864/11864 [==============================] - 7s 560us/step - loss: 0.0983 - accuracy: 0.5984 - val_loss: 0.1026 - val_accuracy: 0.5773\n",
      "Epoch 1261/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0985 - accuracy: 0.5974 - val_loss: 0.1027 - val_accuracy: 0.5813\n",
      "Epoch 1262/5000\n",
      "11864/11864 [==============================] - 7s 565us/step - loss: 0.0983 - accuracy: 0.5981 - val_loss: 0.1021 - val_accuracy: 0.5833\n",
      "Epoch 1263/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0984 - accuracy: 0.5980 - val_loss: 0.1027 - val_accuracy: 0.5790\n",
      "Epoch 1264/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0983 - accuracy: 0.5981 - val_loss: 0.1023 - val_accuracy: 0.5793\n",
      "Epoch 1265/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0984 - accuracy: 0.5982 - val_loss: 0.1026 - val_accuracy: 0.5779\n",
      "Epoch 1266/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0984 - accuracy: 0.5971 - val_loss: 0.1024 - val_accuracy: 0.5817\n",
      "Epoch 1267/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0984 - accuracy: 0.5976 - val_loss: 0.1027 - val_accuracy: 0.5806\n",
      "Epoch 1268/5000\n",
      "11864/11864 [==============================] - 7s 564us/step - loss: 0.0984 - accuracy: 0.5983 - val_loss: 0.1021 - val_accuracy: 0.5817\n",
      "Epoch 1269/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0982 - accuracy: 0.5981 - val_loss: 0.1021 - val_accuracy: 0.5816\n",
      "Epoch 1270/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0983 - accuracy: 0.5986 - val_loss: 0.1025 - val_accuracy: 0.5809\n",
      "Epoch 1271/5000\n",
      "11864/11864 [==============================] - 7s 565us/step - loss: 0.0983 - accuracy: 0.5981 - val_loss: 0.1022 - val_accuracy: 0.5808\n",
      "Epoch 1272/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0984 - accuracy: 0.5979 - val_loss: 0.1021 - val_accuracy: 0.5806\n",
      "Epoch 1273/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0983 - accuracy: 0.5981 - val_loss: 0.1019 - val_accuracy: 0.5820\n",
      "Epoch 1274/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0983 - accuracy: 0.5976 - val_loss: 0.1024 - val_accuracy: 0.5806\n",
      "Epoch 1275/5000\n",
      "11864/11864 [==============================] - 7s 565us/step - loss: 0.0984 - accuracy: 0.5975 - val_loss: 0.1029 - val_accuracy: 0.5775\n",
      "Epoch 1276/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0983 - accuracy: 0.5976 - val_loss: 0.1023 - val_accuracy: 0.5802\n",
      "Epoch 1277/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0984 - accuracy: 0.5980 - val_loss: 0.1021 - val_accuracy: 0.5824\n",
      "Epoch 1278/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0984 - accuracy: 0.5981 - val_loss: 0.1025 - val_accuracy: 0.5788\n",
      "Epoch 1279/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0984 - accuracy: 0.5981 - val_loss: 0.1024 - val_accuracy: 0.5806\n",
      "Epoch 1280/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0984 - accuracy: 0.5979 - val_loss: 0.1028 - val_accuracy: 0.5808\n",
      "Epoch 1281/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0984 - accuracy: 0.5978 - val_loss: 0.1023 - val_accuracy: 0.5790\n",
      "Epoch 1282/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0984 - accuracy: 0.5975 - val_loss: 0.1031 - val_accuracy: 0.5807\n",
      "Epoch 1283/5000\n",
      "11864/11864 [==============================] - 7s 565us/step - loss: 0.0984 - accuracy: 0.5978 - val_loss: 0.1024 - val_accuracy: 0.5809\n",
      "Epoch 1284/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0984 - accuracy: 0.5983 - val_loss: 0.1025 - val_accuracy: 0.5785\n",
      "Epoch 1285/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0984 - accuracy: 0.5975 - val_loss: 0.1025 - val_accuracy: 0.5802\n",
      "Epoch 1286/5000\n",
      "11864/11864 [==============================] - 7s 565us/step - loss: 0.0985 - accuracy: 0.5979 - val_loss: 0.1022 - val_accuracy: 0.5816\n",
      "Epoch 1287/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0983 - accuracy: 0.5978 - val_loss: 0.1030 - val_accuracy: 0.5781\n",
      "Epoch 1288/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0984 - accuracy: 0.5979 - val_loss: 0.1028 - val_accuracy: 0.5807\n",
      "Epoch 1289/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0984 - accuracy: 0.5978 - val_loss: 0.1025 - val_accuracy: 0.5802\n",
      "Epoch 1290/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0983 - accuracy: 0.5984 - val_loss: 0.1023 - val_accuracy: 0.5800\n",
      "Epoch 1291/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0984 - accuracy: 0.5969 - val_loss: 0.1023 - val_accuracy: 0.5797\n",
      "Epoch 1292/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0983 - accuracy: 0.5978 - val_loss: 0.1018 - val_accuracy: 0.5821\n",
      "Epoch 1293/5000\n",
      "11864/11864 [==============================] - 7s 565us/step - loss: 0.0984 - accuracy: 0.5975 - val_loss: 0.1020 - val_accuracy: 0.5816\n",
      "Epoch 1294/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0983 - accuracy: 0.5987 - val_loss: 0.1025 - val_accuracy: 0.5805\n",
      "Epoch 1295/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0984 - accuracy: 0.5980 - val_loss: 0.1023 - val_accuracy: 0.5811\n",
      "Epoch 1296/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0983 - accuracy: 0.5975 - val_loss: 0.1025 - val_accuracy: 0.5794\n",
      "Epoch 1297/5000\n",
      "11864/11864 [==============================] - 7s 565us/step - loss: 0.0984 - accuracy: 0.5973 - val_loss: 0.1023 - val_accuracy: 0.5802\n",
      "Epoch 1298/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0983 - accuracy: 0.5981 - val_loss: 0.1028 - val_accuracy: 0.5796\n",
      "Epoch 1299/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0983 - accuracy: 0.5985 - val_loss: 0.1030 - val_accuracy: 0.5796\n",
      "Epoch 1300/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0984 - accuracy: 0.5975 - val_loss: 0.1023 - val_accuracy: 0.5806\n",
      "Epoch 1301/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0983 - accuracy: 0.5985 - val_loss: 0.1021 - val_accuracy: 0.5828\n",
      "Epoch 1302/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0984 - accuracy: 0.5979 - val_loss: 0.1022 - val_accuracy: 0.5819\n",
      "Epoch 1303/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0984 - accuracy: 0.5977 - val_loss: 0.1023 - val_accuracy: 0.5811\n",
      "Epoch 1304/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0984 - accuracy: 0.5976 - val_loss: 0.1027 - val_accuracy: 0.5774\n",
      "Epoch 1305/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0984 - accuracy: 0.5983 - val_loss: 0.1023 - val_accuracy: 0.5814\n",
      "Epoch 1306/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0984 - accuracy: 0.5970 - val_loss: 0.1024 - val_accuracy: 0.5795\n",
      "Epoch 1307/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0984 - accuracy: 0.5981 - val_loss: 0.1027 - val_accuracy: 0.5783\n",
      "Epoch 1308/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0983 - accuracy: 0.5981 - val_loss: 0.1026 - val_accuracy: 0.5746\n",
      "Epoch 1309/5000\n",
      "11864/11864 [==============================] - 7s 564us/step - loss: 0.0983 - accuracy: 0.5978 - val_loss: 0.1037 - val_accuracy: 0.5770\n",
      "Epoch 1310/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0984 - accuracy: 0.5978 - val_loss: 0.1027 - val_accuracy: 0.5785\n",
      "Epoch 1311/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0983 - accuracy: 0.5982 - val_loss: 0.1026 - val_accuracy: 0.5798\n",
      "Epoch 1312/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0984 - accuracy: 0.5973 - val_loss: 0.1020 - val_accuracy: 0.5810\n",
      "Epoch 1313/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0984 - accuracy: 0.5973 - val_loss: 0.1023 - val_accuracy: 0.5829\n",
      "Epoch 1314/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0983 - accuracy: 0.5975 - val_loss: 0.1029 - val_accuracy: 0.5773\n",
      "Epoch 1315/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0983 - accuracy: 0.5985 - val_loss: 0.1024 - val_accuracy: 0.5811\n",
      "Epoch 1316/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0984 - accuracy: 0.5973 - val_loss: 0.1018 - val_accuracy: 0.5826\n",
      "Epoch 1317/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0983 - accuracy: 0.5990 - val_loss: 0.1023 - val_accuracy: 0.5813\n",
      "Epoch 1318/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0983 - accuracy: 0.5977 - val_loss: 0.1024 - val_accuracy: 0.5808\n",
      "Epoch 1319/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0985 - accuracy: 0.5972 - val_loss: 0.1022 - val_accuracy: 0.5810\n",
      "Epoch 1320/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0983 - accuracy: 0.5980 - val_loss: 0.1024 - val_accuracy: 0.5792\n",
      "Epoch 1321/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0983 - accuracy: 0.5980 - val_loss: 0.1028 - val_accuracy: 0.5810\n",
      "Epoch 1322/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0983 - accuracy: 0.5982 - val_loss: 0.1024 - val_accuracy: 0.5792\n",
      "Epoch 1323/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0984 - accuracy: 0.5971 - val_loss: 0.1027 - val_accuracy: 0.5770\n",
      "Epoch 1324/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0984 - accuracy: 0.5972 - val_loss: 0.1029 - val_accuracy: 0.5766\n",
      "Epoch 1325/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0984 - accuracy: 0.5975 - val_loss: 0.1019 - val_accuracy: 0.5806\n",
      "Epoch 1326/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0984 - accuracy: 0.5978 - val_loss: 0.1024 - val_accuracy: 0.5810\n",
      "Epoch 1327/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0984 - accuracy: 0.5983 - val_loss: 0.1026 - val_accuracy: 0.5793\n",
      "Epoch 1328/5000\n",
      "11864/11864 [==============================] - 7s 565us/step - loss: 0.0983 - accuracy: 0.5990 - val_loss: 0.1030 - val_accuracy: 0.5788\n",
      "Epoch 1329/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0983 - accuracy: 0.5980 - val_loss: 0.1020 - val_accuracy: 0.5795\n",
      "Epoch 1330/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0984 - accuracy: 0.5980 - val_loss: 0.1024 - val_accuracy: 0.5827\n",
      "Epoch 1331/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0983 - accuracy: 0.5980 - val_loss: 0.1027 - val_accuracy: 0.5792\n",
      "Epoch 1332/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0983 - accuracy: 0.5982 - val_loss: 0.1058 - val_accuracy: 0.5668\n",
      "Epoch 1333/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0982 - accuracy: 0.5991 - val_loss: 0.1028 - val_accuracy: 0.5804\n",
      "Epoch 1334/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0984 - accuracy: 0.5980 - val_loss: 0.1026 - val_accuracy: 0.5804\n",
      "Epoch 1335/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0984 - accuracy: 0.5982 - val_loss: 0.1021 - val_accuracy: 0.5793\n",
      "Epoch 1336/5000\n",
      "11864/11864 [==============================] - 7s 564us/step - loss: 0.0984 - accuracy: 0.5981 - val_loss: 0.1026 - val_accuracy: 0.5807\n",
      "Epoch 1337/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0983 - accuracy: 0.5981 - val_loss: 0.1022 - val_accuracy: 0.5817\n",
      "Epoch 1338/5000\n",
      "11864/11864 [==============================] - 7s 565us/step - loss: 0.0984 - accuracy: 0.5977 - val_loss: 0.1028 - val_accuracy: 0.5807\n",
      "Epoch 1339/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0983 - accuracy: 0.5985 - val_loss: 0.1023 - val_accuracy: 0.5811\n",
      "Epoch 1340/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0983 - accuracy: 0.5977 - val_loss: 0.1029 - val_accuracy: 0.5802\n",
      "Epoch 1341/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0983 - accuracy: 0.5976 - val_loss: 0.1025 - val_accuracy: 0.5808\n",
      "Epoch 1342/5000\n",
      "11864/11864 [==============================] - 7s 566us/step - loss: 0.0984 - accuracy: 0.5981 - val_loss: 0.1019 - val_accuracy: 0.5823\n",
      "Epoch 1343/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0983 - accuracy: 0.5982 - val_loss: 0.1029 - val_accuracy: 0.5761\n",
      "Epoch 1344/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0983 - accuracy: 0.5977 - val_loss: 0.1033 - val_accuracy: 0.5793\n",
      "Epoch 1345/5000\n",
      "11864/11864 [==============================] - 7s 563us/step - loss: 0.0982 - accuracy: 0.5994 - val_loss: 0.1024 - val_accuracy: 0.5807\n",
      "Epoch 1346/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0983 - accuracy: 0.5985 - val_loss: 0.1022 - val_accuracy: 0.5797\n",
      "Epoch 1347/5000\n",
      "11864/11864 [==============================] - 7s 566us/step - loss: 0.0984 - accuracy: 0.5976 - val_loss: 0.1033 - val_accuracy: 0.5754\n",
      "Epoch 1348/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0984 - accuracy: 0.5970 - val_loss: 0.1026 - val_accuracy: 0.5800\n",
      "Epoch 1349/5000\n",
      "11864/11864 [==============================] - 7s 562us/step - loss: 0.0984 - accuracy: 0.5974 - val_loss: 0.1028 - val_accuracy: 0.5747\n",
      "Epoch 1350/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0984 - accuracy: 0.5969 - val_loss: 0.1022 - val_accuracy: 0.5804\n",
      "Epoch 1351/5000\n",
      "11864/11864 [==============================] - 7s 565us/step - loss: 0.0984 - accuracy: 0.5975 - val_loss: 0.1022 - val_accuracy: 0.5812\n",
      "Epoch 1352/5000\n",
      "11864/11864 [==============================] - 7s 566us/step - loss: 0.0983 - accuracy: 0.5979 - val_loss: 0.1023 - val_accuracy: 0.5795\n",
      "Epoch 1353/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0983 - accuracy: 0.5979 - val_loss: 0.1025 - val_accuracy: 0.5790\n",
      "Epoch 1354/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0983 - accuracy: 0.5993 - val_loss: 0.1019 - val_accuracy: 0.5831\n",
      "Epoch 1355/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0983 - accuracy: 0.5980 - val_loss: 0.1024 - val_accuracy: 0.5778\n",
      "Epoch 1356/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0984 - accuracy: 0.5979 - val_loss: 0.1031 - val_accuracy: 0.5793\n",
      "Epoch 1357/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0983 - accuracy: 0.5980 - val_loss: 0.1025 - val_accuracy: 0.5794\n",
      "Epoch 1358/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0983 - accuracy: 0.5985 - val_loss: 0.1036 - val_accuracy: 0.5761\n",
      "Epoch 1359/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0982 - accuracy: 0.5990 - val_loss: 0.1025 - val_accuracy: 0.5808\n",
      "Epoch 1360/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0983 - accuracy: 0.5976 - val_loss: 0.1031 - val_accuracy: 0.5775\n",
      "Epoch 1361/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0984 - accuracy: 0.5980 - val_loss: 0.1025 - val_accuracy: 0.5801\n",
      "Epoch 1362/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0983 - accuracy: 0.5977 - val_loss: 0.1020 - val_accuracy: 0.5800\n",
      "Epoch 1363/5000\n",
      "11864/11864 [==============================] - 7s 563us/step - loss: 0.0984 - accuracy: 0.5984 - val_loss: 0.1028 - val_accuracy: 0.5800\n",
      "Epoch 1364/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0984 - accuracy: 0.5980 - val_loss: 0.1019 - val_accuracy: 0.5826\n",
      "Epoch 1365/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0983 - accuracy: 0.5981 - val_loss: 0.1025 - val_accuracy: 0.5806\n",
      "Epoch 1366/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0983 - accuracy: 0.5982 - val_loss: 0.1027 - val_accuracy: 0.5791\n",
      "Epoch 1367/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0983 - accuracy: 0.5986 - val_loss: 0.1030 - val_accuracy: 0.5803\n",
      "Epoch 1368/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0983 - accuracy: 0.5985 - val_loss: 0.1020 - val_accuracy: 0.5794\n",
      "Epoch 1369/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0982 - accuracy: 0.5993 - val_loss: 0.1027 - val_accuracy: 0.5796\n",
      "Epoch 1370/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0983 - accuracy: 0.5986 - val_loss: 0.1020 - val_accuracy: 0.5851\n",
      "Epoch 1371/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0984 - accuracy: 0.5977 - val_loss: 0.1026 - val_accuracy: 0.5785\n",
      "Epoch 1372/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0984 - accuracy: 0.5985 - val_loss: 0.1032 - val_accuracy: 0.5790\n",
      "Epoch 1373/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0984 - accuracy: 0.5977 - val_loss: 0.1018 - val_accuracy: 0.5835\n",
      "Epoch 1374/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0983 - accuracy: 0.5983 - val_loss: 0.1022 - val_accuracy: 0.5802\n",
      "Epoch 1375/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0983 - accuracy: 0.5979 - val_loss: 0.1022 - val_accuracy: 0.5831\n",
      "Epoch 1376/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0983 - accuracy: 0.5978 - val_loss: 0.1027 - val_accuracy: 0.5766\n",
      "Epoch 1377/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0982 - accuracy: 0.5978 - val_loss: 0.1023 - val_accuracy: 0.5812\n",
      "Epoch 1378/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0982 - accuracy: 0.5982 - val_loss: 0.1024 - val_accuracy: 0.5799\n",
      "Epoch 1379/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0982 - accuracy: 0.5982 - val_loss: 0.1019 - val_accuracy: 0.5811\n",
      "Epoch 1380/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0983 - accuracy: 0.5985 - val_loss: 0.1024 - val_accuracy: 0.5773\n",
      "Epoch 1381/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0983 - accuracy: 0.5974 - val_loss: 0.1021 - val_accuracy: 0.5816\n",
      "Epoch 1382/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0983 - accuracy: 0.5977 - val_loss: 0.1028 - val_accuracy: 0.5802\n",
      "Epoch 1383/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0983 - accuracy: 0.5984 - val_loss: 0.1021 - val_accuracy: 0.5820\n",
      "Epoch 1384/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0984 - accuracy: 0.5982 - val_loss: 0.1026 - val_accuracy: 0.5802\n",
      "Epoch 1385/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0983 - accuracy: 0.5980 - val_loss: 0.1026 - val_accuracy: 0.5800\n",
      "Epoch 1386/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0983 - accuracy: 0.5988 - val_loss: 0.1020 - val_accuracy: 0.5845\n",
      "Epoch 1387/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0983 - accuracy: 0.5981 - val_loss: 0.1021 - val_accuracy: 0.5806\n",
      "Epoch 1388/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0983 - accuracy: 0.5988 - val_loss: 0.1022 - val_accuracy: 0.5810\n",
      "Epoch 1389/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0983 - accuracy: 0.5981 - val_loss: 0.1020 - val_accuracy: 0.5833\n",
      "Epoch 1390/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0983 - accuracy: 0.5975 - val_loss: 0.1026 - val_accuracy: 0.5828\n",
      "Epoch 1391/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0984 - accuracy: 0.5973 - val_loss: 0.1030 - val_accuracy: 0.5733\n",
      "Epoch 1392/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0983 - accuracy: 0.5984 - val_loss: 0.1022 - val_accuracy: 0.5802\n",
      "Epoch 1393/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0983 - accuracy: 0.5982 - val_loss: 0.1024 - val_accuracy: 0.5786\n",
      "Epoch 1394/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0984 - accuracy: 0.5970 - val_loss: 0.1021 - val_accuracy: 0.5814\n",
      "Epoch 1395/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0983 - accuracy: 0.5982 - val_loss: 0.1024 - val_accuracy: 0.5809\n",
      "Epoch 1396/5000\n",
      "11864/11864 [==============================] - 7s 564us/step - loss: 0.0983 - accuracy: 0.5982 - val_loss: 0.1022 - val_accuracy: 0.5792\n",
      "Epoch 1397/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0983 - accuracy: 0.5981 - val_loss: 0.1021 - val_accuracy: 0.5809\n",
      "Epoch 1398/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0983 - accuracy: 0.5976 - val_loss: 0.1023 - val_accuracy: 0.5815\n",
      "Epoch 1399/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0983 - accuracy: 0.5982 - val_loss: 0.1022 - val_accuracy: 0.5825\n",
      "Epoch 1400/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0983 - accuracy: 0.5982 - val_loss: 0.1020 - val_accuracy: 0.5819\n",
      "Epoch 1401/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0983 - accuracy: 0.5982 - val_loss: 0.1029 - val_accuracy: 0.5773\n",
      "Epoch 1402/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0983 - accuracy: 0.5979 - val_loss: 0.1019 - val_accuracy: 0.5806\n",
      "Epoch 1403/5000\n",
      "11864/11864 [==============================] - 7s 566us/step - loss: 0.0984 - accuracy: 0.5975 - val_loss: 0.1031 - val_accuracy: 0.5768\n",
      "Epoch 1404/5000\n",
      "11864/11864 [==============================] - 7s 564us/step - loss: 0.0983 - accuracy: 0.5990 - val_loss: 0.1026 - val_accuracy: 0.5776\n",
      "Epoch 1405/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0983 - accuracy: 0.5976 - val_loss: 0.1018 - val_accuracy: 0.5817\n",
      "Epoch 1406/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0982 - accuracy: 0.5980 - val_loss: 0.1019 - val_accuracy: 0.5811\n",
      "Epoch 1407/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0983 - accuracy: 0.5982 - val_loss: 0.1023 - val_accuracy: 0.5808\n",
      "Epoch 1408/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0984 - accuracy: 0.5983 - val_loss: 0.1021 - val_accuracy: 0.5828\n",
      "Epoch 1409/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0984 - accuracy: 0.5973 - val_loss: 0.1021 - val_accuracy: 0.5800\n",
      "Epoch 1410/5000\n",
      "11864/11864 [==============================] - 7s 566us/step - loss: 0.0983 - accuracy: 0.5984 - val_loss: 0.1021 - val_accuracy: 0.5805\n",
      "Epoch 1411/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0983 - accuracy: 0.5978 - val_loss: 0.1030 - val_accuracy: 0.5795\n",
      "Epoch 1412/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0983 - accuracy: 0.5976 - val_loss: 0.1026 - val_accuracy: 0.5812\n",
      "Epoch 1413/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0983 - accuracy: 0.5989 - val_loss: 0.1019 - val_accuracy: 0.5831\n",
      "Epoch 1414/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0982 - accuracy: 0.5985 - val_loss: 0.1025 - val_accuracy: 0.5811\n",
      "Epoch 1415/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0983 - accuracy: 0.5982 - val_loss: 0.1025 - val_accuracy: 0.5816\n",
      "Epoch 1416/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0983 - accuracy: 0.5980 - val_loss: 0.1026 - val_accuracy: 0.5796\n",
      "Epoch 1417/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0982 - accuracy: 0.5985 - val_loss: 0.1026 - val_accuracy: 0.5818\n",
      "Epoch 1418/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0982 - accuracy: 0.5989 - val_loss: 0.1022 - val_accuracy: 0.5804\n",
      "Epoch 1419/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0983 - accuracy: 0.5983 - val_loss: 0.1017 - val_accuracy: 0.5822\n",
      "Epoch 1420/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0983 - accuracy: 0.5981 - val_loss: 0.1021 - val_accuracy: 0.5810\n",
      "Epoch 1421/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0983 - accuracy: 0.5979 - val_loss: 0.1026 - val_accuracy: 0.5787\n",
      "Epoch 1422/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0983 - accuracy: 0.5984 - val_loss: 0.1028 - val_accuracy: 0.5833\n",
      "Epoch 1423/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0984 - accuracy: 0.5984 - val_loss: 0.1021 - val_accuracy: 0.5839\n",
      "Epoch 1424/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0983 - accuracy: 0.5984 - val_loss: 0.1023 - val_accuracy: 0.5813\n",
      "Epoch 1425/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0984 - accuracy: 0.5984 - val_loss: 0.1023 - val_accuracy: 0.5780\n",
      "Epoch 1426/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0983 - accuracy: 0.5974 - val_loss: 0.1021 - val_accuracy: 0.5798\n",
      "Epoch 1427/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0983 - accuracy: 0.5985 - val_loss: 0.1017 - val_accuracy: 0.5835\n",
      "Epoch 1428/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0982 - accuracy: 0.5989 - val_loss: 0.1020 - val_accuracy: 0.5785\n",
      "Epoch 1429/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0983 - accuracy: 0.5981 - val_loss: 0.1028 - val_accuracy: 0.5781\n",
      "Epoch 1430/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0983 - accuracy: 0.5982 - val_loss: 0.1020 - val_accuracy: 0.5800\n",
      "Epoch 1431/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0983 - accuracy: 0.5983 - val_loss: 0.1023 - val_accuracy: 0.5802\n",
      "Epoch 1432/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0983 - accuracy: 0.5982 - val_loss: 0.1018 - val_accuracy: 0.5810\n",
      "Epoch 1433/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0983 - accuracy: 0.5978 - val_loss: 0.1019 - val_accuracy: 0.5800\n",
      "Epoch 1434/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0983 - accuracy: 0.5978 - val_loss: 0.1027 - val_accuracy: 0.5766\n",
      "Epoch 1435/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0984 - accuracy: 0.5985 - val_loss: 0.1021 - val_accuracy: 0.5788\n",
      "Epoch 1436/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0983 - accuracy: 0.5984 - val_loss: 0.1029 - val_accuracy: 0.5765\n",
      "Epoch 1437/5000\n",
      "11864/11864 [==============================] - 7s 566us/step - loss: 0.0982 - accuracy: 0.5978 - val_loss: 0.1023 - val_accuracy: 0.5797\n",
      "Epoch 1438/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0983 - accuracy: 0.5989 - val_loss: 0.1021 - val_accuracy: 0.5835\n",
      "Epoch 1439/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0983 - accuracy: 0.5979 - val_loss: 0.1027 - val_accuracy: 0.5802\n",
      "Epoch 1440/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0983 - accuracy: 0.5984 - val_loss: 0.1028 - val_accuracy: 0.5787\n",
      "Epoch 1441/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0984 - accuracy: 0.5980 - val_loss: 0.1018 - val_accuracy: 0.5811\n",
      "Epoch 1442/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0983 - accuracy: 0.5985 - val_loss: 0.1023 - val_accuracy: 0.5811\n",
      "Epoch 1443/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0985 - accuracy: 0.5979 - val_loss: 0.1017 - val_accuracy: 0.5829\n",
      "Epoch 1444/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0983 - accuracy: 0.5984 - val_loss: 0.1025 - val_accuracy: 0.5769\n",
      "Epoch 1445/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0983 - accuracy: 0.5973 - val_loss: 0.1023 - val_accuracy: 0.5808\n",
      "Epoch 1446/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0983 - accuracy: 0.5976 - val_loss: 0.1031 - val_accuracy: 0.5783\n",
      "Epoch 1447/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0984 - accuracy: 0.5978 - val_loss: 0.1024 - val_accuracy: 0.5785\n",
      "Epoch 1448/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0983 - accuracy: 0.5983 - val_loss: 0.1025 - val_accuracy: 0.5811\n",
      "Epoch 1449/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0983 - accuracy: 0.5982 - val_loss: 0.1019 - val_accuracy: 0.5788\n",
      "Epoch 1450/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0983 - accuracy: 0.5976 - val_loss: 0.1029 - val_accuracy: 0.5788\n",
      "Epoch 1451/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0983 - accuracy: 0.5974 - val_loss: 0.1031 - val_accuracy: 0.5787\n",
      "Epoch 1452/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0984 - accuracy: 0.5978 - val_loss: 0.1022 - val_accuracy: 0.5815\n",
      "Epoch 1453/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0983 - accuracy: 0.5981 - val_loss: 0.1023 - val_accuracy: 0.5837\n",
      "Epoch 1454/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0983 - accuracy: 0.5980 - val_loss: 0.1023 - val_accuracy: 0.5812\n",
      "Epoch 1455/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0983 - accuracy: 0.5988 - val_loss: 0.1026 - val_accuracy: 0.5783\n",
      "Epoch 1456/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0983 - accuracy: 0.5982 - val_loss: 0.1030 - val_accuracy: 0.5794\n",
      "Epoch 1457/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0983 - accuracy: 0.5994 - val_loss: 0.1022 - val_accuracy: 0.5814\n",
      "Epoch 1458/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0983 - accuracy: 0.5981 - val_loss: 0.1020 - val_accuracy: 0.5798\n",
      "Epoch 1459/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0982 - accuracy: 0.5986 - val_loss: 0.1025 - val_accuracy: 0.5786\n",
      "Epoch 1460/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0983 - accuracy: 0.5985 - val_loss: 0.1032 - val_accuracy: 0.5780\n",
      "Epoch 1461/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0984 - accuracy: 0.5979 - val_loss: 0.1024 - val_accuracy: 0.5807\n",
      "Epoch 1462/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0983 - accuracy: 0.5986 - val_loss: 0.1021 - val_accuracy: 0.5809\n",
      "Epoch 1463/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0983 - accuracy: 0.5980 - val_loss: 0.1026 - val_accuracy: 0.5817\n",
      "Epoch 1464/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0983 - accuracy: 0.5979 - val_loss: 0.1016 - val_accuracy: 0.5829\n",
      "Epoch 1465/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0983 - accuracy: 0.5984 - val_loss: 0.1025 - val_accuracy: 0.5828\n",
      "Epoch 1466/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0984 - accuracy: 0.5981 - val_loss: 0.1023 - val_accuracy: 0.5801\n",
      "Epoch 1467/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0983 - accuracy: 0.5976 - val_loss: 0.1019 - val_accuracy: 0.5836\n",
      "Epoch 1468/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0984 - accuracy: 0.5975 - val_loss: 0.1033 - val_accuracy: 0.5769\n",
      "Epoch 1469/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0984 - accuracy: 0.5981 - val_loss: 0.1020 - val_accuracy: 0.5809\n",
      "Epoch 1470/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0982 - accuracy: 0.5984 - val_loss: 0.1020 - val_accuracy: 0.5825\n",
      "Epoch 1471/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0983 - accuracy: 0.5982 - val_loss: 0.1021 - val_accuracy: 0.5809\n",
      "Epoch 1472/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0982 - accuracy: 0.5986 - val_loss: 0.1021 - val_accuracy: 0.5823\n",
      "Epoch 1473/5000\n",
      "11864/11864 [==============================] - 7s 568us/step - loss: 0.0983 - accuracy: 0.5989 - val_loss: 0.1019 - val_accuracy: 0.5814\n",
      "Epoch 1474/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0983 - accuracy: 0.5979 - val_loss: 0.1019 - val_accuracy: 0.5829\n",
      "Epoch 1475/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0982 - accuracy: 0.5983 - val_loss: 0.1032 - val_accuracy: 0.5769\n",
      "Epoch 1476/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0984 - accuracy: 0.5978 - val_loss: 0.1025 - val_accuracy: 0.5799\n",
      "Epoch 1477/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0984 - accuracy: 0.5977 - val_loss: 0.1020 - val_accuracy: 0.5816\n",
      "Epoch 1478/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0983 - accuracy: 0.5976 - val_loss: 0.1027 - val_accuracy: 0.5782\n",
      "Epoch 1479/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0984 - accuracy: 0.5976 - val_loss: 0.1022 - val_accuracy: 0.5827\n",
      "Epoch 1480/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0983 - accuracy: 0.5977 - val_loss: 0.1030 - val_accuracy: 0.5758\n",
      "Epoch 1481/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0983 - accuracy: 0.5982 - val_loss: 0.1024 - val_accuracy: 0.5808\n",
      "Epoch 1482/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0983 - accuracy: 0.5989 - val_loss: 0.1023 - val_accuracy: 0.5785\n",
      "Epoch 1483/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0983 - accuracy: 0.5982 - val_loss: 0.1018 - val_accuracy: 0.5817\n",
      "Epoch 1484/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0983 - accuracy: 0.5987 - val_loss: 0.1030 - val_accuracy: 0.5787\n",
      "Epoch 1485/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0983 - accuracy: 0.5981 - val_loss: 0.1020 - val_accuracy: 0.5818\n",
      "Epoch 1486/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0984 - accuracy: 0.5975 - val_loss: 0.1029 - val_accuracy: 0.5795\n",
      "Epoch 1487/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0983 - accuracy: 0.5985 - val_loss: 0.1022 - val_accuracy: 0.5821\n",
      "Epoch 1488/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0983 - accuracy: 0.5984 - val_loss: 0.1028 - val_accuracy: 0.5790\n",
      "Epoch 1489/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0983 - accuracy: 0.5986 - val_loss: 0.1017 - val_accuracy: 0.5822\n",
      "Epoch 1490/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0983 - accuracy: 0.5987 - val_loss: 0.1032 - val_accuracy: 0.5779\n",
      "Epoch 1491/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0983 - accuracy: 0.5980 - val_loss: 0.1024 - val_accuracy: 0.5800\n",
      "Epoch 1492/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0982 - accuracy: 0.5985 - val_loss: 0.1029 - val_accuracy: 0.5787\n",
      "Epoch 1493/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0983 - accuracy: 0.5977 - val_loss: 0.1028 - val_accuracy: 0.5786\n",
      "Epoch 1494/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0983 - accuracy: 0.5989 - val_loss: 0.1032 - val_accuracy: 0.5778\n",
      "Epoch 1495/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0983 - accuracy: 0.5985 - val_loss: 0.1021 - val_accuracy: 0.5795\n",
      "Epoch 1496/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0984 - accuracy: 0.5976 - val_loss: 0.1020 - val_accuracy: 0.5835\n",
      "Epoch 1497/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0982 - accuracy: 0.5980 - val_loss: 0.1024 - val_accuracy: 0.5828\n",
      "Epoch 1498/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0983 - accuracy: 0.5981 - val_loss: 0.1020 - val_accuracy: 0.5836\n",
      "Epoch 1499/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0984 - accuracy: 0.5970 - val_loss: 0.1020 - val_accuracy: 0.5836\n",
      "Epoch 1500/5000\n",
      "11864/11864 [==============================] - 7s 565us/step - loss: 0.0983 - accuracy: 0.5980 - val_loss: 0.1026 - val_accuracy: 0.5827\n",
      "Epoch 1501/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0984 - accuracy: 0.5972 - val_loss: 0.1028 - val_accuracy: 0.5805\n",
      "Epoch 1502/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0983 - accuracy: 0.5983 - val_loss: 0.1028 - val_accuracy: 0.5775\n",
      "Epoch 1503/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0983 - accuracy: 0.5978 - val_loss: 0.1023 - val_accuracy: 0.5807\n",
      "Epoch 1504/5000\n",
      "11864/11864 [==============================] - 7s 566us/step - loss: 0.0983 - accuracy: 0.5980 - val_loss: 0.1020 - val_accuracy: 0.5816\n",
      "Epoch 1505/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0983 - accuracy: 0.5985 - val_loss: 0.1017 - val_accuracy: 0.5844\n",
      "Epoch 1506/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0983 - accuracy: 0.5983 - val_loss: 0.1024 - val_accuracy: 0.5798\n",
      "Epoch 1507/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0983 - accuracy: 0.5985 - val_loss: 0.1027 - val_accuracy: 0.5790\n",
      "Epoch 1508/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0983 - accuracy: 0.5984 - val_loss: 0.1021 - val_accuracy: 0.5800\n",
      "Epoch 1509/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0984 - accuracy: 0.5979 - val_loss: 0.1027 - val_accuracy: 0.5765\n",
      "Epoch 1510/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0983 - accuracy: 0.5985 - val_loss: 0.1021 - val_accuracy: 0.5808\n",
      "Epoch 1511/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0983 - accuracy: 0.5982 - val_loss: 0.1030 - val_accuracy: 0.5803\n",
      "Epoch 1512/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0983 - accuracy: 0.5985 - val_loss: 0.1023 - val_accuracy: 0.5803\n",
      "Epoch 1513/5000\n",
      "11864/11864 [==============================] - 7s 563us/step - loss: 0.0984 - accuracy: 0.5979 - val_loss: 0.1027 - val_accuracy: 0.5772\n",
      "Epoch 1514/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0983 - accuracy: 0.5979 - val_loss: 0.1024 - val_accuracy: 0.5820\n",
      "Epoch 1515/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0983 - accuracy: 0.5982 - val_loss: 0.1028 - val_accuracy: 0.5786\n",
      "Epoch 1516/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0983 - accuracy: 0.5979 - val_loss: 0.1023 - val_accuracy: 0.5833\n",
      "Epoch 1517/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0983 - accuracy: 0.5987 - val_loss: 0.1025 - val_accuracy: 0.5779\n",
      "Epoch 1518/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0983 - accuracy: 0.5983 - val_loss: 0.1022 - val_accuracy: 0.5788\n",
      "Epoch 1519/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0984 - accuracy: 0.5986 - val_loss: 0.1020 - val_accuracy: 0.5838\n",
      "Epoch 1520/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0983 - accuracy: 0.5987 - val_loss: 0.1021 - val_accuracy: 0.5816\n",
      "Epoch 1521/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0983 - accuracy: 0.5983 - val_loss: 0.1017 - val_accuracy: 0.5824\n",
      "Epoch 1522/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0984 - accuracy: 0.5975 - val_loss: 0.1020 - val_accuracy: 0.5794\n",
      "Epoch 1523/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0984 - accuracy: 0.5980 - val_loss: 0.1026 - val_accuracy: 0.5801\n",
      "Epoch 1524/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0984 - accuracy: 0.5974 - val_loss: 0.1021 - val_accuracy: 0.5838\n",
      "Epoch 1525/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0982 - accuracy: 0.5988 - val_loss: 0.1013 - val_accuracy: 0.5834\n",
      "Epoch 1526/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0983 - accuracy: 0.5982 - val_loss: 0.1025 - val_accuracy: 0.5816\n",
      "Epoch 1527/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0983 - accuracy: 0.5988 - val_loss: 0.1023 - val_accuracy: 0.5804\n",
      "Epoch 1528/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0984 - accuracy: 0.5979 - val_loss: 0.1023 - val_accuracy: 0.5804\n",
      "Epoch 1529/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0983 - accuracy: 0.5986 - val_loss: 0.1027 - val_accuracy: 0.5805\n",
      "Epoch 1530/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0983 - accuracy: 0.5987 - val_loss: 0.1019 - val_accuracy: 0.5814\n",
      "Epoch 1531/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0982 - accuracy: 0.5981 - val_loss: 0.1028 - val_accuracy: 0.5816\n",
      "Epoch 1532/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0983 - accuracy: 0.5981 - val_loss: 0.1024 - val_accuracy: 0.5788\n",
      "Epoch 1533/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0983 - accuracy: 0.5985 - val_loss: 0.1024 - val_accuracy: 0.5801\n",
      "Epoch 1534/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0983 - accuracy: 0.5982 - val_loss: 0.1025 - val_accuracy: 0.5758\n",
      "Epoch 1535/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0983 - accuracy: 0.5985 - val_loss: 0.1021 - val_accuracy: 0.5816\n",
      "Epoch 1536/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0983 - accuracy: 0.5985 - val_loss: 0.1025 - val_accuracy: 0.5790\n",
      "Epoch 1537/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0983 - accuracy: 0.5985 - val_loss: 0.1018 - val_accuracy: 0.5832\n",
      "Epoch 1538/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0983 - accuracy: 0.5981 - val_loss: 0.1021 - val_accuracy: 0.5815\n",
      "Epoch 1539/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0983 - accuracy: 0.5982 - val_loss: 0.1021 - val_accuracy: 0.5801\n",
      "Epoch 1540/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0983 - accuracy: 0.5984 - val_loss: 0.1024 - val_accuracy: 0.5785\n",
      "Epoch 1541/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0983 - accuracy: 0.5979 - val_loss: 0.1017 - val_accuracy: 0.5809\n",
      "Epoch 1542/5000\n",
      "11864/11864 [==============================] - 7s 565us/step - loss: 0.0983 - accuracy: 0.5978 - val_loss: 0.1022 - val_accuracy: 0.5790\n",
      "Epoch 1543/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0983 - accuracy: 0.5981 - val_loss: 0.1023 - val_accuracy: 0.5799\n",
      "Epoch 1544/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0983 - accuracy: 0.5983 - val_loss: 0.1024 - val_accuracy: 0.5813\n",
      "Epoch 1545/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0983 - accuracy: 0.5975 - val_loss: 0.1022 - val_accuracy: 0.5821\n",
      "Epoch 1546/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0984 - accuracy: 0.5974 - val_loss: 0.1023 - val_accuracy: 0.5830\n",
      "Epoch 1547/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0984 - accuracy: 0.5970 - val_loss: 0.1016 - val_accuracy: 0.5833\n",
      "Epoch 1548/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0983 - accuracy: 0.5990 - val_loss: 0.1016 - val_accuracy: 0.5835\n",
      "Epoch 1549/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0983 - accuracy: 0.5983 - val_loss: 0.1021 - val_accuracy: 0.5805\n",
      "Epoch 1550/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0983 - accuracy: 0.5982 - val_loss: 0.1027 - val_accuracy: 0.5789\n",
      "Epoch 1551/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0982 - accuracy: 0.5988 - val_loss: 0.1017 - val_accuracy: 0.5822\n",
      "Epoch 1552/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0983 - accuracy: 0.5983 - val_loss: 0.1027 - val_accuracy: 0.5801\n",
      "Epoch 1553/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0983 - accuracy: 0.5982 - val_loss: 0.1021 - val_accuracy: 0.5799\n",
      "Epoch 1554/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0982 - accuracy: 0.5984 - val_loss: 0.1019 - val_accuracy: 0.5829\n",
      "Epoch 1555/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0983 - accuracy: 0.5984 - val_loss: 0.1021 - val_accuracy: 0.5804\n",
      "Epoch 1556/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0983 - accuracy: 0.5984 - val_loss: 0.1019 - val_accuracy: 0.5818\n",
      "Epoch 1557/5000\n",
      "11864/11864 [==============================] - 7s 569us/step - loss: 0.0982 - accuracy: 0.5986 - val_loss: 0.1023 - val_accuracy: 0.5819\n",
      "Epoch 1558/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0983 - accuracy: 0.5975 - val_loss: 0.1020 - val_accuracy: 0.5818\n",
      "Epoch 1559/5000\n",
      "11864/11864 [==============================] - 7s 574us/step - loss: 0.0982 - accuracy: 0.5987 - val_loss: 0.1022 - val_accuracy: 0.5822\n",
      "Epoch 1560/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0983 - accuracy: 0.5982 - val_loss: 0.1023 - val_accuracy: 0.5827\n",
      "Epoch 1561/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0982 - accuracy: 0.5987 - val_loss: 0.1019 - val_accuracy: 0.5829\n",
      "Epoch 1562/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0982 - accuracy: 0.5991 - val_loss: 0.1030 - val_accuracy: 0.5819\n",
      "Epoch 1563/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0983 - accuracy: 0.5987 - val_loss: 0.1017 - val_accuracy: 0.5830\n",
      "Epoch 1564/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0982 - accuracy: 0.5985 - val_loss: 0.1034 - val_accuracy: 0.5712\n",
      "Epoch 1565/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0982 - accuracy: 0.5982 - val_loss: 0.1023 - val_accuracy: 0.5779\n",
      "Epoch 1566/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0983 - accuracy: 0.5989 - val_loss: 0.1019 - val_accuracy: 0.5835\n",
      "Epoch 1567/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0982 - accuracy: 0.5986 - val_loss: 0.1026 - val_accuracy: 0.5801\n",
      "Epoch 1568/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0983 - accuracy: 0.5979 - val_loss: 0.1027 - val_accuracy: 0.5790\n",
      "Epoch 1569/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0982 - accuracy: 0.5985 - val_loss: 0.1024 - val_accuracy: 0.5779\n",
      "Epoch 1570/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0983 - accuracy: 0.5986 - val_loss: 0.1019 - val_accuracy: 0.5820\n",
      "Epoch 1571/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0982 - accuracy: 0.5985 - val_loss: 0.1026 - val_accuracy: 0.5822\n",
      "Epoch 1572/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0983 - accuracy: 0.5976 - val_loss: 0.1033 - val_accuracy: 0.5797\n",
      "Epoch 1573/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0982 - accuracy: 0.5993 - val_loss: 0.1021 - val_accuracy: 0.5839\n",
      "Epoch 1574/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0982 - accuracy: 0.5993 - val_loss: 0.1028 - val_accuracy: 0.5782\n",
      "Epoch 1575/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0983 - accuracy: 0.5983 - val_loss: 0.1020 - val_accuracy: 0.5846\n",
      "Epoch 1576/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0983 - accuracy: 0.5982 - val_loss: 0.1020 - val_accuracy: 0.5783\n",
      "Epoch 1577/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0982 - accuracy: 0.5983 - val_loss: 0.1027 - val_accuracy: 0.5814\n",
      "Epoch 1578/5000\n",
      "11864/11864 [==============================] - 7s 575us/step - loss: 0.0983 - accuracy: 0.5980 - val_loss: 0.1028 - val_accuracy: 0.5787\n",
      "Epoch 1579/5000\n",
      "11864/11864 [==============================] - 7s 570us/step - loss: 0.0983 - accuracy: 0.5988 - val_loss: 0.1027 - val_accuracy: 0.5765\n",
      "Epoch 1580/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0983 - accuracy: 0.5985 - val_loss: 0.1024 - val_accuracy: 0.5799\n",
      "Epoch 1581/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0983 - accuracy: 0.5983 - val_loss: 0.1023 - val_accuracy: 0.5809\n",
      "Epoch 1582/5000\n",
      "11864/11864 [==============================] - 7s 567us/step - loss: 0.0983 - accuracy: 0.5985 - val_loss: 0.1021 - val_accuracy: 0.5825\n",
      "Epoch 1583/5000\n",
      "11864/11864 [==============================] - 7s 566us/step - loss: 0.0983 - accuracy: 0.5976 - val_loss: 0.1024 - val_accuracy: 0.5812\n",
      "Epoch 1584/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0983 - accuracy: 0.5982 - val_loss: 0.1024 - val_accuracy: 0.5807\n",
      "Epoch 1585/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0982 - accuracy: 0.5987 - val_loss: 0.1023 - val_accuracy: 0.5814\n",
      "Epoch 1586/5000\n",
      "11864/11864 [==============================] - 7s 571us/step - loss: 0.0983 - accuracy: 0.5983 - val_loss: 0.1023 - val_accuracy: 0.5802\n",
      "Epoch 1587/5000\n",
      "11864/11864 [==============================] - 7s 572us/step - loss: 0.0982 - accuracy: 0.5985 - val_loss: 0.1024 - val_accuracy: 0.5800\n",
      "Epoch 1588/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0983 - accuracy: 0.5984 - val_loss: 0.1023 - val_accuracy: 0.5815\n",
      "Epoch 1589/5000\n",
      "11864/11864 [==============================] - 7s 573us/step - loss: 0.0982 - accuracy: 0.5986 - val_loss: 0.1025 - val_accuracy: 0.5794\n",
      "Epoch 1590/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0983 - accuracy: 0.5980 - val_loss: 0.1026 - val_accuracy: 0.5800\n",
      "Epoch 1591/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0983 - accuracy: 0.5981 - val_loss: 0.1018 - val_accuracy: 0.5824\n",
      "Epoch 1592/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0983 - accuracy: 0.5979 - val_loss: 0.1023 - val_accuracy: 0.5798\n",
      "Epoch 1593/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0982 - accuracy: 0.5983 - val_loss: 0.1027 - val_accuracy: 0.5786\n",
      "Epoch 1594/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0983 - accuracy: 0.5984 - val_loss: 0.1021 - val_accuracy: 0.5829\n",
      "Epoch 1595/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0982 - accuracy: 0.5988 - val_loss: 0.1016 - val_accuracy: 0.5826\n",
      "Epoch 1596/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0982 - accuracy: 0.5992 - val_loss: 0.1018 - val_accuracy: 0.5853\n",
      "Epoch 1597/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0982 - accuracy: 0.5982 - val_loss: 0.1021 - val_accuracy: 0.5819\n",
      "Epoch 1598/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1019 - val_accuracy: 0.5845\n",
      "Epoch 1599/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0981 - accuracy: 0.5979 - val_loss: 0.1021 - val_accuracy: 0.5847\n",
      "Epoch 1600/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0983 - accuracy: 0.5982 - val_loss: 0.1021 - val_accuracy: 0.5807\n",
      "Epoch 1601/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0983 - accuracy: 0.5977 - val_loss: 0.1017 - val_accuracy: 0.5820\n",
      "Epoch 1602/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0982 - accuracy: 0.5990 - val_loss: 0.1022 - val_accuracy: 0.5819\n",
      "Epoch 1603/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0982 - accuracy: 0.5990 - val_loss: 0.1021 - val_accuracy: 0.5848\n",
      "Epoch 1604/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0983 - accuracy: 0.5988 - val_loss: 0.1027 - val_accuracy: 0.5799\n",
      "Epoch 1605/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0982 - accuracy: 0.5987 - val_loss: 0.1022 - val_accuracy: 0.5804\n",
      "Epoch 1606/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1018 - val_accuracy: 0.5829\n",
      "Epoch 1607/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0982 - accuracy: 0.5990 - val_loss: 0.1028 - val_accuracy: 0.5820\n",
      "Epoch 1608/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0983 - accuracy: 0.5984 - val_loss: 0.1024 - val_accuracy: 0.5816\n",
      "Epoch 1609/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0983 - accuracy: 0.5982 - val_loss: 0.1029 - val_accuracy: 0.5785\n",
      "Epoch 1610/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0982 - accuracy: 0.5982 - val_loss: 0.1018 - val_accuracy: 0.5833\n",
      "Epoch 1611/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1025 - val_accuracy: 0.5834\n",
      "Epoch 1612/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0983 - accuracy: 0.5991 - val_loss: 0.1020 - val_accuracy: 0.5820\n",
      "Epoch 1613/5000\n",
      "11864/11864 [==============================] - 7s 576us/step - loss: 0.0982 - accuracy: 0.5985 - val_loss: 0.1020 - val_accuracy: 0.5833\n",
      "Epoch 1614/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0982 - accuracy: 0.5980 - val_loss: 0.1025 - val_accuracy: 0.5816\n",
      "Epoch 1615/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1022 - val_accuracy: 0.5792\n",
      "Epoch 1616/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0983 - accuracy: 0.5985 - val_loss: 0.1022 - val_accuracy: 0.5802\n",
      "Epoch 1617/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0982 - accuracy: 0.5990 - val_loss: 0.1022 - val_accuracy: 0.5829\n",
      "Epoch 1618/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0983 - accuracy: 0.5979 - val_loss: 0.1023 - val_accuracy: 0.5803\n",
      "Epoch 1619/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1034 - val_accuracy: 0.5794\n",
      "Epoch 1620/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0983 - accuracy: 0.5979 - val_loss: 0.1027 - val_accuracy: 0.5810\n",
      "Epoch 1621/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0982 - accuracy: 0.5987 - val_loss: 0.1014 - val_accuracy: 0.5811\n",
      "Epoch 1622/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1026 - val_accuracy: 0.5796\n",
      "Epoch 1623/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0982 - accuracy: 0.5985 - val_loss: 0.1025 - val_accuracy: 0.5814\n",
      "Epoch 1624/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0982 - accuracy: 0.5992 - val_loss: 0.1026 - val_accuracy: 0.5793\n",
      "Epoch 1625/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0982 - accuracy: 0.5988 - val_loss: 0.1020 - val_accuracy: 0.5816\n",
      "Epoch 1626/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0982 - accuracy: 0.5988 - val_loss: 0.1033 - val_accuracy: 0.5786\n",
      "Epoch 1627/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1023 - val_accuracy: 0.5824\n",
      "Epoch 1628/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0983 - accuracy: 0.5980 - val_loss: 0.1035 - val_accuracy: 0.5797\n",
      "Epoch 1629/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0982 - accuracy: 0.5989 - val_loss: 0.1020 - val_accuracy: 0.5823\n",
      "Epoch 1630/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1017 - val_accuracy: 0.5828\n",
      "Epoch 1631/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0982 - accuracy: 0.5989 - val_loss: 0.1022 - val_accuracy: 0.5806\n",
      "Epoch 1632/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0982 - accuracy: 0.5985 - val_loss: 0.1019 - val_accuracy: 0.5817\n",
      "Epoch 1633/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0982 - accuracy: 0.5988 - val_loss: 0.1020 - val_accuracy: 0.5835\n",
      "Epoch 1634/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0982 - accuracy: 0.5986 - val_loss: 0.1018 - val_accuracy: 0.5835\n",
      "Epoch 1635/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0982 - accuracy: 0.5993 - val_loss: 0.1024 - val_accuracy: 0.5795\n",
      "Epoch 1636/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0982 - accuracy: 0.5984 - val_loss: 0.1032 - val_accuracy: 0.5767\n",
      "Epoch 1637/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0982 - accuracy: 0.5988 - val_loss: 0.1019 - val_accuracy: 0.5834\n",
      "Epoch 1638/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0982 - accuracy: 0.5985 - val_loss: 0.1023 - val_accuracy: 0.5817\n",
      "Epoch 1639/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0982 - accuracy: 0.5981 - val_loss: 0.1020 - val_accuracy: 0.5818\n",
      "Epoch 1640/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0981 - accuracy: 0.5984 - val_loss: 0.1019 - val_accuracy: 0.5817\n",
      "Epoch 1641/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1024 - val_accuracy: 0.5787\n",
      "Epoch 1642/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0983 - accuracy: 0.5986 - val_loss: 0.1023 - val_accuracy: 0.5820\n",
      "Epoch 1643/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1027 - val_accuracy: 0.5780\n",
      "Epoch 1644/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0982 - accuracy: 0.5985 - val_loss: 0.1025 - val_accuracy: 0.5815\n",
      "Epoch 1645/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0982 - accuracy: 0.5987 - val_loss: 0.1022 - val_accuracy: 0.5809\n",
      "Epoch 1646/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0982 - accuracy: 0.5978 - val_loss: 0.1026 - val_accuracy: 0.5750\n",
      "Epoch 1647/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1017 - val_accuracy: 0.5827\n",
      "Epoch 1648/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0982 - accuracy: 0.5986 - val_loss: 0.1020 - val_accuracy: 0.5819\n",
      "Epoch 1649/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0981 - accuracy: 0.5983 - val_loss: 0.1026 - val_accuracy: 0.5798\n",
      "Epoch 1650/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0982 - accuracy: 0.5985 - val_loss: 0.1030 - val_accuracy: 0.5808\n",
      "Epoch 1651/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1020 - val_accuracy: 0.5822\n",
      "Epoch 1652/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1023 - val_accuracy: 0.5804\n",
      "Epoch 1653/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1019 - val_accuracy: 0.5825\n",
      "Epoch 1654/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0982 - accuracy: 0.5993 - val_loss: 0.1022 - val_accuracy: 0.5815\n",
      "Epoch 1655/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0982 - accuracy: 0.5989 - val_loss: 0.1024 - val_accuracy: 0.5812\n",
      "Epoch 1656/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0981 - accuracy: 0.5994 - val_loss: 0.1031 - val_accuracy: 0.5801\n",
      "Epoch 1657/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0981 - accuracy: 0.5981 - val_loss: 0.1023 - val_accuracy: 0.5787\n",
      "Epoch 1658/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0982 - accuracy: 0.5986 - val_loss: 0.1017 - val_accuracy: 0.5826\n",
      "Epoch 1659/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0982 - accuracy: 0.5980 - val_loss: 0.1023 - val_accuracy: 0.5776\n",
      "Epoch 1660/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0982 - accuracy: 0.5983 - val_loss: 0.1025 - val_accuracy: 0.5808\n",
      "Epoch 1661/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1022 - val_accuracy: 0.5801\n",
      "Epoch 1662/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0983 - accuracy: 0.5985 - val_loss: 0.1026 - val_accuracy: 0.5824\n",
      "Epoch 1663/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0982 - accuracy: 0.5983 - val_loss: 0.1020 - val_accuracy: 0.5834\n",
      "Epoch 1664/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0982 - accuracy: 0.5988 - val_loss: 0.1020 - val_accuracy: 0.5838\n",
      "Epoch 1665/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1023 - val_accuracy: 0.5796\n",
      "Epoch 1666/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0982 - accuracy: 0.5989 - val_loss: 0.1022 - val_accuracy: 0.5803\n",
      "Epoch 1667/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1023 - val_accuracy: 0.5830\n",
      "Epoch 1668/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1026 - val_accuracy: 0.5794\n",
      "Epoch 1669/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0982 - accuracy: 0.5990 - val_loss: 0.1021 - val_accuracy: 0.5790\n",
      "Epoch 1670/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0982 - accuracy: 0.5990 - val_loss: 0.1021 - val_accuracy: 0.5825\n",
      "Epoch 1671/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1021 - val_accuracy: 0.5803\n",
      "Epoch 1672/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0982 - accuracy: 0.5987 - val_loss: 0.1028 - val_accuracy: 0.5789\n",
      "Epoch 1673/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0982 - accuracy: 0.5991 - val_loss: 0.1023 - val_accuracy: 0.5833\n",
      "Epoch 1674/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0981 - accuracy: 0.5994 - val_loss: 0.1019 - val_accuracy: 0.5841\n",
      "Epoch 1675/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0982 - accuracy: 0.5991 - val_loss: 0.1029 - val_accuracy: 0.5824\n",
      "Epoch 1676/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1026 - val_accuracy: 0.5808\n",
      "Epoch 1677/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0982 - accuracy: 0.5986 - val_loss: 0.1027 - val_accuracy: 0.5810\n",
      "Epoch 1678/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0981 - accuracy: 0.5994 - val_loss: 0.1025 - val_accuracy: 0.5809\n",
      "Epoch 1679/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0981 - accuracy: 0.5984 - val_loss: 0.1019 - val_accuracy: 0.5823\n",
      "Epoch 1680/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1016 - val_accuracy: 0.5827\n",
      "Epoch 1681/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0982 - accuracy: 0.5984 - val_loss: 0.1025 - val_accuracy: 0.5805\n",
      "Epoch 1682/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0982 - accuracy: 0.5988 - val_loss: 0.1017 - val_accuracy: 0.5816\n",
      "Epoch 1683/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1023 - val_accuracy: 0.5835\n",
      "Epoch 1684/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1024 - val_accuracy: 0.5802\n",
      "Epoch 1685/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1024 - val_accuracy: 0.5805\n",
      "Epoch 1686/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0982 - accuracy: 0.5987 - val_loss: 0.1021 - val_accuracy: 0.5811\n",
      "Epoch 1687/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0982 - accuracy: 0.5988 - val_loss: 0.1016 - val_accuracy: 0.5841\n",
      "Epoch 1688/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1025 - val_accuracy: 0.5801\n",
      "Epoch 1689/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0981 - accuracy: 0.5996 - val_loss: 0.1018 - val_accuracy: 0.5820\n",
      "Epoch 1690/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0982 - accuracy: 0.5986 - val_loss: 0.1020 - val_accuracy: 0.5839\n",
      "Epoch 1691/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0982 - accuracy: 0.5985 - val_loss: 0.1028 - val_accuracy: 0.5799\n",
      "Epoch 1692/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0982 - accuracy: 0.5981 - val_loss: 0.1022 - val_accuracy: 0.5805\n",
      "Epoch 1693/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1031 - val_accuracy: 0.5779\n",
      "Epoch 1694/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0982 - accuracy: 0.5982 - val_loss: 0.1024 - val_accuracy: 0.5834\n",
      "Epoch 1695/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0981 - accuracy: 0.5981 - val_loss: 0.1025 - val_accuracy: 0.5787\n",
      "Epoch 1696/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1022 - val_accuracy: 0.5802\n",
      "Epoch 1697/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0982 - accuracy: 0.5987 - val_loss: 0.1019 - val_accuracy: 0.5835\n",
      "Epoch 1698/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1016 - val_accuracy: 0.5842\n",
      "Epoch 1699/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1019 - val_accuracy: 0.5818\n",
      "Epoch 1700/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1027 - val_accuracy: 0.5833\n",
      "Epoch 1701/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0981 - accuracy: 0.5995 - val_loss: 0.1024 - val_accuracy: 0.5810\n",
      "Epoch 1702/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1018 - val_accuracy: 0.5828\n",
      "Epoch 1703/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0982 - accuracy: 0.5984 - val_loss: 0.1017 - val_accuracy: 0.5834\n",
      "Epoch 1704/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0982 - accuracy: 0.5983 - val_loss: 0.1017 - val_accuracy: 0.5815\n",
      "Epoch 1705/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1027 - val_accuracy: 0.5777\n",
      "Epoch 1706/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0980 - accuracy: 0.5999 - val_loss: 0.1023 - val_accuracy: 0.5813\n",
      "Epoch 1707/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1023 - val_accuracy: 0.5793\n",
      "Epoch 1708/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0981 - accuracy: 0.5994 - val_loss: 0.1020 - val_accuracy: 0.5814\n",
      "Epoch 1709/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0981 - accuracy: 0.5982 - val_loss: 0.1022 - val_accuracy: 0.5809\n",
      "Epoch 1710/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1023 - val_accuracy: 0.5799\n",
      "Epoch 1711/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0981 - accuracy: 0.5981 - val_loss: 0.1019 - val_accuracy: 0.5827\n",
      "Epoch 1712/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1018 - val_accuracy: 0.5829\n",
      "Epoch 1713/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1022 - val_accuracy: 0.5782\n",
      "Epoch 1714/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1014 - val_accuracy: 0.5839\n",
      "Epoch 1715/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1017 - val_accuracy: 0.5848\n",
      "Epoch 1716/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1022 - val_accuracy: 0.5809\n",
      "Epoch 1717/5000\n",
      "11864/11864 [==============================] - 7s 577us/step - loss: 0.0982 - accuracy: 0.5988 - val_loss: 0.1021 - val_accuracy: 0.5802\n",
      "Epoch 1718/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1025 - val_accuracy: 0.5800\n",
      "Epoch 1719/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0982 - accuracy: 0.5975 - val_loss: 0.1025 - val_accuracy: 0.5802\n",
      "Epoch 1720/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1021 - val_accuracy: 0.5839\n",
      "Epoch 1721/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0982 - accuracy: 0.5981 - val_loss: 0.1030 - val_accuracy: 0.5828\n",
      "Epoch 1722/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0982 - accuracy: 0.5992 - val_loss: 0.1025 - val_accuracy: 0.5807\n",
      "Epoch 1723/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0982 - accuracy: 0.5984 - val_loss: 0.1024 - val_accuracy: 0.5823\n",
      "Epoch 1724/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0983 - accuracy: 0.5973 - val_loss: 0.1020 - val_accuracy: 0.5823\n",
      "Epoch 1725/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0982 - accuracy: 0.5982 - val_loss: 0.1017 - val_accuracy: 0.5829\n",
      "Epoch 1726/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1022 - val_accuracy: 0.5824\n",
      "Epoch 1727/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0982 - accuracy: 0.5992 - val_loss: 0.1030 - val_accuracy: 0.5773\n",
      "Epoch 1728/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0982 - accuracy: 0.5990 - val_loss: 0.1025 - val_accuracy: 0.5804\n",
      "Epoch 1729/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1026 - val_accuracy: 0.5797\n",
      "Epoch 1730/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0981 - accuracy: 0.5995 - val_loss: 0.1019 - val_accuracy: 0.5805\n",
      "Epoch 1731/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1024 - val_accuracy: 0.5802\n",
      "Epoch 1732/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0982 - accuracy: 0.5978 - val_loss: 0.1016 - val_accuracy: 0.5817\n",
      "Epoch 1733/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0981 - accuracy: 0.5983 - val_loss: 0.1027 - val_accuracy: 0.5812\n",
      "Epoch 1734/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1023 - val_accuracy: 0.5804\n",
      "Epoch 1735/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1017 - val_accuracy: 0.5822\n",
      "Epoch 1736/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1030 - val_accuracy: 0.5774\n",
      "Epoch 1737/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0981 - accuracy: 0.5998 - val_loss: 0.1015 - val_accuracy: 0.5851\n",
      "Epoch 1738/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0982 - accuracy: 0.5988 - val_loss: 0.1020 - val_accuracy: 0.5830\n",
      "Epoch 1739/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0981 - accuracy: 0.5994 - val_loss: 0.1027 - val_accuracy: 0.5789\n",
      "Epoch 1740/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1025 - val_accuracy: 0.5807\n",
      "Epoch 1741/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0982 - accuracy: 0.5985 - val_loss: 0.1033 - val_accuracy: 0.5771\n",
      "Epoch 1742/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0981 - accuracy: 0.5996 - val_loss: 0.1025 - val_accuracy: 0.5796\n",
      "Epoch 1743/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1018 - val_accuracy: 0.5836\n",
      "Epoch 1744/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0982 - accuracy: 0.5990 - val_loss: 0.1025 - val_accuracy: 0.5769\n",
      "Epoch 1745/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1024 - val_accuracy: 0.5776\n",
      "Epoch 1746/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1027 - val_accuracy: 0.5781\n",
      "Epoch 1747/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1026 - val_accuracy: 0.5776\n",
      "Epoch 1748/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1029 - val_accuracy: 0.5764\n",
      "Epoch 1749/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1026 - val_accuracy: 0.5822\n",
      "Epoch 1750/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0983 - accuracy: 0.5983 - val_loss: 0.1020 - val_accuracy: 0.5815\n",
      "Epoch 1751/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0982 - accuracy: 0.5987 - val_loss: 0.1027 - val_accuracy: 0.5799\n",
      "Epoch 1752/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5996 - val_loss: 0.1020 - val_accuracy: 0.5827\n",
      "Epoch 1753/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0982 - accuracy: 0.5988 - val_loss: 0.1028 - val_accuracy: 0.5807\n",
      "Epoch 1754/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0981 - accuracy: 0.5994 - val_loss: 0.1027 - val_accuracy: 0.5812\n",
      "Epoch 1755/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0982 - accuracy: 0.5986 - val_loss: 0.1021 - val_accuracy: 0.5823\n",
      "Epoch 1756/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1019 - val_accuracy: 0.5822\n",
      "Epoch 1757/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0982 - accuracy: 0.5987 - val_loss: 0.1027 - val_accuracy: 0.5821\n",
      "Epoch 1758/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0982 - accuracy: 0.5986 - val_loss: 0.1022 - val_accuracy: 0.5794\n",
      "Epoch 1759/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1018 - val_accuracy: 0.5821\n",
      "Epoch 1760/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0982 - accuracy: 0.5987 - val_loss: 0.1023 - val_accuracy: 0.5779\n",
      "Epoch 1761/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1021 - val_accuracy: 0.5803\n",
      "Epoch 1762/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1024 - val_accuracy: 0.5783\n",
      "Epoch 1763/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0981 - accuracy: 0.5995 - val_loss: 0.1027 - val_accuracy: 0.5807\n",
      "Epoch 1764/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0981 - accuracy: 0.5994 - val_loss: 0.1021 - val_accuracy: 0.5839\n",
      "Epoch 1765/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1026 - val_accuracy: 0.5789\n",
      "Epoch 1766/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0982 - accuracy: 0.5990 - val_loss: 0.1029 - val_accuracy: 0.5782\n",
      "Epoch 1767/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1019 - val_accuracy: 0.5824\n",
      "Epoch 1768/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1030 - val_accuracy: 0.5820\n",
      "Epoch 1769/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1026 - val_accuracy: 0.5801\n",
      "Epoch 1770/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1027 - val_accuracy: 0.5826\n",
      "Epoch 1771/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0981 - accuracy: 0.5999 - val_loss: 0.1017 - val_accuracy: 0.5832\n",
      "Epoch 1772/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1024 - val_accuracy: 0.5826\n",
      "Epoch 1773/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0981 - accuracy: 0.5998 - val_loss: 0.1023 - val_accuracy: 0.5786\n",
      "Epoch 1774/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1014 - val_accuracy: 0.5860\n",
      "Epoch 1775/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0981 - accuracy: 0.5994 - val_loss: 0.1027 - val_accuracy: 0.5808\n",
      "Epoch 1776/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1018 - val_accuracy: 0.5798\n",
      "Epoch 1777/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1023 - val_accuracy: 0.5802\n",
      "Epoch 1778/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1022 - val_accuracy: 0.5826\n",
      "Epoch 1779/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1014 - val_accuracy: 0.5859\n",
      "Epoch 1780/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1025 - val_accuracy: 0.5669\n",
      "Epoch 1781/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0981 - accuracy: 0.5981 - val_loss: 0.1030 - val_accuracy: 0.5779\n",
      "Epoch 1782/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1022 - val_accuracy: 0.5782\n",
      "Epoch 1783/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1022 - val_accuracy: 0.5808\n",
      "Epoch 1784/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1021 - val_accuracy: 0.5811\n",
      "Epoch 1785/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0981 - accuracy: 0.5984 - val_loss: 0.1029 - val_accuracy: 0.5802\n",
      "Epoch 1786/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0982 - accuracy: 0.5986 - val_loss: 0.1020 - val_accuracy: 0.5817\n",
      "Epoch 1787/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1026 - val_accuracy: 0.5836\n",
      "Epoch 1788/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1018 - val_accuracy: 0.5840\n",
      "Epoch 1789/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0982 - accuracy: 0.5996 - val_loss: 0.1027 - val_accuracy: 0.5817\n",
      "Epoch 1790/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0982 - accuracy: 0.5982 - val_loss: 0.1024 - val_accuracy: 0.5802\n",
      "Epoch 1791/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0982 - accuracy: 0.5991 - val_loss: 0.1022 - val_accuracy: 0.5816\n",
      "Epoch 1792/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1021 - val_accuracy: 0.5826\n",
      "Epoch 1793/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1022 - val_accuracy: 0.5824\n",
      "Epoch 1794/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0982 - accuracy: 0.5985 - val_loss: 0.1020 - val_accuracy: 0.5823\n",
      "Epoch 1795/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0982 - accuracy: 0.5985 - val_loss: 0.1019 - val_accuracy: 0.5817\n",
      "Epoch 1796/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1016 - val_accuracy: 0.5811\n",
      "Epoch 1797/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0982 - accuracy: 0.5979 - val_loss: 0.1018 - val_accuracy: 0.5816\n",
      "Epoch 1798/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0982 - accuracy: 0.5986 - val_loss: 0.1022 - val_accuracy: 0.5806\n",
      "Epoch 1799/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1023 - val_accuracy: 0.5809\n",
      "Epoch 1800/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0982 - accuracy: 0.5992 - val_loss: 0.1026 - val_accuracy: 0.5811\n",
      "Epoch 1801/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0982 - accuracy: 0.5984 - val_loss: 0.1026 - val_accuracy: 0.5834\n",
      "Epoch 1802/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1016 - val_accuracy: 0.5832\n",
      "Epoch 1803/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0982 - accuracy: 0.5988 - val_loss: 0.1029 - val_accuracy: 0.5736\n",
      "Epoch 1804/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0981 - accuracy: 0.5995 - val_loss: 0.1022 - val_accuracy: 0.5809\n",
      "Epoch 1805/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1019 - val_accuracy: 0.5829\n",
      "Epoch 1806/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1019 - val_accuracy: 0.5819\n",
      "Epoch 1807/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1027 - val_accuracy: 0.5781\n",
      "Epoch 1808/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1022 - val_accuracy: 0.5810\n",
      "Epoch 1809/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1029 - val_accuracy: 0.5787\n",
      "Epoch 1810/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1026 - val_accuracy: 0.5798\n",
      "Epoch 1811/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0982 - accuracy: 0.5988 - val_loss: 0.1022 - val_accuracy: 0.5810\n",
      "Epoch 1812/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0980 - accuracy: 0.6000 - val_loss: 0.1025 - val_accuracy: 0.5807\n",
      "Epoch 1813/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0982 - accuracy: 0.5989 - val_loss: 0.1021 - val_accuracy: 0.5848\n",
      "Epoch 1814/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1028 - val_accuracy: 0.5777\n",
      "Epoch 1815/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1025 - val_accuracy: 0.5822\n",
      "Epoch 1816/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1024 - val_accuracy: 0.5800\n",
      "Epoch 1817/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1024 - val_accuracy: 0.5792\n",
      "Epoch 1818/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1026 - val_accuracy: 0.5804\n",
      "Epoch 1819/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1020 - val_accuracy: 0.5823\n",
      "Epoch 1820/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1021 - val_accuracy: 0.5808\n",
      "Epoch 1821/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0981 - accuracy: 0.5994 - val_loss: 0.1020 - val_accuracy: 0.5832\n",
      "Epoch 1822/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1028 - val_accuracy: 0.5752\n",
      "Epoch 1823/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0982 - accuracy: 0.5996 - val_loss: 0.1014 - val_accuracy: 0.5850\n",
      "Epoch 1824/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0981 - accuracy: 0.5995 - val_loss: 0.1021 - val_accuracy: 0.5835\n",
      "Epoch 1825/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1023 - val_accuracy: 0.5818\n",
      "Epoch 1826/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0981 - accuracy: 0.5983 - val_loss: 0.1022 - val_accuracy: 0.5826\n",
      "Epoch 1827/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1021 - val_accuracy: 0.5820\n",
      "Epoch 1828/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0981 - accuracy: 0.5984 - val_loss: 0.1017 - val_accuracy: 0.5828\n",
      "Epoch 1829/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1023 - val_accuracy: 0.5816\n",
      "Epoch 1830/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0982 - accuracy: 0.5981 - val_loss: 0.1028 - val_accuracy: 0.5803\n",
      "Epoch 1831/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1021 - val_accuracy: 0.5828\n",
      "Epoch 1832/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1027 - val_accuracy: 0.5808\n",
      "Epoch 1833/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0981 - accuracy: 0.5984 - val_loss: 0.1026 - val_accuracy: 0.5801\n",
      "Epoch 1834/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1025 - val_accuracy: 0.5798\n",
      "Epoch 1835/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1022 - val_accuracy: 0.5834\n",
      "Epoch 1836/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1022 - val_accuracy: 0.5805\n",
      "Epoch 1837/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1029 - val_accuracy: 0.5809\n",
      "Epoch 1838/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1033 - val_accuracy: 0.5773\n",
      "Epoch 1839/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1027 - val_accuracy: 0.5840\n",
      "Epoch 1840/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1023 - val_accuracy: 0.5817\n",
      "Epoch 1841/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1024 - val_accuracy: 0.5843\n",
      "Epoch 1842/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1018 - val_accuracy: 0.5829\n",
      "Epoch 1843/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1022 - val_accuracy: 0.5828\n",
      "Epoch 1844/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1022 - val_accuracy: 0.5806\n",
      "Epoch 1845/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0981 - accuracy: 0.5996 - val_loss: 0.1022 - val_accuracy: 0.5800\n",
      "Epoch 1846/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1017 - val_accuracy: 0.5830\n",
      "Epoch 1847/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1022 - val_accuracy: 0.5834\n",
      "Epoch 1848/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1023 - val_accuracy: 0.5790\n",
      "Epoch 1849/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1026 - val_accuracy: 0.5823\n",
      "Epoch 1850/5000\n",
      "11864/11864 [==============================] - 7s 579us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1014 - val_accuracy: 0.5835\n",
      "Epoch 1851/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1027 - val_accuracy: 0.5780\n",
      "Epoch 1852/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0980 - accuracy: 0.5999 - val_loss: 0.1024 - val_accuracy: 0.5826\n",
      "Epoch 1853/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1030 - val_accuracy: 0.5718\n",
      "Epoch 1854/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0981 - accuracy: 0.5995 - val_loss: 0.1015 - val_accuracy: 0.5815\n",
      "Epoch 1855/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1027 - val_accuracy: 0.5812\n",
      "Epoch 1856/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1022 - val_accuracy: 0.5833\n",
      "Epoch 1857/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0982 - accuracy: 0.5988 - val_loss: 0.1028 - val_accuracy: 0.5783\n",
      "Epoch 1858/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1023 - val_accuracy: 0.5824\n",
      "Epoch 1859/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0981 - accuracy: 0.5999 - val_loss: 0.1022 - val_accuracy: 0.5824\n",
      "Epoch 1860/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1027 - val_accuracy: 0.5787\n",
      "Epoch 1861/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1025 - val_accuracy: 0.5795\n",
      "Epoch 1862/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1020 - val_accuracy: 0.5853\n",
      "Epoch 1863/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0981 - accuracy: 0.5995 - val_loss: 0.1025 - val_accuracy: 0.5802\n",
      "Epoch 1864/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0982 - accuracy: 0.5990 - val_loss: 0.1024 - val_accuracy: 0.5798\n",
      "Epoch 1865/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1026 - val_accuracy: 0.5824\n",
      "Epoch 1866/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1021 - val_accuracy: 0.5812\n",
      "Epoch 1867/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0981 - accuracy: 0.5996 - val_loss: 0.1023 - val_accuracy: 0.5813\n",
      "Epoch 1868/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0981 - accuracy: 0.5997 - val_loss: 0.1029 - val_accuracy: 0.5801\n",
      "Epoch 1869/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1024 - val_accuracy: 0.5799\n",
      "Epoch 1870/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0980 - accuracy: 0.6000 - val_loss: 0.1042 - val_accuracy: 0.5785\n",
      "Epoch 1871/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1018 - val_accuracy: 0.5836\n",
      "Epoch 1872/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0981 - accuracy: 0.5996 - val_loss: 0.1024 - val_accuracy: 0.5820\n",
      "Epoch 1873/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1031 - val_accuracy: 0.5798\n",
      "Epoch 1874/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1020 - val_accuracy: 0.5827\n",
      "Epoch 1875/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0981 - accuracy: 0.5996 - val_loss: 0.1019 - val_accuracy: 0.5830\n",
      "Epoch 1876/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0980 - accuracy: 0.6000 - val_loss: 0.1040 - val_accuracy: 0.5790\n",
      "Epoch 1877/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1023 - val_accuracy: 0.5804\n",
      "Epoch 1878/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1025 - val_accuracy: 0.5818\n",
      "Epoch 1879/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5995 - val_loss: 0.1022 - val_accuracy: 0.5816\n",
      "Epoch 1880/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1033 - val_accuracy: 0.5777\n",
      "Epoch 1881/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1024 - val_accuracy: 0.5834\n",
      "Epoch 1882/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1024 - val_accuracy: 0.5821\n",
      "Epoch 1883/5000\n",
      "11864/11864 [==============================] - 7s 578us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1024 - val_accuracy: 0.5780\n",
      "Epoch 1884/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1022 - val_accuracy: 0.5817\n",
      "Epoch 1885/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1023 - val_accuracy: 0.5838\n",
      "Epoch 1886/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0982 - accuracy: 0.5983 - val_loss: 0.1018 - val_accuracy: 0.5820\n",
      "Epoch 1887/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1021 - val_accuracy: 0.5830\n",
      "Epoch 1888/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1024 - val_accuracy: 0.5819\n",
      "Epoch 1889/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0981 - accuracy: 0.5996 - val_loss: 0.1021 - val_accuracy: 0.5814\n",
      "Epoch 1890/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1018 - val_accuracy: 0.5830\n",
      "Epoch 1891/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0982 - accuracy: 0.5981 - val_loss: 0.1024 - val_accuracy: 0.5789\n",
      "Epoch 1892/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0982 - accuracy: 0.5992 - val_loss: 0.1021 - val_accuracy: 0.5816\n",
      "Epoch 1893/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0982 - accuracy: 0.5993 - val_loss: 0.1020 - val_accuracy: 0.5824\n",
      "Epoch 1894/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0982 - accuracy: 0.5989 - val_loss: 0.1019 - val_accuracy: 0.5830\n",
      "Epoch 1895/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5984 - val_loss: 0.1024 - val_accuracy: 0.5807\n",
      "Epoch 1896/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1020 - val_accuracy: 0.5823\n",
      "Epoch 1897/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1019 - val_accuracy: 0.5852\n",
      "Epoch 1898/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1023 - val_accuracy: 0.5814\n",
      "Epoch 1899/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1021 - val_accuracy: 0.5816\n",
      "Epoch 1900/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0982 - accuracy: 0.5995 - val_loss: 0.1025 - val_accuracy: 0.5806\n",
      "Epoch 1901/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0982 - accuracy: 0.5981 - val_loss: 0.1026 - val_accuracy: 0.5795\n",
      "Epoch 1902/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0981 - accuracy: 0.5994 - val_loss: 0.1029 - val_accuracy: 0.5795\n",
      "Epoch 1903/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0982 - accuracy: 0.5992 - val_loss: 0.1026 - val_accuracy: 0.5813\n",
      "Epoch 1904/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1026 - val_accuracy: 0.5809\n",
      "Epoch 1905/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1022 - val_accuracy: 0.5815\n",
      "Epoch 1906/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0982 - accuracy: 0.5989 - val_loss: 0.1020 - val_accuracy: 0.5842\n",
      "Epoch 1907/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1016 - val_accuracy: 0.5831\n",
      "Epoch 1908/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1021 - val_accuracy: 0.5827\n",
      "Epoch 1909/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1027 - val_accuracy: 0.5802\n",
      "Epoch 1910/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0982 - accuracy: 0.5988 - val_loss: 0.1025 - val_accuracy: 0.5808\n",
      "Epoch 1911/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1026 - val_accuracy: 0.5786\n",
      "Epoch 1912/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0982 - accuracy: 0.5986 - val_loss: 0.1021 - val_accuracy: 0.5798\n",
      "Epoch 1913/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0982 - accuracy: 0.5983 - val_loss: 0.1026 - val_accuracy: 0.5812\n",
      "Epoch 1914/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0982 - accuracy: 0.5992 - val_loss: 0.1026 - val_accuracy: 0.5812\n",
      "Epoch 1915/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0981 - accuracy: 0.5983 - val_loss: 0.1026 - val_accuracy: 0.5804\n",
      "Epoch 1916/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1029 - val_accuracy: 0.5791\n",
      "Epoch 1917/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0982 - accuracy: 0.5989 - val_loss: 0.1027 - val_accuracy: 0.5762\n",
      "Epoch 1918/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5994 - val_loss: 0.1026 - val_accuracy: 0.5798\n",
      "Epoch 1919/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1022 - val_accuracy: 0.5800\n",
      "Epoch 1920/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0982 - accuracy: 0.5988 - val_loss: 0.1028 - val_accuracy: 0.5808\n",
      "Epoch 1921/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0981 - accuracy: 0.5996 - val_loss: 0.1022 - val_accuracy: 0.5805\n",
      "Epoch 1922/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0981 - accuracy: 0.5995 - val_loss: 0.1025 - val_accuracy: 0.5823\n",
      "Epoch 1923/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1026 - val_accuracy: 0.5803\n",
      "Epoch 1924/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0981 - accuracy: 0.5998 - val_loss: 0.1028 - val_accuracy: 0.5749\n",
      "Epoch 1925/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0982 - accuracy: 0.5986 - val_loss: 0.1023 - val_accuracy: 0.5815\n",
      "Epoch 1926/5000\n",
      "11864/11864 [==============================] - 7s 580us/step - loss: 0.0982 - accuracy: 0.5992 - val_loss: 0.1026 - val_accuracy: 0.5794\n",
      "Epoch 1927/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0981 - accuracy: 0.5982 - val_loss: 0.1024 - val_accuracy: 0.5792\n",
      "Epoch 1928/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1021 - val_accuracy: 0.5811\n",
      "Epoch 1929/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1026 - val_accuracy: 0.5797\n",
      "Epoch 1930/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0981 - accuracy: 0.5994 - val_loss: 0.1022 - val_accuracy: 0.5797\n",
      "Epoch 1931/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0982 - accuracy: 0.5994 - val_loss: 0.1026 - val_accuracy: 0.5820\n",
      "Epoch 1932/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0981 - accuracy: 0.5996 - val_loss: 0.1023 - val_accuracy: 0.5818\n",
      "Epoch 1933/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0981 - accuracy: 0.5995 - val_loss: 0.1029 - val_accuracy: 0.5823\n",
      "Epoch 1934/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0982 - accuracy: 0.5991 - val_loss: 0.1020 - val_accuracy: 0.5802\n",
      "Epoch 1935/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0982 - accuracy: 0.5992 - val_loss: 0.1021 - val_accuracy: 0.5795\n",
      "Epoch 1936/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1029 - val_accuracy: 0.5780\n",
      "Epoch 1937/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0982 - accuracy: 0.5988 - val_loss: 0.1021 - val_accuracy: 0.5824\n",
      "Epoch 1938/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1022 - val_accuracy: 0.5794\n",
      "Epoch 1939/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0981 - accuracy: 0.5995 - val_loss: 0.1020 - val_accuracy: 0.5805\n",
      "Epoch 1940/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1022 - val_accuracy: 0.5812\n",
      "Epoch 1941/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1026 - val_accuracy: 0.5801\n",
      "Epoch 1942/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1024 - val_accuracy: 0.5790\n",
      "Epoch 1943/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0982 - accuracy: 0.5987 - val_loss: 0.1023 - val_accuracy: 0.5805\n",
      "Epoch 1944/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0982 - accuracy: 0.5983 - val_loss: 0.1024 - val_accuracy: 0.5808\n",
      "Epoch 1945/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1021 - val_accuracy: 0.5802\n",
      "Epoch 1946/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0981 - accuracy: 0.5994 - val_loss: 0.1026 - val_accuracy: 0.5803\n",
      "Epoch 1947/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0981 - accuracy: 0.5997 - val_loss: 0.1026 - val_accuracy: 0.5830\n",
      "Epoch 1948/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1023 - val_accuracy: 0.5806\n",
      "Epoch 1949/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0982 - accuracy: 0.5999 - val_loss: 0.1022 - val_accuracy: 0.5826\n",
      "Epoch 1950/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1021 - val_accuracy: 0.5818\n",
      "Epoch 1951/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1023 - val_accuracy: 0.5799\n",
      "Epoch 1952/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1022 - val_accuracy: 0.5793\n",
      "Epoch 1953/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1028 - val_accuracy: 0.5804\n",
      "Epoch 1954/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0982 - accuracy: 0.5988 - val_loss: 0.1021 - val_accuracy: 0.5827\n",
      "Epoch 1955/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0982 - accuracy: 0.5988 - val_loss: 0.1025 - val_accuracy: 0.5819\n",
      "Epoch 1956/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1021 - val_accuracy: 0.5809\n",
      "Epoch 1957/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1024 - val_accuracy: 0.5803\n",
      "Epoch 1958/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0982 - accuracy: 0.5986 - val_loss: 0.1022 - val_accuracy: 0.5782\n",
      "Epoch 1959/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0982 - accuracy: 0.5979 - val_loss: 0.1021 - val_accuracy: 0.5815\n",
      "Epoch 1960/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1024 - val_accuracy: 0.5817\n",
      "Epoch 1961/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0981 - accuracy: 0.5996 - val_loss: 0.1017 - val_accuracy: 0.5833\n",
      "Epoch 1962/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0982 - accuracy: 0.5980 - val_loss: 0.1027 - val_accuracy: 0.5801\n",
      "Epoch 1963/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1023 - val_accuracy: 0.5817\n",
      "Epoch 1964/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1021 - val_accuracy: 0.5833\n",
      "Epoch 1965/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1024 - val_accuracy: 0.5788\n",
      "Epoch 1966/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5994 - val_loss: 0.1022 - val_accuracy: 0.5812\n",
      "Epoch 1967/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0982 - accuracy: 0.5987 - val_loss: 0.1019 - val_accuracy: 0.5809\n",
      "Epoch 1968/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0982 - accuracy: 0.5987 - val_loss: 0.1027 - val_accuracy: 0.5788\n",
      "Epoch 1969/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1023 - val_accuracy: 0.5786\n",
      "Epoch 1970/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1020 - val_accuracy: 0.5828\n",
      "Epoch 1971/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1029 - val_accuracy: 0.5784\n",
      "Epoch 1972/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0982 - accuracy: 0.5986 - val_loss: 0.1023 - val_accuracy: 0.5774\n",
      "Epoch 1973/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0982 - accuracy: 0.5988 - val_loss: 0.1020 - val_accuracy: 0.5807\n",
      "Epoch 1974/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1018 - val_accuracy: 0.5811\n",
      "Epoch 1975/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1026 - val_accuracy: 0.5823\n",
      "Epoch 1976/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0982 - accuracy: 0.5988 - val_loss: 0.1026 - val_accuracy: 0.5791\n",
      "Epoch 1977/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0982 - accuracy: 0.5986 - val_loss: 0.1022 - val_accuracy: 0.5807\n",
      "Epoch 1978/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0982 - accuracy: 0.5985 - val_loss: 0.1024 - val_accuracy: 0.5818\n",
      "Epoch 1979/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0982 - accuracy: 0.5987 - val_loss: 0.1021 - val_accuracy: 0.5812\n",
      "Epoch 1980/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1030 - val_accuracy: 0.5808\n",
      "Epoch 1981/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1023 - val_accuracy: 0.5788\n",
      "Epoch 1982/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1028 - val_accuracy: 0.5786\n",
      "Epoch 1983/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0982 - accuracy: 0.5993 - val_loss: 0.1021 - val_accuracy: 0.5815\n",
      "Epoch 1984/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1021 - val_accuracy: 0.5817\n",
      "Epoch 1985/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0982 - accuracy: 0.5982 - val_loss: 0.1020 - val_accuracy: 0.5814\n",
      "Epoch 1986/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1019 - val_accuracy: 0.5810\n",
      "Epoch 1987/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1030 - val_accuracy: 0.5771\n",
      "Epoch 1988/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0982 - accuracy: 0.5984 - val_loss: 0.1028 - val_accuracy: 0.5822\n",
      "Epoch 1989/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0982 - accuracy: 0.5984 - val_loss: 0.1025 - val_accuracy: 0.5805\n",
      "Epoch 1990/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1029 - val_accuracy: 0.5795\n",
      "Epoch 1991/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0982 - accuracy: 0.5984 - val_loss: 0.1029 - val_accuracy: 0.5807\n",
      "Epoch 1992/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0982 - accuracy: 0.5989 - val_loss: 0.1024 - val_accuracy: 0.5805\n",
      "Epoch 1993/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1020 - val_accuracy: 0.5818\n",
      "Epoch 1994/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1022 - val_accuracy: 0.5817\n",
      "Epoch 1995/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0980 - accuracy: 0.6001 - val_loss: 0.1015 - val_accuracy: 0.5830\n",
      "Epoch 1996/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1031 - val_accuracy: 0.5812\n",
      "Epoch 1997/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1027 - val_accuracy: 0.5796\n",
      "Epoch 1998/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0982 - accuracy: 0.5987 - val_loss: 0.1023 - val_accuracy: 0.5815\n",
      "Epoch 1999/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0981 - accuracy: 0.5983 - val_loss: 0.1021 - val_accuracy: 0.5836\n",
      "Epoch 2000/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0982 - accuracy: 0.5993 - val_loss: 0.1023 - val_accuracy: 0.5825\n",
      "Epoch 2001/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0982 - accuracy: 0.5981 - val_loss: 0.1020 - val_accuracy: 0.5820\n",
      "Epoch 2002/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1018 - val_accuracy: 0.5831\n",
      "Epoch 2003/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0982 - accuracy: 0.5983 - val_loss: 0.1025 - val_accuracy: 0.5763\n",
      "Epoch 2004/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0982 - accuracy: 0.5985 - val_loss: 0.1021 - val_accuracy: 0.5817\n",
      "Epoch 2005/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0982 - accuracy: 0.5990 - val_loss: 0.1024 - val_accuracy: 0.5808\n",
      "Epoch 2006/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0982 - accuracy: 0.5981 - val_loss: 0.1021 - val_accuracy: 0.5784\n",
      "Epoch 2007/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1022 - val_accuracy: 0.5798\n",
      "Epoch 2008/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1027 - val_accuracy: 0.5786\n",
      "Epoch 2009/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0983 - accuracy: 0.5982 - val_loss: 0.1028 - val_accuracy: 0.5762\n",
      "Epoch 2010/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0982 - accuracy: 0.5989 - val_loss: 0.1027 - val_accuracy: 0.5803\n",
      "Epoch 2011/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1019 - val_accuracy: 0.5818\n",
      "Epoch 2012/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0981 - accuracy: 0.5982 - val_loss: 0.1029 - val_accuracy: 0.5741\n",
      "Epoch 2013/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0982 - accuracy: 0.5986 - val_loss: 0.1019 - val_accuracy: 0.5802\n",
      "Epoch 2014/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1027 - val_accuracy: 0.5779\n",
      "Epoch 2015/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0982 - accuracy: 0.5978 - val_loss: 0.1024 - val_accuracy: 0.5798\n",
      "Epoch 2016/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0980 - accuracy: 0.5987 - val_loss: 0.1020 - val_accuracy: 0.5816\n",
      "Epoch 2017/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1022 - val_accuracy: 0.5790\n",
      "Epoch 2018/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1027 - val_accuracy: 0.5782\n",
      "Epoch 2019/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0982 - accuracy: 0.5984 - val_loss: 0.1027 - val_accuracy: 0.5789\n",
      "Epoch 2020/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0982 - accuracy: 0.5974 - val_loss: 0.1023 - val_accuracy: 0.5817\n",
      "Epoch 2021/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0982 - accuracy: 0.5984 - val_loss: 0.1028 - val_accuracy: 0.5822\n",
      "Epoch 2022/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0982 - accuracy: 0.5988 - val_loss: 0.1026 - val_accuracy: 0.5790\n",
      "Epoch 2023/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1024 - val_accuracy: 0.5802\n",
      "Epoch 2024/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0982 - accuracy: 0.5988 - val_loss: 0.1023 - val_accuracy: 0.5804\n",
      "Epoch 2025/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1022 - val_accuracy: 0.5805\n",
      "Epoch 2026/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1025 - val_accuracy: 0.5813\n",
      "Epoch 2027/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1029 - val_accuracy: 0.5776\n",
      "Epoch 2028/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0981 - accuracy: 0.5996 - val_loss: 0.1025 - val_accuracy: 0.5814\n",
      "Epoch 2029/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1028 - val_accuracy: 0.5766\n",
      "Epoch 2030/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0981 - accuracy: 0.5999 - val_loss: 0.1026 - val_accuracy: 0.5794\n",
      "Epoch 2031/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5982 - val_loss: 0.1023 - val_accuracy: 0.5805\n",
      "Epoch 2032/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0982 - accuracy: 0.5983 - val_loss: 0.1027 - val_accuracy: 0.5786\n",
      "Epoch 2033/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0982 - accuracy: 0.5988 - val_loss: 0.1042 - val_accuracy: 0.5790\n",
      "Epoch 2034/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0981 - accuracy: 0.5994 - val_loss: 0.1027 - val_accuracy: 0.5771\n",
      "Epoch 2035/5000\n",
      "11864/11864 [==============================] - 7s 581us/step - loss: 0.0982 - accuracy: 0.5983 - val_loss: 0.1026 - val_accuracy: 0.5786\n",
      "Epoch 2036/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0983 - accuracy: 0.5980 - val_loss: 0.1032 - val_accuracy: 0.5769\n",
      "Epoch 2037/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1023 - val_accuracy: 0.5802\n",
      "Epoch 2038/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0982 - accuracy: 0.5986 - val_loss: 0.1025 - val_accuracy: 0.5811\n",
      "Epoch 2039/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1022 - val_accuracy: 0.5822\n",
      "Epoch 2040/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0982 - accuracy: 0.5985 - val_loss: 0.1021 - val_accuracy: 0.5809\n",
      "Epoch 2041/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0982 - accuracy: 0.5989 - val_loss: 0.1024 - val_accuracy: 0.5816\n",
      "Epoch 2042/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0982 - accuracy: 0.5990 - val_loss: 0.1021 - val_accuracy: 0.5782\n",
      "Epoch 2043/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1020 - val_accuracy: 0.5817\n",
      "Epoch 2044/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0981 - accuracy: 0.5997 - val_loss: 0.1032 - val_accuracy: 0.5800\n",
      "Epoch 2045/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1021 - val_accuracy: 0.5800\n",
      "Epoch 2046/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1028 - val_accuracy: 0.5807\n",
      "Epoch 2047/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1026 - val_accuracy: 0.5822\n",
      "Epoch 2048/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1028 - val_accuracy: 0.5744\n",
      "Epoch 2049/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1028 - val_accuracy: 0.5798\n",
      "Epoch 2050/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0982 - accuracy: 0.5987 - val_loss: 0.1023 - val_accuracy: 0.5795\n",
      "Epoch 2051/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1026 - val_accuracy: 0.5779\n",
      "Epoch 2052/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1023 - val_accuracy: 0.5795\n",
      "Epoch 2053/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0982 - accuracy: 0.5979 - val_loss: 0.1024 - val_accuracy: 0.5811\n",
      "Epoch 2054/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1026 - val_accuracy: 0.5816\n",
      "Epoch 2055/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1028 - val_accuracy: 0.5787\n",
      "Epoch 2056/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0982 - accuracy: 0.5982 - val_loss: 0.1023 - val_accuracy: 0.5808\n",
      "Epoch 2057/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0982 - accuracy: 0.5985 - val_loss: 0.1021 - val_accuracy: 0.5818\n",
      "Epoch 2058/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0982 - accuracy: 0.5990 - val_loss: 0.1023 - val_accuracy: 0.5814\n",
      "Epoch 2059/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0982 - accuracy: 0.5988 - val_loss: 0.1029 - val_accuracy: 0.5804\n",
      "Epoch 2060/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0982 - accuracy: 0.5983 - val_loss: 0.1019 - val_accuracy: 0.5848\n",
      "Epoch 2061/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0983 - accuracy: 0.5983 - val_loss: 0.1021 - val_accuracy: 0.5789\n",
      "Epoch 2062/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0982 - accuracy: 0.5982 - val_loss: 0.1027 - val_accuracy: 0.5812\n",
      "Epoch 2063/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0982 - accuracy: 0.5977 - val_loss: 0.1020 - val_accuracy: 0.5803\n",
      "Epoch 2064/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0982 - accuracy: 0.5985 - val_loss: 0.1025 - val_accuracy: 0.5796\n",
      "Epoch 2065/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1027 - val_accuracy: 0.5802\n",
      "Epoch 2066/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1032 - val_accuracy: 0.5777\n",
      "Epoch 2067/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1018 - val_accuracy: 0.5836\n",
      "Epoch 2068/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0982 - accuracy: 0.5989 - val_loss: 0.1024 - val_accuracy: 0.5824\n",
      "Epoch 2069/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0982 - accuracy: 0.5987 - val_loss: 0.1026 - val_accuracy: 0.5814\n",
      "Epoch 2070/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0980 - accuracy: 0.5999 - val_loss: 0.1027 - val_accuracy: 0.5789\n",
      "Epoch 2071/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1023 - val_accuracy: 0.5791\n",
      "Epoch 2072/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0982 - accuracy: 0.5985 - val_loss: 0.1022 - val_accuracy: 0.5810\n",
      "Epoch 2073/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1029 - val_accuracy: 0.5799\n",
      "Epoch 2074/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1019 - val_accuracy: 0.5835\n",
      "Epoch 2075/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1020 - val_accuracy: 0.5819\n",
      "Epoch 2076/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0982 - accuracy: 0.5982 - val_loss: 0.1020 - val_accuracy: 0.5821\n",
      "Epoch 2077/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1023 - val_accuracy: 0.5810\n",
      "Epoch 2078/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1026 - val_accuracy: 0.5787\n",
      "Epoch 2079/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0983 - accuracy: 0.5983 - val_loss: 0.1029 - val_accuracy: 0.5791\n",
      "Epoch 2080/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1032 - val_accuracy: 0.5779\n",
      "Epoch 2081/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1026 - val_accuracy: 0.5803\n",
      "Epoch 2082/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0982 - accuracy: 0.5987 - val_loss: 0.1021 - val_accuracy: 0.5800\n",
      "Epoch 2083/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0982 - accuracy: 0.5993 - val_loss: 0.1020 - val_accuracy: 0.5816\n",
      "Epoch 2084/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0982 - accuracy: 0.5989 - val_loss: 0.1031 - val_accuracy: 0.5781\n",
      "Epoch 2085/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1027 - val_accuracy: 0.5831\n",
      "Epoch 2086/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1030 - val_accuracy: 0.5830\n",
      "Epoch 2087/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0982 - accuracy: 0.5994 - val_loss: 0.1024 - val_accuracy: 0.5788\n",
      "Epoch 2088/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0982 - accuracy: 0.5986 - val_loss: 0.1020 - val_accuracy: 0.5827\n",
      "Epoch 2089/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0982 - accuracy: 0.5991 - val_loss: 0.1021 - val_accuracy: 0.5826\n",
      "Epoch 2090/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0982 - accuracy: 0.5986 - val_loss: 0.1029 - val_accuracy: 0.5794\n",
      "Epoch 2091/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0982 - accuracy: 0.5985 - val_loss: 0.1019 - val_accuracy: 0.5836\n",
      "Epoch 2092/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0982 - accuracy: 0.5995 - val_loss: 0.1023 - val_accuracy: 0.5801\n",
      "Epoch 2093/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0982 - accuracy: 0.5994 - val_loss: 0.1031 - val_accuracy: 0.5757\n",
      "Epoch 2094/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0981 - accuracy: 0.5996 - val_loss: 0.1021 - val_accuracy: 0.5825\n",
      "Epoch 2095/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1033 - val_accuracy: 0.5765\n",
      "Epoch 2096/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0982 - accuracy: 0.5995 - val_loss: 0.1026 - val_accuracy: 0.5792\n",
      "Epoch 2097/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0981 - accuracy: 0.5995 - val_loss: 0.1022 - val_accuracy: 0.5797\n",
      "Epoch 2098/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1018 - val_accuracy: 0.5804\n",
      "Epoch 2099/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0982 - accuracy: 0.5990 - val_loss: 0.1032 - val_accuracy: 0.5775\n",
      "Epoch 2100/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1023 - val_accuracy: 0.5799\n",
      "Epoch 2101/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1026 - val_accuracy: 0.5815\n",
      "Epoch 2102/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0981 - accuracy: 0.5994 - val_loss: 0.1023 - val_accuracy: 0.5801\n",
      "Epoch 2103/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1029 - val_accuracy: 0.5782\n",
      "Epoch 2104/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1025 - val_accuracy: 0.5773\n",
      "Epoch 2105/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0982 - accuracy: 0.5984 - val_loss: 0.1026 - val_accuracy: 0.5815\n",
      "Epoch 2106/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5983 - val_loss: 0.1021 - val_accuracy: 0.5814\n",
      "Epoch 2107/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1027 - val_accuracy: 0.5829\n",
      "Epoch 2108/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1035 - val_accuracy: 0.5685\n",
      "Epoch 2109/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0981 - accuracy: 0.5983 - val_loss: 0.1026 - val_accuracy: 0.5790\n",
      "Epoch 2110/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1023 - val_accuracy: 0.5820\n",
      "Epoch 2111/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5996 - val_loss: 0.1023 - val_accuracy: 0.5829\n",
      "Epoch 2112/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1034 - val_accuracy: 0.5751\n",
      "Epoch 2113/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0982 - accuracy: 0.5984 - val_loss: 0.1029 - val_accuracy: 0.5809\n",
      "Epoch 2114/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0983 - accuracy: 0.5983 - val_loss: 0.1026 - val_accuracy: 0.5814\n",
      "Epoch 2115/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0981 - accuracy: 0.5997 - val_loss: 0.1020 - val_accuracy: 0.5826\n",
      "Epoch 2116/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0981 - accuracy: 0.5983 - val_loss: 0.1026 - val_accuracy: 0.5788\n",
      "Epoch 2117/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0982 - accuracy: 0.5985 - val_loss: 0.1026 - val_accuracy: 0.5836\n",
      "Epoch 2118/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1027 - val_accuracy: 0.5770\n",
      "Epoch 2119/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1015 - val_accuracy: 0.5846\n",
      "Epoch 2120/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0982 - accuracy: 0.5981 - val_loss: 0.1018 - val_accuracy: 0.5818\n",
      "Epoch 2121/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0982 - accuracy: 0.5982 - val_loss: 0.1029 - val_accuracy: 0.5791\n",
      "Epoch 2122/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0982 - accuracy: 0.5984 - val_loss: 0.1027 - val_accuracy: 0.5797\n",
      "Epoch 2123/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1020 - val_accuracy: 0.5794\n",
      "Epoch 2124/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0982 - accuracy: 0.5983 - val_loss: 0.1026 - val_accuracy: 0.5811\n",
      "Epoch 2125/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1025 - val_accuracy: 0.5778\n",
      "Epoch 2126/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0982 - accuracy: 0.5980 - val_loss: 0.1028 - val_accuracy: 0.5721\n",
      "Epoch 2127/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0982 - accuracy: 0.5989 - val_loss: 0.1020 - val_accuracy: 0.5821\n",
      "Epoch 2128/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0982 - accuracy: 0.5980 - val_loss: 0.1026 - val_accuracy: 0.5800\n",
      "Epoch 2129/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0982 - accuracy: 0.5989 - val_loss: 0.1037 - val_accuracy: 0.5804\n",
      "Epoch 2130/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1026 - val_accuracy: 0.5790\n",
      "Epoch 2131/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0982 - accuracy: 0.5979 - val_loss: 0.1021 - val_accuracy: 0.5835\n",
      "Epoch 2132/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0981 - accuracy: 0.5984 - val_loss: 0.1024 - val_accuracy: 0.5794\n",
      "Epoch 2133/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0982 - accuracy: 0.5982 - val_loss: 0.1032 - val_accuracy: 0.5755\n",
      "Epoch 2134/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0982 - accuracy: 0.5983 - val_loss: 0.1029 - val_accuracy: 0.5794\n",
      "Epoch 2135/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1024 - val_accuracy: 0.5810\n",
      "Epoch 2136/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0982 - accuracy: 0.5982 - val_loss: 0.1029 - val_accuracy: 0.5783\n",
      "Epoch 2137/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0982 - accuracy: 0.5981 - val_loss: 0.1018 - val_accuracy: 0.5821\n",
      "Epoch 2138/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1018 - val_accuracy: 0.5829\n",
      "Epoch 2139/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0981 - accuracy: 0.5981 - val_loss: 0.1019 - val_accuracy: 0.5826\n",
      "Epoch 2140/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1023 - val_accuracy: 0.5797\n",
      "Epoch 2141/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0981 - accuracy: 0.5982 - val_loss: 0.1021 - val_accuracy: 0.5801\n",
      "Epoch 2142/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0982 - accuracy: 0.5985 - val_loss: 0.1026 - val_accuracy: 0.5820\n",
      "Epoch 2143/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1026 - val_accuracy: 0.5767\n",
      "Epoch 2144/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1015 - val_accuracy: 0.5835\n",
      "Epoch 2145/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1020 - val_accuracy: 0.5826\n",
      "Epoch 2146/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0981 - accuracy: 0.5994 - val_loss: 0.1035 - val_accuracy: 0.5787\n",
      "Epoch 2147/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0981 - accuracy: 0.5998 - val_loss: 0.1028 - val_accuracy: 0.5783\n",
      "Epoch 2148/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0982 - accuracy: 0.5984 - val_loss: 0.1031 - val_accuracy: 0.5774\n",
      "Epoch 2149/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1029 - val_accuracy: 0.5815\n",
      "Epoch 2150/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0981 - accuracy: 0.5994 - val_loss: 0.1024 - val_accuracy: 0.5807\n",
      "Epoch 2151/5000\n",
      "11864/11864 [==============================] - 7s 582us/step - loss: 0.0982 - accuracy: 0.5983 - val_loss: 0.1024 - val_accuracy: 0.5804\n",
      "Epoch 2152/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1024 - val_accuracy: 0.5819\n",
      "Epoch 2153/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1024 - val_accuracy: 0.5812\n",
      "Epoch 2154/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0982 - accuracy: 0.5988 - val_loss: 0.1022 - val_accuracy: 0.5811\n",
      "Epoch 2155/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0982 - accuracy: 0.5986 - val_loss: 0.1025 - val_accuracy: 0.5816\n",
      "Epoch 2156/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0982 - accuracy: 0.5994 - val_loss: 0.1031 - val_accuracy: 0.5824\n",
      "Epoch 2157/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1025 - val_accuracy: 0.5821\n",
      "Epoch 2158/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1025 - val_accuracy: 0.5776\n",
      "Epoch 2159/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0981 - accuracy: 0.5982 - val_loss: 0.1024 - val_accuracy: 0.5810\n",
      "Epoch 2160/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1019 - val_accuracy: 0.5811\n",
      "Epoch 2161/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0982 - accuracy: 0.5980 - val_loss: 0.1030 - val_accuracy: 0.5762\n",
      "Epoch 2162/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1026 - val_accuracy: 0.5787\n",
      "Epoch 2163/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0982 - accuracy: 0.5988 - val_loss: 0.1020 - val_accuracy: 0.5815\n",
      "Epoch 2164/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1026 - val_accuracy: 0.5811\n",
      "Epoch 2165/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5995 - val_loss: 0.1027 - val_accuracy: 0.5794\n",
      "Epoch 2166/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0982 - accuracy: 0.5985 - val_loss: 0.1030 - val_accuracy: 0.5784\n",
      "Epoch 2167/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1028 - val_accuracy: 0.5795\n",
      "Epoch 2168/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0982 - accuracy: 0.5983 - val_loss: 0.1022 - val_accuracy: 0.5801\n",
      "Epoch 2169/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1021 - val_accuracy: 0.5835\n",
      "Epoch 2170/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0982 - accuracy: 0.5987 - val_loss: 0.1025 - val_accuracy: 0.5798\n",
      "Epoch 2171/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5984 - val_loss: 0.1019 - val_accuracy: 0.5813\n",
      "Epoch 2172/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0982 - accuracy: 0.5988 - val_loss: 0.1021 - val_accuracy: 0.5815\n",
      "Epoch 2173/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0981 - accuracy: 0.5980 - val_loss: 0.1024 - val_accuracy: 0.5800\n",
      "Epoch 2174/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0981 - accuracy: 0.5981 - val_loss: 0.1027 - val_accuracy: 0.5812\n",
      "Epoch 2175/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1022 - val_accuracy: 0.5836\n",
      "Epoch 2176/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1028 - val_accuracy: 0.5780\n",
      "Epoch 2177/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0983 - accuracy: 0.5985 - val_loss: 0.1022 - val_accuracy: 0.5829\n",
      "Epoch 2178/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1024 - val_accuracy: 0.5788\n",
      "Epoch 2179/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0982 - accuracy: 0.5981 - val_loss: 0.1026 - val_accuracy: 0.5801\n",
      "Epoch 2180/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0982 - accuracy: 0.5988 - val_loss: 0.1026 - val_accuracy: 0.5830\n",
      "Epoch 2181/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0982 - accuracy: 0.5985 - val_loss: 0.1031 - val_accuracy: 0.5763\n",
      "Epoch 2182/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0982 - accuracy: 0.5989 - val_loss: 0.1022 - val_accuracy: 0.5821\n",
      "Epoch 2183/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1020 - val_accuracy: 0.5808\n",
      "Epoch 2184/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0980 - accuracy: 0.5986 - val_loss: 0.1031 - val_accuracy: 0.5790\n",
      "Epoch 2185/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0982 - accuracy: 0.5988 - val_loss: 0.1023 - val_accuracy: 0.5833\n",
      "Epoch 2186/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0982 - accuracy: 0.5981 - val_loss: 0.1017 - val_accuracy: 0.5836\n",
      "Epoch 2187/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0981 - accuracy: 0.5984 - val_loss: 0.1027 - val_accuracy: 0.5817\n",
      "Epoch 2188/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0982 - accuracy: 0.5975 - val_loss: 0.1027 - val_accuracy: 0.5801\n",
      "Epoch 2189/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0982 - accuracy: 0.5983 - val_loss: 0.1022 - val_accuracy: 0.5818\n",
      "Epoch 2190/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0982 - accuracy: 0.5983 - val_loss: 0.1027 - val_accuracy: 0.5806\n",
      "Epoch 2191/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0982 - accuracy: 0.5986 - val_loss: 0.1024 - val_accuracy: 0.5817\n",
      "Epoch 2192/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0982 - accuracy: 0.5986 - val_loss: 0.1039 - val_accuracy: 0.5785\n",
      "Epoch 2193/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1025 - val_accuracy: 0.5787\n",
      "Epoch 2194/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0981 - accuracy: 0.5983 - val_loss: 0.1025 - val_accuracy: 0.5800\n",
      "Epoch 2195/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1021 - val_accuracy: 0.5823\n",
      "Epoch 2196/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1018 - val_accuracy: 0.5816\n",
      "Epoch 2197/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1022 - val_accuracy: 0.5811\n",
      "Epoch 2198/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5984 - val_loss: 0.1032 - val_accuracy: 0.5788\n",
      "Epoch 2199/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0982 - accuracy: 0.5982 - val_loss: 0.1025 - val_accuracy: 0.5797\n",
      "Epoch 2200/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0982 - accuracy: 0.5987 - val_loss: 0.1030 - val_accuracy: 0.5770\n",
      "Epoch 2201/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0982 - accuracy: 0.5984 - val_loss: 0.1027 - val_accuracy: 0.5828\n",
      "Epoch 2202/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1020 - val_accuracy: 0.5809\n",
      "Epoch 2203/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0982 - accuracy: 0.5986 - val_loss: 0.1020 - val_accuracy: 0.5809\n",
      "Epoch 2204/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0982 - accuracy: 0.5983 - val_loss: 0.1028 - val_accuracy: 0.5800\n",
      "Epoch 2205/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0982 - accuracy: 0.5990 - val_loss: 0.1022 - val_accuracy: 0.5832\n",
      "Epoch 2206/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0982 - accuracy: 0.5979 - val_loss: 0.1025 - val_accuracy: 0.5733\n",
      "Epoch 2207/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0982 - accuracy: 0.5988 - val_loss: 0.1026 - val_accuracy: 0.5785\n",
      "Epoch 2208/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0982 - accuracy: 0.5981 - val_loss: 0.1023 - val_accuracy: 0.5795\n",
      "Epoch 2209/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0980 - accuracy: 0.5987 - val_loss: 0.1026 - val_accuracy: 0.5818\n",
      "Epoch 2210/5000\n",
      "11864/11864 [==============================] - 7s 584us/step - loss: 0.0982 - accuracy: 0.5982 - val_loss: 0.1021 - val_accuracy: 0.5831\n",
      "Epoch 2211/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0982 - accuracy: 0.5983 - val_loss: 0.1022 - val_accuracy: 0.5807\n",
      "Epoch 2212/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1018 - val_accuracy: 0.5804\n",
      "Epoch 2213/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1023 - val_accuracy: 0.5808\n",
      "Epoch 2214/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1026 - val_accuracy: 0.5776\n",
      "Epoch 2215/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1023 - val_accuracy: 0.5812\n",
      "Epoch 2216/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0980 - accuracy: 0.5986 - val_loss: 0.1026 - val_accuracy: 0.5791\n",
      "Epoch 2217/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0981 - accuracy: 0.5981 - val_loss: 0.1021 - val_accuracy: 0.5816\n",
      "Epoch 2218/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0982 - accuracy: 0.5989 - val_loss: 0.1018 - val_accuracy: 0.5829\n",
      "Epoch 2219/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0982 - accuracy: 0.5986 - val_loss: 0.1027 - val_accuracy: 0.5808\n",
      "Epoch 2220/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0982 - accuracy: 0.5984 - val_loss: 0.1020 - val_accuracy: 0.5829\n",
      "Epoch 2221/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0982 - accuracy: 0.5979 - val_loss: 0.1025 - val_accuracy: 0.5819\n",
      "Epoch 2222/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1018 - val_accuracy: 0.5820\n",
      "Epoch 2223/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0982 - accuracy: 0.5989 - val_loss: 0.1024 - val_accuracy: 0.5803\n",
      "Epoch 2224/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1025 - val_accuracy: 0.5817\n",
      "Epoch 2225/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1021 - val_accuracy: 0.5825\n",
      "Epoch 2226/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0982 - accuracy: 0.5986 - val_loss: 0.1024 - val_accuracy: 0.5805\n",
      "Epoch 2227/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1020 - val_accuracy: 0.5818\n",
      "Epoch 2228/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1020 - val_accuracy: 0.5786\n",
      "Epoch 2229/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0982 - accuracy: 0.5987 - val_loss: 0.1023 - val_accuracy: 0.5804\n",
      "Epoch 2230/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1028 - val_accuracy: 0.5785\n",
      "Epoch 2231/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1029 - val_accuracy: 0.5830\n",
      "Epoch 2232/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0982 - accuracy: 0.5985 - val_loss: 0.1028 - val_accuracy: 0.5746\n",
      "Epoch 2233/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0981 - accuracy: 0.5981 - val_loss: 0.1018 - val_accuracy: 0.5816\n",
      "Epoch 2234/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0982 - accuracy: 0.5988 - val_loss: 0.1030 - val_accuracy: 0.5798\n",
      "Epoch 2235/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1023 - val_accuracy: 0.5811\n",
      "Epoch 2236/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0982 - accuracy: 0.5992 - val_loss: 0.1020 - val_accuracy: 0.5825\n",
      "Epoch 2237/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0981 - accuracy: 0.5981 - val_loss: 0.1026 - val_accuracy: 0.5746\n",
      "Epoch 2238/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0982 - accuracy: 0.5987 - val_loss: 0.1019 - val_accuracy: 0.5825\n",
      "Epoch 2239/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0982 - accuracy: 0.5983 - val_loss: 0.1025 - val_accuracy: 0.5783\n",
      "Epoch 2240/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0981 - accuracy: 0.5994 - val_loss: 0.1020 - val_accuracy: 0.5803\n",
      "Epoch 2241/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0982 - accuracy: 0.5984 - val_loss: 0.1027 - val_accuracy: 0.5785\n",
      "Epoch 2242/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1029 - val_accuracy: 0.5782\n",
      "Epoch 2243/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0981 - accuracy: 0.5984 - val_loss: 0.1025 - val_accuracy: 0.5803\n",
      "Epoch 2244/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1029 - val_accuracy: 0.5790\n",
      "Epoch 2245/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1025 - val_accuracy: 0.5815\n",
      "Epoch 2246/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1023 - val_accuracy: 0.5794\n",
      "Epoch 2247/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0982 - accuracy: 0.5983 - val_loss: 0.1019 - val_accuracy: 0.5822\n",
      "Epoch 2248/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5982 - val_loss: 0.1024 - val_accuracy: 0.5831\n",
      "Epoch 2249/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0981 - accuracy: 0.5981 - val_loss: 0.1026 - val_accuracy: 0.5777\n",
      "Epoch 2250/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0981 - accuracy: 0.5984 - val_loss: 0.1020 - val_accuracy: 0.5820\n",
      "Epoch 2251/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1020 - val_accuracy: 0.5825\n",
      "Epoch 2252/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1026 - val_accuracy: 0.5813\n",
      "Epoch 2253/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0982 - accuracy: 0.5988 - val_loss: 0.1025 - val_accuracy: 0.5808\n",
      "Epoch 2254/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0982 - accuracy: 0.5984 - val_loss: 0.1018 - val_accuracy: 0.5842\n",
      "Epoch 2255/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5984 - val_loss: 0.1032 - val_accuracy: 0.5802\n",
      "Epoch 2256/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0982 - accuracy: 0.5988 - val_loss: 0.1021 - val_accuracy: 0.5822\n",
      "Epoch 2257/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0981 - accuracy: 0.5983 - val_loss: 0.1023 - val_accuracy: 0.5773\n",
      "Epoch 2258/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1022 - val_accuracy: 0.5824\n",
      "Epoch 2259/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1026 - val_accuracy: 0.5792\n",
      "Epoch 2260/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1031 - val_accuracy: 0.5788\n",
      "Epoch 2261/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0982 - accuracy: 0.5982 - val_loss: 0.1028 - val_accuracy: 0.5821\n",
      "Epoch 2262/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0980 - accuracy: 0.5986 - val_loss: 0.1021 - val_accuracy: 0.5806\n",
      "Epoch 2263/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1024 - val_accuracy: 0.5799\n",
      "Epoch 2264/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0982 - accuracy: 0.5988 - val_loss: 0.1032 - val_accuracy: 0.5815\n",
      "Epoch 2265/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1018 - val_accuracy: 0.5823\n",
      "Epoch 2266/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1020 - val_accuracy: 0.5825\n",
      "Epoch 2267/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1021 - val_accuracy: 0.5821\n",
      "Epoch 2268/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1019 - val_accuracy: 0.5813\n",
      "Epoch 2269/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1023 - val_accuracy: 0.5798\n",
      "Epoch 2270/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1024 - val_accuracy: 0.5797\n",
      "Epoch 2271/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1025 - val_accuracy: 0.5807\n",
      "Epoch 2272/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0981 - accuracy: 0.5994 - val_loss: 0.1032 - val_accuracy: 0.5765\n",
      "Epoch 2273/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1019 - val_accuracy: 0.5821\n",
      "Epoch 2274/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1021 - val_accuracy: 0.5793\n",
      "Epoch 2275/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0982 - accuracy: 0.5984 - val_loss: 0.1026 - val_accuracy: 0.5807\n",
      "Epoch 2276/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1024 - val_accuracy: 0.5822\n",
      "Epoch 2277/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0982 - accuracy: 0.5983 - val_loss: 0.1015 - val_accuracy: 0.5841\n",
      "Epoch 2278/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1025 - val_accuracy: 0.5804\n",
      "Epoch 2279/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1017 - val_accuracy: 0.5821\n",
      "Epoch 2280/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1026 - val_accuracy: 0.5790\n",
      "Epoch 2281/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1023 - val_accuracy: 0.5815\n",
      "Epoch 2282/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1029 - val_accuracy: 0.5787\n",
      "Epoch 2283/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1028 - val_accuracy: 0.5791\n",
      "Epoch 2284/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1019 - val_accuracy: 0.5814\n",
      "Epoch 2285/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1018 - val_accuracy: 0.5821\n",
      "Epoch 2286/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1021 - val_accuracy: 0.5801\n",
      "Epoch 2287/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1025 - val_accuracy: 0.5810\n",
      "Epoch 2288/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0980 - accuracy: 0.5987 - val_loss: 0.1025 - val_accuracy: 0.5812\n",
      "Epoch 2289/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1023 - val_accuracy: 0.5799\n",
      "Epoch 2290/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0981 - accuracy: 0.5983 - val_loss: 0.1015 - val_accuracy: 0.5819\n",
      "Epoch 2291/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1025 - val_accuracy: 0.5815\n",
      "Epoch 2292/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0981 - accuracy: 0.5976 - val_loss: 0.1022 - val_accuracy: 0.5798\n",
      "Epoch 2293/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1016 - val_accuracy: 0.5840\n",
      "Epoch 2294/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0981 - accuracy: 0.5984 - val_loss: 0.1017 - val_accuracy: 0.5826\n",
      "Epoch 2295/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0979 - accuracy: 0.5989 - val_loss: 0.1022 - val_accuracy: 0.5798\n",
      "Epoch 2296/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0982 - accuracy: 0.5980 - val_loss: 0.1024 - val_accuracy: 0.5800\n",
      "Epoch 2297/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1028 - val_accuracy: 0.5796\n",
      "Epoch 2298/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0981 - accuracy: 0.5982 - val_loss: 0.1024 - val_accuracy: 0.5799\n",
      "Epoch 2299/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1029 - val_accuracy: 0.5780\n",
      "Epoch 2300/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0981 - accuracy: 0.5984 - val_loss: 0.1025 - val_accuracy: 0.5804\n",
      "Epoch 2301/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1018 - val_accuracy: 0.5817\n",
      "Epoch 2302/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1021 - val_accuracy: 0.5813\n",
      "Epoch 2303/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0981 - accuracy: 0.5996 - val_loss: 0.1024 - val_accuracy: 0.5832\n",
      "Epoch 2304/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1032 - val_accuracy: 0.5753\n",
      "Epoch 2305/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0981 - accuracy: 0.5995 - val_loss: 0.1019 - val_accuracy: 0.5815\n",
      "Epoch 2306/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1026 - val_accuracy: 0.5816\n",
      "Epoch 2307/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1029 - val_accuracy: 0.5813\n",
      "Epoch 2308/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1028 - val_accuracy: 0.5784\n",
      "Epoch 2309/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1027 - val_accuracy: 0.5784\n",
      "Epoch 2310/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0982 - accuracy: 0.5982 - val_loss: 0.1027 - val_accuracy: 0.5796\n",
      "Epoch 2311/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1026 - val_accuracy: 0.5784\n",
      "Epoch 2312/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0982 - accuracy: 0.5983 - val_loss: 0.1016 - val_accuracy: 0.5820\n",
      "Epoch 2313/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1029 - val_accuracy: 0.5783\n",
      "Epoch 2314/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1028 - val_accuracy: 0.5782\n",
      "Epoch 2315/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1026 - val_accuracy: 0.5786\n",
      "Epoch 2316/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1020 - val_accuracy: 0.5830\n",
      "Epoch 2317/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1031 - val_accuracy: 0.5790\n",
      "Epoch 2318/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1021 - val_accuracy: 0.5819\n",
      "Epoch 2319/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0982 - accuracy: 0.5988 - val_loss: 0.1021 - val_accuracy: 0.5815\n",
      "Epoch 2320/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1026 - val_accuracy: 0.5838\n",
      "Epoch 2321/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1025 - val_accuracy: 0.5812\n",
      "Epoch 2322/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1019 - val_accuracy: 0.5805\n",
      "Epoch 2323/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1019 - val_accuracy: 0.5808\n",
      "Epoch 2324/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0979 - accuracy: 0.5994 - val_loss: 0.1029 - val_accuracy: 0.5724\n",
      "Epoch 2325/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1024 - val_accuracy: 0.5805\n",
      "Epoch 2326/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1025 - val_accuracy: 0.5774\n",
      "Epoch 2327/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0981 - accuracy: 0.5996 - val_loss: 0.1024 - val_accuracy: 0.5808\n",
      "Epoch 2328/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1018 - val_accuracy: 0.5842\n",
      "Epoch 2329/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1026 - val_accuracy: 0.5793\n",
      "Epoch 2330/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1031 - val_accuracy: 0.5791\n",
      "Epoch 2331/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0981 - accuracy: 0.5983 - val_loss: 0.1022 - val_accuracy: 0.5813\n",
      "Epoch 2332/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1030 - val_accuracy: 0.5800\n",
      "Epoch 2333/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0982 - accuracy: 0.5983 - val_loss: 0.1026 - val_accuracy: 0.5820\n",
      "Epoch 2334/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0982 - accuracy: 0.5983 - val_loss: 0.1024 - val_accuracy: 0.5776\n",
      "Epoch 2335/5000\n",
      "11864/11864 [==============================] - 7s 583us/step - loss: 0.0981 - accuracy: 0.5982 - val_loss: 0.1027 - val_accuracy: 0.5799\n",
      "Epoch 2336/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1015 - val_accuracy: 0.5833\n",
      "Epoch 2337/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0981 - accuracy: 0.5981 - val_loss: 0.1025 - val_accuracy: 0.5811\n",
      "Epoch 2338/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1019 - val_accuracy: 0.5824\n",
      "Epoch 2339/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1025 - val_accuracy: 0.5804\n",
      "Epoch 2340/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1027 - val_accuracy: 0.5784\n",
      "Epoch 2341/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1022 - val_accuracy: 0.5792\n",
      "Epoch 2342/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1028 - val_accuracy: 0.5804\n",
      "Epoch 2343/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0982 - accuracy: 0.5991 - val_loss: 0.1028 - val_accuracy: 0.5780\n",
      "Epoch 2344/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1022 - val_accuracy: 0.5791\n",
      "Epoch 2345/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1018 - val_accuracy: 0.5815\n",
      "Epoch 2346/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1021 - val_accuracy: 0.5803\n",
      "Epoch 2347/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1022 - val_accuracy: 0.5801\n",
      "Epoch 2348/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1027 - val_accuracy: 0.5828\n",
      "Epoch 2349/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1025 - val_accuracy: 0.5809\n",
      "Epoch 2350/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0980 - accuracy: 0.6000 - val_loss: 0.1028 - val_accuracy: 0.5807\n",
      "Epoch 2351/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1022 - val_accuracy: 0.5827\n",
      "Epoch 2352/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1022 - val_accuracy: 0.5814\n",
      "Epoch 2353/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1033 - val_accuracy: 0.5764\n",
      "Epoch 2354/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0980 - accuracy: 0.5987 - val_loss: 0.1028 - val_accuracy: 0.5778\n",
      "Epoch 2355/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1025 - val_accuracy: 0.5796\n",
      "Epoch 2356/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1021 - val_accuracy: 0.5821\n",
      "Epoch 2357/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1024 - val_accuracy: 0.5790\n",
      "Epoch 2358/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1024 - val_accuracy: 0.5788\n",
      "Epoch 2359/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1022 - val_accuracy: 0.5800\n",
      "Epoch 2360/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1021 - val_accuracy: 0.5798\n",
      "Epoch 2361/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1027 - val_accuracy: 0.5650\n",
      "Epoch 2362/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1022 - val_accuracy: 0.5819\n",
      "Epoch 2363/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0982 - accuracy: 0.5987 - val_loss: 0.1027 - val_accuracy: 0.5785\n",
      "Epoch 2364/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1031 - val_accuracy: 0.5806\n",
      "Epoch 2365/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1018 - val_accuracy: 0.5806\n",
      "Epoch 2366/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1037 - val_accuracy: 0.5676\n",
      "Epoch 2367/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0982 - accuracy: 0.5987 - val_loss: 0.1024 - val_accuracy: 0.5826\n",
      "Epoch 2368/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1026 - val_accuracy: 0.5766\n",
      "Epoch 2369/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0982 - accuracy: 0.5985 - val_loss: 0.1026 - val_accuracy: 0.5795\n",
      "Epoch 2370/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1023 - val_accuracy: 0.5779\n",
      "Epoch 2371/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0982 - accuracy: 0.5991 - val_loss: 0.1024 - val_accuracy: 0.5800\n",
      "Epoch 2372/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1028 - val_accuracy: 0.5779\n",
      "Epoch 2373/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0982 - accuracy: 0.5983 - val_loss: 0.1021 - val_accuracy: 0.5818\n",
      "Epoch 2374/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1023 - val_accuracy: 0.5834\n",
      "Epoch 2375/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1023 - val_accuracy: 0.5805\n",
      "Epoch 2376/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0982 - accuracy: 0.5986 - val_loss: 0.1023 - val_accuracy: 0.5838\n",
      "Epoch 2377/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1020 - val_accuracy: 0.5809\n",
      "Epoch 2378/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1029 - val_accuracy: 0.5788\n",
      "Epoch 2379/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0981 - accuracy: 0.5981 - val_loss: 0.1023 - val_accuracy: 0.5810\n",
      "Epoch 2380/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0981 - accuracy: 0.5984 - val_loss: 0.1022 - val_accuracy: 0.5791\n",
      "Epoch 2381/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0981 - accuracy: 0.5977 - val_loss: 0.1019 - val_accuracy: 0.5819\n",
      "Epoch 2382/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0982 - accuracy: 0.5990 - val_loss: 0.1022 - val_accuracy: 0.5812\n",
      "Epoch 2383/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0981 - accuracy: 0.5977 - val_loss: 0.1026 - val_accuracy: 0.5792\n",
      "Epoch 2384/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1026 - val_accuracy: 0.5823\n",
      "Epoch 2385/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1024 - val_accuracy: 0.5797\n",
      "Epoch 2386/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0981 - accuracy: 0.5982 - val_loss: 0.1022 - val_accuracy: 0.5787\n",
      "Epoch 2387/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0981 - accuracy: 0.5980 - val_loss: 0.1020 - val_accuracy: 0.5804\n",
      "Epoch 2388/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0981 - accuracy: 0.5981 - val_loss: 0.1030 - val_accuracy: 0.5810\n",
      "Epoch 2389/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1020 - val_accuracy: 0.5801\n",
      "Epoch 2390/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0981 - accuracy: 0.5981 - val_loss: 0.1022 - val_accuracy: 0.5791\n",
      "Epoch 2391/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0981 - accuracy: 0.5984 - val_loss: 0.1023 - val_accuracy: 0.5801\n",
      "Epoch 2392/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1023 - val_accuracy: 0.5801\n",
      "Epoch 2393/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0982 - accuracy: 0.5989 - val_loss: 0.1032 - val_accuracy: 0.5766\n",
      "Epoch 2394/5000\n",
      "11864/11864 [==============================] - 7s 586us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1031 - val_accuracy: 0.5784\n",
      "Epoch 2395/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1022 - val_accuracy: 0.5819\n",
      "Epoch 2396/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0981 - accuracy: 0.5994 - val_loss: 0.1027 - val_accuracy: 0.5772\n",
      "Epoch 2397/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0980 - accuracy: 0.5986 - val_loss: 0.1027 - val_accuracy: 0.5780\n",
      "Epoch 2398/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0981 - accuracy: 0.5981 - val_loss: 0.1028 - val_accuracy: 0.5798\n",
      "Epoch 2399/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0981 - accuracy: 0.5978 - val_loss: 0.1025 - val_accuracy: 0.5804\n",
      "Epoch 2400/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0982 - accuracy: 0.5989 - val_loss: 0.1027 - val_accuracy: 0.5793\n",
      "Epoch 2401/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1023 - val_accuracy: 0.5824\n",
      "Epoch 2402/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1018 - val_accuracy: 0.5814\n",
      "Epoch 2403/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0982 - accuracy: 0.5979 - val_loss: 0.1028 - val_accuracy: 0.5796\n",
      "Epoch 2404/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0983 - accuracy: 0.5986 - val_loss: 0.1024 - val_accuracy: 0.5822\n",
      "Epoch 2405/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0982 - accuracy: 0.5983 - val_loss: 0.1017 - val_accuracy: 0.5796\n",
      "Epoch 2406/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1027 - val_accuracy: 0.5800\n",
      "Epoch 2407/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1020 - val_accuracy: 0.5831\n",
      "Epoch 2408/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1023 - val_accuracy: 0.5803\n",
      "Epoch 2409/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1029 - val_accuracy: 0.5798\n",
      "Epoch 2410/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1027 - val_accuracy: 0.5804\n",
      "Epoch 2411/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1027 - val_accuracy: 0.5783\n",
      "Epoch 2412/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1027 - val_accuracy: 0.5815\n",
      "Epoch 2413/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1024 - val_accuracy: 0.5776\n",
      "Epoch 2414/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1027 - val_accuracy: 0.5790\n",
      "Epoch 2415/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1024 - val_accuracy: 0.5777\n",
      "Epoch 2416/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1021 - val_accuracy: 0.5823\n",
      "Epoch 2417/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1026 - val_accuracy: 0.5821\n",
      "Epoch 2418/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1020 - val_accuracy: 0.5813\n",
      "Epoch 2419/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0980 - accuracy: 0.6000 - val_loss: 0.1026 - val_accuracy: 0.5815\n",
      "Epoch 2420/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0982 - accuracy: 0.5986 - val_loss: 0.1021 - val_accuracy: 0.5794\n",
      "Epoch 2421/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1026 - val_accuracy: 0.5785\n",
      "Epoch 2422/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0981 - accuracy: 0.5981 - val_loss: 0.1025 - val_accuracy: 0.5801\n",
      "Epoch 2423/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0981 - accuracy: 0.5980 - val_loss: 0.1021 - val_accuracy: 0.5820\n",
      "Epoch 2424/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1024 - val_accuracy: 0.5805\n",
      "Epoch 2425/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1019 - val_accuracy: 0.5816\n",
      "Epoch 2426/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0981 - accuracy: 0.5994 - val_loss: 0.1020 - val_accuracy: 0.5815\n",
      "Epoch 2427/5000\n",
      "11864/11864 [==============================] - 7s 587us/step - loss: 0.0980 - accuracy: 0.5986 - val_loss: 0.1022 - val_accuracy: 0.5802\n",
      "Epoch 2428/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1024 - val_accuracy: 0.5817\n",
      "Epoch 2429/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1029 - val_accuracy: 0.5774\n",
      "Epoch 2430/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1027 - val_accuracy: 0.5794\n",
      "Epoch 2431/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0982 - accuracy: 0.5989 - val_loss: 0.1023 - val_accuracy: 0.5811\n",
      "Epoch 2432/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1026 - val_accuracy: 0.5786\n",
      "Epoch 2433/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1023 - val_accuracy: 0.5815\n",
      "Epoch 2434/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1028 - val_accuracy: 0.5796\n",
      "Epoch 2435/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0981 - accuracy: 0.5998 - val_loss: 0.1026 - val_accuracy: 0.5793\n",
      "Epoch 2436/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0982 - accuracy: 0.5995 - val_loss: 0.1025 - val_accuracy: 0.5810\n",
      "Epoch 2437/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1017 - val_accuracy: 0.5821\n",
      "Epoch 2438/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0982 - accuracy: 0.5983 - val_loss: 0.1022 - val_accuracy: 0.5811\n",
      "Epoch 2439/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1025 - val_accuracy: 0.5816\n",
      "Epoch 2440/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1026 - val_accuracy: 0.5790\n",
      "Epoch 2441/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1026 - val_accuracy: 0.5798\n",
      "Epoch 2442/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1021 - val_accuracy: 0.5836\n",
      "Epoch 2443/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1021 - val_accuracy: 0.5828\n",
      "Epoch 2444/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1024 - val_accuracy: 0.5808\n",
      "Epoch 2445/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1023 - val_accuracy: 0.5741\n",
      "Epoch 2446/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1017 - val_accuracy: 0.5819\n",
      "Epoch 2447/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0981 - accuracy: 0.5983 - val_loss: 0.1023 - val_accuracy: 0.5806\n",
      "Epoch 2448/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1023 - val_accuracy: 0.5819\n",
      "Epoch 2449/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1029 - val_accuracy: 0.5798\n",
      "Epoch 2450/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0981 - accuracy: 0.5983 - val_loss: 0.1029 - val_accuracy: 0.5802\n",
      "Epoch 2451/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0981 - accuracy: 0.5995 - val_loss: 0.1034 - val_accuracy: 0.5787\n",
      "Epoch 2452/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0980 - accuracy: 0.5986 - val_loss: 0.1021 - val_accuracy: 0.5791\n",
      "Epoch 2453/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1025 - val_accuracy: 0.5822\n",
      "Epoch 2454/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0980 - accuracy: 0.5986 - val_loss: 0.1022 - val_accuracy: 0.5803\n",
      "Epoch 2455/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0981 - accuracy: 0.5984 - val_loss: 0.1028 - val_accuracy: 0.5811\n",
      "Epoch 2456/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1027 - val_accuracy: 0.5778\n",
      "Epoch 2457/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1024 - val_accuracy: 0.5797\n",
      "Epoch 2458/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1021 - val_accuracy: 0.5806\n",
      "Epoch 2459/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0980 - accuracy: 0.5977 - val_loss: 0.1020 - val_accuracy: 0.5817\n",
      "Epoch 2460/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0982 - accuracy: 0.5983 - val_loss: 0.1023 - val_accuracy: 0.5818\n",
      "Epoch 2461/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1019 - val_accuracy: 0.5820\n",
      "Epoch 2462/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1016 - val_accuracy: 0.5837\n",
      "Epoch 2463/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1027 - val_accuracy: 0.5811\n",
      "Epoch 2464/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1022 - val_accuracy: 0.5795\n",
      "Epoch 2465/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1023 - val_accuracy: 0.5809\n",
      "Epoch 2466/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1019 - val_accuracy: 0.5820\n",
      "Epoch 2467/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1032 - val_accuracy: 0.5795\n",
      "Epoch 2468/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1018 - val_accuracy: 0.5833\n",
      "Epoch 2469/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1018 - val_accuracy: 0.5813\n",
      "Epoch 2470/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1022 - val_accuracy: 0.5824\n",
      "Epoch 2471/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1022 - val_accuracy: 0.5815\n",
      "Epoch 2472/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1022 - val_accuracy: 0.5807\n",
      "Epoch 2473/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1022 - val_accuracy: 0.5822\n",
      "Epoch 2474/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0981 - accuracy: 0.5984 - val_loss: 0.1020 - val_accuracy: 0.5816\n",
      "Epoch 2475/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0980 - accuracy: 0.5987 - val_loss: 0.1038 - val_accuracy: 0.5779\n",
      "Epoch 2476/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0982 - accuracy: 0.5985 - val_loss: 0.1022 - val_accuracy: 0.5806\n",
      "Epoch 2477/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0980 - accuracy: 0.5987 - val_loss: 0.1024 - val_accuracy: 0.5754\n",
      "Epoch 2478/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1027 - val_accuracy: 0.5772\n",
      "Epoch 2479/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1024 - val_accuracy: 0.5811\n",
      "Epoch 2480/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1032 - val_accuracy: 0.5799\n",
      "Epoch 2481/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1021 - val_accuracy: 0.5822\n",
      "Epoch 2482/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1018 - val_accuracy: 0.5827\n",
      "Epoch 2483/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0981 - accuracy: 0.5983 - val_loss: 0.1027 - val_accuracy: 0.5797\n",
      "Epoch 2484/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1024 - val_accuracy: 0.5810\n",
      "Epoch 2485/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1030 - val_accuracy: 0.5797\n",
      "Epoch 2486/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0982 - accuracy: 0.5979 - val_loss: 0.1022 - val_accuracy: 0.5802\n",
      "Epoch 2487/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1028 - val_accuracy: 0.5811\n",
      "Epoch 2488/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1028 - val_accuracy: 0.5815\n",
      "Epoch 2489/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1014 - val_accuracy: 0.5829\n",
      "Epoch 2490/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0979 - accuracy: 0.5990 - val_loss: 0.1025 - val_accuracy: 0.5803\n",
      "Epoch 2491/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1026 - val_accuracy: 0.5768\n",
      "Epoch 2492/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0980 - accuracy: 0.5986 - val_loss: 0.1024 - val_accuracy: 0.5814\n",
      "Epoch 2493/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0981 - accuracy: 0.5984 - val_loss: 0.1025 - val_accuracy: 0.5812\n",
      "Epoch 2494/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1030 - val_accuracy: 0.5801\n",
      "Epoch 2495/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1023 - val_accuracy: 0.5818\n",
      "Epoch 2496/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1021 - val_accuracy: 0.5838\n",
      "Epoch 2497/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1018 - val_accuracy: 0.5840\n",
      "Epoch 2498/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0980 - accuracy: 0.5984 - val_loss: 0.1019 - val_accuracy: 0.5817\n",
      "Epoch 2499/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1029 - val_accuracy: 0.5768\n",
      "Epoch 2500/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1029 - val_accuracy: 0.5818\n",
      "Epoch 2501/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1021 - val_accuracy: 0.5821\n",
      "Epoch 2502/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1017 - val_accuracy: 0.5831\n",
      "Epoch 2503/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1020 - val_accuracy: 0.5818\n",
      "Epoch 2504/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0980 - accuracy: 0.5983 - val_loss: 0.1022 - val_accuracy: 0.5785\n",
      "Epoch 2505/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1030 - val_accuracy: 0.5796\n",
      "Epoch 2506/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0981 - accuracy: 0.5983 - val_loss: 0.1030 - val_accuracy: 0.5801\n",
      "Epoch 2507/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1021 - val_accuracy: 0.5782\n",
      "Epoch 2508/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1022 - val_accuracy: 0.5808\n",
      "Epoch 2509/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1025 - val_accuracy: 0.5804\n",
      "Epoch 2510/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1027 - val_accuracy: 0.5792\n",
      "Epoch 2511/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0982 - accuracy: 0.5990 - val_loss: 0.1033 - val_accuracy: 0.5769\n",
      "Epoch 2512/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1024 - val_accuracy: 0.5777\n",
      "Epoch 2513/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0982 - accuracy: 0.5985 - val_loss: 0.1025 - val_accuracy: 0.5777\n",
      "Epoch 2514/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1019 - val_accuracy: 0.5831\n",
      "Epoch 2515/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1021 - val_accuracy: 0.5808\n",
      "Epoch 2516/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0981 - accuracy: 0.5995 - val_loss: 0.1018 - val_accuracy: 0.5810\n",
      "Epoch 2517/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1025 - val_accuracy: 0.5802\n",
      "Epoch 2518/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0980 - accuracy: 0.6005 - val_loss: 0.1027 - val_accuracy: 0.5767\n",
      "Epoch 2519/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1022 - val_accuracy: 0.5784\n",
      "Epoch 2520/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1024 - val_accuracy: 0.5806\n",
      "Epoch 2521/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0980 - accuracy: 0.5986 - val_loss: 0.1024 - val_accuracy: 0.5804\n",
      "Epoch 2522/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0980 - accuracy: 0.5984 - val_loss: 0.1025 - val_accuracy: 0.5786\n",
      "Epoch 2523/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1022 - val_accuracy: 0.5808\n",
      "Epoch 2524/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0980 - accuracy: 0.5986 - val_loss: 0.1029 - val_accuracy: 0.5776\n",
      "Epoch 2525/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1022 - val_accuracy: 0.5808\n",
      "Epoch 2526/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1027 - val_accuracy: 0.5762\n",
      "Epoch 2527/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1020 - val_accuracy: 0.5818\n",
      "Epoch 2528/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0981 - accuracy: 0.5982 - val_loss: 0.1020 - val_accuracy: 0.5816\n",
      "Epoch 2529/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1028 - val_accuracy: 0.5792\n",
      "Epoch 2530/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1025 - val_accuracy: 0.5820\n",
      "Epoch 2531/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1016 - val_accuracy: 0.5827\n",
      "Epoch 2532/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1018 - val_accuracy: 0.5826\n",
      "Epoch 2533/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1024 - val_accuracy: 0.5809\n",
      "Epoch 2534/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1031 - val_accuracy: 0.5775\n",
      "Epoch 2535/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1028 - val_accuracy: 0.5770\n",
      "Epoch 2536/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1026 - val_accuracy: 0.5789\n",
      "Epoch 2537/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1026 - val_accuracy: 0.5788\n",
      "Epoch 2538/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1020 - val_accuracy: 0.5795\n",
      "Epoch 2539/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1033 - val_accuracy: 0.5779\n",
      "Epoch 2540/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1023 - val_accuracy: 0.5807\n",
      "Epoch 2541/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0980 - accuracy: 0.5983 - val_loss: 0.1026 - val_accuracy: 0.5787\n",
      "Epoch 2542/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1025 - val_accuracy: 0.5799\n",
      "Epoch 2543/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0982 - accuracy: 0.5985 - val_loss: 0.1026 - val_accuracy: 0.5796\n",
      "Epoch 2544/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0980 - accuracy: 0.5984 - val_loss: 0.1017 - val_accuracy: 0.5807\n",
      "Epoch 2545/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0981 - accuracy: 0.5983 - val_loss: 0.1023 - val_accuracy: 0.5791\n",
      "Epoch 2546/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0981 - accuracy: 0.5995 - val_loss: 0.1022 - val_accuracy: 0.5806\n",
      "Epoch 2547/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1030 - val_accuracy: 0.5712\n",
      "Epoch 2548/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1024 - val_accuracy: 0.5797\n",
      "Epoch 2549/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0980 - accuracy: 0.5986 - val_loss: 0.1024 - val_accuracy: 0.5794\n",
      "Epoch 2550/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1026 - val_accuracy: 0.5774\n",
      "Epoch 2551/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1020 - val_accuracy: 0.5820\n",
      "Epoch 2552/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1024 - val_accuracy: 0.5818\n",
      "Epoch 2553/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0980 - accuracy: 0.5985 - val_loss: 0.1023 - val_accuracy: 0.5787\n",
      "Epoch 2554/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1029 - val_accuracy: 0.5803\n",
      "Epoch 2555/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1021 - val_accuracy: 0.5823\n",
      "Epoch 2556/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0981 - accuracy: 0.5982 - val_loss: 0.1027 - val_accuracy: 0.5778\n",
      "Epoch 2557/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0981 - accuracy: 0.5996 - val_loss: 0.1021 - val_accuracy: 0.5811\n",
      "Epoch 2558/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1020 - val_accuracy: 0.5819\n",
      "Epoch 2559/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0980 - accuracy: 0.6002 - val_loss: 0.1029 - val_accuracy: 0.5635\n",
      "Epoch 2560/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1027 - val_accuracy: 0.5788\n",
      "Epoch 2561/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0981 - accuracy: 0.5997 - val_loss: 0.1026 - val_accuracy: 0.5801\n",
      "Epoch 2562/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1027 - val_accuracy: 0.5772\n",
      "Epoch 2563/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0980 - accuracy: 0.5986 - val_loss: 0.1018 - val_accuracy: 0.5803\n",
      "Epoch 2564/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1035 - val_accuracy: 0.5755\n",
      "Epoch 2565/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0980 - accuracy: 0.5982 - val_loss: 0.1020 - val_accuracy: 0.5811\n",
      "Epoch 2566/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1024 - val_accuracy: 0.5796\n",
      "Epoch 2567/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1030 - val_accuracy: 0.5809\n",
      "Epoch 2568/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1024 - val_accuracy: 0.5787\n",
      "Epoch 2569/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1022 - val_accuracy: 0.5829\n",
      "Epoch 2570/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0980 - accuracy: 0.5986 - val_loss: 0.1021 - val_accuracy: 0.5823\n",
      "Epoch 2571/5000\n",
      "11864/11864 [==============================] - 7s 589us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1024 - val_accuracy: 0.5804\n",
      "Epoch 2572/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1027 - val_accuracy: 0.5798\n",
      "Epoch 2573/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1027 - val_accuracy: 0.5788\n",
      "Epoch 2574/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1027 - val_accuracy: 0.5713\n",
      "Epoch 2575/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0980 - accuracy: 0.5986 - val_loss: 0.1019 - val_accuracy: 0.5821\n",
      "Epoch 2576/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0980 - accuracy: 0.5987 - val_loss: 0.1030 - val_accuracy: 0.5776\n",
      "Epoch 2577/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1023 - val_accuracy: 0.5823\n",
      "Epoch 2578/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1021 - val_accuracy: 0.5834\n",
      "Epoch 2579/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1034 - val_accuracy: 0.5764\n",
      "Epoch 2580/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1023 - val_accuracy: 0.5823\n",
      "Epoch 2581/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1036 - val_accuracy: 0.5771\n",
      "Epoch 2582/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1019 - val_accuracy: 0.5829\n",
      "Epoch 2583/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1025 - val_accuracy: 0.5779\n",
      "Epoch 2584/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0980 - accuracy: 0.5986 - val_loss: 0.1023 - val_accuracy: 0.5810\n",
      "Epoch 2585/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0980 - accuracy: 0.5986 - val_loss: 0.1024 - val_accuracy: 0.5787\n",
      "Epoch 2586/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0980 - accuracy: 0.5984 - val_loss: 0.1029 - val_accuracy: 0.5773\n",
      "Epoch 2587/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0979 - accuracy: 0.5993 - val_loss: 0.1025 - val_accuracy: 0.5810\n",
      "Epoch 2588/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1032 - val_accuracy: 0.5785\n",
      "Epoch 2589/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1028 - val_accuracy: 0.5819\n",
      "Epoch 2590/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0982 - accuracy: 0.5983 - val_loss: 0.1022 - val_accuracy: 0.5793\n",
      "Epoch 2591/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0980 - accuracy: 0.5986 - val_loss: 0.1024 - val_accuracy: 0.5813\n",
      "Epoch 2592/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0980 - accuracy: 0.5983 - val_loss: 0.1028 - val_accuracy: 0.5787\n",
      "Epoch 2593/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0980 - accuracy: 0.5986 - val_loss: 0.1031 - val_accuracy: 0.5780\n",
      "Epoch 2594/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1029 - val_accuracy: 0.5793\n",
      "Epoch 2595/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1023 - val_accuracy: 0.5779\n",
      "Epoch 2596/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1022 - val_accuracy: 0.5821\n",
      "Epoch 2597/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0979 - accuracy: 0.5989 - val_loss: 0.1020 - val_accuracy: 0.5818\n",
      "Epoch 2598/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1027 - val_accuracy: 0.5734\n",
      "Epoch 2599/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1020 - val_accuracy: 0.5805\n",
      "Epoch 2600/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1020 - val_accuracy: 0.5822\n",
      "Epoch 2601/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1024 - val_accuracy: 0.5811\n",
      "Epoch 2602/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1021 - val_accuracy: 0.5804\n",
      "Epoch 2603/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1026 - val_accuracy: 0.5793\n",
      "Epoch 2604/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1019 - val_accuracy: 0.5823\n",
      "Epoch 2605/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1022 - val_accuracy: 0.5805\n",
      "Epoch 2606/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1024 - val_accuracy: 0.5826\n",
      "Epoch 2607/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1033 - val_accuracy: 0.5768\n",
      "Epoch 2608/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1020 - val_accuracy: 0.5829\n",
      "Epoch 2609/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0981 - accuracy: 0.5984 - val_loss: 0.1028 - val_accuracy: 0.5831\n",
      "Epoch 2610/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1028 - val_accuracy: 0.5802\n",
      "Epoch 2611/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1024 - val_accuracy: 0.5796\n",
      "Epoch 2612/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0980 - accuracy: 0.5986 - val_loss: 0.1019 - val_accuracy: 0.5829\n",
      "Epoch 2613/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0981 - accuracy: 0.5984 - val_loss: 0.1029 - val_accuracy: 0.5805\n",
      "Epoch 2614/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1026 - val_accuracy: 0.5800\n",
      "Epoch 2615/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5980 - val_loss: 0.1027 - val_accuracy: 0.5800\n",
      "Epoch 2616/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0980 - accuracy: 0.5985 - val_loss: 0.1026 - val_accuracy: 0.5800\n",
      "Epoch 2617/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1024 - val_accuracy: 0.5815\n",
      "Epoch 2618/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1020 - val_accuracy: 0.5809\n",
      "Epoch 2619/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1024 - val_accuracy: 0.5805\n",
      "Epoch 2620/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1021 - val_accuracy: 0.5800\n",
      "Epoch 2621/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0981 - accuracy: 0.5994 - val_loss: 0.1026 - val_accuracy: 0.5773\n",
      "Epoch 2622/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1025 - val_accuracy: 0.5810\n",
      "Epoch 2623/5000\n",
      "11864/11864 [==============================] - 7s 585us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1022 - val_accuracy: 0.5799\n",
      "Epoch 2624/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1026 - val_accuracy: 0.5795\n",
      "Epoch 2625/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0980 - accuracy: 0.5981 - val_loss: 0.1027 - val_accuracy: 0.5794\n",
      "Epoch 2626/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0980 - accuracy: 0.5986 - val_loss: 0.1022 - val_accuracy: 0.5815\n",
      "Epoch 2627/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0981 - accuracy: 0.5983 - val_loss: 0.1022 - val_accuracy: 0.5786\n",
      "Epoch 2628/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1022 - val_accuracy: 0.5832\n",
      "Epoch 2629/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1021 - val_accuracy: 0.5801\n",
      "Epoch 2630/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1032 - val_accuracy: 0.5746\n",
      "Epoch 2631/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1028 - val_accuracy: 0.5816\n",
      "Epoch 2632/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1021 - val_accuracy: 0.5818\n",
      "Epoch 2633/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1022 - val_accuracy: 0.5816\n",
      "Epoch 2634/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0979 - accuracy: 0.5994 - val_loss: 0.1020 - val_accuracy: 0.5808\n",
      "Epoch 2635/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1025 - val_accuracy: 0.5809\n",
      "Epoch 2636/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1022 - val_accuracy: 0.5825\n",
      "Epoch 2637/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1027 - val_accuracy: 0.5771\n",
      "Epoch 2638/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1023 - val_accuracy: 0.5812\n",
      "Epoch 2639/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0981 - accuracy: 0.5982 - val_loss: 0.1030 - val_accuracy: 0.5767\n",
      "Epoch 2640/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0980 - accuracy: 0.5983 - val_loss: 0.1026 - val_accuracy: 0.5799\n",
      "Epoch 2641/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1030 - val_accuracy: 0.5802\n",
      "Epoch 2642/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1022 - val_accuracy: 0.5803\n",
      "Epoch 2643/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1018 - val_accuracy: 0.5806\n",
      "Epoch 2644/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1024 - val_accuracy: 0.5814\n",
      "Epoch 2645/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1031 - val_accuracy: 0.5810\n",
      "Epoch 2646/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0981 - accuracy: 0.5983 - val_loss: 0.1024 - val_accuracy: 0.5775\n",
      "Epoch 2647/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1029 - val_accuracy: 0.5822\n",
      "Epoch 2648/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1023 - val_accuracy: 0.5802\n",
      "Epoch 2649/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1021 - val_accuracy: 0.5819\n",
      "Epoch 2650/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0980 - accuracy: 0.5977 - val_loss: 0.1026 - val_accuracy: 0.5801\n",
      "Epoch 2651/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0980 - accuracy: 0.5987 - val_loss: 0.1019 - val_accuracy: 0.5823\n",
      "Epoch 2652/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1024 - val_accuracy: 0.5800\n",
      "Epoch 2653/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0980 - accuracy: 0.5983 - val_loss: 0.1022 - val_accuracy: 0.5815\n",
      "Epoch 2654/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1021 - val_accuracy: 0.5795\n",
      "Epoch 2655/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1024 - val_accuracy: 0.5786\n",
      "Epoch 2656/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0980 - accuracy: 0.5987 - val_loss: 0.1025 - val_accuracy: 0.5806\n",
      "Epoch 2657/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0980 - accuracy: 0.6000 - val_loss: 0.1021 - val_accuracy: 0.5839\n",
      "Epoch 2658/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1023 - val_accuracy: 0.5815\n",
      "Epoch 2659/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0981 - accuracy: 0.5994 - val_loss: 0.1024 - val_accuracy: 0.5824\n",
      "Epoch 2660/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1024 - val_accuracy: 0.5783\n",
      "Epoch 2661/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1022 - val_accuracy: 0.5817\n",
      "Epoch 2662/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1021 - val_accuracy: 0.5818\n",
      "Epoch 2663/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0982 - accuracy: 0.5985 - val_loss: 0.1018 - val_accuracy: 0.5807\n",
      "Epoch 2664/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0981 - accuracy: 0.5983 - val_loss: 0.1024 - val_accuracy: 0.5800\n",
      "Epoch 2665/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0981 - accuracy: 0.5979 - val_loss: 0.1023 - val_accuracy: 0.5745\n",
      "Epoch 2666/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1033 - val_accuracy: 0.5677\n",
      "Epoch 2667/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1024 - val_accuracy: 0.5818\n",
      "Epoch 2668/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0982 - accuracy: 0.5982 - val_loss: 0.1020 - val_accuracy: 0.5832\n",
      "Epoch 2669/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0980 - accuracy: 0.5985 - val_loss: 0.1023 - val_accuracy: 0.5805\n",
      "Epoch 2670/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1023 - val_accuracy: 0.5806\n",
      "Epoch 2671/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0980 - accuracy: 0.5983 - val_loss: 0.1022 - val_accuracy: 0.5810\n",
      "Epoch 2672/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0981 - accuracy: 0.5981 - val_loss: 0.1018 - val_accuracy: 0.5815\n",
      "Epoch 2673/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1031 - val_accuracy: 0.5768\n",
      "Epoch 2674/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1034 - val_accuracy: 0.5733\n",
      "Epoch 2675/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0980 - accuracy: 0.6002 - val_loss: 0.1025 - val_accuracy: 0.5789\n",
      "Epoch 2676/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1027 - val_accuracy: 0.5817\n",
      "Epoch 2677/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1023 - val_accuracy: 0.5797\n",
      "Epoch 2678/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1021 - val_accuracy: 0.5800\n",
      "Epoch 2679/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0981 - accuracy: 0.5979 - val_loss: 0.1021 - val_accuracy: 0.5810\n",
      "Epoch 2680/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1026 - val_accuracy: 0.5768\n",
      "Epoch 2681/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0980 - accuracy: 0.5983 - val_loss: 0.1018 - val_accuracy: 0.5832\n",
      "Epoch 2682/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1031 - val_accuracy: 0.5806\n",
      "Epoch 2683/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1020 - val_accuracy: 0.5829\n",
      "Epoch 2684/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1020 - val_accuracy: 0.5824\n",
      "Epoch 2685/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1020 - val_accuracy: 0.5830\n",
      "Epoch 2686/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0981 - accuracy: 0.5981 - val_loss: 0.1024 - val_accuracy: 0.5793\n",
      "Epoch 2687/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1027 - val_accuracy: 0.5769\n",
      "Epoch 2688/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0981 - accuracy: 0.5984 - val_loss: 0.1026 - val_accuracy: 0.5817\n",
      "Epoch 2689/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1022 - val_accuracy: 0.5806\n",
      "Epoch 2690/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1021 - val_accuracy: 0.5796\n",
      "Epoch 2691/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1024 - val_accuracy: 0.5819\n",
      "Epoch 2692/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1021 - val_accuracy: 0.5804\n",
      "Epoch 2693/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0980 - accuracy: 0.5982 - val_loss: 0.1028 - val_accuracy: 0.5794\n",
      "Epoch 2694/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1022 - val_accuracy: 0.5814\n",
      "Epoch 2695/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1025 - val_accuracy: 0.5792\n",
      "Epoch 2696/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1019 - val_accuracy: 0.5818\n",
      "Epoch 2697/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0980 - accuracy: 0.5999 - val_loss: 0.1024 - val_accuracy: 0.5804\n",
      "Epoch 2698/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1022 - val_accuracy: 0.5820\n",
      "Epoch 2699/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1027 - val_accuracy: 0.5822\n",
      "Epoch 2700/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0982 - accuracy: 0.5986 - val_loss: 0.1016 - val_accuracy: 0.5821\n",
      "Epoch 2701/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0980 - accuracy: 0.5983 - val_loss: 0.1018 - val_accuracy: 0.5810\n",
      "Epoch 2702/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1028 - val_accuracy: 0.5797\n",
      "Epoch 2703/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1023 - val_accuracy: 0.5823\n",
      "Epoch 2704/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1020 - val_accuracy: 0.5829\n",
      "Epoch 2705/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1026 - val_accuracy: 0.5814\n",
      "Epoch 2706/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1025 - val_accuracy: 0.5796\n",
      "Epoch 2707/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0981 - accuracy: 0.5983 - val_loss: 0.1022 - val_accuracy: 0.5795\n",
      "Epoch 2708/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0981 - accuracy: 0.5981 - val_loss: 0.1022 - val_accuracy: 0.5822\n",
      "Epoch 2709/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1018 - val_accuracy: 0.5835\n",
      "Epoch 2710/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0979 - accuracy: 0.5993 - val_loss: 0.1033 - val_accuracy: 0.5784\n",
      "Epoch 2711/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0980 - accuracy: 0.5986 - val_loss: 0.1025 - val_accuracy: 0.5816\n",
      "Epoch 2712/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1027 - val_accuracy: 0.5786\n",
      "Epoch 2713/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1025 - val_accuracy: 0.5800\n",
      "Epoch 2714/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1031 - val_accuracy: 0.5783\n",
      "Epoch 2715/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0980 - accuracy: 0.5983 - val_loss: 0.1018 - val_accuracy: 0.5815\n",
      "Epoch 2716/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0979 - accuracy: 0.5989 - val_loss: 0.1025 - val_accuracy: 0.5821\n",
      "Epoch 2717/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0981 - accuracy: 0.5983 - val_loss: 0.1024 - val_accuracy: 0.5779\n",
      "Epoch 2718/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1021 - val_accuracy: 0.5829\n",
      "Epoch 2719/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0980 - accuracy: 0.5986 - val_loss: 0.1025 - val_accuracy: 0.5792\n",
      "Epoch 2720/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0980 - accuracy: 0.5979 - val_loss: 0.1023 - val_accuracy: 0.5807\n",
      "Epoch 2721/5000\n",
      "11864/11864 [==============================] - 7s 588us/step - loss: 0.0980 - accuracy: 0.5987 - val_loss: 0.1027 - val_accuracy: 0.5797\n",
      "Epoch 2722/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1023 - val_accuracy: 0.5805\n",
      "Epoch 2723/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1024 - val_accuracy: 0.5818\n",
      "Epoch 2724/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1023 - val_accuracy: 0.5813\n",
      "Epoch 2725/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1023 - val_accuracy: 0.5790\n",
      "Epoch 2726/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1022 - val_accuracy: 0.5807\n",
      "Epoch 2727/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1024 - val_accuracy: 0.5781\n",
      "Epoch 2728/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0982 - accuracy: 0.5985 - val_loss: 0.1029 - val_accuracy: 0.5751\n",
      "Epoch 2729/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1025 - val_accuracy: 0.5807\n",
      "Epoch 2730/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1035 - val_accuracy: 0.5783\n",
      "Epoch 2731/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1018 - val_accuracy: 0.5808\n",
      "Epoch 2732/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0978 - accuracy: 0.5997 - val_loss: 0.1031 - val_accuracy: 0.5755\n",
      "Epoch 2733/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0981 - accuracy: 0.5981 - val_loss: 0.1029 - val_accuracy: 0.5803\n",
      "Epoch 2734/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0980 - accuracy: 0.5985 - val_loss: 0.1026 - val_accuracy: 0.5789\n",
      "Epoch 2735/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0980 - accuracy: 0.5984 - val_loss: 0.1028 - val_accuracy: 0.5804\n",
      "Epoch 2736/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1028 - val_accuracy: 0.5794\n",
      "Epoch 2737/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1022 - val_accuracy: 0.5803\n",
      "Epoch 2738/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1025 - val_accuracy: 0.5833\n",
      "Epoch 2739/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0979 - accuracy: 0.5987 - val_loss: 0.1019 - val_accuracy: 0.5827\n",
      "Epoch 2740/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0981 - accuracy: 0.5982 - val_loss: 0.1027 - val_accuracy: 0.5767\n",
      "Epoch 2741/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0980 - accuracy: 0.5985 - val_loss: 0.1023 - val_accuracy: 0.5811\n",
      "Epoch 2742/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1026 - val_accuracy: 0.5814\n",
      "Epoch 2743/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1025 - val_accuracy: 0.5822\n",
      "Epoch 2744/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1022 - val_accuracy: 0.5813\n",
      "Epoch 2745/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0980 - accuracy: 0.5985 - val_loss: 0.1020 - val_accuracy: 0.5838\n",
      "Epoch 2746/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0980 - accuracy: 0.5983 - val_loss: 0.1018 - val_accuracy: 0.5823\n",
      "Epoch 2747/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1029 - val_accuracy: 0.5777\n",
      "Epoch 2748/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1023 - val_accuracy: 0.5811\n",
      "Epoch 2749/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1030 - val_accuracy: 0.5778\n",
      "Epoch 2750/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1038 - val_accuracy: 0.5764\n",
      "Epoch 2751/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1023 - val_accuracy: 0.5821\n",
      "Epoch 2752/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0980 - accuracy: 0.5986 - val_loss: 0.1022 - val_accuracy: 0.5797\n",
      "Epoch 2753/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5983 - val_loss: 0.1023 - val_accuracy: 0.5796\n",
      "Epoch 2754/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0980 - accuracy: 0.5977 - val_loss: 0.1024 - val_accuracy: 0.5787\n",
      "Epoch 2755/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0981 - accuracy: 0.5979 - val_loss: 0.1020 - val_accuracy: 0.5815\n",
      "Epoch 2756/5000\n",
      "11864/11864 [==============================] - 7s 593us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1019 - val_accuracy: 0.5818\n",
      "Epoch 2757/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0980 - accuracy: 0.5987 - val_loss: 0.1029 - val_accuracy: 0.5810\n",
      "Epoch 2758/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0980 - accuracy: 0.5986 - val_loss: 0.1023 - val_accuracy: 0.5814\n",
      "Epoch 2759/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0981 - accuracy: 0.5983 - val_loss: 0.1022 - val_accuracy: 0.5788\n",
      "Epoch 2760/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1023 - val_accuracy: 0.5807\n",
      "Epoch 2761/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0981 - accuracy: 0.5982 - val_loss: 0.1028 - val_accuracy: 0.5743\n",
      "Epoch 2762/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1031 - val_accuracy: 0.5814\n",
      "Epoch 2763/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1023 - val_accuracy: 0.5828\n",
      "Epoch 2764/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1025 - val_accuracy: 0.5788\n",
      "Epoch 2765/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0981 - accuracy: 0.5980 - val_loss: 0.1021 - val_accuracy: 0.5814\n",
      "Epoch 2766/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1022 - val_accuracy: 0.5828\n",
      "Epoch 2767/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0981 - accuracy: 0.5984 - val_loss: 0.1025 - val_accuracy: 0.5817\n",
      "Epoch 2768/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0981 - accuracy: 0.5996 - val_loss: 0.1026 - val_accuracy: 0.5808\n",
      "Epoch 2769/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1021 - val_accuracy: 0.5817\n",
      "Epoch 2770/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0981 - accuracy: 0.5983 - val_loss: 0.1021 - val_accuracy: 0.5829\n",
      "Epoch 2771/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0980 - accuracy: 0.5982 - val_loss: 0.1026 - val_accuracy: 0.5809\n",
      "Epoch 2772/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1024 - val_accuracy: 0.5813\n",
      "Epoch 2773/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1020 - val_accuracy: 0.5810\n",
      "Epoch 2774/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1021 - val_accuracy: 0.5804\n",
      "Epoch 2775/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1027 - val_accuracy: 0.5792\n",
      "Epoch 2776/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1027 - val_accuracy: 0.5805\n",
      "Epoch 2777/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1026 - val_accuracy: 0.5808\n",
      "Epoch 2778/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1026 - val_accuracy: 0.5797\n",
      "Epoch 2779/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1024 - val_accuracy: 0.5808\n",
      "Epoch 2780/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0981 - accuracy: 0.5984 - val_loss: 0.1024 - val_accuracy: 0.5815\n",
      "Epoch 2781/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1025 - val_accuracy: 0.5804\n",
      "Epoch 2782/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1014 - val_accuracy: 0.5836\n",
      "Epoch 2783/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1026 - val_accuracy: 0.5817\n",
      "Epoch 2784/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1027 - val_accuracy: 0.5811\n",
      "Epoch 2785/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1022 - val_accuracy: 0.5806\n",
      "Epoch 2786/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1022 - val_accuracy: 0.5821\n",
      "Epoch 2787/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0979 - accuracy: 0.5990 - val_loss: 0.1026 - val_accuracy: 0.5789\n",
      "Epoch 2788/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0980 - accuracy: 0.5987 - val_loss: 0.1030 - val_accuracy: 0.5805\n",
      "Epoch 2789/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1025 - val_accuracy: 0.5806\n",
      "Epoch 2790/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0979 - accuracy: 0.5994 - val_loss: 0.1021 - val_accuracy: 0.5822\n",
      "Epoch 2791/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1024 - val_accuracy: 0.5810\n",
      "Epoch 2792/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1025 - val_accuracy: 0.5794\n",
      "Epoch 2793/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0980 - accuracy: 0.5987 - val_loss: 0.1030 - val_accuracy: 0.5764\n",
      "Epoch 2794/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1026 - val_accuracy: 0.5795\n",
      "Epoch 2795/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0981 - accuracy: 0.5979 - val_loss: 0.1023 - val_accuracy: 0.5807\n",
      "Epoch 2796/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0980 - accuracy: 0.5982 - val_loss: 0.1023 - val_accuracy: 0.5797\n",
      "Epoch 2797/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0979 - accuracy: 0.5994 - val_loss: 0.1017 - val_accuracy: 0.5817\n",
      "Epoch 2798/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1026 - val_accuracy: 0.5809\n",
      "Epoch 2799/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1029 - val_accuracy: 0.5805\n",
      "Epoch 2800/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1021 - val_accuracy: 0.5809\n",
      "Epoch 2801/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0979 - accuracy: 0.5993 - val_loss: 0.1026 - val_accuracy: 0.5822\n",
      "Epoch 2802/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1031 - val_accuracy: 0.5793\n",
      "Epoch 2803/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1020 - val_accuracy: 0.5826\n",
      "Epoch 2804/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0980 - accuracy: 0.5987 - val_loss: 0.1026 - val_accuracy: 0.5803\n",
      "Epoch 2805/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0979 - accuracy: 0.5991 - val_loss: 0.1020 - val_accuracy: 0.5837\n",
      "Epoch 2806/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1021 - val_accuracy: 0.5802\n",
      "Epoch 2807/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1027 - val_accuracy: 0.5801\n",
      "Epoch 2808/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1022 - val_accuracy: 0.5839\n",
      "Epoch 2809/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0980 - accuracy: 0.6000 - val_loss: 0.1019 - val_accuracy: 0.5835\n",
      "Epoch 2810/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0980 - accuracy: 0.5987 - val_loss: 0.1018 - val_accuracy: 0.5808\n",
      "Epoch 2811/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1026 - val_accuracy: 0.5792\n",
      "Epoch 2812/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0980 - accuracy: 0.5986 - val_loss: 0.1019 - val_accuracy: 0.5835\n",
      "Epoch 2813/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0979 - accuracy: 0.5992 - val_loss: 0.1021 - val_accuracy: 0.5804\n",
      "Epoch 2814/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1028 - val_accuracy: 0.5759\n",
      "Epoch 2815/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0979 - accuracy: 0.5993 - val_loss: 0.1030 - val_accuracy: 0.5785\n",
      "Epoch 2816/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1025 - val_accuracy: 0.5780\n",
      "Epoch 2817/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1027 - val_accuracy: 0.5807\n",
      "Epoch 2818/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1022 - val_accuracy: 0.5765\n",
      "Epoch 2819/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1027 - val_accuracy: 0.5777\n",
      "Epoch 2820/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0981 - accuracy: 0.5981 - val_loss: 0.1018 - val_accuracy: 0.5822\n",
      "Epoch 2821/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0981 - accuracy: 0.5978 - val_loss: 0.1026 - val_accuracy: 0.5790\n",
      "Epoch 2822/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0981 - accuracy: 0.5978 - val_loss: 0.1017 - val_accuracy: 0.5843\n",
      "Epoch 2823/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0981 - accuracy: 0.5982 - val_loss: 0.1032 - val_accuracy: 0.5791\n",
      "Epoch 2824/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0982 - accuracy: 0.5982 - val_loss: 0.1025 - val_accuracy: 0.5811\n",
      "Epoch 2825/5000\n",
      "11864/11864 [==============================] - 7s 590us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1028 - val_accuracy: 0.5788\n",
      "Epoch 2826/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0981 - accuracy: 0.5995 - val_loss: 0.1029 - val_accuracy: 0.5783\n",
      "Epoch 2827/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1024 - val_accuracy: 0.5826\n",
      "Epoch 2828/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1026 - val_accuracy: 0.5821\n",
      "Epoch 2829/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1022 - val_accuracy: 0.5815\n",
      "Epoch 2830/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0980 - accuracy: 0.5987 - val_loss: 0.1018 - val_accuracy: 0.5829\n",
      "Epoch 2831/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1026 - val_accuracy: 0.5806\n",
      "Epoch 2832/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0981 - accuracy: 0.5978 - val_loss: 0.1022 - val_accuracy: 0.5804\n",
      "Epoch 2833/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1025 - val_accuracy: 0.5802\n",
      "Epoch 2834/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1025 - val_accuracy: 0.5790\n",
      "Epoch 2835/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0981 - accuracy: 0.5984 - val_loss: 0.1026 - val_accuracy: 0.5787\n",
      "Epoch 2836/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1018 - val_accuracy: 0.5823\n",
      "Epoch 2837/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1022 - val_accuracy: 0.5819\n",
      "Epoch 2838/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0981 - accuracy: 0.5984 - val_loss: 0.1025 - val_accuracy: 0.5806\n",
      "Epoch 2839/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1023 - val_accuracy: 0.5810\n",
      "Epoch 2840/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1021 - val_accuracy: 0.5818\n",
      "Epoch 2841/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1025 - val_accuracy: 0.5802\n",
      "Epoch 2842/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1017 - val_accuracy: 0.5814\n",
      "Epoch 2843/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0979 - accuracy: 0.5990 - val_loss: 0.1027 - val_accuracy: 0.5811\n",
      "Epoch 2844/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1030 - val_accuracy: 0.5779\n",
      "Epoch 2845/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1032 - val_accuracy: 0.5779\n",
      "Epoch 2846/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0981 - accuracy: 0.5983 - val_loss: 0.1026 - val_accuracy: 0.5800\n",
      "Epoch 2847/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0981 - accuracy: 0.5983 - val_loss: 0.1031 - val_accuracy: 0.5767\n",
      "Epoch 2848/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1023 - val_accuracy: 0.5810\n",
      "Epoch 2849/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1024 - val_accuracy: 0.5814\n",
      "Epoch 2850/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0980 - accuracy: 0.5987 - val_loss: 0.1027 - val_accuracy: 0.5794\n",
      "Epoch 2851/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1021 - val_accuracy: 0.5814\n",
      "Epoch 2852/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1020 - val_accuracy: 0.5811\n",
      "Epoch 2853/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1027 - val_accuracy: 0.5792\n",
      "Epoch 2854/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1023 - val_accuracy: 0.5814\n",
      "Epoch 2855/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0982 - accuracy: 0.5983 - val_loss: 0.1025 - val_accuracy: 0.5763\n",
      "Epoch 2856/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1026 - val_accuracy: 0.5808\n",
      "Epoch 2857/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0981 - accuracy: 0.5981 - val_loss: 0.1023 - val_accuracy: 0.5791\n",
      "Epoch 2858/5000\n",
      "11864/11864 [==============================] - 7s 591us/step - loss: 0.0981 - accuracy: 0.5984 - val_loss: 0.1024 - val_accuracy: 0.5789\n",
      "Epoch 2859/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1020 - val_accuracy: 0.5832\n",
      "Epoch 2860/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0981 - accuracy: 0.5979 - val_loss: 0.1025 - val_accuracy: 0.5799\n",
      "Epoch 2861/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1024 - val_accuracy: 0.5810\n",
      "Epoch 2862/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0980 - accuracy: 0.5984 - val_loss: 0.1021 - val_accuracy: 0.5803\n",
      "Epoch 2863/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0980 - accuracy: 0.5986 - val_loss: 0.1023 - val_accuracy: 0.5790\n",
      "Epoch 2864/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1024 - val_accuracy: 0.5786\n",
      "Epoch 2865/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1027 - val_accuracy: 0.5807\n",
      "Epoch 2866/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0980 - accuracy: 0.5987 - val_loss: 0.1027 - val_accuracy: 0.5792\n",
      "Epoch 2867/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1023 - val_accuracy: 0.5788\n",
      "Epoch 2868/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0980 - accuracy: 0.5987 - val_loss: 0.1020 - val_accuracy: 0.5824\n",
      "Epoch 2869/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0980 - accuracy: 0.5986 - val_loss: 0.1022 - val_accuracy: 0.5803\n",
      "Epoch 2870/5000\n",
      "11864/11864 [==============================] - 7s 594us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1020 - val_accuracy: 0.5813\n",
      "Epoch 2871/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1025 - val_accuracy: 0.5813\n",
      "Epoch 2872/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1022 - val_accuracy: 0.5803\n",
      "Epoch 2873/5000\n",
      "11864/11864 [==============================] - 7s 592us/step - loss: 0.0980 - accuracy: 0.5986 - val_loss: 0.1022 - val_accuracy: 0.5787\n",
      "Epoch 2874/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1018 - val_accuracy: 0.5828\n",
      "Epoch 2875/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1023 - val_accuracy: 0.5803\n",
      "Epoch 2876/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1021 - val_accuracy: 0.5803\n",
      "Epoch 2877/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1020 - val_accuracy: 0.5805\n",
      "Epoch 2878/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1023 - val_accuracy: 0.5817\n",
      "Epoch 2879/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1024 - val_accuracy: 0.5815\n",
      "Epoch 2880/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1022 - val_accuracy: 0.5817\n",
      "Epoch 2881/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1030 - val_accuracy: 0.5764\n",
      "Epoch 2882/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0981 - accuracy: 0.5980 - val_loss: 0.1029 - val_accuracy: 0.5800\n",
      "Epoch 2883/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0980 - accuracy: 0.5986 - val_loss: 0.1028 - val_accuracy: 0.5785\n",
      "Epoch 2884/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0980 - accuracy: 0.5986 - val_loss: 0.1019 - val_accuracy: 0.5814\n",
      "Epoch 2885/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1021 - val_accuracy: 0.5814\n",
      "Epoch 2886/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0981 - accuracy: 0.5983 - val_loss: 0.1031 - val_accuracy: 0.5786\n",
      "Epoch 2887/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0979 - accuracy: 0.5991 - val_loss: 0.1018 - val_accuracy: 0.5844\n",
      "Epoch 2888/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0980 - accuracy: 0.5985 - val_loss: 0.1032 - val_accuracy: 0.5778\n",
      "Epoch 2889/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1030 - val_accuracy: 0.5761\n",
      "Epoch 2890/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0980 - accuracy: 0.5985 - val_loss: 0.1023 - val_accuracy: 0.5827\n",
      "Epoch 2891/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0980 - accuracy: 0.5986 - val_loss: 0.1025 - val_accuracy: 0.5827\n",
      "Epoch 2892/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1024 - val_accuracy: 0.5795\n",
      "Epoch 2893/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1023 - val_accuracy: 0.5811\n",
      "Epoch 2894/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1024 - val_accuracy: 0.5815\n",
      "Epoch 2895/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0981 - accuracy: 0.5977 - val_loss: 0.1024 - val_accuracy: 0.5808\n",
      "Epoch 2896/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1028 - val_accuracy: 0.5777\n",
      "Epoch 2897/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1020 - val_accuracy: 0.5814\n",
      "Epoch 2898/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0981 - accuracy: 0.5994 - val_loss: 0.1023 - val_accuracy: 0.5823\n",
      "Epoch 2899/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1033 - val_accuracy: 0.5750\n",
      "Epoch 2900/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0980 - accuracy: 0.5986 - val_loss: 0.1018 - val_accuracy: 0.5840\n",
      "Epoch 2901/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0981 - accuracy: 0.5978 - val_loss: 0.1028 - val_accuracy: 0.5822\n",
      "Epoch 2902/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1025 - val_accuracy: 0.5820\n",
      "Epoch 2903/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1025 - val_accuracy: 0.5794\n",
      "Epoch 2904/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1020 - val_accuracy: 0.5811\n",
      "Epoch 2905/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1023 - val_accuracy: 0.5789\n",
      "Epoch 2906/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0980 - accuracy: 0.5986 - val_loss: 0.1025 - val_accuracy: 0.5777\n",
      "Epoch 2907/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1021 - val_accuracy: 0.5812\n",
      "Epoch 2908/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0980 - accuracy: 0.5987 - val_loss: 0.1027 - val_accuracy: 0.5804\n",
      "Epoch 2909/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0982 - accuracy: 0.5984 - val_loss: 0.1026 - val_accuracy: 0.5807\n",
      "Epoch 2910/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1022 - val_accuracy: 0.5809\n",
      "Epoch 2911/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0982 - accuracy: 0.5988 - val_loss: 0.1021 - val_accuracy: 0.5802\n",
      "Epoch 2912/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1021 - val_accuracy: 0.5789\n",
      "Epoch 2913/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0981 - accuracy: 0.5981 - val_loss: 0.1023 - val_accuracy: 0.5799\n",
      "Epoch 2914/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1022 - val_accuracy: 0.5820\n",
      "Epoch 2915/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1027 - val_accuracy: 0.5789\n",
      "Epoch 2916/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1033 - val_accuracy: 0.5708\n",
      "Epoch 2917/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1025 - val_accuracy: 0.5797\n",
      "Epoch 2918/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1030 - val_accuracy: 0.5768\n",
      "Epoch 2919/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0980 - accuracy: 0.5987 - val_loss: 0.1027 - val_accuracy: 0.5813\n",
      "Epoch 2920/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0981 - accuracy: 0.5984 - val_loss: 0.1021 - val_accuracy: 0.5813\n",
      "Epoch 2921/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0980 - accuracy: 0.5980 - val_loss: 0.1024 - val_accuracy: 0.5826\n",
      "Epoch 2922/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1017 - val_accuracy: 0.5840\n",
      "Epoch 2923/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1031 - val_accuracy: 0.5805\n",
      "Epoch 2924/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1023 - val_accuracy: 0.5811\n",
      "Epoch 2925/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1022 - val_accuracy: 0.5830\n",
      "Epoch 2926/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0980 - accuracy: 0.5984 - val_loss: 0.1022 - val_accuracy: 0.5799\n",
      "Epoch 2927/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1029 - val_accuracy: 0.5822\n",
      "Epoch 2928/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0980 - accuracy: 0.5987 - val_loss: 0.1021 - val_accuracy: 0.5819\n",
      "Epoch 2929/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1023 - val_accuracy: 0.5807\n",
      "Epoch 2930/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0981 - accuracy: 0.5983 - val_loss: 0.1026 - val_accuracy: 0.5754\n",
      "Epoch 2931/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0981 - accuracy: 0.5983 - val_loss: 0.1023 - val_accuracy: 0.5834\n",
      "Epoch 2932/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1021 - val_accuracy: 0.5830\n",
      "Epoch 2933/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1025 - val_accuracy: 0.5803\n",
      "Epoch 2934/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1023 - val_accuracy: 0.5812\n",
      "Epoch 2935/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1029 - val_accuracy: 0.5800\n",
      "Epoch 2936/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1031 - val_accuracy: 0.5795\n",
      "Epoch 2937/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0981 - accuracy: 0.5996 - val_loss: 0.1027 - val_accuracy: 0.5826\n",
      "Epoch 2938/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1024 - val_accuracy: 0.5820\n",
      "Epoch 2939/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1023 - val_accuracy: 0.5801\n",
      "Epoch 2940/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0979 - accuracy: 0.5990 - val_loss: 0.1024 - val_accuracy: 0.5821\n",
      "Epoch 2941/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1028 - val_accuracy: 0.5827\n",
      "Epoch 2942/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1031 - val_accuracy: 0.5802\n",
      "Epoch 2943/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0980 - accuracy: 0.5987 - val_loss: 0.1028 - val_accuracy: 0.5779\n",
      "Epoch 2944/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1026 - val_accuracy: 0.5819\n",
      "Epoch 2945/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1023 - val_accuracy: 0.5806\n",
      "Epoch 2946/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1021 - val_accuracy: 0.5823\n",
      "Epoch 2947/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0981 - accuracy: 0.5982 - val_loss: 0.1024 - val_accuracy: 0.5794\n",
      "Epoch 2948/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1025 - val_accuracy: 0.5804\n",
      "Epoch 2949/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1022 - val_accuracy: 0.5796\n",
      "Epoch 2950/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1022 - val_accuracy: 0.5824\n",
      "Epoch 2951/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1021 - val_accuracy: 0.5801\n",
      "Epoch 2952/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0980 - accuracy: 0.5987 - val_loss: 0.1029 - val_accuracy: 0.5799\n",
      "Epoch 2953/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1021 - val_accuracy: 0.5823\n",
      "Epoch 2954/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1027 - val_accuracy: 0.5768\n",
      "Epoch 2955/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1025 - val_accuracy: 0.5788\n",
      "Epoch 2956/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1025 - val_accuracy: 0.5822\n",
      "Epoch 2957/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0981 - accuracy: 0.5984 - val_loss: 0.1024 - val_accuracy: 0.5795\n",
      "Epoch 2958/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1016 - val_accuracy: 0.5837\n",
      "Epoch 2959/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1024 - val_accuracy: 0.5804\n",
      "Epoch 2960/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1025 - val_accuracy: 0.5822\n",
      "Epoch 2961/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1018 - val_accuracy: 0.5810\n",
      "Epoch 2962/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1023 - val_accuracy: 0.5805\n",
      "Epoch 2963/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0980 - accuracy: 0.5999 - val_loss: 0.1021 - val_accuracy: 0.5822\n",
      "Epoch 2964/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1022 - val_accuracy: 0.5798\n",
      "Epoch 2965/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0979 - accuracy: 0.5989 - val_loss: 0.1019 - val_accuracy: 0.5814\n",
      "Epoch 2966/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1027 - val_accuracy: 0.5795\n",
      "Epoch 2967/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1022 - val_accuracy: 0.5835\n",
      "Epoch 2968/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1021 - val_accuracy: 0.5812\n",
      "Epoch 2969/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1024 - val_accuracy: 0.5840\n",
      "Epoch 2970/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1027 - val_accuracy: 0.5650\n",
      "Epoch 2971/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1023 - val_accuracy: 0.5841\n",
      "Epoch 2972/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1020 - val_accuracy: 0.5835\n",
      "Epoch 2973/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1022 - val_accuracy: 0.5793\n",
      "Epoch 2974/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1019 - val_accuracy: 0.5830\n",
      "Epoch 2975/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1023 - val_accuracy: 0.5790\n",
      "Epoch 2976/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1027 - val_accuracy: 0.5781\n",
      "Epoch 2977/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0980 - accuracy: 0.5983 - val_loss: 0.1021 - val_accuracy: 0.5826\n",
      "Epoch 2978/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0980 - accuracy: 0.5987 - val_loss: 0.1022 - val_accuracy: 0.5807\n",
      "Epoch 2979/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1027 - val_accuracy: 0.5806\n",
      "Epoch 2980/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1017 - val_accuracy: 0.5816\n",
      "Epoch 2981/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1023 - val_accuracy: 0.5829\n",
      "Epoch 2982/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1026 - val_accuracy: 0.5802\n",
      "Epoch 2983/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1022 - val_accuracy: 0.5815\n",
      "Epoch 2984/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1022 - val_accuracy: 0.5806\n",
      "Epoch 2985/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1028 - val_accuracy: 0.5804\n",
      "Epoch 2986/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0981 - accuracy: 0.5980 - val_loss: 0.1029 - val_accuracy: 0.5763\n",
      "Epoch 2987/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1021 - val_accuracy: 0.5846\n",
      "Epoch 2988/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1018 - val_accuracy: 0.5821\n",
      "Epoch 2989/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1023 - val_accuracy: 0.5830\n",
      "Epoch 2990/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0981 - accuracy: 0.5997 - val_loss: 0.1021 - val_accuracy: 0.5803\n",
      "Epoch 2991/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1026 - val_accuracy: 0.5818\n",
      "Epoch 2992/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0980 - accuracy: 0.5986 - val_loss: 0.1022 - val_accuracy: 0.5798\n",
      "Epoch 2993/5000\n",
      "11864/11864 [==============================] - 7s 597us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1029 - val_accuracy: 0.5797\n",
      "Epoch 2994/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1031 - val_accuracy: 0.5791\n",
      "Epoch 2995/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1021 - val_accuracy: 0.5832\n",
      "Epoch 2996/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1023 - val_accuracy: 0.5810\n",
      "Epoch 2997/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1042 - val_accuracy: 0.5771\n",
      "Epoch 2998/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0980 - accuracy: 0.5987 - val_loss: 0.1029 - val_accuracy: 0.5762\n",
      "Epoch 2999/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1023 - val_accuracy: 0.5806\n",
      "Epoch 3000/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1023 - val_accuracy: 0.5813\n",
      "Epoch 3001/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1021 - val_accuracy: 0.5830\n",
      "Epoch 3002/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1026 - val_accuracy: 0.5788\n",
      "Epoch 3003/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1022 - val_accuracy: 0.5838\n",
      "Epoch 3004/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0981 - accuracy: 0.5995 - val_loss: 0.1020 - val_accuracy: 0.5829\n",
      "Epoch 3005/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1017 - val_accuracy: 0.5825\n",
      "Epoch 3006/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1020 - val_accuracy: 0.5823\n",
      "Epoch 3007/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1031 - val_accuracy: 0.5644\n",
      "Epoch 3008/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0979 - accuracy: 0.6001 - val_loss: 0.1038 - val_accuracy: 0.5769\n",
      "Epoch 3009/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1024 - val_accuracy: 0.5811\n",
      "Epoch 3010/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0981 - accuracy: 0.5996 - val_loss: 0.1020 - val_accuracy: 0.5818\n",
      "Epoch 3011/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1018 - val_accuracy: 0.5818\n",
      "Epoch 3012/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1032 - val_accuracy: 0.5787\n",
      "Epoch 3013/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1023 - val_accuracy: 0.5849\n",
      "Epoch 3014/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1020 - val_accuracy: 0.5831\n",
      "Epoch 3015/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0981 - accuracy: 0.6001 - val_loss: 0.1023 - val_accuracy: 0.5815\n",
      "Epoch 3016/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1026 - val_accuracy: 0.5805\n",
      "Epoch 3017/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1025 - val_accuracy: 0.5809\n",
      "Epoch 3018/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1026 - val_accuracy: 0.5801\n",
      "Epoch 3019/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1024 - val_accuracy: 0.5798\n",
      "Epoch 3020/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1027 - val_accuracy: 0.5749\n",
      "Epoch 3021/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1027 - val_accuracy: 0.5804\n",
      "Epoch 3022/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1021 - val_accuracy: 0.5789\n",
      "Epoch 3023/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1023 - val_accuracy: 0.5801\n",
      "Epoch 3024/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1022 - val_accuracy: 0.5840\n",
      "Epoch 3025/5000\n",
      "11864/11864 [==============================] - 7s 596us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1027 - val_accuracy: 0.5797\n",
      "Epoch 3026/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1023 - val_accuracy: 0.5822\n",
      "Epoch 3027/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0981 - accuracy: 0.5983 - val_loss: 0.1036 - val_accuracy: 0.5768\n",
      "Epoch 3028/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1024 - val_accuracy: 0.5818\n",
      "Epoch 3029/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1023 - val_accuracy: 0.5823\n",
      "Epoch 3030/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1023 - val_accuracy: 0.5813\n",
      "Epoch 3031/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1021 - val_accuracy: 0.5818\n",
      "Epoch 3032/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0981 - accuracy: 0.5997 - val_loss: 0.1024 - val_accuracy: 0.5809\n",
      "Epoch 3033/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1020 - val_accuracy: 0.5822\n",
      "Epoch 3034/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1027 - val_accuracy: 0.5806\n",
      "Epoch 3035/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0980 - accuracy: 0.5999 - val_loss: 0.1027 - val_accuracy: 0.5808\n",
      "Epoch 3036/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1023 - val_accuracy: 0.5814\n",
      "Epoch 3037/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1021 - val_accuracy: 0.5796\n",
      "Epoch 3038/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0981 - accuracy: 0.5995 - val_loss: 0.1019 - val_accuracy: 0.5840\n",
      "Epoch 3039/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1022 - val_accuracy: 0.5806\n",
      "Epoch 3040/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1023 - val_accuracy: 0.5796\n",
      "Epoch 3041/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1028 - val_accuracy: 0.5808\n",
      "Epoch 3042/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1019 - val_accuracy: 0.5835\n",
      "Epoch 3043/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1022 - val_accuracy: 0.5822\n",
      "Epoch 3044/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1022 - val_accuracy: 0.5793\n",
      "Epoch 3045/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1022 - val_accuracy: 0.5811\n",
      "Epoch 3046/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0978 - accuracy: 0.6000 - val_loss: 0.1036 - val_accuracy: 0.5784\n",
      "Epoch 3047/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1019 - val_accuracy: 0.5828\n",
      "Epoch 3048/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1023 - val_accuracy: 0.5775\n",
      "Epoch 3049/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1024 - val_accuracy: 0.5794\n",
      "Epoch 3050/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1022 - val_accuracy: 0.5814\n",
      "Epoch 3051/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0981 - accuracy: 0.5982 - val_loss: 0.1022 - val_accuracy: 0.5790\n",
      "Epoch 3052/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1029 - val_accuracy: 0.5834\n",
      "Epoch 3053/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1025 - val_accuracy: 0.5799\n",
      "Epoch 3054/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1025 - val_accuracy: 0.5769\n",
      "Epoch 3055/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0982 - accuracy: 0.5991 - val_loss: 0.1024 - val_accuracy: 0.5809\n",
      "Epoch 3056/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1022 - val_accuracy: 0.5800\n",
      "Epoch 3057/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1042 - val_accuracy: 0.5776\n",
      "Epoch 3058/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1026 - val_accuracy: 0.5826\n",
      "Epoch 3059/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1017 - val_accuracy: 0.5847\n",
      "Epoch 3060/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1021 - val_accuracy: 0.5809\n",
      "Epoch 3061/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1021 - val_accuracy: 0.5810\n",
      "Epoch 3062/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1023 - val_accuracy: 0.5825\n",
      "Epoch 3063/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1033 - val_accuracy: 0.5814\n",
      "Epoch 3064/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1018 - val_accuracy: 0.5826\n",
      "Epoch 3065/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0981 - accuracy: 0.5994 - val_loss: 0.1018 - val_accuracy: 0.5823\n",
      "Epoch 3066/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1028 - val_accuracy: 0.5772\n",
      "Epoch 3067/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1023 - val_accuracy: 0.5814\n",
      "Epoch 3068/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1031 - val_accuracy: 0.5812\n",
      "Epoch 3069/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1021 - val_accuracy: 0.5817\n",
      "Epoch 3070/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1023 - val_accuracy: 0.5798\n",
      "Epoch 3071/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0979 - accuracy: 0.5988 - val_loss: 0.1023 - val_accuracy: 0.5806\n",
      "Epoch 3072/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1027 - val_accuracy: 0.5810\n",
      "Epoch 3073/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1029 - val_accuracy: 0.5813\n",
      "Epoch 3074/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1027 - val_accuracy: 0.5815\n",
      "Epoch 3075/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1025 - val_accuracy: 0.5806\n",
      "Epoch 3076/5000\n",
      "11864/11864 [==============================] - 7s 598us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1032 - val_accuracy: 0.5792\n",
      "Epoch 3077/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0981 - accuracy: 0.5995 - val_loss: 0.1029 - val_accuracy: 0.5810\n",
      "Epoch 3078/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0980 - accuracy: 0.6001 - val_loss: 0.1023 - val_accuracy: 0.5827\n",
      "Epoch 3079/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1026 - val_accuracy: 0.5823\n",
      "Epoch 3080/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1029 - val_accuracy: 0.5805\n",
      "Epoch 3081/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1023 - val_accuracy: 0.5755\n",
      "Epoch 3082/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0980 - accuracy: 0.6002 - val_loss: 0.1028 - val_accuracy: 0.5797\n",
      "Epoch 3083/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1025 - val_accuracy: 0.5813\n",
      "Epoch 3084/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1024 - val_accuracy: 0.5836\n",
      "Epoch 3085/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1029 - val_accuracy: 0.5781\n",
      "Epoch 3086/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0981 - accuracy: 0.5983 - val_loss: 0.1026 - val_accuracy: 0.5836\n",
      "Epoch 3087/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1028 - val_accuracy: 0.5788\n",
      "Epoch 3088/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1030 - val_accuracy: 0.5788\n",
      "Epoch 3089/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1026 - val_accuracy: 0.5798\n",
      "Epoch 3090/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1022 - val_accuracy: 0.5824\n",
      "Epoch 3091/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1026 - val_accuracy: 0.5830\n",
      "Epoch 3092/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0982 - accuracy: 0.5984 - val_loss: 0.1022 - val_accuracy: 0.5812\n",
      "Epoch 3093/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1025 - val_accuracy: 0.5817\n",
      "Epoch 3094/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1024 - val_accuracy: 0.5815\n",
      "Epoch 3095/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0980 - accuracy: 0.6001 - val_loss: 0.1028 - val_accuracy: 0.5813\n",
      "Epoch 3096/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0978 - accuracy: 0.6004 - val_loss: 0.1023 - val_accuracy: 0.5798\n",
      "Epoch 3097/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1025 - val_accuracy: 0.5829\n",
      "Epoch 3098/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1028 - val_accuracy: 0.5794\n",
      "Epoch 3099/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1028 - val_accuracy: 0.5771\n",
      "Epoch 3100/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1025 - val_accuracy: 0.5804\n",
      "Epoch 3101/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1029 - val_accuracy: 0.5798\n",
      "Epoch 3102/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1028 - val_accuracy: 0.5782\n",
      "Epoch 3103/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1024 - val_accuracy: 0.5816\n",
      "Epoch 3104/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1022 - val_accuracy: 0.5817\n",
      "Epoch 3105/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1020 - val_accuracy: 0.5829\n",
      "Epoch 3106/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1027 - val_accuracy: 0.5786\n",
      "Epoch 3107/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1028 - val_accuracy: 0.5804\n",
      "Epoch 3108/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1031 - val_accuracy: 0.5804\n",
      "Epoch 3109/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1045 - val_accuracy: 0.5734\n",
      "Epoch 3110/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1020 - val_accuracy: 0.5830\n",
      "Epoch 3111/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1023 - val_accuracy: 0.5835\n",
      "Epoch 3112/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1028 - val_accuracy: 0.5770\n",
      "Epoch 3113/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0980 - accuracy: 0.5987 - val_loss: 0.1021 - val_accuracy: 0.5814\n",
      "Epoch 3114/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0981 - accuracy: 0.5981 - val_loss: 0.1022 - val_accuracy: 0.5827\n",
      "Epoch 3115/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1024 - val_accuracy: 0.5822\n",
      "Epoch 3116/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1028 - val_accuracy: 0.5789\n",
      "Epoch 3117/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0980 - accuracy: 0.6001 - val_loss: 0.1027 - val_accuracy: 0.5832\n",
      "Epoch 3118/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0980 - accuracy: 0.5986 - val_loss: 0.1023 - val_accuracy: 0.5820\n",
      "Epoch 3119/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0981 - accuracy: 0.5984 - val_loss: 0.1028 - val_accuracy: 0.5813\n",
      "Epoch 3120/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1023 - val_accuracy: 0.5826\n",
      "Epoch 3121/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0979 - accuracy: 0.5990 - val_loss: 0.1025 - val_accuracy: 0.5834\n",
      "Epoch 3122/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1026 - val_accuracy: 0.5836\n",
      "Epoch 3123/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1029 - val_accuracy: 0.5805\n",
      "Epoch 3124/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1022 - val_accuracy: 0.5830\n",
      "Epoch 3125/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1026 - val_accuracy: 0.5808\n",
      "Epoch 3126/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1025 - val_accuracy: 0.5803\n",
      "Epoch 3127/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1032 - val_accuracy: 0.5747\n",
      "Epoch 3128/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0980 - accuracy: 0.5985 - val_loss: 0.1021 - val_accuracy: 0.5850\n",
      "Epoch 3129/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0980 - accuracy: 0.5986 - val_loss: 0.1024 - val_accuracy: 0.5809\n",
      "Epoch 3130/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1031 - val_accuracy: 0.5798\n",
      "Epoch 3131/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0981 - accuracy: 0.5996 - val_loss: 0.1023 - val_accuracy: 0.5815\n",
      "Epoch 3132/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0980 - accuracy: 0.5987 - val_loss: 0.1032 - val_accuracy: 0.5752\n",
      "Epoch 3133/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1029 - val_accuracy: 0.5810\n",
      "Epoch 3134/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0980 - accuracy: 0.6000 - val_loss: 0.1023 - val_accuracy: 0.5813\n",
      "Epoch 3135/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1022 - val_accuracy: 0.5821\n",
      "Epoch 3136/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0981 - accuracy: 0.5996 - val_loss: 0.1017 - val_accuracy: 0.5825\n",
      "Epoch 3137/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0979 - accuracy: 0.5991 - val_loss: 0.1029 - val_accuracy: 0.5827\n",
      "Epoch 3138/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1026 - val_accuracy: 0.5822\n",
      "Epoch 3139/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1025 - val_accuracy: 0.5808\n",
      "Epoch 3140/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1024 - val_accuracy: 0.5811\n",
      "Epoch 3141/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1022 - val_accuracy: 0.5807\n",
      "Epoch 3142/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1020 - val_accuracy: 0.5837\n",
      "Epoch 3143/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1027 - val_accuracy: 0.5817\n",
      "Epoch 3144/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1021 - val_accuracy: 0.5818\n",
      "Epoch 3145/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1025 - val_accuracy: 0.5801\n",
      "Epoch 3146/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0980 - accuracy: 0.5986 - val_loss: 0.1026 - val_accuracy: 0.5790\n",
      "Epoch 3147/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0979 - accuracy: 0.5990 - val_loss: 0.1028 - val_accuracy: 0.5816\n",
      "Epoch 3148/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1023 - val_accuracy: 0.5801\n",
      "Epoch 3149/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1018 - val_accuracy: 0.5840\n",
      "Epoch 3150/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1020 - val_accuracy: 0.5790\n",
      "Epoch 3151/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0979 - accuracy: 0.6001 - val_loss: 0.1031 - val_accuracy: 0.5776\n",
      "Epoch 3152/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0979 - accuracy: 0.5982 - val_loss: 0.1021 - val_accuracy: 0.5832\n",
      "Epoch 3153/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0981 - accuracy: 0.5983 - val_loss: 0.1027 - val_accuracy: 0.5785\n",
      "Epoch 3154/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0980 - accuracy: 0.5987 - val_loss: 0.1030 - val_accuracy: 0.5815\n",
      "Epoch 3155/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1028 - val_accuracy: 0.5783\n",
      "Epoch 3156/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0981 - accuracy: 0.5983 - val_loss: 0.1023 - val_accuracy: 0.5803\n",
      "Epoch 3157/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1023 - val_accuracy: 0.5799\n",
      "Epoch 3158/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1021 - val_accuracy: 0.5806\n",
      "Epoch 3159/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1028 - val_accuracy: 0.5800\n",
      "Epoch 3160/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1025 - val_accuracy: 0.5809\n",
      "Epoch 3161/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1021 - val_accuracy: 0.5833\n",
      "Epoch 3162/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1022 - val_accuracy: 0.5808\n",
      "Epoch 3163/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1023 - val_accuracy: 0.5824\n",
      "Epoch 3164/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0981 - accuracy: 0.5996 - val_loss: 0.1023 - val_accuracy: 0.5819\n",
      "Epoch 3165/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1024 - val_accuracy: 0.5813\n",
      "Epoch 3166/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0981 - accuracy: 0.5982 - val_loss: 0.1019 - val_accuracy: 0.5837\n",
      "Epoch 3167/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1025 - val_accuracy: 0.5789\n",
      "Epoch 3168/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1028 - val_accuracy: 0.5815\n",
      "Epoch 3169/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1026 - val_accuracy: 0.5813\n",
      "Epoch 3170/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1024 - val_accuracy: 0.5795\n",
      "Epoch 3171/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1023 - val_accuracy: 0.5811\n",
      "Epoch 3172/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1026 - val_accuracy: 0.5804\n",
      "Epoch 3173/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1024 - val_accuracy: 0.5804\n",
      "Epoch 3174/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1029 - val_accuracy: 0.5794\n",
      "Epoch 3175/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1023 - val_accuracy: 0.5831\n",
      "Epoch 3176/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1026 - val_accuracy: 0.5806\n",
      "Epoch 3177/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0981 - accuracy: 0.6003 - val_loss: 0.1026 - val_accuracy: 0.5783\n",
      "Epoch 3178/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1026 - val_accuracy: 0.5806\n",
      "Epoch 3179/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1022 - val_accuracy: 0.5827\n",
      "Epoch 3180/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1023 - val_accuracy: 0.5811\n",
      "Epoch 3181/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1031 - val_accuracy: 0.5793\n",
      "Epoch 3182/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1026 - val_accuracy: 0.5800\n",
      "Epoch 3183/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1021 - val_accuracy: 0.5837\n",
      "Epoch 3184/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1024 - val_accuracy: 0.5817\n",
      "Epoch 3185/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1027 - val_accuracy: 0.5806\n",
      "Epoch 3186/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1029 - val_accuracy: 0.5797\n",
      "Epoch 3187/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1028 - val_accuracy: 0.5798\n",
      "Epoch 3188/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1031 - val_accuracy: 0.5771\n",
      "Epoch 3189/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1026 - val_accuracy: 0.5810\n",
      "Epoch 3190/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1024 - val_accuracy: 0.5785\n",
      "Epoch 3191/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1020 - val_accuracy: 0.5800\n",
      "Epoch 3192/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1028 - val_accuracy: 0.5765\n",
      "Epoch 3193/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1029 - val_accuracy: 0.5790\n",
      "Epoch 3194/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1024 - val_accuracy: 0.5810\n",
      "Epoch 3195/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1030 - val_accuracy: 0.5775\n",
      "Epoch 3196/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1026 - val_accuracy: 0.5804\n",
      "Epoch 3197/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0980 - accuracy: 0.5999 - val_loss: 0.1022 - val_accuracy: 0.5800\n",
      "Epoch 3198/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1027 - val_accuracy: 0.5790\n",
      "Epoch 3199/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0979 - accuracy: 0.5990 - val_loss: 0.1023 - val_accuracy: 0.5832\n",
      "Epoch 3200/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1025 - val_accuracy: 0.5797\n",
      "Epoch 3201/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1028 - val_accuracy: 0.5783\n",
      "Epoch 3202/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1032 - val_accuracy: 0.5770\n",
      "Epoch 3203/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0981 - accuracy: 0.5984 - val_loss: 0.1025 - val_accuracy: 0.5820\n",
      "Epoch 3204/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1025 - val_accuracy: 0.5829\n",
      "Epoch 3205/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1029 - val_accuracy: 0.5812\n",
      "Epoch 3206/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1024 - val_accuracy: 0.5794\n",
      "Epoch 3207/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1027 - val_accuracy: 0.5814\n",
      "Epoch 3208/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0979 - accuracy: 0.6004 - val_loss: 0.1028 - val_accuracy: 0.5811\n",
      "Epoch 3209/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0979 - accuracy: 0.5992 - val_loss: 0.1024 - val_accuracy: 0.5804\n",
      "Epoch 3210/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1028 - val_accuracy: 0.5808\n",
      "Epoch 3211/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0979 - accuracy: 0.5994 - val_loss: 0.1020 - val_accuracy: 0.5818\n",
      "Epoch 3212/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1026 - val_accuracy: 0.5790\n",
      "Epoch 3213/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1022 - val_accuracy: 0.5811\n",
      "Epoch 3214/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1030 - val_accuracy: 0.5805\n",
      "Epoch 3215/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1026 - val_accuracy: 0.5797\n",
      "Epoch 3216/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1026 - val_accuracy: 0.5834\n",
      "Epoch 3217/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1033 - val_accuracy: 0.5791\n",
      "Epoch 3218/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1035 - val_accuracy: 0.5768\n",
      "Epoch 3219/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1021 - val_accuracy: 0.5803\n",
      "Epoch 3220/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1025 - val_accuracy: 0.5810\n",
      "Epoch 3221/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0981 - accuracy: 0.5996 - val_loss: 0.1026 - val_accuracy: 0.5803\n",
      "Epoch 3222/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1030 - val_accuracy: 0.5753\n",
      "Epoch 3223/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1029 - val_accuracy: 0.5782\n",
      "Epoch 3224/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0980 - accuracy: 0.5999 - val_loss: 0.1024 - val_accuracy: 0.5793\n",
      "Epoch 3225/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1036 - val_accuracy: 0.5802\n",
      "Epoch 3226/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0980 - accuracy: 0.5986 - val_loss: 0.1023 - val_accuracy: 0.5793\n",
      "Epoch 3227/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1026 - val_accuracy: 0.5815\n",
      "Epoch 3228/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1023 - val_accuracy: 0.5816\n",
      "Epoch 3229/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0980 - accuracy: 0.5987 - val_loss: 0.1026 - val_accuracy: 0.5796\n",
      "Epoch 3230/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1028 - val_accuracy: 0.5794\n",
      "Epoch 3231/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1023 - val_accuracy: 0.5800\n",
      "Epoch 3232/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1027 - val_accuracy: 0.5783\n",
      "Epoch 3233/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0980 - accuracy: 0.5983 - val_loss: 0.1022 - val_accuracy: 0.5804\n",
      "Epoch 3234/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1025 - val_accuracy: 0.5815\n",
      "Epoch 3235/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1025 - val_accuracy: 0.5815\n",
      "Epoch 3236/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1028 - val_accuracy: 0.5783\n",
      "Epoch 3237/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0982 - accuracy: 0.5987 - val_loss: 0.1034 - val_accuracy: 0.5663\n",
      "Epoch 3238/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1022 - val_accuracy: 0.5846\n",
      "Epoch 3239/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1024 - val_accuracy: 0.5821\n",
      "Epoch 3240/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1024 - val_accuracy: 0.5825\n",
      "Epoch 3241/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1025 - val_accuracy: 0.5826\n",
      "Epoch 3242/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1042 - val_accuracy: 0.5799\n",
      "Epoch 3243/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1028 - val_accuracy: 0.5813\n",
      "Epoch 3244/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1019 - val_accuracy: 0.5812\n",
      "Epoch 3245/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0980 - accuracy: 0.5999 - val_loss: 0.1036 - val_accuracy: 0.5780\n",
      "Epoch 3246/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1023 - val_accuracy: 0.5804\n",
      "Epoch 3247/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0979 - accuracy: 0.5991 - val_loss: 0.1024 - val_accuracy: 0.5820\n",
      "Epoch 3248/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0980 - accuracy: 0.5985 - val_loss: 0.1029 - val_accuracy: 0.5777\n",
      "Epoch 3249/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1026 - val_accuracy: 0.5814\n",
      "Epoch 3250/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1027 - val_accuracy: 0.5800\n",
      "Epoch 3251/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0982 - accuracy: 0.5987 - val_loss: 0.1024 - val_accuracy: 0.5819\n",
      "Epoch 3252/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1033 - val_accuracy: 0.5781\n",
      "Epoch 3253/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1025 - val_accuracy: 0.5792\n",
      "Epoch 3254/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1021 - val_accuracy: 0.5816\n",
      "Epoch 3255/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1030 - val_accuracy: 0.5795\n",
      "Epoch 3256/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1025 - val_accuracy: 0.5831\n",
      "Epoch 3257/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1026 - val_accuracy: 0.5815\n",
      "Epoch 3258/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1032 - val_accuracy: 0.5709\n",
      "Epoch 3259/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0979 - accuracy: 0.6002 - val_loss: 0.1021 - val_accuracy: 0.5802\n",
      "Epoch 3260/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1025 - val_accuracy: 0.5809\n",
      "Epoch 3261/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0979 - accuracy: 0.5994 - val_loss: 0.1026 - val_accuracy: 0.5823\n",
      "Epoch 3262/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1023 - val_accuracy: 0.5816\n",
      "Epoch 3263/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0980 - accuracy: 0.5987 - val_loss: 0.1023 - val_accuracy: 0.5823\n",
      "Epoch 3264/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0980 - accuracy: 0.5999 - val_loss: 0.1026 - val_accuracy: 0.5790\n",
      "Epoch 3265/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1019 - val_accuracy: 0.5831\n",
      "Epoch 3266/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0980 - accuracy: 0.5999 - val_loss: 0.1030 - val_accuracy: 0.5766\n",
      "Epoch 3267/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1025 - val_accuracy: 0.5821\n",
      "Epoch 3268/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1019 - val_accuracy: 0.5823\n",
      "Epoch 3269/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1021 - val_accuracy: 0.5824\n",
      "Epoch 3270/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1022 - val_accuracy: 0.5791\n",
      "Epoch 3271/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0981 - accuracy: 0.5997 - val_loss: 0.1024 - val_accuracy: 0.5801\n",
      "Epoch 3272/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0981 - accuracy: 0.5995 - val_loss: 0.1026 - val_accuracy: 0.5801\n",
      "Epoch 3273/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0980 - accuracy: 0.6001 - val_loss: 0.1032 - val_accuracy: 0.5776\n",
      "Epoch 3274/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0981 - accuracy: 0.5997 - val_loss: 0.1023 - val_accuracy: 0.5811\n",
      "Epoch 3275/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0980 - accuracy: 0.6002 - val_loss: 0.1028 - val_accuracy: 0.5818\n",
      "Epoch 3276/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0979 - accuracy: 0.5989 - val_loss: 0.1021 - val_accuracy: 0.5825\n",
      "Epoch 3277/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1030 - val_accuracy: 0.5778\n",
      "Epoch 3278/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0979 - accuracy: 0.5990 - val_loss: 0.1024 - val_accuracy: 0.5801\n",
      "Epoch 3279/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1028 - val_accuracy: 0.5817\n",
      "Epoch 3280/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1022 - val_accuracy: 0.5822\n",
      "Epoch 3281/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1024 - val_accuracy: 0.5832\n",
      "Epoch 3282/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0982 - accuracy: 0.5991 - val_loss: 0.1021 - val_accuracy: 0.5799\n",
      "Epoch 3283/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1029 - val_accuracy: 0.5815\n",
      "Epoch 3284/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1027 - val_accuracy: 0.5789\n",
      "Epoch 3285/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1021 - val_accuracy: 0.5789\n",
      "Epoch 3286/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1028 - val_accuracy: 0.5793\n",
      "Epoch 3287/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1028 - val_accuracy: 0.5793\n",
      "Epoch 3288/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0979 - accuracy: 0.5994 - val_loss: 0.1026 - val_accuracy: 0.5811\n",
      "Epoch 3289/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1019 - val_accuracy: 0.5827\n",
      "Epoch 3290/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1027 - val_accuracy: 0.5795\n",
      "Epoch 3291/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1021 - val_accuracy: 0.5817\n",
      "Epoch 3292/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1022 - val_accuracy: 0.5829\n",
      "Epoch 3293/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1029 - val_accuracy: 0.5800\n",
      "Epoch 3294/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1028 - val_accuracy: 0.5801\n",
      "Epoch 3295/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1028 - val_accuracy: 0.5804\n",
      "Epoch 3296/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0980 - accuracy: 0.5982 - val_loss: 0.1029 - val_accuracy: 0.5786\n",
      "Epoch 3297/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1020 - val_accuracy: 0.5814\n",
      "Epoch 3298/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1024 - val_accuracy: 0.5821\n",
      "Epoch 3299/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1028 - val_accuracy: 0.5780\n",
      "Epoch 3300/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0979 - accuracy: 0.5994 - val_loss: 0.1023 - val_accuracy: 0.5839\n",
      "Epoch 3301/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0980 - accuracy: 0.5985 - val_loss: 0.1029 - val_accuracy: 0.5828\n",
      "Epoch 3302/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1021 - val_accuracy: 0.5802\n",
      "Epoch 3303/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1031 - val_accuracy: 0.5806\n",
      "Epoch 3304/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0979 - accuracy: 0.6003 - val_loss: 0.1020 - val_accuracy: 0.5826\n",
      "Epoch 3305/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1023 - val_accuracy: 0.5820\n",
      "Epoch 3306/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0980 - accuracy: 0.5987 - val_loss: 0.1028 - val_accuracy: 0.5726\n",
      "Epoch 3307/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1020 - val_accuracy: 0.5817\n",
      "Epoch 3308/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0980 - accuracy: 0.6001 - val_loss: 0.1029 - val_accuracy: 0.5791\n",
      "Epoch 3309/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0982 - accuracy: 0.5985 - val_loss: 0.1026 - val_accuracy: 0.5802\n",
      "Epoch 3310/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1025 - val_accuracy: 0.5810\n",
      "Epoch 3311/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1025 - val_accuracy: 0.5799\n",
      "Epoch 3312/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1022 - val_accuracy: 0.5815\n",
      "Epoch 3313/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1030 - val_accuracy: 0.5788\n",
      "Epoch 3314/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1024 - val_accuracy: 0.5817\n",
      "Epoch 3315/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1033 - val_accuracy: 0.5706\n",
      "Epoch 3316/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0980 - accuracy: 0.5986 - val_loss: 0.1024 - val_accuracy: 0.5818\n",
      "Epoch 3317/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1023 - val_accuracy: 0.5816\n",
      "Epoch 3318/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1030 - val_accuracy: 0.5775\n",
      "Epoch 3319/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1029 - val_accuracy: 0.5820\n",
      "Epoch 3320/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0981 - accuracy: 0.5984 - val_loss: 0.1023 - val_accuracy: 0.5806\n",
      "Epoch 3321/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1020 - val_accuracy: 0.5821\n",
      "Epoch 3322/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1025 - val_accuracy: 0.5804\n",
      "Epoch 3323/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1027 - val_accuracy: 0.5809\n",
      "Epoch 3324/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1017 - val_accuracy: 0.5832\n",
      "Epoch 3325/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1026 - val_accuracy: 0.5786\n",
      "Epoch 3326/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1028 - val_accuracy: 0.5838\n",
      "Epoch 3327/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1022 - val_accuracy: 0.5816\n",
      "Epoch 3328/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1025 - val_accuracy: 0.5825\n",
      "Epoch 3329/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1022 - val_accuracy: 0.5816\n",
      "Epoch 3330/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1027 - val_accuracy: 0.5804\n",
      "Epoch 3331/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0980 - accuracy: 0.6001 - val_loss: 0.1021 - val_accuracy: 0.5813\n",
      "Epoch 3332/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1024 - val_accuracy: 0.5820\n",
      "Epoch 3333/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1024 - val_accuracy: 0.5816\n",
      "Epoch 3334/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1020 - val_accuracy: 0.5840\n",
      "Epoch 3335/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1028 - val_accuracy: 0.5805\n",
      "Epoch 3336/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1024 - val_accuracy: 0.5806\n",
      "Epoch 3337/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1021 - val_accuracy: 0.5831\n",
      "Epoch 3338/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1030 - val_accuracy: 0.5797\n",
      "Epoch 3339/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1030 - val_accuracy: 0.5793\n",
      "Epoch 3340/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1031 - val_accuracy: 0.5790\n",
      "Epoch 3341/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1025 - val_accuracy: 0.5788\n",
      "Epoch 3342/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1033 - val_accuracy: 0.5810\n",
      "Epoch 3343/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0979 - accuracy: 0.6004 - val_loss: 0.1025 - val_accuracy: 0.5802\n",
      "Epoch 3344/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0979 - accuracy: 0.5993 - val_loss: 0.1025 - val_accuracy: 0.5801\n",
      "Epoch 3345/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1021 - val_accuracy: 0.5808\n",
      "Epoch 3346/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1026 - val_accuracy: 0.5806\n",
      "Epoch 3347/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1025 - val_accuracy: 0.5814\n",
      "Epoch 3348/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1028 - val_accuracy: 0.5815\n",
      "Epoch 3349/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1024 - val_accuracy: 0.5800\n",
      "Epoch 3350/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1029 - val_accuracy: 0.5756\n",
      "Epoch 3351/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1031 - val_accuracy: 0.5763\n",
      "Epoch 3352/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1026 - val_accuracy: 0.5809\n",
      "Epoch 3353/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1028 - val_accuracy: 0.5805\n",
      "Epoch 3354/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1020 - val_accuracy: 0.5811\n",
      "Epoch 3355/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1021 - val_accuracy: 0.5813\n",
      "Epoch 3356/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1026 - val_accuracy: 0.5806\n",
      "Epoch 3357/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1029 - val_accuracy: 0.5818\n",
      "Epoch 3358/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0979 - accuracy: 0.5993 - val_loss: 0.1033 - val_accuracy: 0.5774\n",
      "Epoch 3359/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1025 - val_accuracy: 0.5810\n",
      "Epoch 3360/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0980 - accuracy: 0.5987 - val_loss: 0.1026 - val_accuracy: 0.5781\n",
      "Epoch 3361/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1027 - val_accuracy: 0.5802\n",
      "Epoch 3362/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1023 - val_accuracy: 0.5828\n",
      "Epoch 3363/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1024 - val_accuracy: 0.5755\n",
      "Epoch 3364/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1027 - val_accuracy: 0.5815\n",
      "Epoch 3365/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1024 - val_accuracy: 0.5808\n",
      "Epoch 3366/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1028 - val_accuracy: 0.5815\n",
      "Epoch 3367/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1019 - val_accuracy: 0.5845\n",
      "Epoch 3368/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1023 - val_accuracy: 0.5814\n",
      "Epoch 3369/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1028 - val_accuracy: 0.5845\n",
      "Epoch 3370/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1022 - val_accuracy: 0.5807\n",
      "Epoch 3371/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0980 - accuracy: 0.5985 - val_loss: 0.1021 - val_accuracy: 0.5838\n",
      "Epoch 3372/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1028 - val_accuracy: 0.5776\n",
      "Epoch 3373/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1035 - val_accuracy: 0.5679\n",
      "Epoch 3374/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0979 - accuracy: 0.5993 - val_loss: 0.1027 - val_accuracy: 0.5794\n",
      "Epoch 3375/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1032 - val_accuracy: 0.5793\n",
      "Epoch 3376/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0981 - accuracy: 0.5994 - val_loss: 0.1023 - val_accuracy: 0.5816\n",
      "Epoch 3377/5000\n",
      "11864/11864 [==============================] - 7s 601us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1027 - val_accuracy: 0.5808\n",
      "Epoch 3378/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1023 - val_accuracy: 0.5765\n",
      "Epoch 3379/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1030 - val_accuracy: 0.5807\n",
      "Epoch 3380/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0979 - accuracy: 0.5993 - val_loss: 0.1026 - val_accuracy: 0.5791\n",
      "Epoch 3381/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1022 - val_accuracy: 0.5784\n",
      "Epoch 3382/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1026 - val_accuracy: 0.5812\n",
      "Epoch 3383/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1028 - val_accuracy: 0.5791\n",
      "Epoch 3384/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1030 - val_accuracy: 0.5810\n",
      "Epoch 3385/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1021 - val_accuracy: 0.5820\n",
      "Epoch 3386/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1028 - val_accuracy: 0.5810\n",
      "Epoch 3387/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1028 - val_accuracy: 0.5796\n",
      "Epoch 3388/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1029 - val_accuracy: 0.5797\n",
      "Epoch 3389/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0979 - accuracy: 0.6002 - val_loss: 0.1030 - val_accuracy: 0.5809\n",
      "Epoch 3390/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1021 - val_accuracy: 0.5824\n",
      "Epoch 3391/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0979 - accuracy: 0.5993 - val_loss: 0.1029 - val_accuracy: 0.5803\n",
      "Epoch 3392/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1025 - val_accuracy: 0.5778\n",
      "Epoch 3393/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1025 - val_accuracy: 0.5799\n",
      "Epoch 3394/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1028 - val_accuracy: 0.5787\n",
      "Epoch 3395/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1034 - val_accuracy: 0.5735\n",
      "Epoch 3396/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1026 - val_accuracy: 0.5804\n",
      "Epoch 3397/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1023 - val_accuracy: 0.5783\n",
      "Epoch 3398/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1028 - val_accuracy: 0.5799\n",
      "Epoch 3399/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0979 - accuracy: 0.6001 - val_loss: 0.1021 - val_accuracy: 0.5805\n",
      "Epoch 3400/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1023 - val_accuracy: 0.5802\n",
      "Epoch 3401/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1030 - val_accuracy: 0.5812\n",
      "Epoch 3402/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1022 - val_accuracy: 0.5802\n",
      "Epoch 3403/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1028 - val_accuracy: 0.5790\n",
      "Epoch 3404/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0979 - accuracy: 0.6003 - val_loss: 0.1028 - val_accuracy: 0.5778\n",
      "Epoch 3405/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0979 - accuracy: 0.5993 - val_loss: 0.1022 - val_accuracy: 0.5836\n",
      "Epoch 3406/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1026 - val_accuracy: 0.5809\n",
      "Epoch 3407/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1026 - val_accuracy: 0.5778\n",
      "Epoch 3408/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1024 - val_accuracy: 0.5809\n",
      "Epoch 3409/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1023 - val_accuracy: 0.5802\n",
      "Epoch 3410/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1025 - val_accuracy: 0.5805\n",
      "Epoch 3411/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1026 - val_accuracy: 0.5804\n",
      "Epoch 3412/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1021 - val_accuracy: 0.5831\n",
      "Epoch 3413/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0980 - accuracy: 0.5979 - val_loss: 0.1022 - val_accuracy: 0.5839\n",
      "Epoch 3414/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1022 - val_accuracy: 0.5823\n",
      "Epoch 3415/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1025 - val_accuracy: 0.5789\n",
      "Epoch 3416/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1022 - val_accuracy: 0.5830\n",
      "Epoch 3417/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1028 - val_accuracy: 0.5784\n",
      "Epoch 3418/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0980 - accuracy: 0.6000 - val_loss: 0.1025 - val_accuracy: 0.5825\n",
      "Epoch 3419/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1026 - val_accuracy: 0.5800\n",
      "Epoch 3420/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1021 - val_accuracy: 0.5820\n",
      "Epoch 3421/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1033 - val_accuracy: 0.5784\n",
      "Epoch 3422/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0982 - accuracy: 0.5994 - val_loss: 0.1025 - val_accuracy: 0.5816\n",
      "Epoch 3423/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0981 - accuracy: 0.5995 - val_loss: 0.1025 - val_accuracy: 0.5801\n",
      "Epoch 3424/5000\n",
      "11864/11864 [==============================] - 7s 599us/step - loss: 0.0980 - accuracy: 0.5985 - val_loss: 0.1036 - val_accuracy: 0.5762\n",
      "Epoch 3425/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0980 - accuracy: 0.6000 - val_loss: 0.1025 - val_accuracy: 0.5823\n",
      "Epoch 3426/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1036 - val_accuracy: 0.5763\n",
      "Epoch 3427/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1020 - val_accuracy: 0.5810\n",
      "Epoch 3428/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1030 - val_accuracy: 0.5732\n",
      "Epoch 3429/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1026 - val_accuracy: 0.5786\n",
      "Epoch 3430/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0981 - accuracy: 0.5995 - val_loss: 0.1036 - val_accuracy: 0.5783\n",
      "Epoch 3431/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0979 - accuracy: 0.5992 - val_loss: 0.1025 - val_accuracy: 0.5793\n",
      "Epoch 3432/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0981 - accuracy: 0.5997 - val_loss: 0.1035 - val_accuracy: 0.5759\n",
      "Epoch 3433/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1023 - val_accuracy: 0.5795\n",
      "Epoch 3434/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0979 - accuracy: 0.6001 - val_loss: 0.1022 - val_accuracy: 0.5824\n",
      "Epoch 3435/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1022 - val_accuracy: 0.5822\n",
      "Epoch 3436/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0980 - accuracy: 0.5985 - val_loss: 0.1026 - val_accuracy: 0.5786\n",
      "Epoch 3437/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1021 - val_accuracy: 0.5787\n",
      "Epoch 3438/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1023 - val_accuracy: 0.5840\n",
      "Epoch 3439/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1025 - val_accuracy: 0.5812\n",
      "Epoch 3440/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1020 - val_accuracy: 0.5803\n",
      "Epoch 3441/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0979 - accuracy: 0.6004 - val_loss: 0.1018 - val_accuracy: 0.5829\n",
      "Epoch 3442/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1030 - val_accuracy: 0.5803\n",
      "Epoch 3443/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1024 - val_accuracy: 0.5790\n",
      "Epoch 3444/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1030 - val_accuracy: 0.5822\n",
      "Epoch 3445/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0978 - accuracy: 0.6006 - val_loss: 0.1028 - val_accuracy: 0.5790\n",
      "Epoch 3446/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1023 - val_accuracy: 0.5803\n",
      "Epoch 3447/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1032 - val_accuracy: 0.5813\n",
      "Epoch 3448/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1029 - val_accuracy: 0.5779\n",
      "Epoch 3449/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0979 - accuracy: 0.6002 - val_loss: 0.1024 - val_accuracy: 0.5793\n",
      "Epoch 3450/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0981 - accuracy: 0.5999 - val_loss: 0.1023 - val_accuracy: 0.5821\n",
      "Epoch 3451/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0979 - accuracy: 0.5989 - val_loss: 0.1024 - val_accuracy: 0.5796\n",
      "Epoch 3452/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0979 - accuracy: 0.5991 - val_loss: 0.1024 - val_accuracy: 0.5816\n",
      "Epoch 3453/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1026 - val_accuracy: 0.5838\n",
      "Epoch 3454/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1032 - val_accuracy: 0.5791\n",
      "Epoch 3455/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0980 - accuracy: 0.5999 - val_loss: 0.1030 - val_accuracy: 0.5819\n",
      "Epoch 3456/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0981 - accuracy: 0.5999 - val_loss: 0.1024 - val_accuracy: 0.5803\n",
      "Epoch 3457/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1021 - val_accuracy: 0.5807\n",
      "Epoch 3458/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1028 - val_accuracy: 0.5752\n",
      "Epoch 3459/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1023 - val_accuracy: 0.5817\n",
      "Epoch 3460/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0979 - accuracy: 0.5989 - val_loss: 0.1022 - val_accuracy: 0.5833\n",
      "Epoch 3461/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1026 - val_accuracy: 0.5821\n",
      "Epoch 3462/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0979 - accuracy: 0.5991 - val_loss: 0.1028 - val_accuracy: 0.5794\n",
      "Epoch 3463/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1021 - val_accuracy: 0.5822\n",
      "Epoch 3464/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1024 - val_accuracy: 0.5831\n",
      "Epoch 3465/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0979 - accuracy: 0.6001 - val_loss: 0.1025 - val_accuracy: 0.5742\n",
      "Epoch 3466/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1024 - val_accuracy: 0.5798\n",
      "Epoch 3467/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1021 - val_accuracy: 0.5844\n",
      "Epoch 3468/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0979 - accuracy: 0.5993 - val_loss: 0.1023 - val_accuracy: 0.5791\n",
      "Epoch 3469/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1027 - val_accuracy: 0.5787\n",
      "Epoch 3470/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0979 - accuracy: 0.5987 - val_loss: 0.1024 - val_accuracy: 0.5797\n",
      "Epoch 3471/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1031 - val_accuracy: 0.5779\n",
      "Epoch 3472/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0979 - accuracy: 0.5991 - val_loss: 0.1030 - val_accuracy: 0.5799\n",
      "Epoch 3473/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1026 - val_accuracy: 0.5821\n",
      "Epoch 3474/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1026 - val_accuracy: 0.5780\n",
      "Epoch 3475/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0979 - accuracy: 0.6002 - val_loss: 0.1023 - val_accuracy: 0.5805\n",
      "Epoch 3476/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0979 - accuracy: 0.5993 - val_loss: 0.1027 - val_accuracy: 0.5799\n",
      "Epoch 3477/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1027 - val_accuracy: 0.5771\n",
      "Epoch 3478/5000\n",
      "11864/11864 [==============================] - 7s 595us/step - loss: 0.0981 - accuracy: 0.6002 - val_loss: 0.1028 - val_accuracy: 0.5774\n",
      "Epoch 3479/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1023 - val_accuracy: 0.5829\n",
      "Epoch 3480/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0979 - accuracy: 0.5994 - val_loss: 0.1023 - val_accuracy: 0.5806\n",
      "Epoch 3481/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1027 - val_accuracy: 0.5825\n",
      "Epoch 3482/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1024 - val_accuracy: 0.5794\n",
      "Epoch 3483/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0978 - accuracy: 0.6005 - val_loss: 0.1022 - val_accuracy: 0.5793\n",
      "Epoch 3484/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1026 - val_accuracy: 0.5799\n",
      "Epoch 3485/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1022 - val_accuracy: 0.5824\n",
      "Epoch 3486/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1025 - val_accuracy: 0.5814\n",
      "Epoch 3487/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0981 - accuracy: 0.5981 - val_loss: 0.1026 - val_accuracy: 0.5800\n",
      "Epoch 3488/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0981 - accuracy: 0.5997 - val_loss: 0.1022 - val_accuracy: 0.5824\n",
      "Epoch 3489/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1022 - val_accuracy: 0.5809\n",
      "Epoch 3490/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0979 - accuracy: 0.5992 - val_loss: 0.1027 - val_accuracy: 0.5761\n",
      "Epoch 3491/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1022 - val_accuracy: 0.5837\n",
      "Epoch 3492/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1023 - val_accuracy: 0.5814\n",
      "Epoch 3493/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1019 - val_accuracy: 0.5833\n",
      "Epoch 3494/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0979 - accuracy: 0.5993 - val_loss: 0.1024 - val_accuracy: 0.5826\n",
      "Epoch 3495/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1029 - val_accuracy: 0.5770\n",
      "Epoch 3496/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1029 - val_accuracy: 0.5788\n",
      "Epoch 3497/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1024 - val_accuracy: 0.5824\n",
      "Epoch 3498/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1024 - val_accuracy: 0.5813\n",
      "Epoch 3499/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0979 - accuracy: 0.5991 - val_loss: 0.1027 - val_accuracy: 0.5777\n",
      "Epoch 3500/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0981 - accuracy: 0.5995 - val_loss: 0.1026 - val_accuracy: 0.5805\n",
      "Epoch 3501/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0979 - accuracy: 0.5993 - val_loss: 0.1025 - val_accuracy: 0.5800\n",
      "Epoch 3502/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1027 - val_accuracy: 0.5784\n",
      "Epoch 3503/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1021 - val_accuracy: 0.5834\n",
      "Epoch 3504/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1025 - val_accuracy: 0.5802\n",
      "Epoch 3505/5000\n",
      "11864/11864 [==============================] - 7s 605us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1021 - val_accuracy: 0.5818\n",
      "Epoch 3506/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1027 - val_accuracy: 0.5812\n",
      "Epoch 3507/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0979 - accuracy: 0.6001 - val_loss: 0.1021 - val_accuracy: 0.5825\n",
      "Epoch 3508/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1024 - val_accuracy: 0.5839\n",
      "Epoch 3509/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1022 - val_accuracy: 0.5816\n",
      "Epoch 3510/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0979 - accuracy: 0.6001 - val_loss: 0.1030 - val_accuracy: 0.5805\n",
      "Epoch 3511/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0979 - accuracy: 0.5994 - val_loss: 0.1026 - val_accuracy: 0.5814\n",
      "Epoch 3512/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1024 - val_accuracy: 0.5855\n",
      "Epoch 3513/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0980 - accuracy: 0.6002 - val_loss: 0.1019 - val_accuracy: 0.5848\n",
      "Epoch 3514/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0979 - accuracy: 0.5992 - val_loss: 0.1025 - val_accuracy: 0.5803\n",
      "Epoch 3515/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1018 - val_accuracy: 0.5856\n",
      "Epoch 3516/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1035 - val_accuracy: 0.5740\n",
      "Epoch 3517/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0979 - accuracy: 0.6001 - val_loss: 0.1029 - val_accuracy: 0.5765\n",
      "Epoch 3518/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0978 - accuracy: 0.5998 - val_loss: 0.1024 - val_accuracy: 0.5805\n",
      "Epoch 3519/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1033 - val_accuracy: 0.5785\n",
      "Epoch 3520/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1026 - val_accuracy: 0.5818\n",
      "Epoch 3521/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0980 - accuracy: 0.5999 - val_loss: 0.1023 - val_accuracy: 0.5831\n",
      "Epoch 3522/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1018 - val_accuracy: 0.5845\n",
      "Epoch 3523/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1022 - val_accuracy: 0.5836\n",
      "Epoch 3524/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1025 - val_accuracy: 0.5816\n",
      "Epoch 3525/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1027 - val_accuracy: 0.5811\n",
      "Epoch 3526/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1019 - val_accuracy: 0.5833\n",
      "Epoch 3527/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1027 - val_accuracy: 0.5822\n",
      "Epoch 3528/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0979 - accuracy: 0.6003 - val_loss: 0.1029 - val_accuracy: 0.5795\n",
      "Epoch 3529/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1033 - val_accuracy: 0.5782\n",
      "Epoch 3530/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1017 - val_accuracy: 0.5841\n",
      "Epoch 3531/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0979 - accuracy: 0.6006 - val_loss: 0.1022 - val_accuracy: 0.5835\n",
      "Epoch 3532/5000\n",
      "11864/11864 [==============================] - 8s 691us/step - loss: 0.0980 - accuracy: 0.6000 - val_loss: 0.1024 - val_accuracy: 0.5815\n",
      "Epoch 3533/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1025 - val_accuracy: 0.5774\n",
      "Epoch 3534/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0979 - accuracy: 0.6002 - val_loss: 0.1028 - val_accuracy: 0.5820\n",
      "Epoch 3535/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1019 - val_accuracy: 0.5825\n",
      "Epoch 3536/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1031 - val_accuracy: 0.5801\n",
      "Epoch 3537/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1020 - val_accuracy: 0.5839\n",
      "Epoch 3538/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0979 - accuracy: 0.6003 - val_loss: 0.1020 - val_accuracy: 0.5821\n",
      "Epoch 3539/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0979 - accuracy: 0.6005 - val_loss: 0.1023 - val_accuracy: 0.5836\n",
      "Epoch 3540/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0979 - accuracy: 0.6001 - val_loss: 0.1026 - val_accuracy: 0.5816\n",
      "Epoch 3541/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0978 - accuracy: 0.5996 - val_loss: 0.1026 - val_accuracy: 0.5813\n",
      "Epoch 3542/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1024 - val_accuracy: 0.5797\n",
      "Epoch 3543/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1027 - val_accuracy: 0.5787\n",
      "Epoch 3544/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1023 - val_accuracy: 0.5813\n",
      "Epoch 3545/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0978 - accuracy: 0.6000 - val_loss: 0.1026 - val_accuracy: 0.5797\n",
      "Epoch 3546/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0980 - accuracy: 0.6001 - val_loss: 0.1027 - val_accuracy: 0.5809\n",
      "Epoch 3547/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1021 - val_accuracy: 0.5820\n",
      "Epoch 3548/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0979 - accuracy: 0.5993 - val_loss: 0.1022 - val_accuracy: 0.5826\n",
      "Epoch 3549/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1021 - val_accuracy: 0.5824\n",
      "Epoch 3550/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1020 - val_accuracy: 0.5816\n",
      "Epoch 3551/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0979 - accuracy: 0.5993 - val_loss: 0.1023 - val_accuracy: 0.5817\n",
      "Epoch 3552/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0978 - accuracy: 0.5997 - val_loss: 0.1024 - val_accuracy: 0.5824\n",
      "Epoch 3553/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1024 - val_accuracy: 0.5810\n",
      "Epoch 3554/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1027 - val_accuracy: 0.5791\n",
      "Epoch 3555/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0980 - accuracy: 0.6001 - val_loss: 0.1018 - val_accuracy: 0.5816\n",
      "Epoch 3556/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1028 - val_accuracy: 0.5804\n",
      "Epoch 3557/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1024 - val_accuracy: 0.5781\n",
      "Epoch 3558/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1026 - val_accuracy: 0.5793\n",
      "Epoch 3559/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1023 - val_accuracy: 0.5815\n",
      "Epoch 3560/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1027 - val_accuracy: 0.5825\n",
      "Epoch 3561/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1020 - val_accuracy: 0.5829\n",
      "Epoch 3562/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0979 - accuracy: 0.6002 - val_loss: 0.1028 - val_accuracy: 0.5792\n",
      "Epoch 3563/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1019 - val_accuracy: 0.5822\n",
      "Epoch 3564/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0979 - accuracy: 0.6004 - val_loss: 0.1028 - val_accuracy: 0.5797\n",
      "Epoch 3565/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0979 - accuracy: 0.5994 - val_loss: 0.1021 - val_accuracy: 0.5810\n",
      "Epoch 3566/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0978 - accuracy: 0.6006 - val_loss: 0.1027 - val_accuracy: 0.5810\n",
      "Epoch 3567/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1025 - val_accuracy: 0.5835\n",
      "Epoch 3568/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0979 - accuracy: 0.6009 - val_loss: 0.1027 - val_accuracy: 0.5810\n",
      "Epoch 3569/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0980 - accuracy: 0.6000 - val_loss: 0.1030 - val_accuracy: 0.5769\n",
      "Epoch 3570/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0979 - accuracy: 0.6003 - val_loss: 0.1025 - val_accuracy: 0.5803\n",
      "Epoch 3571/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1024 - val_accuracy: 0.5838\n",
      "Epoch 3572/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1025 - val_accuracy: 0.5836\n",
      "Epoch 3573/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0981 - accuracy: 0.6001 - val_loss: 0.1026 - val_accuracy: 0.5809\n",
      "Epoch 3574/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1025 - val_accuracy: 0.5817\n",
      "Epoch 3575/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0979 - accuracy: 0.5991 - val_loss: 0.1018 - val_accuracy: 0.5814\n",
      "Epoch 3576/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1024 - val_accuracy: 0.5813\n",
      "Epoch 3577/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1019 - val_accuracy: 0.5834\n",
      "Epoch 3578/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1019 - val_accuracy: 0.5829\n",
      "Epoch 3579/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1024 - val_accuracy: 0.5829\n",
      "Epoch 3580/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0979 - accuracy: 0.6002 - val_loss: 0.1028 - val_accuracy: 0.5771\n",
      "Epoch 3581/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1028 - val_accuracy: 0.5810\n",
      "Epoch 3582/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1021 - val_accuracy: 0.5830\n",
      "Epoch 3583/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1027 - val_accuracy: 0.5799\n",
      "Epoch 3584/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0978 - accuracy: 0.6006 - val_loss: 0.1030 - val_accuracy: 0.5812\n",
      "Epoch 3585/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1024 - val_accuracy: 0.5809\n",
      "Epoch 3586/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1021 - val_accuracy: 0.5829\n",
      "Epoch 3587/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1026 - val_accuracy: 0.5798\n",
      "Epoch 3588/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1026 - val_accuracy: 0.5820\n",
      "Epoch 3589/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1026 - val_accuracy: 0.5812\n",
      "Epoch 3590/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1019 - val_accuracy: 0.5825\n",
      "Epoch 3591/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1032 - val_accuracy: 0.5818\n",
      "Epoch 3592/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1032 - val_accuracy: 0.5800\n",
      "Epoch 3593/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0979 - accuracy: 0.6002 - val_loss: 0.1023 - val_accuracy: 0.5812\n",
      "Epoch 3594/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1020 - val_accuracy: 0.5818\n",
      "Epoch 3595/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1031 - val_accuracy: 0.5817\n",
      "Epoch 3596/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1028 - val_accuracy: 0.5798\n",
      "Epoch 3597/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1021 - val_accuracy: 0.5815\n",
      "Epoch 3598/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1021 - val_accuracy: 0.5824\n",
      "Epoch 3599/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0979 - accuracy: 0.5993 - val_loss: 0.1021 - val_accuracy: 0.5828\n",
      "Epoch 3600/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1027 - val_accuracy: 0.5790\n",
      "Epoch 3601/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0979 - accuracy: 0.5987 - val_loss: 0.1021 - val_accuracy: 0.5819\n",
      "Epoch 3602/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1025 - val_accuracy: 0.5768\n",
      "Epoch 3603/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0978 - accuracy: 0.5996 - val_loss: 0.1029 - val_accuracy: 0.5813\n",
      "Epoch 3604/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1029 - val_accuracy: 0.5797\n",
      "Epoch 3605/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1023 - val_accuracy: 0.5817\n",
      "Epoch 3606/5000\n",
      "11864/11864 [==============================] - 7s 606us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1018 - val_accuracy: 0.5844\n",
      "Epoch 3607/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1031 - val_accuracy: 0.5816\n",
      "Epoch 3608/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1032 - val_accuracy: 0.5806\n",
      "Epoch 3609/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0979 - accuracy: 0.5993 - val_loss: 0.1024 - val_accuracy: 0.5826\n",
      "Epoch 3610/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0979 - accuracy: 0.5990 - val_loss: 0.1026 - val_accuracy: 0.5784\n",
      "Epoch 3611/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1036 - val_accuracy: 0.5785\n",
      "Epoch 3612/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1031 - val_accuracy: 0.5811\n",
      "Epoch 3613/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1020 - val_accuracy: 0.5819\n",
      "Epoch 3614/5000\n",
      "11864/11864 [==============================] - 7s 603us/step - loss: 0.0980 - accuracy: 0.6001 - val_loss: 0.1023 - val_accuracy: 0.5811\n",
      "Epoch 3615/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1023 - val_accuracy: 0.5811\n",
      "Epoch 3616/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1019 - val_accuracy: 0.5826\n",
      "Epoch 3617/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1026 - val_accuracy: 0.5792\n",
      "Epoch 3618/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1023 - val_accuracy: 0.5834\n",
      "Epoch 3619/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1029 - val_accuracy: 0.5761\n",
      "Epoch 3620/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1026 - val_accuracy: 0.5782\n",
      "Epoch 3621/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0979 - accuracy: 0.6002 - val_loss: 0.1035 - val_accuracy: 0.5770\n",
      "Epoch 3622/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1020 - val_accuracy: 0.5824\n",
      "Epoch 3623/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1025 - val_accuracy: 0.5814\n",
      "Epoch 3624/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1035 - val_accuracy: 0.5743\n",
      "Epoch 3625/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1016 - val_accuracy: 0.5836\n",
      "Epoch 3626/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1019 - val_accuracy: 0.5823\n",
      "Epoch 3627/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1020 - val_accuracy: 0.5847\n",
      "Epoch 3628/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1024 - val_accuracy: 0.5818\n",
      "Epoch 3629/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1023 - val_accuracy: 0.5814\n",
      "Epoch 3630/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1023 - val_accuracy: 0.5812\n",
      "Epoch 3631/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0979 - accuracy: 0.5992 - val_loss: 0.1025 - val_accuracy: 0.5764\n",
      "Epoch 3632/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0980 - accuracy: 0.5987 - val_loss: 0.1034 - val_accuracy: 0.5789\n",
      "Epoch 3633/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1021 - val_accuracy: 0.5816\n",
      "Epoch 3634/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0979 - accuracy: 0.6002 - val_loss: 0.1027 - val_accuracy: 0.5786\n",
      "Epoch 3635/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1026 - val_accuracy: 0.5782\n",
      "Epoch 3636/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0979 - accuracy: 0.6003 - val_loss: 0.1024 - val_accuracy: 0.5782\n",
      "Epoch 3637/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0979 - accuracy: 0.5985 - val_loss: 0.1029 - val_accuracy: 0.5817\n",
      "Epoch 3638/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1021 - val_accuracy: 0.5807\n",
      "Epoch 3639/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1029 - val_accuracy: 0.5780\n",
      "Epoch 3640/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1029 - val_accuracy: 0.5732\n",
      "Epoch 3641/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1025 - val_accuracy: 0.5824\n",
      "Epoch 3642/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1033 - val_accuracy: 0.5805\n",
      "Epoch 3643/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1023 - val_accuracy: 0.5795\n",
      "Epoch 3644/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1022 - val_accuracy: 0.5837\n",
      "Epoch 3645/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1023 - val_accuracy: 0.5820\n",
      "Epoch 3646/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0979 - accuracy: 0.5991 - val_loss: 0.1026 - val_accuracy: 0.5799\n",
      "Epoch 3647/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1030 - val_accuracy: 0.5799\n",
      "Epoch 3648/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1021 - val_accuracy: 0.5796\n",
      "Epoch 3649/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1023 - val_accuracy: 0.5835\n",
      "Epoch 3650/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1028 - val_accuracy: 0.5832\n",
      "Epoch 3651/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1026 - val_accuracy: 0.5800\n",
      "Epoch 3652/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0980 - accuracy: 0.6001 - val_loss: 0.1024 - val_accuracy: 0.5843\n",
      "Epoch 3653/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1031 - val_accuracy: 0.5811\n",
      "Epoch 3654/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1033 - val_accuracy: 0.5809\n",
      "Epoch 3655/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0979 - accuracy: 0.5992 - val_loss: 0.1023 - val_accuracy: 0.5796\n",
      "Epoch 3656/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1030 - val_accuracy: 0.5814\n",
      "Epoch 3657/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1020 - val_accuracy: 0.5814\n",
      "Epoch 3658/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0980 - accuracy: 0.5984 - val_loss: 0.1020 - val_accuracy: 0.5819\n",
      "Epoch 3659/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1020 - val_accuracy: 0.5799\n",
      "Epoch 3660/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0979 - accuracy: 0.5991 - val_loss: 0.1023 - val_accuracy: 0.5812\n",
      "Epoch 3661/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1027 - val_accuracy: 0.5760\n",
      "Epoch 3662/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1021 - val_accuracy: 0.5843\n",
      "Epoch 3663/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0978 - accuracy: 0.5996 - val_loss: 0.1027 - val_accuracy: 0.5805\n",
      "Epoch 3664/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1027 - val_accuracy: 0.5800\n",
      "Epoch 3665/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1023 - val_accuracy: 0.5835\n",
      "Epoch 3666/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1029 - val_accuracy: 0.5771\n",
      "Epoch 3667/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1024 - val_accuracy: 0.5781\n",
      "Epoch 3668/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1028 - val_accuracy: 0.5813\n",
      "Epoch 3669/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1024 - val_accuracy: 0.5796\n",
      "Epoch 3670/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1026 - val_accuracy: 0.5810\n",
      "Epoch 3671/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0979 - accuracy: 0.5990 - val_loss: 0.1029 - val_accuracy: 0.5822\n",
      "Epoch 3672/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1021 - val_accuracy: 0.5810\n",
      "Epoch 3673/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1022 - val_accuracy: 0.5818\n",
      "Epoch 3674/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1024 - val_accuracy: 0.5798\n",
      "Epoch 3675/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0979 - accuracy: 0.5991 - val_loss: 0.1034 - val_accuracy: 0.5792\n",
      "Epoch 3676/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1025 - val_accuracy: 0.5785\n",
      "Epoch 3677/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1023 - val_accuracy: 0.5808\n",
      "Epoch 3678/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1023 - val_accuracy: 0.5810\n",
      "Epoch 3679/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1019 - val_accuracy: 0.5797\n",
      "Epoch 3680/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0979 - accuracy: 0.6003 - val_loss: 0.1029 - val_accuracy: 0.5814\n",
      "Epoch 3681/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1025 - val_accuracy: 0.5812\n",
      "Epoch 3682/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1027 - val_accuracy: 0.5808\n",
      "Epoch 3683/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1023 - val_accuracy: 0.5802\n",
      "Epoch 3684/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1025 - val_accuracy: 0.5806\n",
      "Epoch 3685/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1024 - val_accuracy: 0.5816\n",
      "Epoch 3686/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1023 - val_accuracy: 0.5833\n",
      "Epoch 3687/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1024 - val_accuracy: 0.5833\n",
      "Epoch 3688/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1028 - val_accuracy: 0.5787\n",
      "Epoch 3689/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1026 - val_accuracy: 0.5785\n",
      "Epoch 3690/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1019 - val_accuracy: 0.5815\n",
      "Epoch 3691/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0978 - accuracy: 0.5999 - val_loss: 0.1024 - val_accuracy: 0.5802\n",
      "Epoch 3692/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1024 - val_accuracy: 0.5794\n",
      "Epoch 3693/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1023 - val_accuracy: 0.5821\n",
      "Epoch 3694/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1029 - val_accuracy: 0.5818\n",
      "Epoch 3695/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1020 - val_accuracy: 0.5841\n",
      "Epoch 3696/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1022 - val_accuracy: 0.5829\n",
      "Epoch 3697/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1026 - val_accuracy: 0.5830\n",
      "Epoch 3698/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0980 - accuracy: 0.6001 - val_loss: 0.1027 - val_accuracy: 0.5824\n",
      "Epoch 3699/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1027 - val_accuracy: 0.5811\n",
      "Epoch 3700/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0979 - accuracy: 0.6002 - val_loss: 0.1022 - val_accuracy: 0.5827\n",
      "Epoch 3701/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0978 - accuracy: 0.5998 - val_loss: 0.1020 - val_accuracy: 0.5839\n",
      "Epoch 3702/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1030 - val_accuracy: 0.5787\n",
      "Epoch 3703/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0979 - accuracy: 0.5990 - val_loss: 0.1034 - val_accuracy: 0.5757\n",
      "Epoch 3704/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1021 - val_accuracy: 0.5806\n",
      "Epoch 3705/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1027 - val_accuracy: 0.5809\n",
      "Epoch 3706/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0979 - accuracy: 0.5993 - val_loss: 0.1027 - val_accuracy: 0.5779\n",
      "Epoch 3707/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0979 - accuracy: 0.5994 - val_loss: 0.1025 - val_accuracy: 0.5808\n",
      "Epoch 3708/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0979 - accuracy: 0.5994 - val_loss: 0.1030 - val_accuracy: 0.5795\n",
      "Epoch 3709/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0979 - accuracy: 0.6003 - val_loss: 0.1027 - val_accuracy: 0.5811\n",
      "Epoch 3710/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1025 - val_accuracy: 0.5814\n",
      "Epoch 3711/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1022 - val_accuracy: 0.5806\n",
      "Epoch 3712/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1023 - val_accuracy: 0.5824\n",
      "Epoch 3713/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1021 - val_accuracy: 0.5816\n",
      "Epoch 3714/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1023 - val_accuracy: 0.5807\n",
      "Epoch 3715/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0980 - accuracy: 0.6003 - val_loss: 0.1026 - val_accuracy: 0.5818\n",
      "Epoch 3716/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1021 - val_accuracy: 0.5808\n",
      "Epoch 3717/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0979 - accuracy: 0.6005 - val_loss: 0.1026 - val_accuracy: 0.5815\n",
      "Epoch 3718/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0979 - accuracy: 0.6005 - val_loss: 0.1032 - val_accuracy: 0.5763\n",
      "Epoch 3719/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1022 - val_accuracy: 0.5791\n",
      "Epoch 3720/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1023 - val_accuracy: 0.5815\n",
      "Epoch 3721/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0980 - accuracy: 0.6001 - val_loss: 0.1034 - val_accuracy: 0.5780\n",
      "Epoch 3722/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1023 - val_accuracy: 0.5812\n",
      "Epoch 3723/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0980 - accuracy: 0.5985 - val_loss: 0.1028 - val_accuracy: 0.5779\n",
      "Epoch 3724/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0979 - accuracy: 0.5986 - val_loss: 0.1021 - val_accuracy: 0.5830\n",
      "Epoch 3725/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1025 - val_accuracy: 0.5805\n",
      "Epoch 3726/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1026 - val_accuracy: 0.5801\n",
      "Epoch 3727/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0979 - accuracy: 0.5991 - val_loss: 0.1027 - val_accuracy: 0.5788\n",
      "Epoch 3728/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1026 - val_accuracy: 0.5791\n",
      "Epoch 3729/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0980 - accuracy: 0.5999 - val_loss: 0.1024 - val_accuracy: 0.5809\n",
      "Epoch 3730/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1028 - val_accuracy: 0.5791\n",
      "Epoch 3731/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1028 - val_accuracy: 0.5803\n",
      "Epoch 3732/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0980 - accuracy: 0.6000 - val_loss: 0.1024 - val_accuracy: 0.5848\n",
      "Epoch 3733/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1021 - val_accuracy: 0.5809\n",
      "Epoch 3734/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1029 - val_accuracy: 0.5796\n",
      "Epoch 3735/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0979 - accuracy: 0.5994 - val_loss: 0.1023 - val_accuracy: 0.5834\n",
      "Epoch 3736/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1031 - val_accuracy: 0.5808\n",
      "Epoch 3737/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1020 - val_accuracy: 0.5812\n",
      "Epoch 3738/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1025 - val_accuracy: 0.5817\n",
      "Epoch 3739/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1030 - val_accuracy: 0.5822\n",
      "Epoch 3740/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0980 - accuracy: 0.5987 - val_loss: 0.1023 - val_accuracy: 0.5802\n",
      "Epoch 3741/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1027 - val_accuracy: 0.5788\n",
      "Epoch 3742/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1025 - val_accuracy: 0.5797\n",
      "Epoch 3743/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1023 - val_accuracy: 0.5836\n",
      "Epoch 3744/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1018 - val_accuracy: 0.5822\n",
      "Epoch 3745/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1029 - val_accuracy: 0.5814\n",
      "Epoch 3746/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1026 - val_accuracy: 0.5788\n",
      "Epoch 3747/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1025 - val_accuracy: 0.5795\n",
      "Epoch 3748/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0979 - accuracy: 0.5992 - val_loss: 0.1023 - val_accuracy: 0.5816\n",
      "Epoch 3749/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1027 - val_accuracy: 0.5769\n",
      "Epoch 3750/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1032 - val_accuracy: 0.5717\n",
      "Epoch 3751/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1035 - val_accuracy: 0.5789\n",
      "Epoch 3752/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1029 - val_accuracy: 0.5800\n",
      "Epoch 3753/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1023 - val_accuracy: 0.5769\n",
      "Epoch 3754/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1024 - val_accuracy: 0.5809\n",
      "Epoch 3755/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1027 - val_accuracy: 0.5812\n",
      "Epoch 3756/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1025 - val_accuracy: 0.5788\n",
      "Epoch 3757/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1024 - val_accuracy: 0.5810\n",
      "Epoch 3758/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1019 - val_accuracy: 0.5833\n",
      "Epoch 3759/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1027 - val_accuracy: 0.5834\n",
      "Epoch 3760/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0980 - accuracy: 0.6000 - val_loss: 0.1026 - val_accuracy: 0.5802\n",
      "Epoch 3761/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1021 - val_accuracy: 0.5825\n",
      "Epoch 3762/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1027 - val_accuracy: 0.5789\n",
      "Epoch 3763/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0980 - accuracy: 0.6000 - val_loss: 0.1025 - val_accuracy: 0.5801\n",
      "Epoch 3764/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1027 - val_accuracy: 0.5805\n",
      "Epoch 3765/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0979 - accuracy: 0.5993 - val_loss: 0.1024 - val_accuracy: 0.5816\n",
      "Epoch 3766/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1032 - val_accuracy: 0.5766\n",
      "Epoch 3767/5000\n",
      "11864/11864 [==============================] - 7s 600us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1020 - val_accuracy: 0.5836\n",
      "Epoch 3768/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0979 - accuracy: 0.5993 - val_loss: 0.1024 - val_accuracy: 0.5785\n",
      "Epoch 3769/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1025 - val_accuracy: 0.5805\n",
      "Epoch 3770/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1031 - val_accuracy: 0.5795\n",
      "Epoch 3771/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1024 - val_accuracy: 0.5808\n",
      "Epoch 3772/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1028 - val_accuracy: 0.5761\n",
      "Epoch 3773/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1023 - val_accuracy: 0.5779\n",
      "Epoch 3774/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1025 - val_accuracy: 0.5827\n",
      "Epoch 3775/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0980 - accuracy: 0.5985 - val_loss: 0.1032 - val_accuracy: 0.5786\n",
      "Epoch 3776/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1035 - val_accuracy: 0.5733\n",
      "Epoch 3777/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1022 - val_accuracy: 0.5797\n",
      "Epoch 3778/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1023 - val_accuracy: 0.5825\n",
      "Epoch 3779/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1021 - val_accuracy: 0.5829\n",
      "Epoch 3780/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1025 - val_accuracy: 0.5801\n",
      "Epoch 3781/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1023 - val_accuracy: 0.5785\n",
      "Epoch 3782/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1028 - val_accuracy: 0.5800\n",
      "Epoch 3783/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0979 - accuracy: 0.5994 - val_loss: 0.1023 - val_accuracy: 0.5840\n",
      "Epoch 3784/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1024 - val_accuracy: 0.5807\n",
      "Epoch 3785/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0979 - accuracy: 0.5993 - val_loss: 0.1028 - val_accuracy: 0.5793\n",
      "Epoch 3786/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1022 - val_accuracy: 0.5809\n",
      "Epoch 3787/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0978 - accuracy: 0.5999 - val_loss: 0.1029 - val_accuracy: 0.5808\n",
      "Epoch 3788/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0978 - accuracy: 0.6002 - val_loss: 0.1022 - val_accuracy: 0.5810\n",
      "Epoch 3789/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1035 - val_accuracy: 0.5746\n",
      "Epoch 3790/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1023 - val_accuracy: 0.5839\n",
      "Epoch 3791/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1024 - val_accuracy: 0.5814\n",
      "Epoch 3792/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0978 - accuracy: 0.5999 - val_loss: 0.1020 - val_accuracy: 0.5821\n",
      "Epoch 3793/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1021 - val_accuracy: 0.5830\n",
      "Epoch 3794/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0980 - accuracy: 0.6000 - val_loss: 0.1026 - val_accuracy: 0.5754\n",
      "Epoch 3795/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0980 - accuracy: 0.6003 - val_loss: 0.1027 - val_accuracy: 0.5813\n",
      "Epoch 3796/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1031 - val_accuracy: 0.5751\n",
      "Epoch 3797/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1026 - val_accuracy: 0.5790\n",
      "Epoch 3798/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1033 - val_accuracy: 0.5743\n",
      "Epoch 3799/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1024 - val_accuracy: 0.5813\n",
      "Epoch 3800/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0979 - accuracy: 0.5994 - val_loss: 0.1025 - val_accuracy: 0.5813\n",
      "Epoch 3801/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1024 - val_accuracy: 0.5810\n",
      "Epoch 3802/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1028 - val_accuracy: 0.5795\n",
      "Epoch 3803/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0981 - accuracy: 0.5997 - val_loss: 0.1030 - val_accuracy: 0.5769\n",
      "Epoch 3804/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1027 - val_accuracy: 0.5794\n",
      "Epoch 3805/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0979 - accuracy: 0.6003 - val_loss: 0.1022 - val_accuracy: 0.5827\n",
      "Epoch 3806/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1027 - val_accuracy: 0.5797\n",
      "Epoch 3807/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0979 - accuracy: 0.5991 - val_loss: 0.1019 - val_accuracy: 0.5839\n",
      "Epoch 3808/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0979 - accuracy: 0.6003 - val_loss: 0.1021 - val_accuracy: 0.5811\n",
      "Epoch 3809/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0981 - accuracy: 0.5995 - val_loss: 0.1027 - val_accuracy: 0.5805\n",
      "Epoch 3810/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1021 - val_accuracy: 0.5848\n",
      "Epoch 3811/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1019 - val_accuracy: 0.5826\n",
      "Epoch 3812/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0980 - accuracy: 0.6001 - val_loss: 0.1026 - val_accuracy: 0.5787\n",
      "Epoch 3813/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1029 - val_accuracy: 0.5786\n",
      "Epoch 3814/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1030 - val_accuracy: 0.5759\n",
      "Epoch 3815/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1031 - val_accuracy: 0.5784\n",
      "Epoch 3816/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0979 - accuracy: 0.5994 - val_loss: 0.1029 - val_accuracy: 0.5781\n",
      "Epoch 3817/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0979 - accuracy: 0.5992 - val_loss: 0.1017 - val_accuracy: 0.5802\n",
      "Epoch 3818/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0979 - accuracy: 0.5993 - val_loss: 0.1041 - val_accuracy: 0.5514\n",
      "Epoch 3819/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1025 - val_accuracy: 0.5810\n",
      "Epoch 3820/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1027 - val_accuracy: 0.5805\n",
      "Epoch 3821/5000\n",
      "11864/11864 [==============================] - 7s 602us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1022 - val_accuracy: 0.5817\n",
      "Epoch 3822/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1029 - val_accuracy: 0.5802\n",
      "Epoch 3823/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1023 - val_accuracy: 0.5818\n",
      "Epoch 3824/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1020 - val_accuracy: 0.5806\n",
      "Epoch 3825/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0980 - accuracy: 0.6003 - val_loss: 0.1028 - val_accuracy: 0.5819\n",
      "Epoch 3826/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1027 - val_accuracy: 0.5816\n",
      "Epoch 3827/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0978 - accuracy: 0.6000 - val_loss: 0.1028 - val_accuracy: 0.5808\n",
      "Epoch 3828/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0979 - accuracy: 0.6005 - val_loss: 0.1021 - val_accuracy: 0.5825\n",
      "Epoch 3829/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1032 - val_accuracy: 0.5798\n",
      "Epoch 3830/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0979 - accuracy: 0.5988 - val_loss: 0.1029 - val_accuracy: 0.5787\n",
      "Epoch 3831/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1025 - val_accuracy: 0.5805\n",
      "Epoch 3832/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1021 - val_accuracy: 0.5800\n",
      "Epoch 3833/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0979 - accuracy: 0.6001 - val_loss: 0.1032 - val_accuracy: 0.5803\n",
      "Epoch 3834/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1034 - val_accuracy: 0.5630\n",
      "Epoch 3835/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1037 - val_accuracy: 0.5781\n",
      "Epoch 3836/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0979 - accuracy: 0.5994 - val_loss: 0.1030 - val_accuracy: 0.5772\n",
      "Epoch 3837/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1026 - val_accuracy: 0.5822\n",
      "Epoch 3838/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1022 - val_accuracy: 0.5831\n",
      "Epoch 3839/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1026 - val_accuracy: 0.5802\n",
      "Epoch 3840/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1029 - val_accuracy: 0.5763\n",
      "Epoch 3841/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1028 - val_accuracy: 0.5815\n",
      "Epoch 3842/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0979 - accuracy: 0.6002 - val_loss: 0.1030 - val_accuracy: 0.5789\n",
      "Epoch 3843/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1021 - val_accuracy: 0.5839\n",
      "Epoch 3844/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1022 - val_accuracy: 0.5818\n",
      "Epoch 3845/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1023 - val_accuracy: 0.5809\n",
      "Epoch 3846/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0979 - accuracy: 0.5993 - val_loss: 0.1024 - val_accuracy: 0.5830\n",
      "Epoch 3847/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1025 - val_accuracy: 0.5785\n",
      "Epoch 3848/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0979 - accuracy: 0.5993 - val_loss: 0.1030 - val_accuracy: 0.5788\n",
      "Epoch 3849/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1027 - val_accuracy: 0.5799\n",
      "Epoch 3850/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1020 - val_accuracy: 0.5810\n",
      "Epoch 3851/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1030 - val_accuracy: 0.5828\n",
      "Epoch 3852/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1022 - val_accuracy: 0.5800\n",
      "Epoch 3853/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0978 - accuracy: 0.5990 - val_loss: 0.1026 - val_accuracy: 0.5806\n",
      "Epoch 3854/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0979 - accuracy: 0.6002 - val_loss: 0.1022 - val_accuracy: 0.5812\n",
      "Epoch 3855/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1024 - val_accuracy: 0.5843\n",
      "Epoch 3856/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1028 - val_accuracy: 0.5793\n",
      "Epoch 3857/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1023 - val_accuracy: 0.5807\n",
      "Epoch 3858/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0979 - accuracy: 0.5993 - val_loss: 0.1025 - val_accuracy: 0.5807\n",
      "Epoch 3859/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1020 - val_accuracy: 0.5840\n",
      "Epoch 3860/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1025 - val_accuracy: 0.5817\n",
      "Epoch 3861/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1030 - val_accuracy: 0.5717\n",
      "Epoch 3862/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0979 - accuracy: 0.5991 - val_loss: 0.1023 - val_accuracy: 0.5800\n",
      "Epoch 3863/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1040 - val_accuracy: 0.5744\n",
      "Epoch 3864/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1029 - val_accuracy: 0.5825\n",
      "Epoch 3865/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0981 - accuracy: 0.5994 - val_loss: 0.1021 - val_accuracy: 0.5818\n",
      "Epoch 3866/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1031 - val_accuracy: 0.5776\n",
      "Epoch 3867/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0979 - accuracy: 0.6004 - val_loss: 0.1028 - val_accuracy: 0.5802\n",
      "Epoch 3868/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1020 - val_accuracy: 0.5807\n",
      "Epoch 3869/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1027 - val_accuracy: 0.5832\n",
      "Epoch 3870/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0979 - accuracy: 0.5991 - val_loss: 0.1023 - val_accuracy: 0.5830\n",
      "Epoch 3871/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1026 - val_accuracy: 0.5797\n",
      "Epoch 3872/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1035 - val_accuracy: 0.5753\n",
      "Epoch 3873/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0980 - accuracy: 0.5985 - val_loss: 0.1024 - val_accuracy: 0.5793\n",
      "Epoch 3874/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1029 - val_accuracy: 0.5753\n",
      "Epoch 3875/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0980 - accuracy: 0.5984 - val_loss: 0.1033 - val_accuracy: 0.5782\n",
      "Epoch 3876/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1022 - val_accuracy: 0.5824\n",
      "Epoch 3877/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0979 - accuracy: 0.5988 - val_loss: 0.1031 - val_accuracy: 0.5780\n",
      "Epoch 3878/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1027 - val_accuracy: 0.5783\n",
      "Epoch 3879/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0980 - accuracy: 0.5987 - val_loss: 0.1031 - val_accuracy: 0.5784\n",
      "Epoch 3880/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1030 - val_accuracy: 0.5800\n",
      "Epoch 3881/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1019 - val_accuracy: 0.5824\n",
      "Epoch 3882/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0979 - accuracy: 0.6001 - val_loss: 0.1028 - val_accuracy: 0.5826\n",
      "Epoch 3883/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1031 - val_accuracy: 0.5802\n",
      "Epoch 3884/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0980 - accuracy: 0.5987 - val_loss: 0.1021 - val_accuracy: 0.5796\n",
      "Epoch 3885/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1026 - val_accuracy: 0.5792\n",
      "Epoch 3886/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1027 - val_accuracy: 0.5815\n",
      "Epoch 3887/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1020 - val_accuracy: 0.5834\n",
      "Epoch 3888/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1017 - val_accuracy: 0.5813\n",
      "Epoch 3889/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1028 - val_accuracy: 0.5778\n",
      "Epoch 3890/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0979 - accuracy: 0.5993 - val_loss: 0.1021 - val_accuracy: 0.5808\n",
      "Epoch 3891/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0979 - accuracy: 0.5993 - val_loss: 0.1027 - val_accuracy: 0.5783\n",
      "Epoch 3892/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0980 - accuracy: 0.5985 - val_loss: 0.1025 - val_accuracy: 0.5803\n",
      "Epoch 3893/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1019 - val_accuracy: 0.5829\n",
      "Epoch 3894/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1025 - val_accuracy: 0.5812\n",
      "Epoch 3895/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1024 - val_accuracy: 0.5801\n",
      "Epoch 3896/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1024 - val_accuracy: 0.5813\n",
      "Epoch 3897/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1023 - val_accuracy: 0.5805\n",
      "Epoch 3898/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1021 - val_accuracy: 0.5808\n",
      "Epoch 3899/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1025 - val_accuracy: 0.5817\n",
      "Epoch 3900/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1030 - val_accuracy: 0.5822\n",
      "Epoch 3901/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1027 - val_accuracy: 0.5808\n",
      "Epoch 3902/5000\n",
      "11864/11864 [==============================] - 7s 604us/step - loss: 0.0979 - accuracy: 0.5992 - val_loss: 0.1024 - val_accuracy: 0.5796\n",
      "Epoch 3903/5000\n",
      "11864/11864 [==============================] - 7s 607us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1032 - val_accuracy: 0.5755\n",
      "Epoch 3904/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1027 - val_accuracy: 0.5800\n",
      "Epoch 3905/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1030 - val_accuracy: 0.5804\n",
      "Epoch 3906/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1028 - val_accuracy: 0.5792\n",
      "Epoch 3907/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1026 - val_accuracy: 0.5799\n",
      "Epoch 3908/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1026 - val_accuracy: 0.5769\n",
      "Epoch 3909/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0979 - accuracy: 0.5994 - val_loss: 0.1030 - val_accuracy: 0.5802\n",
      "Epoch 3910/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1030 - val_accuracy: 0.5803\n",
      "Epoch 3911/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0979 - accuracy: 0.5993 - val_loss: 0.1025 - val_accuracy: 0.5806\n",
      "Epoch 3912/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1022 - val_accuracy: 0.5814\n",
      "Epoch 3913/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1025 - val_accuracy: 0.5812\n",
      "Epoch 3914/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0980 - accuracy: 0.5999 - val_loss: 0.1025 - val_accuracy: 0.5800\n",
      "Epoch 3915/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0979 - accuracy: 0.6003 - val_loss: 0.1022 - val_accuracy: 0.5796\n",
      "Epoch 3916/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0979 - accuracy: 0.5994 - val_loss: 0.1036 - val_accuracy: 0.5772\n",
      "Epoch 3917/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0979 - accuracy: 0.5992 - val_loss: 0.1021 - val_accuracy: 0.5816\n",
      "Epoch 3918/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1023 - val_accuracy: 0.5812\n",
      "Epoch 3919/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0980 - accuracy: 0.6000 - val_loss: 0.1027 - val_accuracy: 0.5792\n",
      "Epoch 3920/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0979 - accuracy: 0.5990 - val_loss: 0.1025 - val_accuracy: 0.5800\n",
      "Epoch 3921/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0981 - accuracy: 0.5997 - val_loss: 0.1033 - val_accuracy: 0.5777\n",
      "Epoch 3922/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1030 - val_accuracy: 0.5747\n",
      "Epoch 3923/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1031 - val_accuracy: 0.5725\n",
      "Epoch 3924/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1027 - val_accuracy: 0.5729\n",
      "Epoch 3925/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1020 - val_accuracy: 0.5822\n",
      "Epoch 3926/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1032 - val_accuracy: 0.5792\n",
      "Epoch 3927/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1023 - val_accuracy: 0.5783\n",
      "Epoch 3928/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0978 - accuracy: 0.5996 - val_loss: 0.1024 - val_accuracy: 0.5808\n",
      "Epoch 3929/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0979 - accuracy: 0.6001 - val_loss: 0.1023 - val_accuracy: 0.5838\n",
      "Epoch 3930/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1025 - val_accuracy: 0.5792\n",
      "Epoch 3931/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0980 - accuracy: 0.6002 - val_loss: 0.1023 - val_accuracy: 0.5808\n",
      "Epoch 3932/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1024 - val_accuracy: 0.5809\n",
      "Epoch 3933/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1021 - val_accuracy: 0.5791\n",
      "Epoch 3934/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1037 - val_accuracy: 0.5790\n",
      "Epoch 3935/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1029 - val_accuracy: 0.5799\n",
      "Epoch 3936/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1024 - val_accuracy: 0.5802\n",
      "Epoch 3937/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1026 - val_accuracy: 0.5790\n",
      "Epoch 3938/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1025 - val_accuracy: 0.5810\n",
      "Epoch 3939/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1027 - val_accuracy: 0.5776\n",
      "Epoch 3940/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1022 - val_accuracy: 0.5810\n",
      "Epoch 3941/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0980 - accuracy: 0.5985 - val_loss: 0.1028 - val_accuracy: 0.5786\n",
      "Epoch 3942/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1030 - val_accuracy: 0.5771\n",
      "Epoch 3943/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1030 - val_accuracy: 0.5797\n",
      "Epoch 3944/5000\n",
      "11864/11864 [==============================] - 7s 629us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1024 - val_accuracy: 0.5825\n",
      "Epoch 3945/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1030 - val_accuracy: 0.5789\n",
      "Epoch 3946/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1028 - val_accuracy: 0.5782\n",
      "Epoch 3947/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0980 - accuracy: 0.6001 - val_loss: 0.1030 - val_accuracy: 0.5778\n",
      "Epoch 3948/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1028 - val_accuracy: 0.5816\n",
      "Epoch 3949/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0979 - accuracy: 0.6001 - val_loss: 0.1026 - val_accuracy: 0.5807\n",
      "Epoch 3950/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1023 - val_accuracy: 0.5805\n",
      "Epoch 3951/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1027 - val_accuracy: 0.5788\n",
      "Epoch 3952/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1029 - val_accuracy: 0.5773\n",
      "Epoch 3953/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0980 - accuracy: 0.6000 - val_loss: 0.1025 - val_accuracy: 0.5799\n",
      "Epoch 3954/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0980 - accuracy: 0.6003 - val_loss: 0.1033 - val_accuracy: 0.5818\n",
      "Epoch 3955/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0980 - accuracy: 0.6004 - val_loss: 0.1027 - val_accuracy: 0.5803\n",
      "Epoch 3956/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1024 - val_accuracy: 0.5803\n",
      "Epoch 3957/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1036 - val_accuracy: 0.5802\n",
      "Epoch 3958/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1024 - val_accuracy: 0.5808\n",
      "Epoch 3959/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0979 - accuracy: 0.6006 - val_loss: 0.1028 - val_accuracy: 0.5784\n",
      "Epoch 3960/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1024 - val_accuracy: 0.5773\n",
      "Epoch 3961/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1025 - val_accuracy: 0.5797\n",
      "Epoch 3962/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1019 - val_accuracy: 0.5817\n",
      "Epoch 3963/5000\n",
      "11864/11864 [==============================] - 7s 629us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1032 - val_accuracy: 0.5804\n",
      "Epoch 3964/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1042 - val_accuracy: 0.5760\n",
      "Epoch 3965/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0980 - accuracy: 0.6000 - val_loss: 0.1024 - val_accuracy: 0.5795\n",
      "Epoch 3966/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0979 - accuracy: 0.6004 - val_loss: 0.1026 - val_accuracy: 0.5799\n",
      "Epoch 3967/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0979 - accuracy: 0.6005 - val_loss: 0.1028 - val_accuracy: 0.5827\n",
      "Epoch 3968/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1025 - val_accuracy: 0.5815\n",
      "Epoch 3969/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1033 - val_accuracy: 0.5814\n",
      "Epoch 3970/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0981 - accuracy: 0.5997 - val_loss: 0.1031 - val_accuracy: 0.5780\n",
      "Epoch 3971/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1028 - val_accuracy: 0.5816\n",
      "Epoch 3972/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0981 - accuracy: 0.5994 - val_loss: 0.1033 - val_accuracy: 0.5751\n",
      "Epoch 3973/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1027 - val_accuracy: 0.5796\n",
      "Epoch 3974/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1024 - val_accuracy: 0.5805\n",
      "Epoch 3975/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1024 - val_accuracy: 0.5766\n",
      "Epoch 3976/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0978 - accuracy: 0.6001 - val_loss: 0.1027 - val_accuracy: 0.5797\n",
      "Epoch 3977/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0979 - accuracy: 0.6004 - val_loss: 0.1022 - val_accuracy: 0.5801\n",
      "Epoch 3978/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1019 - val_accuracy: 0.5825\n",
      "Epoch 3979/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1029 - val_accuracy: 0.5803\n",
      "Epoch 3980/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0979 - accuracy: 0.6003 - val_loss: 0.1034 - val_accuracy: 0.5751\n",
      "Epoch 3981/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1024 - val_accuracy: 0.5805\n",
      "Epoch 3982/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0979 - accuracy: 0.6005 - val_loss: 0.1020 - val_accuracy: 0.5795\n",
      "Epoch 3983/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1027 - val_accuracy: 0.5752\n",
      "Epoch 3984/5000\n",
      "11864/11864 [==============================] - 7s 611us/step - loss: 0.0979 - accuracy: 0.5994 - val_loss: 0.1026 - val_accuracy: 0.5766\n",
      "Epoch 3985/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0979 - accuracy: 0.5993 - val_loss: 0.1018 - val_accuracy: 0.5813\n",
      "Epoch 3986/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0981 - accuracy: 0.5994 - val_loss: 0.1031 - val_accuracy: 0.5776\n",
      "Epoch 3987/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1040 - val_accuracy: 0.5737\n",
      "Epoch 3988/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0979 - accuracy: 0.5993 - val_loss: 0.1023 - val_accuracy: 0.5804\n",
      "Epoch 3989/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1023 - val_accuracy: 0.5819\n",
      "Epoch 3990/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1027 - val_accuracy: 0.5795\n",
      "Epoch 3991/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0979 - accuracy: 0.5993 - val_loss: 0.1025 - val_accuracy: 0.5813\n",
      "Epoch 3992/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1020 - val_accuracy: 0.5821\n",
      "Epoch 3993/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1025 - val_accuracy: 0.5811\n",
      "Epoch 3994/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1026 - val_accuracy: 0.5798\n",
      "Epoch 3995/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0981 - accuracy: 0.5995 - val_loss: 0.1025 - val_accuracy: 0.5808\n",
      "Epoch 3996/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0981 - accuracy: 0.5994 - val_loss: 0.1027 - val_accuracy: 0.5818\n",
      "Epoch 3997/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1027 - val_accuracy: 0.5804\n",
      "Epoch 3998/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1026 - val_accuracy: 0.5814\n",
      "Epoch 3999/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1024 - val_accuracy: 0.5807\n",
      "Epoch 4000/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0981 - accuracy: 0.5995 - val_loss: 0.1027 - val_accuracy: 0.5796\n",
      "Epoch 4001/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1026 - val_accuracy: 0.5807\n",
      "Epoch 4002/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1029 - val_accuracy: 0.5788\n",
      "Epoch 4003/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1020 - val_accuracy: 0.5822\n",
      "Epoch 4004/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1027 - val_accuracy: 0.5796\n",
      "Epoch 4005/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1024 - val_accuracy: 0.5825\n",
      "Epoch 4006/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0979 - accuracy: 0.6004 - val_loss: 0.1024 - val_accuracy: 0.5794\n",
      "Epoch 4007/5000\n",
      "11864/11864 [==============================] - 7s 631us/step - loss: 0.0979 - accuracy: 0.6001 - val_loss: 0.1024 - val_accuracy: 0.5811\n",
      "Epoch 4008/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0980 - accuracy: 0.6001 - val_loss: 0.1027 - val_accuracy: 0.5814\n",
      "Epoch 4009/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1028 - val_accuracy: 0.5806\n",
      "Epoch 4010/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0980 - accuracy: 0.6003 - val_loss: 0.1035 - val_accuracy: 0.5759\n",
      "Epoch 4011/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0979 - accuracy: 0.6002 - val_loss: 0.1025 - val_accuracy: 0.5819\n",
      "Epoch 4012/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0980 - accuracy: 0.6001 - val_loss: 0.1018 - val_accuracy: 0.5828\n",
      "Epoch 4013/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0979 - accuracy: 0.6002 - val_loss: 0.1033 - val_accuracy: 0.5798\n",
      "Epoch 4014/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0980 - accuracy: 0.6001 - val_loss: 0.1028 - val_accuracy: 0.5825\n",
      "Epoch 4015/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1022 - val_accuracy: 0.5808\n",
      "Epoch 4016/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1021 - val_accuracy: 0.5800\n",
      "Epoch 4017/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1019 - val_accuracy: 0.5829\n",
      "Epoch 4018/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0979 - accuracy: 0.6004 - val_loss: 0.1027 - val_accuracy: 0.5801\n",
      "Epoch 4019/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0979 - accuracy: 0.5994 - val_loss: 0.1025 - val_accuracy: 0.5805\n",
      "Epoch 4020/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1028 - val_accuracy: 0.5784\n",
      "Epoch 4021/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1030 - val_accuracy: 0.5807\n",
      "Epoch 4022/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1032 - val_accuracy: 0.5785\n",
      "Epoch 4023/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1031 - val_accuracy: 0.5788\n",
      "Epoch 4024/5000\n",
      "11864/11864 [==============================] - 7s 629us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1023 - val_accuracy: 0.5815\n",
      "Epoch 4025/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1030 - val_accuracy: 0.5742\n",
      "Epoch 4026/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1023 - val_accuracy: 0.5807\n",
      "Epoch 4027/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0979 - accuracy: 0.6005 - val_loss: 0.1021 - val_accuracy: 0.5827\n",
      "Epoch 4028/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1021 - val_accuracy: 0.5843\n",
      "Epoch 4029/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0979 - accuracy: 0.6003 - val_loss: 0.1024 - val_accuracy: 0.5824\n",
      "Epoch 4030/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1025 - val_accuracy: 0.5806\n",
      "Epoch 4031/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1026 - val_accuracy: 0.5782\n",
      "Epoch 4032/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0980 - accuracy: 0.6000 - val_loss: 0.1022 - val_accuracy: 0.5863\n",
      "Epoch 4033/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0979 - accuracy: 0.6002 - val_loss: 0.1028 - val_accuracy: 0.5768\n",
      "Epoch 4034/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1025 - val_accuracy: 0.5789\n",
      "Epoch 4035/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1025 - val_accuracy: 0.5773\n",
      "Epoch 4036/5000\n",
      "11864/11864 [==============================] - 7s 629us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1024 - val_accuracy: 0.5802\n",
      "Epoch 4037/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0981 - accuracy: 0.5996 - val_loss: 0.1027 - val_accuracy: 0.5773\n",
      "Epoch 4038/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0979 - accuracy: 0.6005 - val_loss: 0.1024 - val_accuracy: 0.5802\n",
      "Epoch 4039/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1028 - val_accuracy: 0.5803\n",
      "Epoch 4040/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1024 - val_accuracy: 0.5790\n",
      "Epoch 4041/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1023 - val_accuracy: 0.5807\n",
      "Epoch 4042/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0979 - accuracy: 0.6002 - val_loss: 0.1023 - val_accuracy: 0.5801\n",
      "Epoch 4043/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0980 - accuracy: 0.6001 - val_loss: 0.1025 - val_accuracy: 0.5810\n",
      "Epoch 4044/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1020 - val_accuracy: 0.5820\n",
      "Epoch 4045/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1027 - val_accuracy: 0.5805\n",
      "Epoch 4046/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1030 - val_accuracy: 0.5765\n",
      "Epoch 4047/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1025 - val_accuracy: 0.5815\n",
      "Epoch 4048/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1023 - val_accuracy: 0.5801\n",
      "Epoch 4049/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0979 - accuracy: 0.6002 - val_loss: 0.1022 - val_accuracy: 0.5795\n",
      "Epoch 4050/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1025 - val_accuracy: 0.5774\n",
      "Epoch 4051/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0980 - accuracy: 0.6001 - val_loss: 0.1026 - val_accuracy: 0.5814\n",
      "Epoch 4052/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1024 - val_accuracy: 0.5831\n",
      "Epoch 4053/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0979 - accuracy: 0.5994 - val_loss: 0.1018 - val_accuracy: 0.5836\n",
      "Epoch 4054/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0980 - accuracy: 0.6000 - val_loss: 0.1028 - val_accuracy: 0.5776\n",
      "Epoch 4055/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0979 - accuracy: 0.6009 - val_loss: 0.1030 - val_accuracy: 0.5789\n",
      "Epoch 4056/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0979 - accuracy: 0.6001 - val_loss: 0.1023 - val_accuracy: 0.5813\n",
      "Epoch 4057/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1035 - val_accuracy: 0.5774\n",
      "Epoch 4058/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1022 - val_accuracy: 0.5802\n",
      "Epoch 4059/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1035 - val_accuracy: 0.5772\n",
      "Epoch 4060/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1025 - val_accuracy: 0.5794\n",
      "Epoch 4061/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0978 - accuracy: 0.6007 - val_loss: 0.1025 - val_accuracy: 0.5848\n",
      "Epoch 4062/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1026 - val_accuracy: 0.5826\n",
      "Epoch 4063/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0980 - accuracy: 0.6000 - val_loss: 0.1022 - val_accuracy: 0.5838\n",
      "Epoch 4064/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1020 - val_accuracy: 0.5812\n",
      "Epoch 4065/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1021 - val_accuracy: 0.5829\n",
      "Epoch 4066/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1026 - val_accuracy: 0.5804\n",
      "Epoch 4067/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1032 - val_accuracy: 0.5819\n",
      "Epoch 4068/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1031 - val_accuracy: 0.5718\n",
      "Epoch 4069/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1031 - val_accuracy: 0.5763\n",
      "Epoch 4070/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1024 - val_accuracy: 0.5817\n",
      "Epoch 4071/5000\n",
      "11864/11864 [==============================] - 7s 631us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1028 - val_accuracy: 0.5793\n",
      "Epoch 4072/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0979 - accuracy: 0.6006 - val_loss: 0.1021 - val_accuracy: 0.5819\n",
      "Epoch 4073/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0979 - accuracy: 0.5993 - val_loss: 0.1031 - val_accuracy: 0.5745\n",
      "Epoch 4074/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1025 - val_accuracy: 0.5791\n",
      "Epoch 4075/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1024 - val_accuracy: 0.5821\n",
      "Epoch 4076/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1025 - val_accuracy: 0.5791\n",
      "Epoch 4077/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1026 - val_accuracy: 0.5825\n",
      "Epoch 4078/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0980 - accuracy: 0.5999 - val_loss: 0.1026 - val_accuracy: 0.5829\n",
      "Epoch 4079/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1029 - val_accuracy: 0.5621\n",
      "Epoch 4080/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1023 - val_accuracy: 0.5806\n",
      "Epoch 4081/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0980 - accuracy: 0.5999 - val_loss: 0.1026 - val_accuracy: 0.5784\n",
      "Epoch 4082/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0979 - accuracy: 0.6001 - val_loss: 0.1028 - val_accuracy: 0.5811\n",
      "Epoch 4083/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0979 - accuracy: 0.6004 - val_loss: 0.1031 - val_accuracy: 0.5739\n",
      "Epoch 4084/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0979 - accuracy: 0.6003 - val_loss: 0.1027 - val_accuracy: 0.5832\n",
      "Epoch 4085/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0979 - accuracy: 0.6002 - val_loss: 0.1024 - val_accuracy: 0.5822\n",
      "Epoch 4086/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1030 - val_accuracy: 0.5784\n",
      "Epoch 4087/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1024 - val_accuracy: 0.5831\n",
      "Epoch 4088/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0979 - accuracy: 0.6003 - val_loss: 0.1031 - val_accuracy: 0.5765\n",
      "Epoch 4089/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0980 - accuracy: 0.6002 - val_loss: 0.1027 - val_accuracy: 0.5826\n",
      "Epoch 4090/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0979 - accuracy: 0.6002 - val_loss: 0.1026 - val_accuracy: 0.5809\n",
      "Epoch 4091/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1029 - val_accuracy: 0.5796\n",
      "Epoch 4092/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0978 - accuracy: 0.5998 - val_loss: 0.1026 - val_accuracy: 0.5767\n",
      "Epoch 4093/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1030 - val_accuracy: 0.5775\n",
      "Epoch 4094/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0978 - accuracy: 0.6000 - val_loss: 0.1029 - val_accuracy: 0.5780\n",
      "Epoch 4095/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0979 - accuracy: 0.5993 - val_loss: 0.1029 - val_accuracy: 0.5761\n",
      "Epoch 4096/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1026 - val_accuracy: 0.5821\n",
      "Epoch 4097/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1023 - val_accuracy: 0.5829\n",
      "Epoch 4098/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1033 - val_accuracy: 0.5779\n",
      "Epoch 4099/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0979 - accuracy: 0.6003 - val_loss: 0.1024 - val_accuracy: 0.5821\n",
      "Epoch 4100/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1023 - val_accuracy: 0.5816\n",
      "Epoch 4101/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0979 - accuracy: 0.6006 - val_loss: 0.1028 - val_accuracy: 0.5794\n",
      "Epoch 4102/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0979 - accuracy: 0.6002 - val_loss: 0.1030 - val_accuracy: 0.5799\n",
      "Epoch 4103/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1025 - val_accuracy: 0.5829\n",
      "Epoch 4104/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0979 - accuracy: 0.6001 - val_loss: 0.1025 - val_accuracy: 0.5803\n",
      "Epoch 4105/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1029 - val_accuracy: 0.5768\n",
      "Epoch 4106/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1026 - val_accuracy: 0.5799\n",
      "Epoch 4107/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0979 - accuracy: 0.6009 - val_loss: 0.1027 - val_accuracy: 0.5807\n",
      "Epoch 4108/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1024 - val_accuracy: 0.5793\n",
      "Epoch 4109/5000\n",
      "11864/11864 [==============================] - 7s 608us/step - loss: 0.0979 - accuracy: 0.6004 - val_loss: 0.1026 - val_accuracy: 0.5809\n",
      "Epoch 4110/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0978 - accuracy: 0.6003 - val_loss: 0.1025 - val_accuracy: 0.5816\n",
      "Epoch 4111/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0978 - accuracy: 0.6000 - val_loss: 0.1032 - val_accuracy: 0.5692\n",
      "Epoch 4112/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1026 - val_accuracy: 0.5824\n",
      "Epoch 4113/5000\n",
      "11864/11864 [==============================] - 7s 629us/step - loss: 0.0979 - accuracy: 0.5992 - val_loss: 0.1037 - val_accuracy: 0.5774\n",
      "Epoch 4114/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0978 - accuracy: 0.5995 - val_loss: 0.1019 - val_accuracy: 0.5831\n",
      "Epoch 4115/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0979 - accuracy: 0.5994 - val_loss: 0.1021 - val_accuracy: 0.5839\n",
      "Epoch 4116/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0978 - accuracy: 0.6007 - val_loss: 0.1029 - val_accuracy: 0.5816\n",
      "Epoch 4117/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1025 - val_accuracy: 0.5819\n",
      "Epoch 4118/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0978 - accuracy: 0.5998 - val_loss: 0.1027 - val_accuracy: 0.5774\n",
      "Epoch 4119/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1026 - val_accuracy: 0.5785\n",
      "Epoch 4120/5000\n",
      "11864/11864 [==============================] - 7s 609us/step - loss: 0.0979 - accuracy: 0.5992 - val_loss: 0.1025 - val_accuracy: 0.5809\n",
      "Epoch 4121/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0978 - accuracy: 0.5997 - val_loss: 0.1024 - val_accuracy: 0.5807\n",
      "Epoch 4122/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0978 - accuracy: 0.6000 - val_loss: 0.1024 - val_accuracy: 0.5814\n",
      "Epoch 4123/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0979 - accuracy: 0.6001 - val_loss: 0.1020 - val_accuracy: 0.5835\n",
      "Epoch 4124/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0978 - accuracy: 0.6002 - val_loss: 0.1028 - val_accuracy: 0.5821\n",
      "Epoch 4125/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1028 - val_accuracy: 0.5808\n",
      "Epoch 4126/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0978 - accuracy: 0.6000 - val_loss: 0.1025 - val_accuracy: 0.5816\n",
      "Epoch 4127/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0979 - accuracy: 0.6001 - val_loss: 0.1025 - val_accuracy: 0.5802\n",
      "Epoch 4128/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1028 - val_accuracy: 0.5808\n",
      "Epoch 4129/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0978 - accuracy: 0.5997 - val_loss: 0.1021 - val_accuracy: 0.5825\n",
      "Epoch 4130/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0978 - accuracy: 0.6001 - val_loss: 0.1028 - val_accuracy: 0.5798\n",
      "Epoch 4131/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1029 - val_accuracy: 0.5773\n",
      "Epoch 4132/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0979 - accuracy: 0.5992 - val_loss: 0.1029 - val_accuracy: 0.5793\n",
      "Epoch 4133/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0978 - accuracy: 0.6005 - val_loss: 0.1027 - val_accuracy: 0.5812\n",
      "Epoch 4134/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1024 - val_accuracy: 0.5827\n",
      "Epoch 4135/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1026 - val_accuracy: 0.5797\n",
      "Epoch 4136/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0979 - accuracy: 0.6001 - val_loss: 0.1023 - val_accuracy: 0.5801\n",
      "Epoch 4137/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0979 - accuracy: 0.6002 - val_loss: 0.1033 - val_accuracy: 0.5792\n",
      "Epoch 4138/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1020 - val_accuracy: 0.5814\n",
      "Epoch 4139/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0978 - accuracy: 0.6001 - val_loss: 0.1025 - val_accuracy: 0.5811\n",
      "Epoch 4140/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0979 - accuracy: 0.6001 - val_loss: 0.1025 - val_accuracy: 0.5777\n",
      "Epoch 4141/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1026 - val_accuracy: 0.5809\n",
      "Epoch 4142/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1026 - val_accuracy: 0.5813\n",
      "Epoch 4143/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1027 - val_accuracy: 0.5809\n",
      "Epoch 4144/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0979 - accuracy: 0.6005 - val_loss: 0.1026 - val_accuracy: 0.5779\n",
      "Epoch 4145/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1034 - val_accuracy: 0.5752\n",
      "Epoch 4146/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1026 - val_accuracy: 0.5817\n",
      "Epoch 4147/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0978 - accuracy: 0.5996 - val_loss: 0.1030 - val_accuracy: 0.5790\n",
      "Epoch 4148/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1025 - val_accuracy: 0.5800\n",
      "Epoch 4149/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0979 - accuracy: 0.6004 - val_loss: 0.1028 - val_accuracy: 0.5803\n",
      "Epoch 4150/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0978 - accuracy: 0.5995 - val_loss: 0.1023 - val_accuracy: 0.5818\n",
      "Epoch 4151/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1028 - val_accuracy: 0.5798\n",
      "Epoch 4152/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1022 - val_accuracy: 0.5816\n",
      "Epoch 4153/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0979 - accuracy: 0.5994 - val_loss: 0.1025 - val_accuracy: 0.5808\n",
      "Epoch 4154/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1032 - val_accuracy: 0.5779\n",
      "Epoch 4155/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0980 - accuracy: 0.6001 - val_loss: 0.1024 - val_accuracy: 0.5809\n",
      "Epoch 4156/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0979 - accuracy: 0.6001 - val_loss: 0.1026 - val_accuracy: 0.5822\n",
      "Epoch 4157/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1026 - val_accuracy: 0.5797\n",
      "Epoch 4158/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0979 - accuracy: 0.5992 - val_loss: 0.1026 - val_accuracy: 0.5798\n",
      "Epoch 4159/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0979 - accuracy: 0.6003 - val_loss: 0.1028 - val_accuracy: 0.5804\n",
      "Epoch 4160/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0978 - accuracy: 0.5998 - val_loss: 0.1027 - val_accuracy: 0.5805\n",
      "Epoch 4161/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0978 - accuracy: 0.6005 - val_loss: 0.1028 - val_accuracy: 0.5831\n",
      "Epoch 4162/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0979 - accuracy: 0.5989 - val_loss: 0.1027 - val_accuracy: 0.5780\n",
      "Epoch 4163/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0979 - accuracy: 0.6001 - val_loss: 0.1025 - val_accuracy: 0.5798\n",
      "Epoch 4164/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1029 - val_accuracy: 0.5802\n",
      "Epoch 4165/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0979 - accuracy: 0.5994 - val_loss: 0.1026 - val_accuracy: 0.5814\n",
      "Epoch 4166/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1029 - val_accuracy: 0.5799\n",
      "Epoch 4167/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1030 - val_accuracy: 0.5804\n",
      "Epoch 4168/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0978 - accuracy: 0.5997 - val_loss: 0.1026 - val_accuracy: 0.5812\n",
      "Epoch 4169/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0978 - accuracy: 0.5998 - val_loss: 0.1021 - val_accuracy: 0.5798\n",
      "Epoch 4170/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0978 - accuracy: 0.6000 - val_loss: 0.1030 - val_accuracy: 0.5768\n",
      "Epoch 4171/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0979 - accuracy: 0.5994 - val_loss: 0.1031 - val_accuracy: 0.5790\n",
      "Epoch 4172/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0978 - accuracy: 0.5996 - val_loss: 0.1029 - val_accuracy: 0.5772\n",
      "Epoch 4173/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0978 - accuracy: 0.5996 - val_loss: 0.1033 - val_accuracy: 0.5806\n",
      "Epoch 4174/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0979 - accuracy: 0.6001 - val_loss: 0.1029 - val_accuracy: 0.5785\n",
      "Epoch 4175/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0979 - accuracy: 0.5994 - val_loss: 0.1032 - val_accuracy: 0.5809\n",
      "Epoch 4176/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0978 - accuracy: 0.6011 - val_loss: 0.1021 - val_accuracy: 0.5811\n",
      "Epoch 4177/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0978 - accuracy: 0.6005 - val_loss: 0.1025 - val_accuracy: 0.5779\n",
      "Epoch 4178/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0978 - accuracy: 0.5999 - val_loss: 0.1026 - val_accuracy: 0.5785\n",
      "Epoch 4179/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0978 - accuracy: 0.5996 - val_loss: 0.1027 - val_accuracy: 0.5759\n",
      "Epoch 4180/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1026 - val_accuracy: 0.5790\n",
      "Epoch 4181/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1022 - val_accuracy: 0.5801\n",
      "Epoch 4182/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1025 - val_accuracy: 0.5787\n",
      "Epoch 4183/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0979 - accuracy: 0.6005 - val_loss: 0.1028 - val_accuracy: 0.5797\n",
      "Epoch 4184/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0979 - accuracy: 0.5992 - val_loss: 0.1024 - val_accuracy: 0.5825\n",
      "Epoch 4185/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0978 - accuracy: 0.6001 - val_loss: 0.1029 - val_accuracy: 0.5776\n",
      "Epoch 4186/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1019 - val_accuracy: 0.5816\n",
      "Epoch 4187/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0978 - accuracy: 0.6004 - val_loss: 0.1029 - val_accuracy: 0.5782\n",
      "Epoch 4188/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0979 - accuracy: 0.5992 - val_loss: 0.1022 - val_accuracy: 0.5806\n",
      "Epoch 4189/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0978 - accuracy: 0.5995 - val_loss: 0.1024 - val_accuracy: 0.5808\n",
      "Epoch 4190/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0979 - accuracy: 0.5991 - val_loss: 0.1031 - val_accuracy: 0.5806\n",
      "Epoch 4191/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0978 - accuracy: 0.6002 - val_loss: 0.1021 - val_accuracy: 0.5818\n",
      "Epoch 4192/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1026 - val_accuracy: 0.5813\n",
      "Epoch 4193/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1019 - val_accuracy: 0.5837\n",
      "Epoch 4194/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0978 - accuracy: 0.5999 - val_loss: 0.1025 - val_accuracy: 0.5828\n",
      "Epoch 4195/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0978 - accuracy: 0.6002 - val_loss: 0.1024 - val_accuracy: 0.5801\n",
      "Epoch 4196/5000\n",
      "11864/11864 [==============================] - 8s 632us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1021 - val_accuracy: 0.5817\n",
      "Epoch 4197/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0978 - accuracy: 0.6004 - val_loss: 0.1020 - val_accuracy: 0.5801\n",
      "Epoch 4198/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1024 - val_accuracy: 0.5803\n",
      "Epoch 4199/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0978 - accuracy: 0.6008 - val_loss: 0.1024 - val_accuracy: 0.5787\n",
      "Epoch 4200/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0979 - accuracy: 0.6002 - val_loss: 0.1026 - val_accuracy: 0.5809\n",
      "Epoch 4201/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0978 - accuracy: 0.6001 - val_loss: 0.1028 - val_accuracy: 0.5793\n",
      "Epoch 4202/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0978 - accuracy: 0.6010 - val_loss: 0.1025 - val_accuracy: 0.5780\n",
      "Epoch 4203/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0980 - accuracy: 0.5999 - val_loss: 0.1028 - val_accuracy: 0.5785\n",
      "Epoch 4204/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0978 - accuracy: 0.6000 - val_loss: 0.1017 - val_accuracy: 0.5844\n",
      "Epoch 4205/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0978 - accuracy: 0.6005 - val_loss: 0.1025 - val_accuracy: 0.5782\n",
      "Epoch 4206/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1022 - val_accuracy: 0.5816\n",
      "Epoch 4207/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0978 - accuracy: 0.6005 - val_loss: 0.1029 - val_accuracy: 0.5785\n",
      "Epoch 4208/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0978 - accuracy: 0.5999 - val_loss: 0.1024 - val_accuracy: 0.5785\n",
      "Epoch 4209/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1027 - val_accuracy: 0.5775\n",
      "Epoch 4210/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0978 - accuracy: 0.6001 - val_loss: 0.1026 - val_accuracy: 0.5797\n",
      "Epoch 4211/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0978 - accuracy: 0.6000 - val_loss: 0.1024 - val_accuracy: 0.5786\n",
      "Epoch 4212/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0978 - accuracy: 0.6002 - val_loss: 0.1024 - val_accuracy: 0.5829\n",
      "Epoch 4213/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1029 - val_accuracy: 0.5801\n",
      "Epoch 4214/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0978 - accuracy: 0.5996 - val_loss: 0.1026 - val_accuracy: 0.5794\n",
      "Epoch 4215/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0978 - accuracy: 0.6002 - val_loss: 0.1030 - val_accuracy: 0.5778\n",
      "Epoch 4216/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1025 - val_accuracy: 0.5850\n",
      "Epoch 4217/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0979 - accuracy: 0.6001 - val_loss: 0.1027 - val_accuracy: 0.5806\n",
      "Epoch 4218/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1018 - val_accuracy: 0.5814\n",
      "Epoch 4219/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0978 - accuracy: 0.6010 - val_loss: 0.1024 - val_accuracy: 0.5811\n",
      "Epoch 4220/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1025 - val_accuracy: 0.5797\n",
      "Epoch 4221/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1026 - val_accuracy: 0.5802\n",
      "Epoch 4222/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0979 - accuracy: 0.5992 - val_loss: 0.1023 - val_accuracy: 0.5792\n",
      "Epoch 4223/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1030 - val_accuracy: 0.5754\n",
      "Epoch 4224/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1024 - val_accuracy: 0.5794\n",
      "Epoch 4225/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0980 - accuracy: 0.6002 - val_loss: 0.1028 - val_accuracy: 0.5775\n",
      "Epoch 4226/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1024 - val_accuracy: 0.5769\n",
      "Epoch 4227/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0977 - accuracy: 0.6003 - val_loss: 0.1029 - val_accuracy: 0.5804\n",
      "Epoch 4228/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0978 - accuracy: 0.6001 - val_loss: 0.1028 - val_accuracy: 0.5817\n",
      "Epoch 4229/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0980 - accuracy: 0.6001 - val_loss: 0.1027 - val_accuracy: 0.5804\n",
      "Epoch 4230/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1038 - val_accuracy: 0.5791\n",
      "Epoch 4231/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0979 - accuracy: 0.6001 - val_loss: 0.1021 - val_accuracy: 0.5809\n",
      "Epoch 4232/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0979 - accuracy: 0.6002 - val_loss: 0.1028 - val_accuracy: 0.5801\n",
      "Epoch 4233/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1031 - val_accuracy: 0.5797\n",
      "Epoch 4234/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1025 - val_accuracy: 0.5774\n",
      "Epoch 4235/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0978 - accuracy: 0.6002 - val_loss: 0.1029 - val_accuracy: 0.5798\n",
      "Epoch 4236/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1034 - val_accuracy: 0.5793\n",
      "Epoch 4237/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1022 - val_accuracy: 0.5815\n",
      "Epoch 4238/5000\n",
      "11864/11864 [==============================] - 7s 632us/step - loss: 0.0979 - accuracy: 0.5993 - val_loss: 0.1031 - val_accuracy: 0.5794\n",
      "Epoch 4239/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0978 - accuracy: 0.5997 - val_loss: 0.1021 - val_accuracy: 0.5811\n",
      "Epoch 4240/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0979 - accuracy: 0.5991 - val_loss: 0.1023 - val_accuracy: 0.5819\n",
      "Epoch 4241/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0979 - accuracy: 0.5991 - val_loss: 0.1023 - val_accuracy: 0.5816\n",
      "Epoch 4242/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0978 - accuracy: 0.5997 - val_loss: 0.1031 - val_accuracy: 0.5795\n",
      "Epoch 4243/5000\n",
      "11864/11864 [==============================] - 7s 629us/step - loss: 0.0978 - accuracy: 0.5999 - val_loss: 0.1029 - val_accuracy: 0.5790\n",
      "Epoch 4244/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0979 - accuracy: 0.5994 - val_loss: 0.1023 - val_accuracy: 0.5817\n",
      "Epoch 4245/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1025 - val_accuracy: 0.5808\n",
      "Epoch 4246/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0977 - accuracy: 0.6009 - val_loss: 0.1027 - val_accuracy: 0.5770\n",
      "Epoch 4247/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1027 - val_accuracy: 0.5808\n",
      "Epoch 4248/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0979 - accuracy: 0.5992 - val_loss: 0.1023 - val_accuracy: 0.5778\n",
      "Epoch 4249/5000\n",
      "11864/11864 [==============================] - 7s 629us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1025 - val_accuracy: 0.5799\n",
      "Epoch 4250/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0978 - accuracy: 0.5998 - val_loss: 0.1026 - val_accuracy: 0.5804\n",
      "Epoch 4251/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0978 - accuracy: 0.5995 - val_loss: 0.1022 - val_accuracy: 0.5815\n",
      "Epoch 4252/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1027 - val_accuracy: 0.5794\n",
      "Epoch 4253/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0978 - accuracy: 0.5996 - val_loss: 0.1028 - val_accuracy: 0.5814\n",
      "Epoch 4254/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0979 - accuracy: 0.5994 - val_loss: 0.1024 - val_accuracy: 0.5831\n",
      "Epoch 4255/5000\n",
      "11864/11864 [==============================] - 8s 633us/step - loss: 0.0977 - accuracy: 0.6005 - val_loss: 0.1027 - val_accuracy: 0.5805\n",
      "Epoch 4256/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1034 - val_accuracy: 0.5790\n",
      "Epoch 4257/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1023 - val_accuracy: 0.5799\n",
      "Epoch 4258/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0980 - accuracy: 0.6000 - val_loss: 0.1026 - val_accuracy: 0.5807\n",
      "Epoch 4259/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0978 - accuracy: 0.6001 - val_loss: 0.1026 - val_accuracy: 0.5832\n",
      "Epoch 4260/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1029 - val_accuracy: 0.5787\n",
      "Epoch 4261/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1024 - val_accuracy: 0.5817\n",
      "Epoch 4262/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1017 - val_accuracy: 0.5827\n",
      "Epoch 4263/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1021 - val_accuracy: 0.5830\n",
      "Epoch 4264/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1032 - val_accuracy: 0.5793\n",
      "Epoch 4265/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1025 - val_accuracy: 0.5820\n",
      "Epoch 4266/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1024 - val_accuracy: 0.5820\n",
      "Epoch 4267/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0978 - accuracy: 0.6006 - val_loss: 0.1024 - val_accuracy: 0.5777\n",
      "Epoch 4268/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1026 - val_accuracy: 0.5796\n",
      "Epoch 4269/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0978 - accuracy: 0.5992 - val_loss: 0.1028 - val_accuracy: 0.5785\n",
      "Epoch 4270/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1018 - val_accuracy: 0.5830\n",
      "Epoch 4271/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0978 - accuracy: 0.6002 - val_loss: 0.1031 - val_accuracy: 0.5799\n",
      "Epoch 4272/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0979 - accuracy: 0.5991 - val_loss: 0.1025 - val_accuracy: 0.5812\n",
      "Epoch 4273/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1025 - val_accuracy: 0.5816\n",
      "Epoch 4274/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0979 - accuracy: 0.6001 - val_loss: 0.1031 - val_accuracy: 0.5811\n",
      "Epoch 4275/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1026 - val_accuracy: 0.5793\n",
      "Epoch 4276/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1016 - val_accuracy: 0.5831\n",
      "Epoch 4277/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0978 - accuracy: 0.6002 - val_loss: 0.1026 - val_accuracy: 0.5776\n",
      "Epoch 4278/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1023 - val_accuracy: 0.5803\n",
      "Epoch 4279/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0979 - accuracy: 0.6002 - val_loss: 0.1025 - val_accuracy: 0.5789\n",
      "Epoch 4280/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0979 - accuracy: 0.5986 - val_loss: 0.1024 - val_accuracy: 0.5808\n",
      "Epoch 4281/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1025 - val_accuracy: 0.5816\n",
      "Epoch 4282/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0979 - accuracy: 0.5990 - val_loss: 0.1029 - val_accuracy: 0.5786\n",
      "Epoch 4283/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0979 - accuracy: 0.6001 - val_loss: 0.1025 - val_accuracy: 0.5815\n",
      "Epoch 4284/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1026 - val_accuracy: 0.5788\n",
      "Epoch 4285/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0979 - accuracy: 0.6001 - val_loss: 0.1024 - val_accuracy: 0.5809\n",
      "Epoch 4286/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1021 - val_accuracy: 0.5806\n",
      "Epoch 4287/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1023 - val_accuracy: 0.5806\n",
      "Epoch 4288/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0979 - accuracy: 0.5989 - val_loss: 0.1028 - val_accuracy: 0.5795\n",
      "Epoch 4289/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0978 - accuracy: 0.6002 - val_loss: 0.1026 - val_accuracy: 0.5772\n",
      "Epoch 4290/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1031 - val_accuracy: 0.5748\n",
      "Epoch 4291/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0978 - accuracy: 0.6008 - val_loss: 0.1029 - val_accuracy: 0.5810\n",
      "Epoch 4292/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0979 - accuracy: 0.6002 - val_loss: 0.1019 - val_accuracy: 0.5830\n",
      "Epoch 4293/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0979 - accuracy: 0.5994 - val_loss: 0.1024 - val_accuracy: 0.5810\n",
      "Epoch 4294/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0978 - accuracy: 0.6002 - val_loss: 0.1024 - val_accuracy: 0.5794\n",
      "Epoch 4295/5000\n",
      "11864/11864 [==============================] - 7s 631us/step - loss: 0.0979 - accuracy: 0.6001 - val_loss: 0.1028 - val_accuracy: 0.5792\n",
      "Epoch 4296/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1024 - val_accuracy: 0.5803\n",
      "Epoch 4297/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0979 - accuracy: 0.5994 - val_loss: 0.1028 - val_accuracy: 0.5791\n",
      "Epoch 4298/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0979 - accuracy: 0.6007 - val_loss: 0.1023 - val_accuracy: 0.5817\n",
      "Epoch 4299/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1027 - val_accuracy: 0.5785\n",
      "Epoch 4300/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0979 - accuracy: 0.6002 - val_loss: 0.1022 - val_accuracy: 0.5808\n",
      "Epoch 4301/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1023 - val_accuracy: 0.5787\n",
      "Epoch 4302/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1026 - val_accuracy: 0.5816\n",
      "Epoch 4303/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1021 - val_accuracy: 0.5804\n",
      "Epoch 4304/5000\n",
      "11864/11864 [==============================] - 7s 631us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1036 - val_accuracy: 0.5714\n",
      "Epoch 4305/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0979 - accuracy: 0.6004 - val_loss: 0.1024 - val_accuracy: 0.5813\n",
      "Epoch 4306/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0979 - accuracy: 0.5994 - val_loss: 0.1027 - val_accuracy: 0.5783\n",
      "Epoch 4307/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1025 - val_accuracy: 0.5796\n",
      "Epoch 4308/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1035 - val_accuracy: 0.5759\n",
      "Epoch 4309/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1032 - val_accuracy: 0.5808\n",
      "Epoch 4310/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1025 - val_accuracy: 0.5824\n",
      "Epoch 4311/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1020 - val_accuracy: 0.5805\n",
      "Epoch 4312/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0979 - accuracy: 0.5994 - val_loss: 0.1029 - val_accuracy: 0.5810\n",
      "Epoch 4313/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0979 - accuracy: 0.6003 - val_loss: 0.1022 - val_accuracy: 0.5793\n",
      "Epoch 4314/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0978 - accuracy: 0.5995 - val_loss: 0.1036 - val_accuracy: 0.5785\n",
      "Epoch 4315/5000\n",
      "11864/11864 [==============================] - 7s 629us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1027 - val_accuracy: 0.5780\n",
      "Epoch 4316/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1024 - val_accuracy: 0.5792\n",
      "Epoch 4317/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1023 - val_accuracy: 0.5806\n",
      "Epoch 4318/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1029 - val_accuracy: 0.5799\n",
      "Epoch 4319/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1026 - val_accuracy: 0.5815\n",
      "Epoch 4320/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0979 - accuracy: 0.5992 - val_loss: 0.1017 - val_accuracy: 0.5820\n",
      "Epoch 4321/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0979 - accuracy: 0.5993 - val_loss: 0.1027 - val_accuracy: 0.5800\n",
      "Epoch 4322/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1019 - val_accuracy: 0.5820\n",
      "Epoch 4323/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1025 - val_accuracy: 0.5824\n",
      "Epoch 4324/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0979 - accuracy: 0.6002 - val_loss: 0.1029 - val_accuracy: 0.5819\n",
      "Epoch 4325/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0978 - accuracy: 0.6002 - val_loss: 0.1029 - val_accuracy: 0.5776\n",
      "Epoch 4326/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1025 - val_accuracy: 0.5825\n",
      "Epoch 4327/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0979 - accuracy: 0.6002 - val_loss: 0.1026 - val_accuracy: 0.5736\n",
      "Epoch 4328/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0979 - accuracy: 0.6005 - val_loss: 0.1025 - val_accuracy: 0.5818\n",
      "Epoch 4329/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1026 - val_accuracy: 0.5796\n",
      "Epoch 4330/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1029 - val_accuracy: 0.5787\n",
      "Epoch 4331/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1029 - val_accuracy: 0.5662\n",
      "Epoch 4332/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0979 - accuracy: 0.5991 - val_loss: 0.1028 - val_accuracy: 0.5794\n",
      "Epoch 4333/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1024 - val_accuracy: 0.5828\n",
      "Epoch 4334/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0978 - accuracy: 0.6000 - val_loss: 0.1029 - val_accuracy: 0.5772\n",
      "Epoch 4335/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0978 - accuracy: 0.6008 - val_loss: 0.1032 - val_accuracy: 0.5807\n",
      "Epoch 4336/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0978 - accuracy: 0.6007 - val_loss: 0.1028 - val_accuracy: 0.5818\n",
      "Epoch 4337/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1027 - val_accuracy: 0.5798\n",
      "Epoch 4338/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0978 - accuracy: 0.6006 - val_loss: 0.1029 - val_accuracy: 0.5780\n",
      "Epoch 4339/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1022 - val_accuracy: 0.5804\n",
      "Epoch 4340/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0978 - accuracy: 0.5996 - val_loss: 0.1027 - val_accuracy: 0.5780\n",
      "Epoch 4341/5000\n",
      "11864/11864 [==============================] - 7s 629us/step - loss: 0.0979 - accuracy: 0.5993 - val_loss: 0.1031 - val_accuracy: 0.5770\n",
      "Epoch 4342/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0979 - accuracy: 0.6002 - val_loss: 0.1037 - val_accuracy: 0.5770\n",
      "Epoch 4343/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1027 - val_accuracy: 0.5773\n",
      "Epoch 4344/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1021 - val_accuracy: 0.5821\n",
      "Epoch 4345/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1027 - val_accuracy: 0.5791\n",
      "Epoch 4346/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0977 - accuracy: 0.6007 - val_loss: 0.1027 - val_accuracy: 0.5799\n",
      "Epoch 4347/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1021 - val_accuracy: 0.5805\n",
      "Epoch 4348/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1028 - val_accuracy: 0.5759\n",
      "Epoch 4349/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1027 - val_accuracy: 0.5797\n",
      "Epoch 4350/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1025 - val_accuracy: 0.5792\n",
      "Epoch 4351/5000\n",
      "11864/11864 [==============================] - 7s 629us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1026 - val_accuracy: 0.5791\n",
      "Epoch 4352/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1037 - val_accuracy: 0.5759\n",
      "Epoch 4353/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0977 - accuracy: 0.6005 - val_loss: 0.1023 - val_accuracy: 0.5800\n",
      "Epoch 4354/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0978 - accuracy: 0.5999 - val_loss: 0.1022 - val_accuracy: 0.5814\n",
      "Epoch 4355/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1025 - val_accuracy: 0.5802\n",
      "Epoch 4356/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0978 - accuracy: 0.6001 - val_loss: 0.1033 - val_accuracy: 0.5792\n",
      "Epoch 4357/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1026 - val_accuracy: 0.5791\n",
      "Epoch 4358/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0978 - accuracy: 0.5998 - val_loss: 0.1025 - val_accuracy: 0.5804\n",
      "Epoch 4359/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0979 - accuracy: 0.5992 - val_loss: 0.1025 - val_accuracy: 0.5802\n",
      "Epoch 4360/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1029 - val_accuracy: 0.5809\n",
      "Epoch 4361/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1028 - val_accuracy: 0.5807\n",
      "Epoch 4362/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0979 - accuracy: 0.5993 - val_loss: 0.1025 - val_accuracy: 0.5785\n",
      "Epoch 4363/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0979 - accuracy: 0.5994 - val_loss: 0.1028 - val_accuracy: 0.5766\n",
      "Epoch 4364/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1028 - val_accuracy: 0.5798\n",
      "Epoch 4365/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0979 - accuracy: 0.6002 - val_loss: 0.1031 - val_accuracy: 0.5763\n",
      "Epoch 4366/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0979 - accuracy: 0.5994 - val_loss: 0.1030 - val_accuracy: 0.5787\n",
      "Epoch 4367/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0979 - accuracy: 0.5993 - val_loss: 0.1027 - val_accuracy: 0.5765\n",
      "Epoch 4368/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1022 - val_accuracy: 0.5818\n",
      "Epoch 4369/5000\n",
      "11864/11864 [==============================] - 7s 629us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1024 - val_accuracy: 0.5817\n",
      "Epoch 4370/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0978 - accuracy: 0.6001 - val_loss: 0.1026 - val_accuracy: 0.5786\n",
      "Epoch 4371/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0980 - accuracy: 0.6000 - val_loss: 0.1029 - val_accuracy: 0.5776\n",
      "Epoch 4372/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0979 - accuracy: 0.5991 - val_loss: 0.1026 - val_accuracy: 0.5812\n",
      "Epoch 4373/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0979 - accuracy: 0.6006 - val_loss: 0.1023 - val_accuracy: 0.5823\n",
      "Epoch 4374/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0979 - accuracy: 0.5993 - val_loss: 0.1026 - val_accuracy: 0.5787\n",
      "Epoch 4375/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1031 - val_accuracy: 0.5799\n",
      "Epoch 4376/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0980 - accuracy: 0.6000 - val_loss: 0.1020 - val_accuracy: 0.5830\n",
      "Epoch 4377/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0979 - accuracy: 0.6001 - val_loss: 0.1026 - val_accuracy: 0.5803\n",
      "Epoch 4378/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0978 - accuracy: 0.6002 - val_loss: 0.1023 - val_accuracy: 0.5800\n",
      "Epoch 4379/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1023 - val_accuracy: 0.5810\n",
      "Epoch 4380/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1029 - val_accuracy: 0.5752\n",
      "Epoch 4381/5000\n",
      "11864/11864 [==============================] - 7s 629us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1029 - val_accuracy: 0.5784\n",
      "Epoch 4382/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0980 - accuracy: 0.6002 - val_loss: 0.1033 - val_accuracy: 0.5741\n",
      "Epoch 4383/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1028 - val_accuracy: 0.5770\n",
      "Epoch 4384/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0979 - accuracy: 0.5994 - val_loss: 0.1023 - val_accuracy: 0.5813\n",
      "Epoch 4385/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1024 - val_accuracy: 0.5784\n",
      "Epoch 4386/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1035 - val_accuracy: 0.5800\n",
      "Epoch 4387/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0978 - accuracy: 0.6004 - val_loss: 0.1041 - val_accuracy: 0.5735\n",
      "Epoch 4388/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1024 - val_accuracy: 0.5816\n",
      "Epoch 4389/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0978 - accuracy: 0.5995 - val_loss: 0.1021 - val_accuracy: 0.5815\n",
      "Epoch 4390/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1026 - val_accuracy: 0.5795\n",
      "Epoch 4391/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1024 - val_accuracy: 0.5831\n",
      "Epoch 4392/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1026 - val_accuracy: 0.5764\n",
      "Epoch 4393/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0978 - accuracy: 0.5991 - val_loss: 0.1022 - val_accuracy: 0.5813\n",
      "Epoch 4394/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0979 - accuracy: 0.5991 - val_loss: 0.1025 - val_accuracy: 0.5822\n",
      "Epoch 4395/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1022 - val_accuracy: 0.5807\n",
      "Epoch 4396/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1022 - val_accuracy: 0.5810\n",
      "Epoch 4397/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0978 - accuracy: 0.6002 - val_loss: 0.1023 - val_accuracy: 0.5808\n",
      "Epoch 4398/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0979 - accuracy: 0.5993 - val_loss: 0.1022 - val_accuracy: 0.5813\n",
      "Epoch 4399/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1025 - val_accuracy: 0.5800\n",
      "Epoch 4400/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1029 - val_accuracy: 0.5795\n",
      "Epoch 4401/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1026 - val_accuracy: 0.5788\n",
      "Epoch 4402/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1032 - val_accuracy: 0.5785\n",
      "Epoch 4403/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1023 - val_accuracy: 0.5816\n",
      "Epoch 4404/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0978 - accuracy: 0.5994 - val_loss: 0.1018 - val_accuracy: 0.5823\n",
      "Epoch 4405/5000\n",
      "11864/11864 [==============================] - 7s 629us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1027 - val_accuracy: 0.5796\n",
      "Epoch 4406/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1029 - val_accuracy: 0.5784\n",
      "Epoch 4407/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1025 - val_accuracy: 0.5773\n",
      "Epoch 4408/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0979 - accuracy: 0.6003 - val_loss: 0.1025 - val_accuracy: 0.5783\n",
      "Epoch 4409/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1026 - val_accuracy: 0.5789\n",
      "Epoch 4410/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1028 - val_accuracy: 0.5788\n",
      "Epoch 4411/5000\n",
      "11864/11864 [==============================] - 7s 629us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1020 - val_accuracy: 0.5801\n",
      "Epoch 4412/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1027 - val_accuracy: 0.5787\n",
      "Epoch 4413/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1027 - val_accuracy: 0.5795\n",
      "Epoch 4414/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0979 - accuracy: 0.5993 - val_loss: 0.1025 - val_accuracy: 0.5805\n",
      "Epoch 4415/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1030 - val_accuracy: 0.5774\n",
      "Epoch 4416/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1025 - val_accuracy: 0.5800\n",
      "Epoch 4417/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1034 - val_accuracy: 0.5723\n",
      "Epoch 4418/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1030 - val_accuracy: 0.5776\n",
      "Epoch 4419/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0979 - accuracy: 0.6003 - val_loss: 0.1018 - val_accuracy: 0.5809\n",
      "Epoch 4420/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1021 - val_accuracy: 0.5835\n",
      "Epoch 4421/5000\n",
      "11864/11864 [==============================] - 7s 629us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1026 - val_accuracy: 0.5796\n",
      "Epoch 4422/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1025 - val_accuracy: 0.5811\n",
      "Epoch 4423/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1021 - val_accuracy: 0.5819\n",
      "Epoch 4424/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1021 - val_accuracy: 0.5830\n",
      "Epoch 4425/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1023 - val_accuracy: 0.5822\n",
      "Epoch 4426/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0979 - accuracy: 0.6004 - val_loss: 0.1022 - val_accuracy: 0.5795\n",
      "Epoch 4427/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1025 - val_accuracy: 0.5803\n",
      "Epoch 4428/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0979 - accuracy: 0.5990 - val_loss: 0.1019 - val_accuracy: 0.5824\n",
      "Epoch 4429/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1030 - val_accuracy: 0.5804\n",
      "Epoch 4430/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1027 - val_accuracy: 0.5795\n",
      "Epoch 4431/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1027 - val_accuracy: 0.5790\n",
      "Epoch 4432/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0979 - accuracy: 0.5991 - val_loss: 0.1028 - val_accuracy: 0.5768\n",
      "Epoch 4433/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1033 - val_accuracy: 0.5796\n",
      "Epoch 4434/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1021 - val_accuracy: 0.5799\n",
      "Epoch 4435/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1022 - val_accuracy: 0.5815\n",
      "Epoch 4436/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1032 - val_accuracy: 0.5794\n",
      "Epoch 4437/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1029 - val_accuracy: 0.5783\n",
      "Epoch 4438/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0980 - accuracy: 0.5999 - val_loss: 0.1027 - val_accuracy: 0.5805\n",
      "Epoch 4439/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0979 - accuracy: 0.5994 - val_loss: 0.1021 - val_accuracy: 0.5816\n",
      "Epoch 4440/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1017 - val_accuracy: 0.5835\n",
      "Epoch 4441/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0980 - accuracy: 0.5999 - val_loss: 0.1023 - val_accuracy: 0.5820\n",
      "Epoch 4442/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0980 - accuracy: 0.5999 - val_loss: 0.1027 - val_accuracy: 0.5716\n",
      "Epoch 4443/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1028 - val_accuracy: 0.5796\n",
      "Epoch 4444/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0980 - accuracy: 0.5999 - val_loss: 0.1025 - val_accuracy: 0.5818\n",
      "Epoch 4445/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0979 - accuracy: 0.6003 - val_loss: 0.1028 - val_accuracy: 0.5794\n",
      "Epoch 4446/5000\n",
      "11864/11864 [==============================] - 7s 612us/step - loss: 0.0979 - accuracy: 0.5994 - val_loss: 0.1021 - val_accuracy: 0.5805\n",
      "Epoch 4447/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0978 - accuracy: 0.5996 - val_loss: 0.1028 - val_accuracy: 0.5821\n",
      "Epoch 4448/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0980 - accuracy: 0.6001 - val_loss: 0.1022 - val_accuracy: 0.5811\n",
      "Epoch 4449/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1022 - val_accuracy: 0.5830\n",
      "Epoch 4450/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0979 - accuracy: 0.5992 - val_loss: 0.1028 - val_accuracy: 0.5782\n",
      "Epoch 4451/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1027 - val_accuracy: 0.5800\n",
      "Epoch 4452/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1029 - val_accuracy: 0.5808\n",
      "Epoch 4453/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1024 - val_accuracy: 0.5781\n",
      "Epoch 4454/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1034 - val_accuracy: 0.5757\n",
      "Epoch 4455/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1025 - val_accuracy: 0.5798\n",
      "Epoch 4456/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1026 - val_accuracy: 0.5828\n",
      "Epoch 4457/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1034 - val_accuracy: 0.5774\n",
      "Epoch 4458/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0978 - accuracy: 0.6004 - val_loss: 0.1031 - val_accuracy: 0.5793\n",
      "Epoch 4459/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1024 - val_accuracy: 0.5808\n",
      "Epoch 4460/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1021 - val_accuracy: 0.5797\n",
      "Epoch 4461/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0978 - accuracy: 0.6002 - val_loss: 0.1026 - val_accuracy: 0.5818\n",
      "Epoch 4462/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1034 - val_accuracy: 0.5797\n",
      "Epoch 4463/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1031 - val_accuracy: 0.5812\n",
      "Epoch 4464/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1025 - val_accuracy: 0.5785\n",
      "Epoch 4465/5000\n",
      "11864/11864 [==============================] - 7s 631us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1023 - val_accuracy: 0.5812\n",
      "Epoch 4466/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1023 - val_accuracy: 0.5806\n",
      "Epoch 4467/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0980 - accuracy: 0.5986 - val_loss: 0.1026 - val_accuracy: 0.5784\n",
      "Epoch 4468/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1024 - val_accuracy: 0.5822\n",
      "Epoch 4469/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0979 - accuracy: 0.5991 - val_loss: 0.1032 - val_accuracy: 0.5823\n",
      "Epoch 4470/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1027 - val_accuracy: 0.5801\n",
      "Epoch 4471/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1023 - val_accuracy: 0.5819\n",
      "Epoch 4472/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1018 - val_accuracy: 0.5795\n",
      "Epoch 4473/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1025 - val_accuracy: 0.5824\n",
      "Epoch 4474/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1026 - val_accuracy: 0.5771\n",
      "Epoch 4475/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0980 - accuracy: 0.6000 - val_loss: 0.1022 - val_accuracy: 0.5809\n",
      "Epoch 4476/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1027 - val_accuracy: 0.5785\n",
      "Epoch 4477/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1029 - val_accuracy: 0.5805\n",
      "Epoch 4478/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1023 - val_accuracy: 0.5832\n",
      "Epoch 4479/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1026 - val_accuracy: 0.5803\n",
      "Epoch 4480/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1029 - val_accuracy: 0.5767\n",
      "Epoch 4481/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1024 - val_accuracy: 0.5784\n",
      "Epoch 4482/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1024 - val_accuracy: 0.5801\n",
      "Epoch 4483/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0979 - accuracy: 0.5989 - val_loss: 0.1022 - val_accuracy: 0.5800\n",
      "Epoch 4484/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0979 - accuracy: 0.5993 - val_loss: 0.1018 - val_accuracy: 0.5833\n",
      "Epoch 4485/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1021 - val_accuracy: 0.5798\n",
      "Epoch 4486/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1027 - val_accuracy: 0.5764\n",
      "Epoch 4487/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0979 - accuracy: 0.5994 - val_loss: 0.1022 - val_accuracy: 0.5801\n",
      "Epoch 4488/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1030 - val_accuracy: 0.5801\n",
      "Epoch 4489/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1034 - val_accuracy: 0.5777\n",
      "Epoch 4490/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0979 - accuracy: 0.6003 - val_loss: 0.1028 - val_accuracy: 0.5808\n",
      "Epoch 4491/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1026 - val_accuracy: 0.5790\n",
      "Epoch 4492/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1021 - val_accuracy: 0.5835\n",
      "Epoch 4493/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1029 - val_accuracy: 0.5774\n",
      "Epoch 4494/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0979 - accuracy: 0.5991 - val_loss: 0.1031 - val_accuracy: 0.5778\n",
      "Epoch 4495/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1030 - val_accuracy: 0.5818\n",
      "Epoch 4496/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0979 - accuracy: 0.5993 - val_loss: 0.1033 - val_accuracy: 0.5805\n",
      "Epoch 4497/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0980 - accuracy: 0.6002 - val_loss: 0.1023 - val_accuracy: 0.5822\n",
      "Epoch 4498/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1023 - val_accuracy: 0.5820\n",
      "Epoch 4499/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1023 - val_accuracy: 0.5808\n",
      "Epoch 4500/5000\n",
      "11864/11864 [==============================] - 7s 613us/step - loss: 0.0978 - accuracy: 0.5995 - val_loss: 0.1030 - val_accuracy: 0.5706\n",
      "Epoch 4501/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0979 - accuracy: 0.6003 - val_loss: 0.1029 - val_accuracy: 0.5775\n",
      "Epoch 4502/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1021 - val_accuracy: 0.5817\n",
      "Epoch 4503/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1026 - val_accuracy: 0.5808\n",
      "Epoch 4504/5000\n",
      "11864/11864 [==============================] - 7s 614us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1021 - val_accuracy: 0.5810\n",
      "Epoch 4505/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1027 - val_accuracy: 0.5812\n",
      "Epoch 4506/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1024 - val_accuracy: 0.5819\n",
      "Epoch 4507/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1023 - val_accuracy: 0.5805\n",
      "Epoch 4508/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0978 - accuracy: 0.5999 - val_loss: 0.1019 - val_accuracy: 0.5809\n",
      "Epoch 4509/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0978 - accuracy: 0.5996 - val_loss: 0.1028 - val_accuracy: 0.5787\n",
      "Epoch 4510/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0979 - accuracy: 0.5994 - val_loss: 0.1027 - val_accuracy: 0.5797\n",
      "Epoch 4511/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0979 - accuracy: 0.5994 - val_loss: 0.1027 - val_accuracy: 0.5803\n",
      "Epoch 4512/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1032 - val_accuracy: 0.5797\n",
      "Epoch 4513/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1033 - val_accuracy: 0.5764\n",
      "Epoch 4514/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1025 - val_accuracy: 0.5797\n",
      "Epoch 4515/5000\n",
      "11864/11864 [==============================] - 8s 633us/step - loss: 0.0980 - accuracy: 0.6003 - val_loss: 0.1035 - val_accuracy: 0.5805\n",
      "Epoch 4516/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1028 - val_accuracy: 0.5818\n",
      "Epoch 4517/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1026 - val_accuracy: 0.5792\n",
      "Epoch 4518/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1030 - val_accuracy: 0.5775\n",
      "Epoch 4519/5000\n",
      "11864/11864 [==============================] - 8s 632us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1022 - val_accuracy: 0.5821\n",
      "Epoch 4520/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1021 - val_accuracy: 0.5809\n",
      "Epoch 4521/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0979 - accuracy: 0.6007 - val_loss: 0.1027 - val_accuracy: 0.5798\n",
      "Epoch 4522/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1027 - val_accuracy: 0.5792\n",
      "Epoch 4523/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1022 - val_accuracy: 0.5801\n",
      "Epoch 4524/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1027 - val_accuracy: 0.5788\n",
      "Epoch 4525/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1019 - val_accuracy: 0.5825\n",
      "Epoch 4526/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0979 - accuracy: 0.5994 - val_loss: 0.1031 - val_accuracy: 0.5798\n",
      "Epoch 4527/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1022 - val_accuracy: 0.5804\n",
      "Epoch 4528/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1025 - val_accuracy: 0.5783\n",
      "Epoch 4529/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1024 - val_accuracy: 0.5796\n",
      "Epoch 4530/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1027 - val_accuracy: 0.5796\n",
      "Epoch 4531/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1035 - val_accuracy: 0.5784\n",
      "Epoch 4532/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0981 - accuracy: 0.5996 - val_loss: 0.1025 - val_accuracy: 0.5816\n",
      "Epoch 4533/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1023 - val_accuracy: 0.5814\n",
      "Epoch 4534/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1022 - val_accuracy: 0.5807\n",
      "Epoch 4535/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1026 - val_accuracy: 0.5806\n",
      "Epoch 4536/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1025 - val_accuracy: 0.5810\n",
      "Epoch 4537/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1034 - val_accuracy: 0.5704\n",
      "Epoch 4538/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0979 - accuracy: 0.5992 - val_loss: 0.1027 - val_accuracy: 0.5789\n",
      "Epoch 4539/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1023 - val_accuracy: 0.5809\n",
      "Epoch 4540/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1040 - val_accuracy: 0.5771\n",
      "Epoch 4541/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0979 - accuracy: 0.5990 - val_loss: 0.1029 - val_accuracy: 0.5811\n",
      "Epoch 4542/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0979 - accuracy: 0.5994 - val_loss: 0.1026 - val_accuracy: 0.5841\n",
      "Epoch 4543/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1024 - val_accuracy: 0.5818\n",
      "Epoch 4544/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1024 - val_accuracy: 0.5812\n",
      "Epoch 4545/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1028 - val_accuracy: 0.5780\n",
      "Epoch 4546/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1026 - val_accuracy: 0.5811\n",
      "Epoch 4547/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0979 - accuracy: 0.6001 - val_loss: 0.1027 - val_accuracy: 0.5797\n",
      "Epoch 4548/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1026 - val_accuracy: 0.5746\n",
      "Epoch 4549/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1028 - val_accuracy: 0.5773\n",
      "Epoch 4550/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1028 - val_accuracy: 0.5790\n",
      "Epoch 4551/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1025 - val_accuracy: 0.5798\n",
      "Epoch 4552/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1018 - val_accuracy: 0.5818\n",
      "Epoch 4553/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1026 - val_accuracy: 0.5813\n",
      "Epoch 4554/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1022 - val_accuracy: 0.5807\n",
      "Epoch 4555/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0979 - accuracy: 0.5989 - val_loss: 0.1025 - val_accuracy: 0.5788\n",
      "Epoch 4556/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0980 - accuracy: 0.5999 - val_loss: 0.1023 - val_accuracy: 0.5798\n",
      "Epoch 4557/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1025 - val_accuracy: 0.5808\n",
      "Epoch 4558/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1030 - val_accuracy: 0.5820\n",
      "Epoch 4559/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0980 - accuracy: 0.5987 - val_loss: 0.1028 - val_accuracy: 0.5800\n",
      "Epoch 4560/5000\n",
      "11864/11864 [==============================] - 7s 610us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1026 - val_accuracy: 0.5792\n",
      "Epoch 4561/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1024 - val_accuracy: 0.5800\n",
      "Epoch 4562/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1023 - val_accuracy: 0.5811\n",
      "Epoch 4563/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1023 - val_accuracy: 0.5823\n",
      "Epoch 4564/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1022 - val_accuracy: 0.5817\n",
      "Epoch 4565/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1023 - val_accuracy: 0.5816\n",
      "Epoch 4566/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1028 - val_accuracy: 0.5783\n",
      "Epoch 4567/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1023 - val_accuracy: 0.5801\n",
      "Epoch 4568/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0979 - accuracy: 0.5993 - val_loss: 0.1027 - val_accuracy: 0.5815\n",
      "Epoch 4569/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1024 - val_accuracy: 0.5803\n",
      "Epoch 4570/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1032 - val_accuracy: 0.5775\n",
      "Epoch 4571/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1029 - val_accuracy: 0.5799\n",
      "Epoch 4572/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0979 - accuracy: 0.5994 - val_loss: 0.1023 - val_accuracy: 0.5802\n",
      "Epoch 4573/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1022 - val_accuracy: 0.5816\n",
      "Epoch 4574/5000\n",
      "11864/11864 [==============================] - 7s 629us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1026 - val_accuracy: 0.5806\n",
      "Epoch 4575/5000\n",
      "11864/11864 [==============================] - 7s 631us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1032 - val_accuracy: 0.5814\n",
      "Epoch 4576/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1025 - val_accuracy: 0.5789\n",
      "Epoch 4577/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1023 - val_accuracy: 0.5819\n",
      "Epoch 4578/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0980 - accuracy: 0.6000 - val_loss: 0.1034 - val_accuracy: 0.5770\n",
      "Epoch 4579/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1026 - val_accuracy: 0.5804\n",
      "Epoch 4580/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1025 - val_accuracy: 0.5788\n",
      "Epoch 4581/5000\n",
      "11864/11864 [==============================] - 7s 631us/step - loss: 0.0980 - accuracy: 0.5986 - val_loss: 0.1031 - val_accuracy: 0.5755\n",
      "Epoch 4582/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0979 - accuracy: 0.6002 - val_loss: 0.1031 - val_accuracy: 0.5768\n",
      "Epoch 4583/5000\n",
      "11864/11864 [==============================] - 7s 629us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1027 - val_accuracy: 0.5782\n",
      "Epoch 4584/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1026 - val_accuracy: 0.5831\n",
      "Epoch 4585/5000\n",
      "11864/11864 [==============================] - 8s 635us/step - loss: 0.0981 - accuracy: 0.5980 - val_loss: 0.1024 - val_accuracy: 0.5806\n",
      "Epoch 4586/5000\n",
      "11864/11864 [==============================] - 8s 632us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1030 - val_accuracy: 0.5776\n",
      "Epoch 4587/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0980 - accuracy: 0.6000 - val_loss: 0.1026 - val_accuracy: 0.5797\n",
      "Epoch 4588/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1023 - val_accuracy: 0.5792\n",
      "Epoch 4589/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1025 - val_accuracy: 0.5803\n",
      "Epoch 4590/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1027 - val_accuracy: 0.5783\n",
      "Epoch 4591/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1024 - val_accuracy: 0.5785\n",
      "Epoch 4592/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1026 - val_accuracy: 0.5795\n",
      "Epoch 4593/5000\n",
      "11864/11864 [==============================] - 8s 640us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1020 - val_accuracy: 0.5806\n",
      "Epoch 4594/5000\n",
      "11864/11864 [==============================] - 8s 633us/step - loss: 0.0979 - accuracy: 0.6004 - val_loss: 0.1028 - val_accuracy: 0.5798\n",
      "Epoch 4595/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0981 - accuracy: 0.5984 - val_loss: 0.1024 - val_accuracy: 0.5783\n",
      "Epoch 4596/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0980 - accuracy: 0.5987 - val_loss: 0.1022 - val_accuracy: 0.5784\n",
      "Epoch 4597/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0979 - accuracy: 0.6007 - val_loss: 0.1027 - val_accuracy: 0.5810\n",
      "Epoch 4598/5000\n",
      "11864/11864 [==============================] - 8s 633us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1028 - val_accuracy: 0.5804\n",
      "Epoch 4599/5000\n",
      "11864/11864 [==============================] - 7s 629us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1028 - val_accuracy: 0.5824\n",
      "Epoch 4600/5000\n",
      "11864/11864 [==============================] - 8s 632us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1024 - val_accuracy: 0.5785\n",
      "Epoch 4601/5000\n",
      "11864/11864 [==============================] - 7s 629us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1026 - val_accuracy: 0.5783\n",
      "Epoch 4602/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1024 - val_accuracy: 0.5806\n",
      "Epoch 4603/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1024 - val_accuracy: 0.5820\n",
      "Epoch 4604/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0979 - accuracy: 0.5992 - val_loss: 0.1022 - val_accuracy: 0.5811\n",
      "Epoch 4605/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1034 - val_accuracy: 0.5794\n",
      "Epoch 4606/5000\n",
      "11864/11864 [==============================] - 7s 632us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1026 - val_accuracy: 0.5785\n",
      "Epoch 4607/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0979 - accuracy: 0.5989 - val_loss: 0.1021 - val_accuracy: 0.5813\n",
      "Epoch 4608/5000\n",
      "11864/11864 [==============================] - 7s 629us/step - loss: 0.0979 - accuracy: 0.6001 - val_loss: 0.1020 - val_accuracy: 0.5807\n",
      "Epoch 4609/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0981 - accuracy: 0.5996 - val_loss: 0.1026 - val_accuracy: 0.5812\n",
      "Epoch 4610/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1027 - val_accuracy: 0.5787\n",
      "Epoch 4611/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0979 - accuracy: 0.5994 - val_loss: 0.1018 - val_accuracy: 0.5816\n",
      "Epoch 4612/5000\n",
      "11864/11864 [==============================] - 7s 629us/step - loss: 0.0979 - accuracy: 0.6007 - val_loss: 0.1027 - val_accuracy: 0.5778\n",
      "Epoch 4613/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0980 - accuracy: 0.5999 - val_loss: 0.1022 - val_accuracy: 0.5828\n",
      "Epoch 4614/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1025 - val_accuracy: 0.5810\n",
      "Epoch 4615/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1020 - val_accuracy: 0.5827\n",
      "Epoch 4616/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1034 - val_accuracy: 0.5778\n",
      "Epoch 4617/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1022 - val_accuracy: 0.5808\n",
      "Epoch 4618/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1026 - val_accuracy: 0.5795\n",
      "Epoch 4619/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0979 - accuracy: 0.6005 - val_loss: 0.1020 - val_accuracy: 0.5851\n",
      "Epoch 4620/5000\n",
      "11864/11864 [==============================] - 7s 632us/step - loss: 0.0979 - accuracy: 0.6003 - val_loss: 0.1028 - val_accuracy: 0.5830\n",
      "Epoch 4621/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1024 - val_accuracy: 0.5833\n",
      "Epoch 4622/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1026 - val_accuracy: 0.5800\n",
      "Epoch 4623/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1016 - val_accuracy: 0.5836\n",
      "Epoch 4624/5000\n",
      "11864/11864 [==============================] - 8s 635us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1024 - val_accuracy: 0.5798\n",
      "Epoch 4625/5000\n",
      "11864/11864 [==============================] - 7s 631us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1032 - val_accuracy: 0.5803\n",
      "Epoch 4626/5000\n",
      "11864/11864 [==============================] - 8s 632us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1033 - val_accuracy: 0.5779\n",
      "Epoch 4627/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1028 - val_accuracy: 0.5830\n",
      "Epoch 4628/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1024 - val_accuracy: 0.5824\n",
      "Epoch 4629/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0980 - accuracy: 0.5999 - val_loss: 0.1030 - val_accuracy: 0.5774\n",
      "Epoch 4630/5000\n",
      "11864/11864 [==============================] - 7s 629us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1026 - val_accuracy: 0.5781\n",
      "Epoch 4631/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1026 - val_accuracy: 0.5807\n",
      "Epoch 4632/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1033 - val_accuracy: 0.5771\n",
      "Epoch 4633/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1023 - val_accuracy: 0.5831\n",
      "Epoch 4634/5000\n",
      "11864/11864 [==============================] - 8s 635us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1042 - val_accuracy: 0.5745\n",
      "Epoch 4635/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1026 - val_accuracy: 0.5805\n",
      "Epoch 4636/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1027 - val_accuracy: 0.5771\n",
      "Epoch 4637/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1028 - val_accuracy: 0.5769\n",
      "Epoch 4638/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0978 - accuracy: 0.6003 - val_loss: 0.1029 - val_accuracy: 0.5807\n",
      "Epoch 4639/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1020 - val_accuracy: 0.5820\n",
      "Epoch 4640/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1031 - val_accuracy: 0.5822\n",
      "Epoch 4641/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0980 - accuracy: 0.5999 - val_loss: 0.1026 - val_accuracy: 0.5825\n",
      "Epoch 4642/5000\n",
      "11864/11864 [==============================] - 7s 632us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1027 - val_accuracy: 0.5804\n",
      "Epoch 4643/5000\n",
      "11864/11864 [==============================] - 7s 632us/step - loss: 0.0981 - accuracy: 0.5995 - val_loss: 0.1024 - val_accuracy: 0.5820\n",
      "Epoch 4644/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0979 - accuracy: 0.5991 - val_loss: 0.1024 - val_accuracy: 0.5808\n",
      "Epoch 4645/5000\n",
      "11864/11864 [==============================] - 7s 631us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1030 - val_accuracy: 0.5773\n",
      "Epoch 4646/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0980 - accuracy: 0.6003 - val_loss: 0.1028 - val_accuracy: 0.5810\n",
      "Epoch 4647/5000\n",
      "11864/11864 [==============================] - 8s 639us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1024 - val_accuracy: 0.5807\n",
      "Epoch 4648/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1041 - val_accuracy: 0.5815\n",
      "Epoch 4649/5000\n",
      "11864/11864 [==============================] - 7s 629us/step - loss: 0.0981 - accuracy: 0.5995 - val_loss: 0.1030 - val_accuracy: 0.5783\n",
      "Epoch 4650/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0979 - accuracy: 0.6000 - val_loss: 0.1027 - val_accuracy: 0.5770\n",
      "Epoch 4651/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1022 - val_accuracy: 0.5815\n",
      "Epoch 4652/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1024 - val_accuracy: 0.5815\n",
      "Epoch 4653/5000\n",
      "11864/11864 [==============================] - 7s 629us/step - loss: 0.0981 - accuracy: 0.5996 - val_loss: 0.1042 - val_accuracy: 0.5788\n",
      "Epoch 4654/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0980 - accuracy: 0.5999 - val_loss: 0.1026 - val_accuracy: 0.5713\n",
      "Epoch 4655/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1023 - val_accuracy: 0.5833\n",
      "Epoch 4656/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0981 - accuracy: 0.5984 - val_loss: 0.1020 - val_accuracy: 0.5824\n",
      "Epoch 4657/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1022 - val_accuracy: 0.5799\n",
      "Epoch 4658/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0979 - accuracy: 0.6005 - val_loss: 0.1033 - val_accuracy: 0.5747\n",
      "Epoch 4659/5000\n",
      "11864/11864 [==============================] - 8s 634us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1029 - val_accuracy: 0.5775\n",
      "Epoch 4660/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1030 - val_accuracy: 0.5814\n",
      "Epoch 4661/5000\n",
      "11864/11864 [==============================] - 8s 634us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1031 - val_accuracy: 0.5816\n",
      "Epoch 4662/5000\n",
      "11864/11864 [==============================] - 8s 637us/step - loss: 0.0979 - accuracy: 0.6001 - val_loss: 0.1027 - val_accuracy: 0.5766\n",
      "Epoch 4663/5000\n",
      "11864/11864 [==============================] - 7s 631us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1022 - val_accuracy: 0.5800\n",
      "Epoch 4664/5000\n",
      "11864/11864 [==============================] - 7s 632us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1020 - val_accuracy: 0.5811\n",
      "Epoch 4665/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1024 - val_accuracy: 0.5813\n",
      "Epoch 4666/5000\n",
      "11864/11864 [==============================] - 8s 633us/step - loss: 0.0979 - accuracy: 0.6001 - val_loss: 0.1022 - val_accuracy: 0.5816\n",
      "Epoch 4667/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0980 - accuracy: 0.6000 - val_loss: 0.1024 - val_accuracy: 0.5837\n",
      "Epoch 4668/5000\n",
      "11864/11864 [==============================] - 8s 635us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1025 - val_accuracy: 0.5804\n",
      "Epoch 4669/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1024 - val_accuracy: 0.5801\n",
      "Epoch 4670/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1030 - val_accuracy: 0.5823\n",
      "Epoch 4671/5000\n",
      "11864/11864 [==============================] - 8s 635us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1022 - val_accuracy: 0.5817\n",
      "Epoch 4672/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0980 - accuracy: 0.6001 - val_loss: 0.1025 - val_accuracy: 0.5820\n",
      "Epoch 4673/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1025 - val_accuracy: 0.5803\n",
      "Epoch 4674/5000\n",
      "11864/11864 [==============================] - 7s 629us/step - loss: 0.0980 - accuracy: 0.6000 - val_loss: 0.1021 - val_accuracy: 0.5832\n",
      "Epoch 4675/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0979 - accuracy: 0.5992 - val_loss: 0.1029 - val_accuracy: 0.5798\n",
      "Epoch 4676/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1032 - val_accuracy: 0.5775\n",
      "Epoch 4677/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1029 - val_accuracy: 0.5778\n",
      "Epoch 4678/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0980 - accuracy: 0.6001 - val_loss: 0.1030 - val_accuracy: 0.5804\n",
      "Epoch 4679/5000\n",
      "11864/11864 [==============================] - 8s 633us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1028 - val_accuracy: 0.5789\n",
      "Epoch 4680/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1027 - val_accuracy: 0.5816\n",
      "Epoch 4681/5000\n",
      "11864/11864 [==============================] - 8s 632us/step - loss: 0.0981 - accuracy: 0.5997 - val_loss: 0.1024 - val_accuracy: 0.5798\n",
      "Epoch 4682/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0979 - accuracy: 0.5992 - val_loss: 0.1029 - val_accuracy: 0.5752\n",
      "Epoch 4683/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1033 - val_accuracy: 0.5737\n",
      "Epoch 4684/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1028 - val_accuracy: 0.5801\n",
      "Epoch 4685/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0981 - accuracy: 0.5998 - val_loss: 0.1030 - val_accuracy: 0.5765\n",
      "Epoch 4686/5000\n",
      "11864/11864 [==============================] - 7s 631us/step - loss: 0.0979 - accuracy: 0.5989 - val_loss: 0.1029 - val_accuracy: 0.5739\n",
      "Epoch 4687/5000\n",
      "11864/11864 [==============================] - 7s 631us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1028 - val_accuracy: 0.5799\n",
      "Epoch 4688/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0981 - accuracy: 0.5994 - val_loss: 0.1024 - val_accuracy: 0.5809\n",
      "Epoch 4689/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1028 - val_accuracy: 0.5786\n",
      "Epoch 4690/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1027 - val_accuracy: 0.5824\n",
      "Epoch 4691/5000\n",
      "11864/11864 [==============================] - 7s 618us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1024 - val_accuracy: 0.5803\n",
      "Epoch 4692/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0979 - accuracy: 0.5992 - val_loss: 0.1028 - val_accuracy: 0.5810\n",
      "Epoch 4693/5000\n",
      "11864/11864 [==============================] - 7s 629us/step - loss: 0.0982 - accuracy: 0.5991 - val_loss: 0.1026 - val_accuracy: 0.5797\n",
      "Epoch 4694/5000\n",
      "11864/11864 [==============================] - 8s 633us/step - loss: 0.0981 - accuracy: 0.5998 - val_loss: 0.1030 - val_accuracy: 0.5778\n",
      "Epoch 4695/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1027 - val_accuracy: 0.5810\n",
      "Epoch 4696/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0980 - accuracy: 0.6000 - val_loss: 0.1026 - val_accuracy: 0.5807\n",
      "Epoch 4697/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1028 - val_accuracy: 0.5777\n",
      "Epoch 4698/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1028 - val_accuracy: 0.5794\n",
      "Epoch 4699/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1028 - val_accuracy: 0.5786\n",
      "Epoch 4700/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0979 - accuracy: 0.5991 - val_loss: 0.1031 - val_accuracy: 0.5792\n",
      "Epoch 4701/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1026 - val_accuracy: 0.5811\n",
      "Epoch 4702/5000\n",
      "11864/11864 [==============================] - 8s 633us/step - loss: 0.0981 - accuracy: 0.6001 - val_loss: 0.1025 - val_accuracy: 0.5803\n",
      "Epoch 4703/5000\n",
      "11864/11864 [==============================] - 7s 629us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1030 - val_accuracy: 0.5804\n",
      "Epoch 4704/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0979 - accuracy: 0.5999 - val_loss: 0.1027 - val_accuracy: 0.5772\n",
      "Epoch 4705/5000\n",
      "11864/11864 [==============================] - 8s 638us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1030 - val_accuracy: 0.5793\n",
      "Epoch 4706/5000\n",
      "11864/11864 [==============================] - 8s 633us/step - loss: 0.0980 - accuracy: 0.5999 - val_loss: 0.1028 - val_accuracy: 0.5811\n",
      "Epoch 4707/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0980 - accuracy: 0.6000 - val_loss: 0.1031 - val_accuracy: 0.5792\n",
      "Epoch 4708/5000\n",
      "11864/11864 [==============================] - 8s 633us/step - loss: 0.0980 - accuracy: 0.5999 - val_loss: 0.1027 - val_accuracy: 0.5808\n",
      "Epoch 4709/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1030 - val_accuracy: 0.5783\n",
      "Epoch 4710/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1027 - val_accuracy: 0.5803\n",
      "Epoch 4711/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0981 - accuracy: 0.5995 - val_loss: 0.1027 - val_accuracy: 0.5778\n",
      "Epoch 4712/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1023 - val_accuracy: 0.5814\n",
      "Epoch 4713/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0981 - accuracy: 0.5981 - val_loss: 0.1023 - val_accuracy: 0.5812\n",
      "Epoch 4714/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0981 - accuracy: 0.5984 - val_loss: 0.1026 - val_accuracy: 0.5798\n",
      "Epoch 4715/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1032 - val_accuracy: 0.5754\n",
      "Epoch 4716/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1024 - val_accuracy: 0.5791\n",
      "Epoch 4717/5000\n",
      "11864/11864 [==============================] - 7s 631us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1029 - val_accuracy: 0.5793\n",
      "Epoch 4718/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0981 - accuracy: 0.5994 - val_loss: 0.1024 - val_accuracy: 0.5811\n",
      "Epoch 4719/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1032 - val_accuracy: 0.5809\n",
      "Epoch 4720/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1031 - val_accuracy: 0.5790\n",
      "Epoch 4721/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1029 - val_accuracy: 0.5776\n",
      "Epoch 4722/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1030 - val_accuracy: 0.5772\n",
      "Epoch 4723/5000\n",
      "11864/11864 [==============================] - 8s 633us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1027 - val_accuracy: 0.5819\n",
      "Epoch 4724/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1021 - val_accuracy: 0.5817\n",
      "Epoch 4725/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1028 - val_accuracy: 0.5802\n",
      "Epoch 4726/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1028 - val_accuracy: 0.5809\n",
      "Epoch 4727/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1032 - val_accuracy: 0.5745\n",
      "Epoch 4728/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1031 - val_accuracy: 0.5790\n",
      "Epoch 4729/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0980 - accuracy: 0.6000 - val_loss: 0.1022 - val_accuracy: 0.5801\n",
      "Epoch 4730/5000\n",
      "11864/11864 [==============================] - 7s 631us/step - loss: 0.0978 - accuracy: 0.6006 - val_loss: 0.1032 - val_accuracy: 0.5771\n",
      "Epoch 4731/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0980 - accuracy: 0.6001 - val_loss: 0.1026 - val_accuracy: 0.5776\n",
      "Epoch 4732/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1029 - val_accuracy: 0.5816\n",
      "Epoch 4733/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1024 - val_accuracy: 0.5794\n",
      "Epoch 4734/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1028 - val_accuracy: 0.5781\n",
      "Epoch 4735/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1032 - val_accuracy: 0.5745\n",
      "Epoch 4736/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1027 - val_accuracy: 0.5799\n",
      "Epoch 4737/5000\n",
      "11864/11864 [==============================] - 8s 638us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1029 - val_accuracy: 0.5788\n",
      "Epoch 4738/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1021 - val_accuracy: 0.5817\n",
      "Epoch 4739/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0980 - accuracy: 0.5986 - val_loss: 0.1025 - val_accuracy: 0.5809\n",
      "Epoch 4740/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1023 - val_accuracy: 0.5804\n",
      "Epoch 4741/5000\n",
      "11864/11864 [==============================] - 7s 632us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1021 - val_accuracy: 0.5807\n",
      "Epoch 4742/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1028 - val_accuracy: 0.5798\n",
      "Epoch 4743/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1026 - val_accuracy: 0.5818\n",
      "Epoch 4744/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0980 - accuracy: 0.5999 - val_loss: 0.1033 - val_accuracy: 0.5792\n",
      "Epoch 4745/5000\n",
      "11864/11864 [==============================] - 8s 636us/step - loss: 0.0979 - accuracy: 0.5996 - val_loss: 0.1026 - val_accuracy: 0.5800\n",
      "Epoch 4746/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0979 - accuracy: 0.5998 - val_loss: 0.1027 - val_accuracy: 0.5802\n",
      "Epoch 4747/5000\n",
      "11864/11864 [==============================] - 7s 632us/step - loss: 0.0980 - accuracy: 0.6000 - val_loss: 0.1033 - val_accuracy: 0.5793\n",
      "Epoch 4748/5000\n",
      "11864/11864 [==============================] - 7s 632us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1026 - val_accuracy: 0.5805\n",
      "Epoch 4749/5000\n",
      "11864/11864 [==============================] - 8s 639us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1032 - val_accuracy: 0.5772\n",
      "Epoch 4750/5000\n",
      "11864/11864 [==============================] - 8s 634us/step - loss: 0.0981 - accuracy: 0.5994 - val_loss: 0.1027 - val_accuracy: 0.5787\n",
      "Epoch 4751/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1022 - val_accuracy: 0.5816\n",
      "Epoch 4752/5000\n",
      "11864/11864 [==============================] - 8s 632us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1031 - val_accuracy: 0.5802\n",
      "Epoch 4753/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1035 - val_accuracy: 0.5756\n",
      "Epoch 4754/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1019 - val_accuracy: 0.5809\n",
      "Epoch 4755/5000\n",
      "11864/11864 [==============================] - 7s 632us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1033 - val_accuracy: 0.5761\n",
      "Epoch 4756/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0980 - accuracy: 0.5987 - val_loss: 0.1031 - val_accuracy: 0.5773\n",
      "Epoch 4757/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1027 - val_accuracy: 0.5799\n",
      "Epoch 4758/5000\n",
      "11864/11864 [==============================] - 7s 632us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1022 - val_accuracy: 0.5795\n",
      "Epoch 4759/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1028 - val_accuracy: 0.5771\n",
      "Epoch 4760/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1028 - val_accuracy: 0.5787\n",
      "Epoch 4761/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1030 - val_accuracy: 0.5807\n",
      "Epoch 4762/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0980 - accuracy: 0.5982 - val_loss: 0.1028 - val_accuracy: 0.5806\n",
      "Epoch 4763/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0980 - accuracy: 0.6000 - val_loss: 0.1029 - val_accuracy: 0.5809\n",
      "Epoch 4764/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1031 - val_accuracy: 0.5786\n",
      "Epoch 4765/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1022 - val_accuracy: 0.5792\n",
      "Epoch 4766/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1033 - val_accuracy: 0.5786\n",
      "Epoch 4767/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1024 - val_accuracy: 0.5784\n",
      "Epoch 4768/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1029 - val_accuracy: 0.5795\n",
      "Epoch 4769/5000\n",
      "11864/11864 [==============================] - 7s 632us/step - loss: 0.0980 - accuracy: 0.5987 - val_loss: 0.1025 - val_accuracy: 0.5802\n",
      "Epoch 4770/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1022 - val_accuracy: 0.5811\n",
      "Epoch 4771/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1029 - val_accuracy: 0.5811\n",
      "Epoch 4772/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1029 - val_accuracy: 0.5804\n",
      "Epoch 4773/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0981 - accuracy: 0.5998 - val_loss: 0.1028 - val_accuracy: 0.5779\n",
      "Epoch 4774/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1024 - val_accuracy: 0.5818\n",
      "Epoch 4775/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1032 - val_accuracy: 0.5761\n",
      "Epoch 4776/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1025 - val_accuracy: 0.5792\n",
      "Epoch 4777/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1030 - val_accuracy: 0.5801\n",
      "Epoch 4778/5000\n",
      "11864/11864 [==============================] - 7s 629us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1026 - val_accuracy: 0.5797\n",
      "Epoch 4779/5000\n",
      "11864/11864 [==============================] - 7s 629us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1027 - val_accuracy: 0.5828\n",
      "Epoch 4780/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1024 - val_accuracy: 0.5798\n",
      "Epoch 4781/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0981 - accuracy: 0.5994 - val_loss: 0.1026 - val_accuracy: 0.5794\n",
      "Epoch 4782/5000\n",
      "11864/11864 [==============================] - 7s 629us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1022 - val_accuracy: 0.5788\n",
      "Epoch 4783/5000\n",
      "11864/11864 [==============================] - 8s 636us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1022 - val_accuracy: 0.5828\n",
      "Epoch 4784/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1033 - val_accuracy: 0.5766\n",
      "Epoch 4785/5000\n",
      "11864/11864 [==============================] - 8s 633us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1023 - val_accuracy: 0.5816\n",
      "Epoch 4786/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0980 - accuracy: 0.5987 - val_loss: 0.1021 - val_accuracy: 0.5827\n",
      "Epoch 4787/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0981 - accuracy: 0.5995 - val_loss: 0.1027 - val_accuracy: 0.5797\n",
      "Epoch 4788/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1027 - val_accuracy: 0.5810\n",
      "Epoch 4789/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1027 - val_accuracy: 0.5815\n",
      "Epoch 4790/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1023 - val_accuracy: 0.5804\n",
      "Epoch 4791/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1029 - val_accuracy: 0.5787\n",
      "Epoch 4792/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1031 - val_accuracy: 0.5800\n",
      "Epoch 4793/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0981 - accuracy: 0.5981 - val_loss: 0.1031 - val_accuracy: 0.5759\n",
      "Epoch 4794/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1032 - val_accuracy: 0.5765\n",
      "Epoch 4795/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1030 - val_accuracy: 0.5806\n",
      "Epoch 4796/5000\n",
      "11864/11864 [==============================] - 8s 633us/step - loss: 0.0979 - accuracy: 0.5988 - val_loss: 0.1025 - val_accuracy: 0.5806\n",
      "Epoch 4797/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1040 - val_accuracy: 0.5758\n",
      "Epoch 4798/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1022 - val_accuracy: 0.5815\n",
      "Epoch 4799/5000\n",
      "11864/11864 [==============================] - 8s 638us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1020 - val_accuracy: 0.5807\n",
      "Epoch 4800/5000\n",
      "11864/11864 [==============================] - 8s 638us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1037 - val_accuracy: 0.5789\n",
      "Epoch 4801/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1023 - val_accuracy: 0.5795\n",
      "Epoch 4802/5000\n",
      "11864/11864 [==============================] - 7s 631us/step - loss: 0.0980 - accuracy: 0.6000 - val_loss: 0.1022 - val_accuracy: 0.5805\n",
      "Epoch 4803/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1035 - val_accuracy: 0.5615\n",
      "Epoch 4804/5000\n",
      "11864/11864 [==============================] - 7s 632us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1029 - val_accuracy: 0.5797\n",
      "Epoch 4805/5000\n",
      "11864/11864 [==============================] - 7s 629us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1027 - val_accuracy: 0.5796\n",
      "Epoch 4806/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1025 - val_accuracy: 0.5787\n",
      "Epoch 4807/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0980 - accuracy: 0.6002 - val_loss: 0.1024 - val_accuracy: 0.5810\n",
      "Epoch 4808/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1027 - val_accuracy: 0.5771\n",
      "Epoch 4809/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1027 - val_accuracy: 0.5819\n",
      "Epoch 4810/5000\n",
      "11864/11864 [==============================] - 7s 629us/step - loss: 0.0979 - accuracy: 0.5993 - val_loss: 0.1028 - val_accuracy: 0.5802\n",
      "Epoch 4811/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0981 - accuracy: 0.5995 - val_loss: 0.1024 - val_accuracy: 0.5810\n",
      "Epoch 4812/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1030 - val_accuracy: 0.5794\n",
      "Epoch 4813/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1037 - val_accuracy: 0.5778\n",
      "Epoch 4814/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1030 - val_accuracy: 0.5783\n",
      "Epoch 4815/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0979 - accuracy: 0.5989 - val_loss: 0.1023 - val_accuracy: 0.5810\n",
      "Epoch 4816/5000\n",
      "11864/11864 [==============================] - 8s 632us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1029 - val_accuracy: 0.5790\n",
      "Epoch 4817/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1034 - val_accuracy: 0.5753\n",
      "Epoch 4818/5000\n",
      "11864/11864 [==============================] - 7s 629us/step - loss: 0.0981 - accuracy: 0.5994 - val_loss: 0.1035 - val_accuracy: 0.5786\n",
      "Epoch 4819/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1029 - val_accuracy: 0.5744\n",
      "Epoch 4820/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1024 - val_accuracy: 0.5805\n",
      "Epoch 4821/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1028 - val_accuracy: 0.5771\n",
      "Epoch 4822/5000\n",
      "11864/11864 [==============================] - 7s 629us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1023 - val_accuracy: 0.5808\n",
      "Epoch 4823/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0980 - accuracy: 0.6000 - val_loss: 0.1026 - val_accuracy: 0.5805\n",
      "Epoch 4824/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1028 - val_accuracy: 0.5795\n",
      "Epoch 4825/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1027 - val_accuracy: 0.5806\n",
      "Epoch 4826/5000\n",
      "11864/11864 [==============================] - 8s 633us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1027 - val_accuracy: 0.5807\n",
      "Epoch 4827/5000\n",
      "11864/11864 [==============================] - 7s 629us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1031 - val_accuracy: 0.5802\n",
      "Epoch 4828/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1026 - val_accuracy: 0.5796\n",
      "Epoch 4829/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0981 - accuracy: 0.5996 - val_loss: 0.1029 - val_accuracy: 0.5779\n",
      "Epoch 4830/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0979 - accuracy: 0.6001 - val_loss: 0.1028 - val_accuracy: 0.5788\n",
      "Epoch 4831/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0981 - accuracy: 0.5996 - val_loss: 0.1028 - val_accuracy: 0.5776\n",
      "Epoch 4832/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0980 - accuracy: 0.5999 - val_loss: 0.1025 - val_accuracy: 0.5794\n",
      "Epoch 4833/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0980 - accuracy: 0.5987 - val_loss: 0.1022 - val_accuracy: 0.5822\n",
      "Epoch 4834/5000\n",
      "11864/11864 [==============================] - 8s 635us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1028 - val_accuracy: 0.5757\n",
      "Epoch 4835/5000\n",
      "11864/11864 [==============================] - 8s 634us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1022 - val_accuracy: 0.5818\n",
      "Epoch 4836/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1021 - val_accuracy: 0.5792\n",
      "Epoch 4837/5000\n",
      "11864/11864 [==============================] - 8s 634us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1033 - val_accuracy: 0.5764\n",
      "Epoch 4838/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1021 - val_accuracy: 0.5814\n",
      "Epoch 4839/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1025 - val_accuracy: 0.5810\n",
      "Epoch 4840/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1029 - val_accuracy: 0.5803\n",
      "Epoch 4841/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1030 - val_accuracy: 0.5778\n",
      "Epoch 4842/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1024 - val_accuracy: 0.5802\n",
      "Epoch 4843/5000\n",
      "11864/11864 [==============================] - 8s 637us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1024 - val_accuracy: 0.5818\n",
      "Epoch 4844/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1028 - val_accuracy: 0.5804\n",
      "Epoch 4845/5000\n",
      "11864/11864 [==============================] - 7s 629us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1030 - val_accuracy: 0.5805\n",
      "Epoch 4846/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1027 - val_accuracy: 0.5777\n",
      "Epoch 4847/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1022 - val_accuracy: 0.5803\n",
      "Epoch 4848/5000\n",
      "11864/11864 [==============================] - 8s 633us/step - loss: 0.0981 - accuracy: 0.5994 - val_loss: 0.1025 - val_accuracy: 0.5779\n",
      "Epoch 4849/5000\n",
      "11864/11864 [==============================] - 8s 636us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1029 - val_accuracy: 0.5785\n",
      "Epoch 4850/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1030 - val_accuracy: 0.5784\n",
      "Epoch 4851/5000\n",
      "11864/11864 [==============================] - 7s 629us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1025 - val_accuracy: 0.5804\n",
      "Epoch 4852/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1023 - val_accuracy: 0.5807\n",
      "Epoch 4853/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1022 - val_accuracy: 0.5799\n",
      "Epoch 4854/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1031 - val_accuracy: 0.5778\n",
      "Epoch 4855/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1024 - val_accuracy: 0.5803\n",
      "Epoch 4856/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1033 - val_accuracy: 0.5737\n",
      "Epoch 4857/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1030 - val_accuracy: 0.5801\n",
      "Epoch 4858/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1035 - val_accuracy: 0.5773\n",
      "Epoch 4859/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0979 - accuracy: 0.5994 - val_loss: 0.1033 - val_accuracy: 0.5798\n",
      "Epoch 4860/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1025 - val_accuracy: 0.5818\n",
      "Epoch 4861/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1030 - val_accuracy: 0.5802\n",
      "Epoch 4862/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1022 - val_accuracy: 0.5808\n",
      "Epoch 4863/5000\n",
      "11864/11864 [==============================] - 7s 621us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1024 - val_accuracy: 0.5801\n",
      "Epoch 4864/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0981 - accuracy: 0.5995 - val_loss: 0.1028 - val_accuracy: 0.5798\n",
      "Epoch 4865/5000\n",
      "11864/11864 [==============================] - 8s 633us/step - loss: 0.0981 - accuracy: 0.5983 - val_loss: 0.1035 - val_accuracy: 0.5687\n",
      "Epoch 4866/5000\n",
      "11864/11864 [==============================] - 8s 636us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1023 - val_accuracy: 0.5792\n",
      "Epoch 4867/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1034 - val_accuracy: 0.5807\n",
      "Epoch 4868/5000\n",
      "11864/11864 [==============================] - 8s 633us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1024 - val_accuracy: 0.5816\n",
      "Epoch 4869/5000\n",
      "11864/11864 [==============================] - 8s 636us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1025 - val_accuracy: 0.5774\n",
      "Epoch 4870/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1028 - val_accuracy: 0.5801\n",
      "Epoch 4871/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1025 - val_accuracy: 0.5802\n",
      "Epoch 4872/5000\n",
      "11864/11864 [==============================] - 7s 631us/step - loss: 0.0979 - accuracy: 0.5995 - val_loss: 0.1040 - val_accuracy: 0.5662\n",
      "Epoch 4873/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1029 - val_accuracy: 0.5787\n",
      "Epoch 4874/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1031 - val_accuracy: 0.5780\n",
      "Epoch 4875/5000\n",
      "11864/11864 [==============================] - 7s 632us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1026 - val_accuracy: 0.5791\n",
      "Epoch 4876/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1025 - val_accuracy: 0.5807\n",
      "Epoch 4877/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1030 - val_accuracy: 0.5782\n",
      "Epoch 4878/5000\n",
      "11864/11864 [==============================] - 8s 633us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1025 - val_accuracy: 0.5790\n",
      "Epoch 4879/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0981 - accuracy: 0.5994 - val_loss: 0.1020 - val_accuracy: 0.5831\n",
      "Epoch 4880/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1021 - val_accuracy: 0.5812\n",
      "Epoch 4881/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1031 - val_accuracy: 0.5794\n",
      "Epoch 4882/5000\n",
      "11864/11864 [==============================] - 7s 631us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1030 - val_accuracy: 0.5779\n",
      "Epoch 4883/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1028 - val_accuracy: 0.5733\n",
      "Epoch 4884/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1024 - val_accuracy: 0.5794\n",
      "Epoch 4885/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0981 - accuracy: 0.5996 - val_loss: 0.1020 - val_accuracy: 0.5815\n",
      "Epoch 4886/5000\n",
      "11864/11864 [==============================] - 7s 629us/step - loss: 0.0982 - accuracy: 0.5987 - val_loss: 0.1024 - val_accuracy: 0.5808\n",
      "Epoch 4887/5000\n",
      "11864/11864 [==============================] - 7s 631us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1028 - val_accuracy: 0.5797\n",
      "Epoch 4888/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1027 - val_accuracy: 0.5789\n",
      "Epoch 4889/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1039 - val_accuracy: 0.5624\n",
      "Epoch 4890/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0980 - accuracy: 0.6007 - val_loss: 0.1035 - val_accuracy: 0.5806\n",
      "Epoch 4891/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1023 - val_accuracy: 0.5805\n",
      "Epoch 4892/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1029 - val_accuracy: 0.5791\n",
      "Epoch 4893/5000\n",
      "11864/11864 [==============================] - 8s 633us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1026 - val_accuracy: 0.5786\n",
      "Epoch 4894/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0981 - accuracy: 0.5984 - val_loss: 0.1025 - val_accuracy: 0.5798\n",
      "Epoch 4895/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0982 - accuracy: 0.5991 - val_loss: 0.1025 - val_accuracy: 0.5818\n",
      "Epoch 4896/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1025 - val_accuracy: 0.5806\n",
      "Epoch 4897/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0979 - accuracy: 0.5994 - val_loss: 0.1029 - val_accuracy: 0.5782\n",
      "Epoch 4898/5000\n",
      "11864/11864 [==============================] - 7s 631us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1024 - val_accuracy: 0.5802\n",
      "Epoch 4899/5000\n",
      "11864/11864 [==============================] - 8s 632us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1024 - val_accuracy: 0.5818\n",
      "Epoch 4900/5000\n",
      "11864/11864 [==============================] - 7s 632us/step - loss: 0.0982 - accuracy: 0.5989 - val_loss: 0.1034 - val_accuracy: 0.5772\n",
      "Epoch 4901/5000\n",
      "11864/11864 [==============================] - 8s 633us/step - loss: 0.0980 - accuracy: 0.5987 - val_loss: 0.1026 - val_accuracy: 0.5798\n",
      "Epoch 4902/5000\n",
      "11864/11864 [==============================] - 7s 632us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1025 - val_accuracy: 0.5799\n",
      "Epoch 4903/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0981 - accuracy: 0.5983 - val_loss: 0.1029 - val_accuracy: 0.5767\n",
      "Epoch 4904/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0980 - accuracy: 0.5982 - val_loss: 0.1027 - val_accuracy: 0.5798\n",
      "Epoch 4905/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0981 - accuracy: 0.5981 - val_loss: 0.1026 - val_accuracy: 0.5793\n",
      "Epoch 4906/5000\n",
      "11864/11864 [==============================] - 8s 633us/step - loss: 0.0981 - accuracy: 0.5994 - val_loss: 0.1024 - val_accuracy: 0.5799\n",
      "Epoch 4907/5000\n",
      "11864/11864 [==============================] - 8s 634us/step - loss: 0.0981 - accuracy: 0.5995 - val_loss: 0.1017 - val_accuracy: 0.5829\n",
      "Epoch 4908/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0981 - accuracy: 0.5983 - val_loss: 0.1025 - val_accuracy: 0.5792\n",
      "Epoch 4909/5000\n",
      "11864/11864 [==============================] - 7s 632us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1024 - val_accuracy: 0.5805\n",
      "Epoch 4910/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1026 - val_accuracy: 0.5800\n",
      "Epoch 4911/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0980 - accuracy: 0.5991 - val_loss: 0.1031 - val_accuracy: 0.5766\n",
      "Epoch 4912/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1021 - val_accuracy: 0.5816\n",
      "Epoch 4913/5000\n",
      "11864/11864 [==============================] - 8s 632us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1026 - val_accuracy: 0.5805\n",
      "Epoch 4914/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1026 - val_accuracy: 0.5795\n",
      "Epoch 4915/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1028 - val_accuracy: 0.5805\n",
      "Epoch 4916/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1025 - val_accuracy: 0.5808\n",
      "Epoch 4917/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0981 - accuracy: 0.5979 - val_loss: 0.1037 - val_accuracy: 0.5781\n",
      "Epoch 4918/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0980 - accuracy: 0.6001 - val_loss: 0.1029 - val_accuracy: 0.5775\n",
      "Epoch 4919/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0980 - accuracy: 0.5994 - val_loss: 0.1029 - val_accuracy: 0.5783\n",
      "Epoch 4920/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1028 - val_accuracy: 0.5791\n",
      "Epoch 4921/5000\n",
      "11864/11864 [==============================] - 8s 632us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1022 - val_accuracy: 0.5797\n",
      "Epoch 4922/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1027 - val_accuracy: 0.5793\n",
      "Epoch 4923/5000\n",
      "11864/11864 [==============================] - 8s 634us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1027 - val_accuracy: 0.5783\n",
      "Epoch 4924/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1024 - val_accuracy: 0.5827\n",
      "Epoch 4925/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0980 - accuracy: 0.5998 - val_loss: 0.1028 - val_accuracy: 0.5772\n",
      "Epoch 4926/5000\n",
      "11864/11864 [==============================] - 7s 629us/step - loss: 0.0981 - accuracy: 0.5995 - val_loss: 0.1024 - val_accuracy: 0.5816\n",
      "Epoch 4927/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0981 - accuracy: 0.5992 - val_loss: 0.1026 - val_accuracy: 0.5788\n",
      "Epoch 4928/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1025 - val_accuracy: 0.5824\n",
      "Epoch 4929/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0981 - accuracy: 0.5984 - val_loss: 0.1027 - val_accuracy: 0.5780\n",
      "Epoch 4930/5000\n",
      "11864/11864 [==============================] - 7s 615us/step - loss: 0.0981 - accuracy: 0.5994 - val_loss: 0.1032 - val_accuracy: 0.5769\n",
      "Epoch 4931/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1030 - val_accuracy: 0.5761\n",
      "Epoch 4932/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1034 - val_accuracy: 0.5807\n",
      "Epoch 4933/5000\n",
      "11864/11864 [==============================] - 7s 617us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1027 - val_accuracy: 0.5797\n",
      "Epoch 4934/5000\n",
      "11864/11864 [==============================] - 8s 633us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1025 - val_accuracy: 0.5792\n",
      "Epoch 4935/5000\n",
      "11864/11864 [==============================] - 7s 620us/step - loss: 0.0981 - accuracy: 0.5977 - val_loss: 0.1024 - val_accuracy: 0.5802\n",
      "Epoch 4936/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0980 - accuracy: 0.5985 - val_loss: 0.1027 - val_accuracy: 0.5785\n",
      "Epoch 4937/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0981 - accuracy: 0.5995 - val_loss: 0.1031 - val_accuracy: 0.5805\n",
      "Epoch 4938/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1028 - val_accuracy: 0.5816\n",
      "Epoch 4939/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1045 - val_accuracy: 0.5808\n",
      "Epoch 4940/5000\n",
      "11864/11864 [==============================] - 7s 631us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1028 - val_accuracy: 0.5805\n",
      "Epoch 4941/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1032 - val_accuracy: 0.5776\n",
      "Epoch 4942/5000\n",
      "11864/11864 [==============================] - 8s 635us/step - loss: 0.0980 - accuracy: 0.5983 - val_loss: 0.1022 - val_accuracy: 0.5804\n",
      "Epoch 4943/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0979 - accuracy: 0.5991 - val_loss: 0.1029 - val_accuracy: 0.5781\n",
      "Epoch 4944/5000\n",
      "11864/11864 [==============================] - 7s 632us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1027 - val_accuracy: 0.5752\n",
      "Epoch 4945/5000\n",
      "11864/11864 [==============================] - 8s 638us/step - loss: 0.0980 - accuracy: 0.5987 - val_loss: 0.1025 - val_accuracy: 0.5778\n",
      "Epoch 4946/5000\n",
      "11864/11864 [==============================] - 8s 633us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1024 - val_accuracy: 0.5805\n",
      "Epoch 4947/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1032 - val_accuracy: 0.5791\n",
      "Epoch 4948/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0981 - accuracy: 0.5991 - val_loss: 0.1032 - val_accuracy: 0.5767\n",
      "Epoch 4949/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0982 - accuracy: 0.5981 - val_loss: 0.1022 - val_accuracy: 0.5803\n",
      "Epoch 4950/5000\n",
      "11864/11864 [==============================] - 8s 639us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1025 - val_accuracy: 0.5803\n",
      "Epoch 4951/5000\n",
      "11864/11864 [==============================] - 8s 634us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1031 - val_accuracy: 0.5777\n",
      "Epoch 4952/5000\n",
      "11864/11864 [==============================] - 8s 633us/step - loss: 0.0981 - accuracy: 0.5982 - val_loss: 0.1031 - val_accuracy: 0.5643\n",
      "Epoch 4953/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0981 - accuracy: 0.5983 - val_loss: 0.1025 - val_accuracy: 0.5782\n",
      "Epoch 4954/5000\n",
      "11864/11864 [==============================] - 7s 619us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1026 - val_accuracy: 0.5796\n",
      "Epoch 4955/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0982 - accuracy: 0.5984 - val_loss: 0.1031 - val_accuracy: 0.5778\n",
      "Epoch 4956/5000\n",
      "11864/11864 [==============================] - 7s 632us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1027 - val_accuracy: 0.5823\n",
      "Epoch 4957/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0980 - accuracy: 0.5987 - val_loss: 0.1023 - val_accuracy: 0.5802\n",
      "Epoch 4958/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1038 - val_accuracy: 0.5786\n",
      "Epoch 4959/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1029 - val_accuracy: 0.5789\n",
      "Epoch 4960/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0981 - accuracy: 0.5983 - val_loss: 0.1026 - val_accuracy: 0.5805\n",
      "Epoch 4961/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1029 - val_accuracy: 0.5772\n",
      "Epoch 4962/5000\n",
      "11864/11864 [==============================] - 8s 634us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1033 - val_accuracy: 0.5770\n",
      "Epoch 4963/5000\n",
      "11864/11864 [==============================] - 7s 626us/step - loss: 0.0981 - accuracy: 0.5980 - val_loss: 0.1026 - val_accuracy: 0.5796\n",
      "Epoch 4964/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0981 - accuracy: 0.5995 - val_loss: 0.1028 - val_accuracy: 0.5815\n",
      "Epoch 4965/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0982 - accuracy: 0.5981 - val_loss: 0.1027 - val_accuracy: 0.5787\n",
      "Epoch 4966/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0982 - accuracy: 0.5986 - val_loss: 0.1019 - val_accuracy: 0.5801\n",
      "Epoch 4967/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0980 - accuracy: 0.5989 - val_loss: 0.1025 - val_accuracy: 0.5772\n",
      "Epoch 4968/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0981 - accuracy: 0.5982 - val_loss: 0.1031 - val_accuracy: 0.5778\n",
      "Epoch 4969/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1030 - val_accuracy: 0.5789\n",
      "Epoch 4970/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0982 - accuracy: 0.5985 - val_loss: 0.1032 - val_accuracy: 0.5780\n",
      "Epoch 4971/5000\n",
      "11864/11864 [==============================] - 7s 616us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1032 - val_accuracy: 0.5761\n",
      "Epoch 4972/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1025 - val_accuracy: 0.5802\n",
      "Epoch 4973/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0981 - accuracy: 0.5987 - val_loss: 0.1027 - val_accuracy: 0.5793\n",
      "Epoch 4974/5000\n",
      "11864/11864 [==============================] - 7s 625us/step - loss: 0.0981 - accuracy: 0.5988 - val_loss: 0.1024 - val_accuracy: 0.5807\n",
      "Epoch 4975/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0980 - accuracy: 0.6000 - val_loss: 0.1034 - val_accuracy: 0.5746\n",
      "Epoch 4976/5000\n",
      "11864/11864 [==============================] - 7s 631us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1026 - val_accuracy: 0.5810\n",
      "Epoch 4977/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0981 - accuracy: 0.5986 - val_loss: 0.1026 - val_accuracy: 0.5770\n",
      "Epoch 4978/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0981 - accuracy: 0.5989 - val_loss: 0.1043 - val_accuracy: 0.5765\n",
      "Epoch 4979/5000\n",
      "11864/11864 [==============================] - 8s 636us/step - loss: 0.0980 - accuracy: 0.5992 - val_loss: 0.1024 - val_accuracy: 0.5798\n",
      "Epoch 4980/5000\n",
      "11864/11864 [==============================] - 8s 634us/step - loss: 0.0980 - accuracy: 0.5995 - val_loss: 0.1026 - val_accuracy: 0.5819\n",
      "Epoch 4981/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0982 - accuracy: 0.5986 - val_loss: 0.1024 - val_accuracy: 0.5814\n",
      "Epoch 4982/5000\n",
      "11864/11864 [==============================] - 8s 637us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1029 - val_accuracy: 0.5786\n",
      "Epoch 4983/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1027 - val_accuracy: 0.5783\n",
      "Epoch 4984/5000\n",
      "11864/11864 [==============================] - 8s 636us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1050 - val_accuracy: 0.5746\n",
      "Epoch 4985/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0981 - accuracy: 0.5982 - val_loss: 0.1029 - val_accuracy: 0.5786\n",
      "Epoch 4986/5000\n",
      "11864/11864 [==============================] - 8s 632us/step - loss: 0.0980 - accuracy: 0.5993 - val_loss: 0.1029 - val_accuracy: 0.5799\n",
      "Epoch 4987/5000\n",
      "11864/11864 [==============================] - 7s 627us/step - loss: 0.0980 - accuracy: 0.5987 - val_loss: 0.1029 - val_accuracy: 0.5780\n",
      "Epoch 4988/5000\n",
      "11864/11864 [==============================] - 8s 634us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1027 - val_accuracy: 0.5816\n",
      "Epoch 4989/5000\n",
      "11864/11864 [==============================] - 7s 624us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1029 - val_accuracy: 0.5778\n",
      "Epoch 4990/5000\n",
      "11864/11864 [==============================] - 7s 622us/step - loss: 0.0979 - accuracy: 0.5997 - val_loss: 0.1025 - val_accuracy: 0.5816\n",
      "Epoch 4991/5000\n",
      "11864/11864 [==============================] - 7s 630us/step - loss: 0.0981 - accuracy: 0.5983 - val_loss: 0.1027 - val_accuracy: 0.5779\n",
      "Epoch 4992/5000\n",
      "11864/11864 [==============================] - 7s 628us/step - loss: 0.0981 - accuracy: 0.5990 - val_loss: 0.1033 - val_accuracy: 0.5783\n",
      "Epoch 4993/5000\n",
      "11864/11864 [==============================] - 8s 633us/step - loss: 0.0980 - accuracy: 0.5997 - val_loss: 0.1026 - val_accuracy: 0.5810\n",
      "Epoch 4994/5000\n",
      "11864/11864 [==============================] - 8s 638us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1026 - val_accuracy: 0.5787\n",
      "Epoch 4995/5000\n",
      "11864/11864 [==============================] - 8s 637us/step - loss: 0.0981 - accuracy: 0.5993 - val_loss: 0.1026 - val_accuracy: 0.5790\n",
      "Epoch 4996/5000\n",
      "11864/11864 [==============================] - 8s 639us/step - loss: 0.0981 - accuracy: 0.5994 - val_loss: 0.1024 - val_accuracy: 0.5813\n",
      "Epoch 4997/5000\n",
      "11864/11864 [==============================] - 8s 634us/step - loss: 0.0981 - accuracy: 0.5985 - val_loss: 0.1023 - val_accuracy: 0.5814\n",
      "Epoch 4998/5000\n",
      "11864/11864 [==============================] - 8s 637us/step - loss: 0.0980 - accuracy: 0.5996 - val_loss: 0.1028 - val_accuracy: 0.5815\n",
      "Epoch 4999/5000\n",
      "11864/11864 [==============================] - 7s 623us/step - loss: 0.0980 - accuracy: 0.5988 - val_loss: 0.1029 - val_accuracy: 0.5776\n",
      "Epoch 5000/5000\n",
      "11864/11864 [==============================] - 8s 638us/step - loss: 0.0980 - accuracy: 0.5990 - val_loss: 0.1031 - val_accuracy: 0.5789\n"
     ]
    }
   ],
   "source": [
    "history = (model.fit(X_train, y_train, epochs=5000, validation_data=(X_val, y_val), callbacks=[model_checkpoint_callback]))\n",
    "#history = (model.fit(X_train, y_train, epochs=5000, validation_data=(X_val, y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICT AND PLOT\n",
    "\n",
    "##### For 5000 epochs, from data saved in history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/csuser/DATA/ARTEMIS/mimic\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig('/media/csuser/DATA/ARTEMIS/mimic/figs/NN_ACCURACYvsEPOCHS.png', dpi=500)\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig('/media/csuser/DATA/ARTEMIS/mimic/figs/NN_LOSSvsEPOCHS.png', dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f5cb3f6d430>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model.load_weights('/media/csuser/DATA/ARTEMIS/models/mimic_smote')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118634, 6)\n",
      "3708/3708 [==============================] - 1s 314us/step\n",
      "(118634, 5)\n",
      "(118634, 5)\n",
      "[4 2 1 ... 4 0 4]\n",
      "[4 3 2 ... 4 0 4]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CONFUSION MATRIX\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, classification_report, recall_score, ConfusionMatrixDisplay\n",
    "from numpy import argmax\n",
    "\n",
    "print(X_test.shape)\n",
    "y_pred = model.predict(X_test)\n",
    "print(y_test.shape)\n",
    "print(y_pred.shape)\n",
    "y_test = argmax(a=y_test, axis=1)\n",
    "y_pred = argmax(a=y_pred, axis=1)\n",
    "print(y_test)\n",
    "print(y_pred)\n",
    "ConfusionMatrixDisplay.from_predictions(y_test+1, y_pred+1)\n",
    "plt.savefig('/media/csuser/DATA/ARTEMIS/mimic/figs/NN_confusion_mimic_smote.png', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 3, 2, ..., 4, 0, 4])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15189.  8191.  9712. 13360. 23369.] [ 8556. 15413. 14052. 10276.   516.] [ 3901. 10724. 19020. 12485.  2683.]\n",
      "[0.79565217 0.43304256 0.33802033 0.51692784 0.89701366] [0.63967151 0.34701745 0.40868541 0.56523947 0.97839648] [0.70918641 0.38528658 0.37000914 0.54000525 0.93593928] [0.63967151 0.34701745 0.40868541 0.56523947 0.97839648]\n"
     ]
    }
   ],
   "source": [
    "TP = np.zeros(5)\n",
    "FP = np.zeros(5)\n",
    "FN = np.zeros(5)\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(len(y_test)):\n",
    "        if y_test[j] == i and y_pred[j] == i:\n",
    "            TP[i] += 1\n",
    "        elif y_test[j] == i and y_pred[j] != i:\n",
    "            FN[i] += 1\n",
    "        elif y_test[j] != i and y_pred[j] == i:\n",
    "            FP[i] += 1\n",
    "print(TP, FN, FP)\n",
    "\n",
    "# Precision or positive predictive value\n",
    "PPV = TP/(TP+FP)\n",
    "\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "\n",
    "# F1\n",
    "F1 = 2 * (PPV * TPR) / (PPV + TPR)\n",
    "\n",
    "# Overall accuracy\n",
    "ACC = np.zeros(5)\n",
    "class_totals = np.zeros(5)\n",
    "for i in range(5):\n",
    "    for j in range(len(y_test)):\n",
    "        class_totals[y_test[j]] += 1\n",
    "        if y_test[j] == y_pred[j]:\n",
    "            ACC[y_test[j]] += 1\n",
    "ACC /= class_totals\n",
    "\n",
    "print(PPV, TPR, F1, ACC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc:  0.588541227641317\n",
      "Prec:  0.5967116529914185\n",
      "Recall:  0.588541227641317\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_test, y_pred)\n",
    "print('Acc: ', acc)\n",
    "\n",
    "prec = precision_score(y_test, y_pred, average='weighted')\n",
    "print('Prec: ', prec)\n",
    "\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# def metrics(y_test, y_pred):\n",
    "#     model_metrics = {}\n",
    "#     max_indices = np.argmax(y_test, axis=1)\n",
    "#     y_test = max_indices + 1\n",
    "    \n",
    "#     max_indices = np.argmax(y_pred, axis=1)\n",
    "#     y_pred = max_indices + 1\n",
    "\n",
    "#     lab = [1, 2, 3, 4,5]\n",
    "    \n",
    "#     for j in lab:\n",
    "#         TP, FP, FN, TN = 0, 0, 0, 0\n",
    "        \n",
    "#         for i in range(len(y_test)):\n",
    "#             if y_test[i] == j and y_pred[i] == j:\n",
    "#                 TP += 1\n",
    "#             elif y_test[i] == j and y_pred[i] != j:\n",
    "#                 FN += 1\n",
    "#             elif y_test[i] != j and y_pred[i] != j:\n",
    "#                 TN += 1\n",
    "#             else:\n",
    "#                 FP += 1\n",
    "        \n",
    "#         # Check if TP + FP or TP + FN is zero before calculating precision and recall\n",
    "#         if TP + FP == 0:\n",
    "#             precision = 0  # Avoid division by zero\n",
    "#         else:\n",
    "#             precision = TP / (TP + FP)\n",
    "        \n",
    "#         if TP + FN == 0:\n",
    "#             recall = 0  # Avoid division by zero\n",
    "#         else:\n",
    "#             recall = TP / (TP + FN)\n",
    "        \n",
    "#         if precision + recall == 0:\n",
    "#             f1_score = 0  # Avoid division by zero\n",
    "#         else:\n",
    "#             f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "        \n",
    "#         model_metrics[j] = {\"TP\": TP, \"TN\": TN, \"FP\": FP, \"FN\": FN, \"precision\": precision, \"recall\": recall, \"f1_score\": f1_score}\n",
    "\n",
    "#     return model_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "y_pred = model.predict(X_test)\n",
    "decision_model_metrics = metrics(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_model_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "RocCurveDisplay.from_predictions(\n",
    "    y_test.ravel(),\n",
    "    y_pred.ravel(),\n",
    "    name=\"micro-average OvR\",\n",
    "    color=\"darkorange\",\n",
    "    # plot_chance_level=True,\n",
    ")\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "# plt.title(\"Micro-averaged One-vs-Rest\\nReceiver Operating Characteristic\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "label_binarizer = LabelBinarizer().fit(y_train)\n",
    "y_onehot_test = label_binarizer.transform(y_test)\n",
    "y_onehot_test.shape  # (n_samples, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_onehot_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_binarizer.transform([2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_of_interest = 2\n",
    "class_id = np.flatnonzero(label_binarizer.classes_ == class_of_interest)[0]\n",
    "class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "RocCurveDisplay.from_predictions(\n",
    "    y_onehot_test[:, class_id],\n",
    "    y_pred[:, class_id],\n",
    "    name=f\"{class_of_interest} vs the rest\",\n",
    "    color=\"darkorange\",\n",
    "    # plot_chance_level=True,\n",
    ")\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"One-vs-Rest ROC curves:\\nVirginica vs (Setosa & Versicolor)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "class_id = 2\n",
    "RocCurveDisplay.from_predictions(\n",
    "    y_onehot_test[:, class_id],\n",
    "    y_pred[:, class_id],\n",
    "    name=f\"{class_of_interest} vs the rest\",\n",
    "    color=\"darkorange\",\n",
    "    \n",
    ")\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"One-vs-Rest ROC curves:\\nVirginica vs (Setosa & Versicolor)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "class_id = 3\n",
    "RocCurveDisplay.from_predictions(\n",
    "    y_onehot_test[:, class_id],\n",
    "    y_pred[:, class_id],\n",
    "    name=f\"{class_of_interest} vs the rest\",\n",
    "    color=\"darkorange\",\n",
    "    \n",
    ")\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"One-vs-Rest ROC curves:\\nVirginica vs (Setosa & Versicolor)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "class_id = 4\n",
    "RocCurveDisplay.from_predictions(\n",
    "    y_onehot_test[:, class_id],\n",
    "    y_pred[:, class_id],\n",
    "    name=f\"{class_of_interest} vs the rest\",\n",
    "    color=\"darkorange\",\n",
    "    \n",
    ")\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"One-vs-Rest ROC curves:\\nVirginica vs (Setosa & Versicolor)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "class_id = 0\n",
    "RocCurveDisplay.from_predictions(\n",
    "    y_onehot_test[:, class_id],\n",
    "    y_pred[:, class_id],\n",
    "    name=f\"{class_of_interest} vs the rest\",\n",
    "    color=\"darkorange\",\n",
    "    \n",
    ")\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"One-vs-Rest ROC curves:\\nVirginica vs (Setosa & Versicolor)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "\n",
    "classes = ['Class 1', 'Class 2', 'Class 3', 'Class 4', 'Class 5']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))  # Create a 2x3 grid of subplots\n",
    "axes[1][2].set_visible(False)\n",
    "\n",
    "for i, class_id in enumerate(range(5)):  # Assuming class IDs start from 0\n",
    "    ax = axes[i//3, i%3]  # Calculate the subplot position\n",
    "\n",
    "    RocCurveDisplay.from_predictions(\n",
    "        y_onehot_test[:, class_id],\n",
    "        y_pred[:, class_id],\n",
    "        name=f\"{classes[class_id]} vs the rest\",\n",
    "        color=\"darkorange\",\n",
    "        ax=ax  # Assign the subplot to the current axis\n",
    "    )\n",
    "\n",
    "\n",
    "    ax.axis(\"square\")\n",
    "    ax.set_xlabel(\"False Positive Rate\")\n",
    "    ax.set_ylabel(\"True Positive Rate\")\n",
    "    ax.set_title(f\"One-vs-Rest ROC curves:\\n{classes[class_id]} vs the rest\")\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_models, histories = [], []\n",
    "n_models, epochs = 50, 5\n",
    "k_fold = KFold(n_models)\n",
    "precision_list =[]\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, random_state=42, train_size= .80)\n",
    "print(X_train.shape)\n",
    "\n",
    "for train_indices, test_indices in k_fold.split(X_train):\n",
    "    \n",
    "\n",
    "    x1_train, y1_train = X_train[train_indices], y_train[train_indices]\n",
    "    x_val, y_val = X_train[test_indices], y_train[test_indices]\n",
    "\n",
    "    model = make_model(input_shape=(3), num_classes=y[0].shape[0])\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(1e-3),\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    histories.append(model.fit(x1_train, \n",
    "                               y1_train, epochs=epochs, \n",
    "                               validation_data = (x_val, y_val)))\n",
    "    \n",
    "    y_pred = model.predict(x_val)\n",
    "\n",
    "    max_indices = np.argmax(y_val, axis=1)\n",
    "    y_val = max_indices + 1\n",
    "    \n",
    "    max_indices = np.argmax(y_pred, axis=1)\n",
    "    y_pred = max_indices + 1\n",
    "\n",
    "    precision = precision_score(y_val, y_pred, average=\"weighted\")\n",
    "    precision_list.append(precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_list_tree = [0.8972521324493244,\n",
    " 0.9050329118957142,\n",
    " 0.9172165785303346,\n",
    " 0.9175694235195049,\n",
    " 0.9139132652340948,\n",
    " 0.9096529140079395,\n",
    " 0.9078916812978447,\n",
    " 0.9153345053308668,\n",
    " 0.9118285116259086,\n",
    " 0.9133121102389169,\n",
    " 0.91744960217773,\n",
    " 0.9138128592901759,\n",
    " 0.9044372628516312,\n",
    " 0.9140189283935687,\n",
    " 0.9094207999093339,\n",
    " 0.906279433297611,\n",
    " 0.9063441393735263,\n",
    " 0.9053194111756259,\n",
    " 0.9091978425159323,\n",
    " 0.9098494096774302,\n",
    " 0.9097243747747501,\n",
    " 0.9099392260190308,\n",
    " 0.9154556745915264,\n",
    " 0.9138648099118555,\n",
    " 0.911321089947818,\n",
    " 0.915020827018602,\n",
    " 0.9136860444519458,\n",
    " 0.9112126939278078,\n",
    " 0.9111347167929121,\n",
    " 0.923757248001491,\n",
    " 0.9098571647375098,\n",
    " 0.911523865134343,\n",
    " 0.9157113959446195,\n",
    " 0.9090935771592038,\n",
    " 0.908241820015837,\n",
    " 0.9075461264489019,\n",
    " 0.9178407627325489,\n",
    " 0.9095257235955037,\n",
    " 0.9106117861661375,\n",
    " 0.9095200584734341,\n",
    " 0.903466873778968,\n",
    " 0.9138346720559205,\n",
    " 0.9124146422885498,\n",
    " 0.8983497657654559,\n",
    " 0.9153151750439699,\n",
    " 0.9115851522533573,\n",
    " 0.9124306328513269,\n",
    " 0.9027732209987848,\n",
    " 0.9056067200706398,\n",
    " 0.9094318386348679]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "# conduct the Wilcoxon-Signed Rank Test\n",
    "stats.wilcoxon(precision_list, precision_list_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(len(precision_list)):\n",
    "    if precision_list[i] > precision_list_tree[i]:\n",
    "        count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
